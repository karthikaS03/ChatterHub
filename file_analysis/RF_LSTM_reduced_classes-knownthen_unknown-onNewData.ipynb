{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%run \"./utils.ipynb\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "loadFromMerged=True\n",
    "loadFromIndexes= False\n",
    "Mapper='S'\n",
    "IgnoreEmpty= True\n",
    "FoldID =\"1\"\n",
    "Epoch_count=100\n",
    "Batch_size=5000\n",
    "INCLUDE_DIRECTION = True\n",
    "\n",
    "LOAD_OLD_DATA_TRAIN = False\n",
    "LOAD_OLD_DATA_TEST = False\n",
    "MERGE_TESTS=True\n",
    "\n",
    "TEST_CLASS_CAP =999999\n",
    "\n",
    "pre_Process_remove_empties = True\n",
    "\n",
    "\n",
    "# per Karthika's change\n",
    "SKIP_LOCK_FILE = True\n",
    "\n",
    "# \n",
    "LOAD_HOMES_ONLY = True\n",
    "\n",
    "test_file_names = [\"home_sk_final.json\"] \n",
    "train_file_names = [\"home_os_final.json\"]\n",
    "\n",
    "train_x_path = '../files/iot_data_2020/train/pcap_segments/'\n",
    "train_y_path = '../files/iot_data_2020/train/hub_segments/'\n",
    "\n",
    "test_y_path = '../files/iot_data_2020/usecases/hub_segments_final/'\n",
    "test_x_path = '../files/iot_data_2020/usecases/pcap_segments_final/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in load from merged\n",
      "18308 13614\n",
      "ignoring file : home_sk_final.json\n",
      "ignoring file : test_data_light.json\n",
      "ignoring file : test_data_lock.json\n",
      "ignoring file : test_data_motion_2.json\n",
      "loading from test files\n",
      "found files :  4\n",
      "ignoring file : home_os_final.json\n",
      "../files/iot_data_2020/usecases/pcap_segments_final/home_sk_final.json\n",
      "5837 5837\n",
      "ignoring file : test_data_light.json\n",
      "ignoring file : test_data_motion_2.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(13614, 1)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x= []\n",
    "y= []\n",
    "\n",
    "x_test = []\n",
    "y_test = []\n",
    "y_test_service= []\n",
    "\n",
    "x_train = []\n",
    "y_train = []\n",
    "y_train_service = []\n",
    "\n",
    "test_names = []\n",
    "\n",
    "add_to_trainig = [0,2]\n",
    "\n",
    "if loadFromMerged:\n",
    "    print(\"in load from merged\")\n",
    "    if LOAD_OLD_DATA_TRAIN:\n",
    "        with open(  '../files/train/test/test_homes/final_upload/Merged_final_with_home/merged_hub_segments_final.json'  ) as f:\n",
    "            y_data = json.load(f)\n",
    "\n",
    "        with open(  '../files/train/test/test_homes/final_upload/Merged_final_with_home/merged_pcap_segments_final.json'  ) as f:\n",
    "            x_data = json.load(f)\n",
    "\n",
    "    #     with open(  '../files/train/merged/hub_segments_2.json'  ) as f:\n",
    "    #         y_data = json.load(f)\n",
    "\n",
    "    #     with open(  '../files/train/merged/pcap_segments_2.json'  ) as f:\n",
    "    #         x_data = json.load(f)\n",
    "\n",
    "        if len( y_data ) != len(x_data) :\n",
    "            print( pick )\n",
    "\n",
    "\n",
    "        x_train,y_train, y_train_service= clean_data( x_data, y_data, IgnoreEmpty , \n",
    "                                                     Mapping=Mapper, include_direction=INCLUDE_DIRECTION )\n",
    "    else:\n",
    "        the_dir = test_x_path if LOAD_HOMES_ONLY else train_x_path\n",
    "        the_dir = os.path.join(the_dir, '*.json')\n",
    "        for pick in sorted(glob.glob( the_dir )):\n",
    "            fname  = os.path.basename(pick)\n",
    "            if len(train_file_names) > 0 and fname not in train_file_names:\n",
    "                print(\"ignoring file : %s\" % fname)\n",
    "                continue\n",
    "#             test_names.append( fname )\n",
    "            with open( os.path.join(test_y_path if LOAD_HOMES_ONLY else train_y_path, fname) ) as f:\n",
    "                y_data = json.load(f)\n",
    "\n",
    "            with open( os.path.join(test_x_path if LOAD_HOMES_ONLY else train_x_path, fname) ) as f:\n",
    "                x_data = json.load(f)\n",
    "\n",
    "            if len( y_data ) != len(x_data) :\n",
    "                print( pick )\n",
    "                continue\n",
    "\n",
    "            x_t,y_t, y_t_s= clean_data( x_data, y_data, IgnoreEmpty , \n",
    "                                                     Mapping=Mapper, include_direction=INCLUDE_DIRECTION )\n",
    "    \n",
    "            x_train.extend(x_t)\n",
    "            y_train.extend(y_t)\n",
    "            y_train_service.extend(y_t_s)\n",
    "            \n",
    "\n",
    "    #     continue\n",
    "#     if loadFromIndexes:\n",
    "#         print(\"load from indexes\")\n",
    "#         with open(\"../files/train/merged/items_2_test-train_indexes.json\")  as f:\n",
    "#             index_info = json.load(f)\n",
    "\n",
    "\n",
    "#         for i in index_info[FoldID][\"test\"]:\n",
    "#             x_test[str(i)]=(x_data[str(i)] )\n",
    "#             y_test[str(i)]=(y_data[str(i)] )\n",
    "\n",
    "#         for i in index_info[FoldID][\"train\"]:\n",
    "#             x_train[str(i)]=(  x_data[str(i)] )\n",
    "#             y_train[str(i)]=(  y_data[str(i)] )\n",
    "        \n",
    "#         x_test_t,y_test_t= clean_data( x_test, y_test, IgnoreEmpty , Mapping=Mapper)\n",
    "#         x_test.append(x_test_t)\n",
    "#         y_test.append(y_test_t)\n",
    "    #     else :\n",
    "    print(\"loading from test files\")\n",
    "    files_path = '../files/train/test/test_homes/final_upload/usecases/pcap_segments_final_final/home*.json' if LOAD_OLD_DATA_TEST else '../files/iot_data_2020/usecases/pcap_segments_final/*.json'\n",
    "    test_y_dir = '../files/train/test/test_homes/final_upload/usecases/hub_segments_final_final/'  if LOAD_OLD_DATA_TEST else '../files/iot_data_2020/usecases/hub_segments_final/'\n",
    "    test_x_dir = '../files/train/test/test_homes/final_upload/usecases/pcap_segments_final_final/' if LOAD_OLD_DATA_TEST else '../files/iot_data_2020/usecases/pcap_segments_final/'\n",
    "    \n",
    "    test_files = [ x for x in sorted(glob.glob(files_path)) if not SKIP_LOCK_FILE or ( SKIP_LOCK_FILE and  'lock' not in x )]\n",
    "    print( \"found files : \" , len(test_files) )\n",
    "    \n",
    "    \n",
    "    for pick  in test_files:\n",
    "        fname  = os.path.basename(pick)\n",
    "        if len(test_file_names) > 0 and fname not in test_file_names:\n",
    "            print(\"ignoring file : %s\" % fname)\n",
    "            continue\n",
    "        test_names.append( fname )\n",
    "        print(pick)\n",
    "        with open( os.path.join(test_y_dir , fname) ) as f:\n",
    "            y_data_test = json.load(f)\n",
    "\n",
    "        with open( os.path.join(test_x_dir, fname) ) as f:\n",
    "            x_data_test = json.load(f)\n",
    "\n",
    "\n",
    "        t_x,t_y, t_z= clean_data( x_data_test, y_data_test, False , Mapping=Mapper, include_direction= INCLUDE_DIRECTION )\n",
    "\n",
    "#         if test_files.index(pick) in add_to_trainig:\n",
    "#             x_test_t,y_test_t, y_test_service_t= clean_data( x_data_test, y_data_test, IgnoreEmpty , Mapping=Mapper)\n",
    "#             x_train.extend(x_test_t)\n",
    "#             y_train.extend(y_test_t)\n",
    "#             y_train_service.extend(y_test_service_t)\n",
    "\n",
    "                \n",
    "        if MERGE_TESTS:\n",
    "            x_test.extend(t_x)\n",
    "            y_test.extend(t_y)\n",
    "            y_test_service.extend(t_z)\n",
    "        else:\n",
    "            x_test.append(t_x)\n",
    "            y_test.append(t_y)\n",
    "            y_test_service.append(t_z)\n",
    "if MERGE_TESTS:\n",
    "    x_test = [x_test]\n",
    "    y_test = [y_test]\n",
    "    y_test_service = [y_test_service]\n",
    "    test_names =['MERGED']\n",
    "#     x_test = x_data[ index_info[\"1\"][\"test\"]  ]\n",
    "#     y_test = y_data[ index_info[\"1\"][\"test\"]  ]\n",
    "    \n",
    "#     x_train = x_data[ index_info[\"1\"][\"train\"]  ]\n",
    "#     y_train = y_data[ index_info[\"1\"][\"train\"]  ]\n",
    "#     x.extend(t_x)\n",
    "#     y.extend(t_y)\n",
    "# else:\n",
    "#     for pick in sorted(glob.glob( '../files/train/hub_segments/*.json' )):\n",
    "#         fname  = os.path.basename(pick)\n",
    "#         test_names.append( fname )\n",
    "#         with open( os.path.join( '../files/train/hub_segments/', fname) ) as f:\n",
    "#             y_data = json.load(f)\n",
    "\n",
    "#         with open( os.path.join('../files/train/pcap_segments/', fname) ) as f:\n",
    "#             x_data = json.load(f)\n",
    "\n",
    "#         if len( y_data ) != len(x_data) :\n",
    "#             print( pick )\n",
    "#             continue\n",
    "\n",
    "#         t_x,t_y= clean_data( x_data, y_data, True, include_direction=INCLUDE_DIRECTION )\n",
    "\n",
    "#         x.extend( t_x)\n",
    "#         y.extend(t_y)\n",
    "\n",
    "x= np.array(x)\n",
    "y= np.array(y)\n",
    "\n",
    "# x_train = np.append( x_train, x_test[0] , axis=0)\n",
    "# x_train = np.append( x_train, x_test[2] , axis=0)\n",
    "\n",
    "# y_train = np.append( y_train, y_test[0] , axis=0)\n",
    "# y_train = np.append( y_train, y_test[2] , axis=0)\n",
    "\n",
    "\n",
    "len(x_train), len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sets the classes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 'acceleration'),\n",
       " (1, 'activity'),\n",
       " (2, 'battery'),\n",
       " (3, 'button'),\n",
       " (4, 'colorTemperature'),\n",
       " (5, 'contact'),\n",
       " (6, 'level'),\n",
       " (7, 'lock'),\n",
       " (8, 'motion'),\n",
       " (9, 'ping'),\n",
       " (10, 'status'),\n",
       " (11, 'switch'),\n",
       " (12, 'temperature'),\n",
       " (13, 'threeAxis'),\n",
       " (14, 'unknown')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = sorted(list(np.unique(  np.concatenate( y_train  ))))\n",
    "# print([ (i , classes[i]) for i in range( len(classes) ) ])\n",
    "\n",
    "service_classes = sorted(list(np.unique(  np.concatenate( y_train_service  ))))\n",
    "[ (i , service_classes[i]) for i in range( len(service_classes) ) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['acceleration',\n",
       " 'activity',\n",
       " 'battery',\n",
       " 'button',\n",
       " 'colorTemperature',\n",
       " 'contact',\n",
       " 'level',\n",
       " 'lock',\n",
       " 'motion',\n",
       " 'ping',\n",
       " 'status',\n",
       " 'switch',\n",
       " 'temperature',\n",
       " 'threeAxis',\n",
       " 'unknown']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter the records by service/event types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "choose services to keep : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if Mapper=='SE':\n",
    "    services_to_keep = ['button-held',\n",
    " 'button-pushed',\n",
    "        \"colorTemperature-XXX\",\n",
    "\"contact-closed\",\n",
    "\"contact-open\",\n",
    "\"level-XXX\",\n",
    "\"lock-locked\",\n",
    "\"lock-unlocked\",\n",
    "\"motion-active\",\n",
    "\"motion-inactive\",\n",
    "\"ping-ping\",\n",
    "\"status-closed\",\n",
    "\"status-open\",\n",
    "\"switch-off\",\n",
    "\"switch-on\",\n",
    "\"temperature-XXX\"\n",
    "    ] \n",
    "else:\n",
    "     services_to_keep =[\"button\",\n",
    "\"colorTemperature\",\n",
    "\"contact\",\n",
    "\"level\",\n",
    "\"lock\",\n",
    "\"motion\",\n",
    "\"ping\",\n",
    "\"status\",\n",
    "\"switch\",\n",
    "\"temperature\"]\n",
    "\n",
    "# keep all ? \n",
    "# services_to_keep= classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "find records which need change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_indexes_to_change =  [ i for i in range(len(y_train)) if\n",
    "              is_clean( y_train[i],to_keep=services_to_keep, return_clean=False) ] \n",
    "\n",
    "y_train = [ ['unknown'] if i in train_indexes_to_change else y_train[i] \n",
    "           for i in range(len(y_train)) ] \n",
    "\n",
    "for t_index in range(len(y_test)):\n",
    "    test_indexes_to_change =  [ i for i in range(len(y_test[t_index])) if\n",
    "                  is_clean( y_test[t_index][i],to_keep=services_to_keep, return_clean=False) ] \n",
    "\n",
    "    y_test[t_index] = [ ['unknown'] if i in test_indexes_to_change else y_test[t_index][i] \n",
    "               for i in range(len(y_test[t_index])) ] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_known_unknown(inp, unknown_ind):\n",
    "    return [ [1,0] if (x[unknown_ind] == 1 ) else [0,1]   for x in inp ]\n",
    "\n",
    "known_unknown_y_train = [ [1,0] if (len(x) == 1 and (\"unknown\" in x or 'unknown-' in x)) else [0,1]   for x in y_train ]\n",
    "\n",
    "known_unknown_y_test= [] \n",
    "\n",
    "for i in range(len(y_test)):\n",
    "    \n",
    "    known_unknown_y_test.append( [ [1,0] if (len(x) == 1 and \"unknown\" in x) else [0,1]   for x in y_test[i] ])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "remove classes that are ignored from the services list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['button',\n",
       " 'colorTemperature',\n",
       " 'contact',\n",
       " 'level',\n",
       " 'lock',\n",
       " 'motion',\n",
       " 'ping',\n",
       " 'status',\n",
       " 'switch',\n",
       " 'temperature',\n",
       " 'unknown']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = services_to_keep\n",
    "classes.append('unknown')\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x,y,_=pre_process_raw( x_train, y_train , 15, zero_pad=True, normalize=True, classes=classes, remove_empty=pre_Process_remove_empties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,_,temp = pre_process_raw( x_test[0], y_test[0] , 13, zero_pad=False, normalize=False, classes=classes, as_string=True, class_cap=TEST_CLASS_CAP,remove_empty=True)\n",
    "indexes_to_keep = temp[1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get the data and preprocess train and test portions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_size= 20\n",
    "x_random_forest_train,y_random_forest_train, _ = pre_process_raw( x_train, y_train , dim_size, zero_pad=False, normalize=False, classes=classes, as_string=True,remove_empty=pre_Process_remove_empties)\n",
    "rf_test = [] \n",
    "\n",
    "rf_tests  = [ pre_process_raw( x_test[i], y_test[i] , dim_size, zero_pad=False, normalize=False, classes=classes, as_string=True, class_cap=TEST_CLASS_CAP,remove_empty=pre_Process_remove_empties) for i in range(len(x_test)) ] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5837 5837\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(rf_tests)):\n",
    "    print(len(rf_tests[i][1]), len(y_test[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[0][3049][0]==classes[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['ping', 'unknown'], dtype='<U7'),\n",
       " ['button',\n",
       "  'colorTemperature',\n",
       "  'contact',\n",
       "  'level',\n",
       "  'lock',\n",
       "  'motion',\n",
       "  'ping',\n",
       "  'status',\n",
       "  'switch',\n",
       "  'temperature',\n",
       "  'unknown'],\n",
       " array([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " y_test[0][3049], classes, rf_tests[0][1][3049]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5837, 5837, 5837)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rf_tests[0][0]), len(x_test[0]), len(y_test[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "vectorize the X vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(analyzer='word', ngram_range=(1, 5))\n",
    "x_xgb_train = vectorizer.fit_transform(x_random_forest_train)\n",
    "xgb_test = []\n",
    "for x in range(len(rf_tests)):\n",
    "    xgb_test.append( ( vectorizer.transform(rf_tests[x][0]),\n",
    "                    rf_tests[x][1],\n",
    "                    rf_tests[x][2]\n",
    "                  ))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "xgb_known_unknown_separator_classifier = OneVsRestClassifier(XGBClassifier())\n",
    "\n",
    "xgb_known_unknown_separator_classifier.fit(x_xgb_train, np.array(known_unknown_y_train))\n",
    "\n",
    "train_known_unknown_pred=xgb_known_unknown_separator_classifier.predict_proba(x_xgb_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================HOME Case : MERGED =============\n",
      "                         Class  Accuracy     Recall  Precision   F Score    Count            TP/TN/FP/FN\n",
      "------------------------------------------------------------------------\n",
      "                       unknown     0.926      0.938     0.920     0.929      2997  2811/ 2594/  246/  186\n",
      "                         known     0.926      0.913     0.933     0.923      2840  2594/ 2811/  186/  246\n",
      "------------------------------------------------------------------------\n",
      "                      AVERAGES     0.926      0.926     0.926     0.926      5837     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "             Weighted AVERAGES     0.926      0.926     0.926     0.926      5837     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "       known Weighted AVERAGES     0.926      0.913     0.933     0.923      5837     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------\n",
      "       non zero count AVERAGES     0.926      0.926     0.926     0.926      5837     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "                sample average     0.926      0.926     0.926     0.926      5837     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "       sensative micro average     0.500      0.500     0.500     0.500      5837     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "           known micro average     0.926      0.913     0.933     0.923      5837     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "                 micro average     0.926      0.926     0.926     0.926      5837     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "Macro F1 : 0.925887\n",
      "Micro F1 : 0.925989\n",
      "sample F1 : 0.925989\n",
      "weighted F1 : 0.925961\n",
      "--------------------------removed unknown----------------------------------------------\n",
      "Macro F1 : 0.482694\n",
      "Micro F1 : 0.933094\n",
      "sample F1 : 0.933094\n",
      "weighted F1 : 0.900798\n",
      "Exact Match ACC : 0.92599 \n",
      "Total Records : 5837 \n",
      "Total ZXeros in True : 0 (0.000)%\n",
      "Total ZXeros in Test : 0 (0.000)%\n",
      "=============================================================================\n"
     ]
    }
   ],
   "source": [
    "test_known_unknown_predicted = []\n",
    "for i in range(len(xgb_test)) :\n",
    "    print( \"==================HOME Case : %s =============\" % test_names[ i] )\n",
    "    xgb_pred=xgb_known_unknown_separator_classifier.predict( xgb_test[i][0])\n",
    "    test_known_unknown_predicted.append(xgb_pred)\n",
    "    print_info( np.array( make_known_unknown(xgb_test[i][1], classes.index('unknown'))), xgb_pred, [\"unknown\",\"known\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5837, 3, (5837, 11))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_known_unknown_predicted[0]), len(xgb_test[0]), (xgb_test[0][1]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "known_indexes_train  = [ i for i in range(len(train_known_unknown_pred)) if train_known_unknown_pred[i][1] ==1 ]\n",
    "\n",
    "x_train_known = x_xgb_train[known_indexes_train]\n",
    "y_train_known = y_random_forest_train[known_indexes_train]\n",
    "\n",
    "xgb_test_known = [] \n",
    "\n",
    "for test_index in range(len(test_known_unknown_predicted)):\n",
    "    known_indexes= [ i for i in range(len(test_known_unknown_predicted[test_index])) if test_known_unknown_predicted[test_index][i][1] ==1 ]\n",
    "    \n",
    "    xgb_test_known.append(  (xgb_test[test_index][0][known_indexes], \n",
    "                            xgb_test[test_index][1][known_indexes],\n",
    "                            xgb_test[test_index][2],\n",
    "                            known_indexes\n",
    "                           ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneVsRestClassifier(estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                            colsample_bylevel=None,\n",
       "                                            colsample_bynode=None,\n",
       "                                            colsample_bytree=None, gamma=None,\n",
       "                                            gpu_id=None, importance_type='gain',\n",
       "                                            interaction_constraints=None,\n",
       "                                            learning_rate=None,\n",
       "                                            max_delta_step=None, max_depth=None,\n",
       "                                            min_child_weight=None, missing=nan,\n",
       "                                            monotone_constraints=None,\n",
       "                                            n_estimators=100, n_jobs=None,\n",
       "                                            num_parallel_tree=None,\n",
       "                                            objective='binary:logistic',\n",
       "                                            random_state=None, reg_alpha=None,\n",
       "                                            reg_lambda=None,\n",
       "                                            scale_pos_weight=None,\n",
       "                                            subsample=None, tree_method=None,\n",
       "                                            validate_parameters=None,\n",
       "                                            verbosity=None),\n",
       "                    n_jobs=None)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_classifier = OneVsRestClassifier(XGBClassifier())\n",
    "\n",
    "xgb_classifier.fit(x_xgb_train, np.array(y_random_forest_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================HOME Case : MERGED =============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/omid/lib/python3.6/site-packages/ipykernel_launcher.py:9: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  if __name__ == '__main__':\n",
      "/opt/anaconda3/envs/omid/lib/python3.6/site-packages/ipykernel_launcher.py:10: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/opt/anaconda3/envs/omid/lib/python3.6/site-packages/ipykernel_launcher.py:13: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  del sys.path[0]\n",
      "/opt/anaconda3/envs/omid/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/envs/omid/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1515: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  average, \"true nor predicted\", 'F-score is', len(true_sum)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         Class  Accuracy     Recall  Precision   F Score    Count            TP/TN/FP/FN\n",
      "------------------------------------------------------------------------\n",
      "                        button     0.993      0.204     1.000     0.339        49    10/ 5788/    0/   39\n",
      "              colorTemperature     1.000      1.000     1.000     1.000         1     1/ 5836/    0/    0\n",
      "                       contact     0.989      0.658     0.906     0.763       161   106/ 5665/   11/   55\n",
      "                         level     0.993      0.340     0.783     0.474        53    18/ 5779/    5/   35\n",
      "                          lock     1.000        nan       nan       nan         0     0/ 5837/    0/    0\n",
      "                        motion     0.960      0.511     0.289     0.370       133    68/ 5537/  167/   65\n",
      "                          ping     0.995      0.995     0.993     0.994      2301  2290/ 3520/   16/   11\n",
      "                        status     0.997      0.912     0.912     0.912       102    93/ 5726/    9/    9\n",
      "                        switch     0.997      0.444     0.571     0.500        18     8/ 5813/    6/   10\n",
      "                   temperature     0.965      0.122     0.414     0.189       196    24/ 5607/   34/  172\n",
      "                       unknown     0.926      0.938     0.920     0.929      2997  2811/ 2594/  246/  186\n",
      "------------------------------------------------------------------------\n",
      "                      AVERAGES     0.983      0.557     0.708     0.588      5837     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "             Weighted AVERAGES     0.959      0.903     0.915     0.902      5837     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "       known Weighted AVERAGES     0.991      0.869     0.911     0.876      5837     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      " known -ping Weighted AVERAGES     0.979      0.460     0.645     0.496      5837     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "       non zero count AVERAGES     0.982      0.613     0.779     0.647      5837     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "                sample average     0.904      0.909     0.909     0.909      5837     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "       sensative micro average     0.987      0.583     0.497     0.537      5837     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "           known micro average     0.989      0.869     0.913     0.890      5837     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "                 micro average     0.983      0.903     0.917     0.910      5837     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "Macro F1 : 0.588031\n",
      "Micro F1 : 0.909837\n",
      "sample F1 : 0.908537\n",
      "weighted F1 : 0.902402\n",
      "--------------------------removed unknown----------------------------------------------\n",
      "Macro F1 : 0.568992\n",
      "Micro F1 : 0.901826\n",
      "sample F1 : 0.896451\n",
      "weighted F1 : 0.882853\n",
      "Exact Match ACC : 0.90423 \n",
      "Total Records : 5837 \n",
      "Total ZXeros in True : 0 (0.000)%\n",
      "Total ZXeros in Test : 66 (0.011)%\n",
      "=============================================================================\n"
     ]
    }
   ],
   "source": [
    "xg_boost_results = []\n",
    "xgb_preds = []\n",
    "for i in range(len(xgb_test_known)) :\n",
    "    print( \"==================HOME Case : %s =============\" % test_names[ i] )\n",
    "    xgb_pred= xgb_classifier.predict( xgb_test_known[i][0])\n",
    "    xgb_pred = add_unknowns_back(xgb_pred,xgb_test[i][1], xgb_test_known[i][3] , classes)\n",
    "    xgb_preds.append(xgb_pred)\n",
    "    xg_boost_results.append(print_info( xgb_test[i][1], xgb_pred, classes, confidance=0.8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(len(rf_test_known)) :\n",
    "#     print( \"==================HOME Case : %s =============\" % test_names[ i] )\n",
    "#     rf_pred= xgb_classifier.predict( rf_test_known[i][0])\n",
    "#     print_info( rf_test_known[i][1], rf_pred, classes, confidance=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## string encoding test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "knownity_rf =  RandomForestClassifier(n_estimators=100, max_depth=400,\n",
    "                             random_state=0 )\n",
    "knownity_rf_results = knownity_rf.fit(x_xgb_train, known_unknown_y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_known_unknown_pred=knownity_rf.predict(x_xgb_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================HOME Case : MERGED =============\n",
      "                         Class  Accuracy     Recall  Precision   F Score    Count            TP/TN/FP/FN\n",
      "------------------------------------------------------------------------\n",
      "                       unknown     0.927      0.939     0.919     0.929      2997  2815/ 2593/  247/  182\n",
      "                         known     0.927      0.913     0.934     0.924      2840  2593/ 2815/  182/  247\n",
      "------------------------------------------------------------------------\n",
      "                      AVERAGES     0.927      0.926     0.927     0.926      5837     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "             Weighted AVERAGES     0.927      0.927     0.927     0.926      5837     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "       known Weighted AVERAGES     0.927      0.913     0.934     0.924      5837     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------\n",
      "       non zero count AVERAGES     0.927      0.926     0.927     0.926      5837     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "                sample average     0.927      0.927     0.927     0.927      5837     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "       sensative micro average     0.500      0.500     0.500     0.500      5837     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "           known micro average     0.927      0.913     0.934     0.924      5837     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "                 micro average     0.927      0.927     0.927     0.927      5837     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "Macro F1 : 0.926397\n",
      "Micro F1 : 0.926503\n",
      "sample F1 : 0.926503\n",
      "weighted F1 : 0.926472\n",
      "--------------------------removed unknown----------------------------------------------\n",
      "Macro F1 : 0.483048\n",
      "Micro F1 : 0.934414\n",
      "sample F1 : 0.934414\n",
      "weighted F1 : 0.902733\n",
      "Exact Match ACC : 0.92650 \n",
      "Total Records : 5837 \n",
      "Total ZXeros in True : 0 (0.000)%\n",
      "Total ZXeros in Test : 0 (0.000)%\n",
      "=============================================================================\n"
     ]
    }
   ],
   "source": [
    "test_known_unknown_predicted = []\n",
    "for i in range(len(rf_tests)) :\n",
    "    print( \"==================HOME Case : %s =============\" % test_names[ i] )\n",
    "    rf_pred=knownity_rf.predict( xgb_test[i][0])\n",
    "    test_known_unknown_predicted.append(rf_pred)\n",
    "    print_info( np.array( make_known_unknown(rf_tests[i][1], classes.index('unknown'))), rf_pred, [\"unknown\",\"known\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(rf_tests[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "known_indexes_train  = [ i for i in range(len(train_known_unknown_pred)) if train_known_unknown_pred[i][1] ==1 ]\n",
    "\n",
    "x_train_known = x_xgb_train[known_indexes_train]\n",
    "y_train_known = y_random_forest_train[known_indexes_train]\n",
    "\n",
    "rf_test_known = [] \n",
    "\n",
    "for test_index in range(len(test_known_unknown_predicted)):\n",
    "    known_indexes= [ i for i in range(len(test_known_unknown_predicted[test_index])) if test_known_unknown_predicted[test_index][i][1] ==1 ]\n",
    "    \n",
    "    rf_test_known.append(  (xgb_test[test_index][0][known_indexes], \n",
    "                            rf_tests[test_index][1][known_indexes],\n",
    "                            rf_tests[test_index][2],\n",
    "                            known_indexes\n",
    "                           ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=200, max_depth=400,\n",
    "                             random_state=0 )\n",
    "t_hist = clf.fit(x_train_known, y_train_known)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================HOME Case : MERGED =============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/omid/lib/python3.6/site-packages/ipykernel_launcher.py:10: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/opt/anaconda3/envs/omid/lib/python3.6/site-packages/ipykernel_launcher.py:9: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  if __name__ == '__main__':\n",
      "/opt/anaconda3/envs/omid/lib/python3.6/site-packages/ipykernel_launcher.py:13: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  del sys.path[0]\n",
      "/opt/anaconda3/envs/omid/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/envs/omid/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1515: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  average, \"true nor predicted\", 'F-score is', len(true_sum)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         Class  Accuracy     Recall  Precision   F Score    Count            TP/TN/FP/FN\n",
      "------------------------------------------------------------------------\n",
      "                        button     0.993      0.184     1.000     0.310        49     9/ 5788/    0/   40\n",
      "              colorTemperature     1.000      0.000       nan     0.000         1     0/ 5836/    0/    1\n",
      "                       contact     0.989      0.640     0.954     0.766       161   103/ 5671/    5/   58\n",
      "                         level     0.991      0.057     0.750     0.105        53     3/ 5783/    1/   50\n",
      "                          lock     1.000        nan       nan       nan         0     0/ 5837/    0/    0\n",
      "                        motion     0.961      0.466     0.281     0.350       133    62/ 5545/  159/   71\n",
      "                          ping     0.996      0.997     0.992     0.995      2301  2294/ 3518/   18/    7\n",
      "                        status     0.998      0.892     0.978     0.933       102    91/ 5733/    2/   11\n",
      "                        switch     0.997      0.000     0.000     0.000        18     0/ 5818/    1/   18\n",
      "                   temperature     0.965      0.128     0.424     0.196       196    25/ 5607/   34/  171\n",
      "                       unknown     0.926      0.939     0.919     0.929      2997  2815/ 2592/  248/  182\n",
      "------------------------------------------------------------------------\n",
      "                      AVERAGES     0.983      0.391     0.573     0.417      5837     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "             Weighted AVERAGES     0.959      0.899     0.915     0.898      5837     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "       known Weighted AVERAGES     0.992      0.858     0.911     0.867      5837     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      " known -ping Weighted AVERAGES     0.979      0.411     0.649     0.455      5837     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "       non zero count AVERAGES     0.982      0.430     0.630     0.458      5837     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "                sample average     0.906      0.908     0.908     0.908      5837     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "       sensative micro average     0.987      0.529     0.500     0.514      5837     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "           known micro average     0.989      0.858     0.922     0.889      5837     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "                 micro average     0.983      0.899     0.920     0.909      5837     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "Macro F1 : 0.416793\n",
      "Micro F1 : 0.909351\n",
      "sample F1 : 0.907789\n",
      "weighted F1 : 0.897882\n",
      "--------------------------removed unknown----------------------------------------------\n",
      "Macro F1 : 0.387795\n",
      "Micro F1 : 0.901708\n",
      "sample F1 : 0.895374\n",
      "weighted F1 : 0.877217\n",
      "Exact Match ACC : 0.90560 \n",
      "Total Records : 5837 \n",
      "Total ZXeros in True : 0 (0.000)%\n",
      "Total ZXeros in Test : 73 (0.013)%\n",
      "=============================================================================\n"
     ]
    }
   ],
   "source": [
    "rf_results = []\n",
    "rf_preds = [] \n",
    "for i in range(len(rf_test_known)) :\n",
    "    print( \"==================HOME Case : %s =============\" % test_names[ i] )\n",
    "    rf_pred= clf.predict( rf_test_known[i][0])\n",
    "    rf_pred = add_unknowns_back(rf_pred,rf_tests[i][1], rf_test_known[i][3] , classes)\n",
    "    rf_preds.append(rf_pred)\n",
    "    rf_results.append(print_info( rf_tests[i][1], rf_pred, classes, confidance=0.09))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(len(rf_test_known)) :\n",
    "#     print( \"==================HOME Case : %s =============\" % test_names[ i] )\n",
    "#     rf_pred= clf.predict( rf_test_known[i][0])\n",
    "#     print_info( rf_test_known[i][1], rf_pred, classes, confidance=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest baseline calc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "preproicess the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_size= 50\n",
    "x_random_forest_train,y_random_forest_train, _ = pre_process_raw( x_train, y_train , dim_size, zero_pad=True, normalize=False, classes=classes,remove_empty=pre_Process_remove_empties)\n",
    "rf_tests  = [ pre_process_raw( x_test[i], y_test[i] , dim_size, zero_pad=True, normalize=False, classes=classes, class_cap=TEST_CLASS_CAP,remove_empty=pre_Process_remove_empties) for i in range(len(x_test)) ] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(rf_tests[0][0]),len( rf_tests[0][1]), len(x_test[0]), len(y_test[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "first stage RF will learn if it is a known or unknown instance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "knownity_rf =  RandomForestClassifier(n_estimators=960, max_depth=9050,\n",
    "                             random_state=0 )\n",
    "knownity_rf_results = knownity_rf.fit(x_random_forest_train, known_unknown_y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_known_unknown_pred=knownity_rf.predict(x_random_forest_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_known_unknown_predicted = []\n",
    "for i in range(len(rf_tests)) :\n",
    "    print( \"==================HOME Case : %s =============\" % test_names[ i] )\n",
    "    rf_pred=knownity_rf.predict( rf_tests[i][0])\n",
    "    test_known_unknown_predicted.append(rf_pred)\n",
    "    print_info( np.array( make_known_unknown(rf_tests[i][1], classes.index('unknown'))), rf_pred, [\"unknown\",\"known\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "known_indexes_train  = [ i for i in range(len(train_known_unknown_pred)) if train_known_unknown_pred[i][1] ==1 ]\n",
    "\n",
    "x_train_known = x_random_forest_train[known_indexes_train]\n",
    "y_train_known = y_random_forest_train[known_indexes_train]\n",
    "\n",
    "rf_test_known = [] \n",
    "\n",
    "for test_index in range(len(rf_tests)):\n",
    "    known_indexes= [ i for i in range(len(test_known_unknown_predicted[test_index])) if test_known_unknown_predicted[test_index][i][1] ==1 ]\n",
    "    print(test_index, max(known_indexes), len(rf_tests[test_index][0]),len(known_indexes))\n",
    "    rf_test_known.append(  (rf_tests[test_index][0][known_indexes], \n",
    "                            rf_tests[test_index][1][known_indexes],\n",
    "                            rf_tests[test_index][1], \n",
    "                           known_indexes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the model\n",
    "dim_size =20\n",
    "x_lstm_prossed_train,y_lstm_prossed_train, _ = pre_process_raw( x_train, y_train , dim_size, zero_pad=False, normalize=False,classes=classes, as_string=True,remove_empty=pre_Process_remove_empties)\n",
    "_, y_s_lstm_processed_train ,_ =  pre_process_raw( x_train, y_train_service , dim_size, zero_pad=False, normalize=False,classes=service_classes, as_string=True,remove_empty=pre_Process_remove_empties)\n",
    "# x_lstm_prossed_test,y_lstm_prossed_test, _ = pre_process_raw( x_test, y_test_2 , dim_size, zero_pad=True, normalize=False,classes=classes)\n",
    "lstm_tests  = [ pre_process_raw( x_test[i], y_test[i] , dim_size, zero_pad=False, normalize=False, classes=classes, class_cap=TEST_CLASS_CAP,remove_empty=pre_Process_remove_empties) for i in range(len(x_test)) ] \n",
    "lstm_tests_services  = [ pre_process_raw( x_test[i], y_test_service[i] , dim_size, zero_pad=False, normalize=True, classes=service_classes, class_cap=TEST_CLASS_CAP,remove_empty=pre_Process_remove_empties) for i in range(len(x_test)) ] \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# known_indexes_train  = [ i for i in range(len(train_known_unknown_pred)) if train_known_unknown_pred[i][1] ==1 ]\n",
    "\n",
    "# # x_lstm_prossed_train = x_lstm_prossed_train[known_indexes_train]\n",
    "# y_lstm_prossed_train = y_lstm_prossed_train[known_indexes_train]\n",
    "\n",
    "# lstm_tests_known = [] \n",
    "\n",
    "# for test_index in range(len(rf_tests)):\n",
    "#     known_indexes= [ i for i in range(len(test_known_unknown_predicted[test_index])) if test_known_unknown_predicted[test_index][i][1] ==1 ]\n",
    "    \n",
    "#     lstm_tests_known.append(  (lstm_tests[test_index][0][known_indexes], \n",
    "#                             lstm_tests[test_index][1][known_indexes],\n",
    "#                             lstm_tests[test_index][2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_lstm_prossed_test2 = np.expand_dims(x_lstm_prossed_test,axis=1)\n",
    "# x_lstm_prossed_train2 =np.expand_dims(x_random_forest_train,axis=1)\n",
    "# x_lstm_prossed_train2 =x_random_forest_train\n",
    "\n",
    "\n",
    "# x_lstm_prossed_test2 = x_lstm_prossed_test.reshape(len(x_lstm_prossed_test),dim_size,1)\n",
    "x_lstm_prossed_train2 =x_train_known.reshape((x_train_known.shape[0],x_train_known.shape[1],1))\n",
    "\n",
    "# y_lstm_prossed_test2 = y_lstm_prossed_test.reshape(len(y_lstm_prossed_test),len(classes),1)\n",
    "# y_lstm_prossed_train2 =y_lstm_prossed_train.reshape(len(y_lstm_prossed_train),len(classes),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_tests_known = []\n",
    "for tt  in range( len(rf_test_known) ):\n",
    "    lstm_tests_known.append( (rf_test_known[tt][0].reshape(rf_test_known[tt][0].shape[0],\n",
    "                                                     rf_test_known[tt][0].shape[1],\n",
    "                                                     1) ,\n",
    "                           rf_test_known[tt][1],\n",
    "                           rf_test_known[tt][2] ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classes.index('ping'), classes.index('unknown'), len(classes), len(y_lstm_prossed_train[0])\n",
    "# ping=classes.index('ping')\n",
    "# unknown =classes.index('unknown')\n",
    "# key = np.ones_like(y_lstm_prossed_train[0])\n",
    "# key[unknown]=0\n",
    "# key[ping]=0\n",
    "# key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(x_lstm_prossed_train2),len( y_lstm_prossed_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs  = Input(  (x_lstm_prossed_train2[0].shape[0]  ,1) )\n",
    "\n",
    "out = Conv1D(128,3,padding='same')(inputs)\n",
    "out = BatchNormalization()(out)\n",
    "out = Activation('relu')(out)\n",
    "out = Dropout(0.2)(out)\n",
    "out = Conv1D(64,3,padding='same')(out)\n",
    "\n",
    "dout_1  = Dropout(0.2)(out)\n",
    "# flt_1   = Flatten()(dout_1)\n",
    "dense_1 = Dense(32, activation='relu')(dout_1)\n",
    "# dout_3  = Dropout(0.2)(dense_1)\n",
    "flt_1   = Flatten()(dense_1)\n",
    "\n",
    "out_put_final = Dense(len(classes), activation='sigmoid', name='Event_output')(flt_1)\n",
    "\n",
    "\n",
    "model2 = Model(inputs=[inputs], outputs=[out_put_final])\n",
    "\n",
    "\n",
    "losses = {\n",
    "    \"Event_output\": f1_loss_perClass ,\n",
    "#     \"Event_output\": f1_loss_perRow \n",
    "    \"Event_output\": \"categorical_crossentropy\",\n",
    "}\n",
    "lossWeights = {\"Event_output\": 200,\n",
    "#                \"Event_output\": 30.0 \n",
    "    \"Event_output\": 5\n",
    "              }\n",
    " \n",
    "\n",
    "\n",
    "model2.compile(loss=losses,loss_weights=lossWeights, optimizer='adam', metrics=[f1_perRow,f1_perClass,'acc'])\n",
    "# model2.compile(loss=losses, loss_weights=lossWeights, optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "checkpoint = ModelCheckpoint('IoTDownNet_cnn_newloss', monitor='loss', verbose=0, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "print(model2.summary())\n",
    "# hist2 = model2.fit(x_lstm_prossed_train2, y_train_known, epochs=70, batch_size=2000, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "losses = {\n",
    "    \"Event_output\": f1_loss_perClass ,\n",
    "    \"Event_output\": f1_loss_perRow ,\n",
    "    \"Event_output\": \"categorical_crossentropy\",\n",
    "}\n",
    "lossWeights = {\n",
    "    \"Event_output\": 300,\n",
    "               \"Event_output\": 300.0 ,\n",
    "    \"Event_output\": 20\n",
    "              }\n",
    " \n",
    "\n",
    "\n",
    "model2.compile(loss=losses,loss_weights=lossWeights, optimizer='adam', metrics=[f1_perRow,f1_perClass,'acc'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hist2 = model2.fit(x_lstm_prossed_train2, y_train_known, epochs=100, batch_size=7010, shuffle=True, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hist2 = model2.fit(x_lstm_prossed_train2, y_train_known, epochs=200, batch_size=7000, shuffle=True, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hist2 = model2.fit(x_lstm_prossed_train2, y_train_known, epochs=300, batch_size=7000, shuffle=True, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model2.load_weights('IoTDownNet_cnn_nocca')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lstm_results = []\n",
    "# lstm_preds = [] \n",
    "# for i in range(len(lstm_tests_known)) :\n",
    "#     print( \"==================HOME Case : %s =============\" % test_names[ i] )\n",
    "#     lstm_pred= model2.predict( lstm_tests_known[i][0])\n",
    "#     lstm_pred = add_unknowns_back(lstm_pred,rf_tests[i][1], rf_test_known[i][3] , classes)\n",
    "#     lstm_preds.append(lstm_pred)\n",
    "#     lstm_results.append(print_info( rf_tests[i][1], lstm_pred, classes, confidance=0.09))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load Seq2Seq results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_2_vec(y_data, classes):\n",
    "    ret = []\n",
    "    \n",
    "    for i,x in enumerate(classes):\n",
    "        if 'unknown' in x:\n",
    "            unknown_index = i\n",
    "            break\n",
    "    \n",
    "    for i,x in enumerate(y_data):\n",
    "        temp = np.zeros(len(classes))\n",
    "        x= list(set(x.split(' ')))\n",
    "        for y in x: \n",
    "            if y in classes:\n",
    "                temp[classes.index(y)] = 1\n",
    "                \n",
    "        if np.sum(temp) == 0 :\n",
    "            temp[unknown_index] = 1\n",
    "        ret.append(temp)\n",
    "    return ret\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load the test fileds from seq2seq output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq2seq_results = []\n",
    "for test_case in test_files:\n",
    "    file_name = os.path.join(\"../files/seq2seq/%s_test_services_to_keep_%d_pred.json\" % (os.path.basename(test_case)[:-5], 0 if Mapper=='S' else 2))\n",
    "    with open(file_name, 'r') as file:\n",
    "        results = file.readlines()\n",
    "        results = [x.strip() for x in results]\n",
    "        results = label_2_vec(results, classes)\n",
    "        if MERGE_TESTS:\n",
    "            seq2seq_results.extend(results)\n",
    "        else:\n",
    "            seq2seq_results.append(results)\n",
    "\n",
    "if MERGE_TESTS:\n",
    "    seq2seq_results = [np.array(seq2seq_results)[indexes_to_keep]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vec_2_str(vec, classes):\n",
    "    ret = []\n",
    "    for item in vec:\n",
    "        temp = []\n",
    "        for x in range(len(classes)):\n",
    "            if item[x]==1:\n",
    "                temp.append(classes[x])\n",
    "        ret.append(' '.join(temp))\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# s = vec_2_str(rf_tests[0][1], classes)\n",
    "# with open('ttt_temp.txt','w') as f:\n",
    "#     for x in s:\n",
    "#         f.write(x+\"\\r\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sams= []\n",
    "# with open('../files/seq2seq/home_os_final_test_services_to_keep_0_label') as f:\n",
    "#     temp = f.readlines()\n",
    "#     temp = [x.strip() for x in temp]\n",
    "#     temp = [' '.join( sorted(x.split(' ')) ) for x in temp]\n",
    "#     sams = temp\n",
    "\n",
    "    \n",
    "# for i in range(len(s)):\n",
    "#     if s[i] != sams[i]:\n",
    "#         print(i+1,\"|\", s[i],\"|\",sams[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(rf_tests[0][1]), len(seq2seq_results), len(seq2seq_results[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(seq2seq_results)) :\n",
    "    print( \"==================HOME Case : %s =============\" % test_names[ i] )\n",
    "    pred = np.array(seq2seq_results[i])\n",
    "    print_info( rf_tests[i][1], pred, classes, confidance=0.09)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show comparative resutls for xgb and RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mask(for_classes, classes):\n",
    "    ret = np.zeros(len(classes))\n",
    "    \n",
    "    for x in for_classes:\n",
    "        ret[classes.index(x)] = 1\n",
    "\n",
    "    return ret\n",
    "\n",
    "xgb_classes = [\n",
    "    'button',\n",
    "    'level',\n",
    " 'lock',\n",
    " \n",
    "    'switch',\n",
    " \n",
    "    \n",
    " ]\n",
    "rf_classes =[\n",
    "   \n",
    "    \n",
    "]\n",
    "lstm_classes = [\n",
    "    'contact',\n",
    "    'ping',\n",
    " 'status',\n",
    "    \n",
    "]\n",
    "seq2seq_classes=[\n",
    "    'colorTemperature',\n",
    "    'motion',\n",
    "    'temperature',\n",
    "    'unknown'\n",
    "]\n",
    "\n",
    "rf_mask =create_mask(rf_classes, classes)\n",
    "xgb_mask = create_mask(xgb_classes, classes)\n",
    "lstm_mask = create_mask(lstm_classes, classes)\n",
    "seq2seq_mask = create_mask(seq2seq_classes, classes)\n",
    "\n",
    "ensambled_Resutls = []\n",
    "for i in range(len(rf_test_known)) :\n",
    "    print( \"==================HOME Case : %s =============\" % test_names[ i] )\n",
    "    the_pred = rf_preds[i] * rf_mask + xgb_preds[i] * xgb_mask + lstm_preds[i]* lstm_mask + seq2seq_results[i] * seq2seq_mask\n",
    "#     rf_pred = add_unknowns_back(rf_pred,rf_tests[i][1], rf_test_known[i][3] , classes)\n",
    "#     rf_preds.append(rf_pred)\n",
    "    ensambled_Resutls.append( print_info( rf_tests[i][1], the_pred, classes, confidance=0.09))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# values, desc = print_info( rf_test_known[i][1], rf_pred, classes, confidance=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def fix_nan(inp):\n",
    "    if np.isnan(inp):\n",
    "        return 0\n",
    "    else:\n",
    "        return inp\n",
    "desc = xg_boost_results[0][1]\n",
    "index = 0 \n",
    "for index in range(len(test_names)):\n",
    "    plt.figure(figsize=(14,4))\n",
    "    plt.plot( [x[0] for x in xg_boost_results[index][0]] , \n",
    "         [fix_nan(x[desc.index(\"F Score\")]) for x in xg_boost_results[index][0]],\n",
    "        label=\"XGBoost\",\n",
    "         color=\"red\" ,\n",
    "             alpha=0.5\n",
    "        )\n",
    "#     plt.plot( [x[0] for x in rf_results[index][0]] , \n",
    "#          [fix_nan(x[desc.index(\"F Score\")]) for x in rf_results[index][0]],\n",
    "#         label=\"RF\",\n",
    "#          color=\"blue\" ,\n",
    "#              alpha=0.5\n",
    "#         )\n",
    "    plt.plot( [x[0] for x in rf_results[index][0]] , \n",
    "     [fix_nan(x[desc.index(\"F Score\")]) for x in ensambled_Resutls[index][0]],\n",
    "    label=\"Ensamble \",\n",
    "     color=\"green\" ,\n",
    "         alpha=0.5\n",
    "    )\n",
    "    \n",
    "    plt.plot( [x[0] for x in xg_boost_results[index][0]] , \n",
    "         [fix_nan(x[desc.index(\"Precision\")]) for x in xg_boost_results[index][0]],\n",
    "        label=\"XGBoost - Precision\",\n",
    "         color=\"red\" ,\n",
    "             marker=\"s\",\n",
    "             alpha=0.5\n",
    "        )\n",
    "#     plt.plot( [x[0] for x in rf_results[index][0]] , \n",
    "#          [fix_nan(x[desc.index(\"Precision\")]) for x in rf_results[index][0]],\n",
    "#         label=\"RF - Precision\",\n",
    "#          color=\"blue\" ,\n",
    "#              marker=\"s\",\n",
    "#              alpha=0.5\n",
    "#         )\n",
    "    plt.plot( [x[0] for x in rf_results[index][0]] , \n",
    "     [fix_nan(x[desc.index(\"Precision\")]) for x in ensambled_Resutls[index][0]],\n",
    "    label=\"Ensambled - Precision\",\n",
    "     color=\"green\" ,\n",
    "         marker=\"s\",\n",
    "         alpha=0.5\n",
    "    )\n",
    "    plt.plot( [x[0] for x in xg_boost_results[index][0]] , \n",
    "         [fix_nan(x[desc.index(\"Recall\")]) for x in xg_boost_results[index][0]],\n",
    "        label=\"XGBoost - Recall\",\n",
    "         color=\"red\" ,\n",
    "             marker=\"+\",\n",
    "             alpha=0.5\n",
    "        )\n",
    "#     plt.plot( [x[0] for x in rf_results[index][0]] , \n",
    "#          [fix_nan(x[desc.index(\"Recall\")]) for x in rf_results[index][0]],\n",
    "#         label=\"RF - Recall\",\n",
    "#          color=\"blue\" ,\n",
    "#              marker=\"+\",\n",
    "#              alpha=0.5\n",
    "#         )\n",
    "\n",
    "    plt.plot( [x[0] for x in rf_results[index][0]] , \n",
    "     [fix_nan(x[desc.index(\"Recall\")]) for x in ensambled_Resutls[index][0]],\n",
    "    label=\"Ensambled - Recall\",\n",
    "     color=\"green\" ,\n",
    "         marker=\"+\",\n",
    "         alpha=0.5\n",
    "    )\n",
    "\n",
    "    # plt.plot( )\n",
    "    plt.legend()\n",
    "    plt.xticks(rotation=90, ha='right')\n",
    "    plt.title(test_names[ index] )\n",
    "    plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Audio, display\n",
    "\n",
    "def allDone():\n",
    "    display(Audio(url='https://sound.peal.io/ps/audios/000/000/537/original/woo_vu_luvub_dub_dub.wav', autoplay=True))\n",
    "allDone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3.6(omid)",
   "language": "python",
   "name": "omid"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
