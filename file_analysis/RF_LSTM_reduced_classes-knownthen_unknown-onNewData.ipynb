{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import json \n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import keras \n",
    "\n",
    "# import numpy\n",
    "# import pandas\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "from keras.datasets import imdb\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "import glob\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "\n",
    "\n",
    "from keras import backend as K\n",
    "\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# import os\n",
    "# os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from xgboost import plot_tree\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "loadFromMerged=True\n",
    "loadFromIndexes= False\n",
    "Mapper='S'\n",
    "IgnoreEmpty= True\n",
    "FoldID =\"1\"\n",
    "Epoch_count=100\n",
    "Batch_size=5000\n",
    "INCLUDE_DIRECTION = False\n",
    "LOAD_OLD_DATA_TRAIN = True\n",
    "LOAD_OLD_DATA_TEST = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data the old way\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_data= [] \n",
    "# y_data= [] \n",
    "\n",
    "\n",
    "# with open( '../files/txt/seq_mapping_large.txt' ) as f:\n",
    "#     x_data =   f.readlines()\n",
    "\n",
    "# with open( '../files/txt/command_mapping_large.txt' ) as f:\n",
    "#     y_data = f.readlines()\n",
    "    \n",
    "    \n",
    "# x_data =[ np.array([ int(y) for y in x.strip().split( ' ') ])   for x in  x_data ] \n",
    "# y_data =[ x.strip().split(' ') for x in  y_data ] \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Load The Data The New Way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  mapps the input records to a integer array for the input\n",
    "def mapping_x( inp, include_direction = False , TrimAt= 15 ):\n",
    "    if include_direction:\n",
    "        return np.array([ int(x[\"packet_length\"]) * (1 if x['packet_source']=='hub' else -1)  for x in inp ][:15])\n",
    "    else:\n",
    "        return np.array([ int(x[\"packet_length\"])  for x in inp ][:15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapping_y_service(inp):\n",
    "    return np.array(  list(set([x[\"event\"] for x in inp])) if (len(inp )>0) else [\"none\"] )\n",
    "\n",
    "def mapping_y_service_event(inp):\n",
    "    return np.array(  list(set([ \"%s-%s\"%( x[\"event\"] ,x[\"val\"] ) for x in inp])) if (len(inp )>0) else [\"none\"] )\n",
    "\n",
    "def mapping_y_device_service(inp):\n",
    "    return np.array(  list(set([ \"%s & %s\"%( x[\"device\"] ,x[\"event\"] ) for x in inp])) if (len(inp )>0) else [\"none\"] )\n",
    "\n",
    "def mapping_y_full(inp):\n",
    "    return np.array(  list(set([ \"%s & %s & %s\"%( x[\"device\"] ,x[\"event\"], x['val'] ) for x in inp])) if (len(inp )>0) else [\"none\"] )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this cleans the data removing emply nodes and turning the nodes into sarrays by calling the mapping function \n",
    "def clean_data( x_data, y_data , removeempty=True, Mapping='S', include_direction=False):\n",
    "    cleans = [] \n",
    "    cleans = (sorted([ x for x in y_data if (removeempty and len(y_data[x]) > 0) or not removeempty  ] ))\n",
    "    \n",
    "    ret_x  = [x_data[x] for x in cleans]\n",
    "    ret_y  = [y_data[x] for x in cleans] \n",
    "    \n",
    "    print( len(y_data), len(cleans) )\n",
    "    \n",
    "    ret_x  = [ mapping_x(x, include_direction=include_direction) for x in ret_x ] \n",
    "    ret_y_s = [ mapping_y_service(y) for y in ret_y ]\n",
    "    if Mapping=='S':\n",
    "        ret_y  = [ mapping_y_service(y) for y in ret_y ]\n",
    "    elif Mapping=='SE':\n",
    "        ret_y  = [ mapping_y_service_event(y) for y in ret_y ]\n",
    "    elif Mapping=='DS':\n",
    "        ret_y  = [ mapping_y_device_service(y) for y in ret_y ]\n",
    "    elif Mapping=='F':\n",
    "        ret_y  = [ mapping_y_full(y) for y in ret_y ]\n",
    "    return ret_x, ret_y, ret_y_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in load from merged\n",
      "58958 57867\n",
      "loading from test files\n",
      "found files :  3\n",
      "home_os_final.json\n",
      "19090 19090\n",
      "test_data_light.json\n",
      "265 265\n",
      "test_data_motion_2.json\n",
      "10436 10436\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(57867, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x= []\n",
    "y= []\n",
    "\n",
    "x_test = []\n",
    "y_test = []\n",
    "y_test_service= []\n",
    "\n",
    "x_train = []\n",
    "y_train = []\n",
    "y_train_service = []\n",
    "\n",
    "test_names = []\n",
    "\n",
    "add_to_trainig = [0,2]\n",
    "\n",
    "if loadFromMerged:\n",
    "    print(\"in load from merged\")\n",
    "    if LOAD_OLD_DATA_TRAIN:\n",
    "        with open(  '../files/train/test/test_homes/final_upload/Merged_final_with_home/merged_hub_segments_final.json'  ) as f:\n",
    "            y_data = json.load(f)\n",
    "\n",
    "        with open(  '../files/train/test/test_homes/final_upload/Merged_final_with_home/merged_pcap_segments_final.json'  ) as f:\n",
    "            x_data = json.load(f)\n",
    "\n",
    "    #     with open(  '../files/train/merged/hub_segments_2.json'  ) as f:\n",
    "    #         y_data = json.load(f)\n",
    "\n",
    "    #     with open(  '../files/train/merged/pcap_segments_2.json'  ) as f:\n",
    "    #         x_data = json.load(f)\n",
    "\n",
    "        if len( y_data ) != len(x_data) :\n",
    "            print( pick )\n",
    "\n",
    "\n",
    "        x_train,y_train, y_train_service= clean_data( x_data, y_data, IgnoreEmpty , \n",
    "                                                     Mapping=Mapper, include_direction=INCLUDE_DIRECTION )\n",
    "    else:\n",
    "        \n",
    "        for pick in sorted(glob.glob( '../files/new_data/train/hub_segments/*.json' )):\n",
    "            fname  = os.path.basename(pick)\n",
    "#             test_names.append( fname )\n",
    "            with open( os.path.join( '../files/new_data/train/hub_segments/', fname) ) as f:\n",
    "                y_data = json.load(f)\n",
    "\n",
    "            with open( os.path.join('../files/new_data/train/pcap_segments/', fname) ) as f:\n",
    "                x_data = json.load(f)\n",
    "\n",
    "            if len( y_data ) != len(x_data) :\n",
    "                print( pick )\n",
    "                continue\n",
    "\n",
    "            x_t,y_t, y_t_s= clean_data( x_data, y_data, IgnoreEmpty , \n",
    "                                                     Mapping=Mapper, include_direction=INCLUDE_DIRECTION )\n",
    "    \n",
    "            x_train.extend(x_t)\n",
    "            y_train.extend(y_t)\n",
    "            y_train_service.extend(y_t_s)\n",
    "            \n",
    "\n",
    "    #     continue\n",
    "#     if loadFromIndexes:\n",
    "#         print(\"load from indexes\")\n",
    "#         with open(\"../files/train/merged/items_2_test-train_indexes.json\")  as f:\n",
    "#             index_info = json.load(f)\n",
    "\n",
    "\n",
    "#         for i in index_info[FoldID][\"test\"]:\n",
    "#             x_test[str(i)]=(x_data[str(i)] )\n",
    "#             y_test[str(i)]=(y_data[str(i)] )\n",
    "\n",
    "#         for i in index_info[FoldID][\"train\"]:\n",
    "#             x_train[str(i)]=(  x_data[str(i)] )\n",
    "#             y_train[str(i)]=(  y_data[str(i)] )\n",
    "        \n",
    "#         x_test_t,y_test_t= clean_data( x_test, y_test, IgnoreEmpty , Mapping=Mapper)\n",
    "#         x_test.append(x_test_t)\n",
    "#         y_test.append(y_test_t)\n",
    "    #     else :\n",
    "    print(\"loading from test files\")\n",
    "    files_path =  '../files/train/test/test_homes/final_upload/usecases/pcap_segments_final_final/home*.json' if LOAD_OLD_DATA_TEST else '../files/new_data/usecases/pcap_segments_final/*.json'\n",
    "    test_y_dir = '../files/train/test/test_homes/final_upload/usecases/hub_segments_final_final/' if LOAD_OLD_DATA_TEST else '../files/new_data/usecases/hub_segments_final/'\n",
    "    test_x_dir = '../files/train/test/test_homes/final_upload/usecases/pcap_segments_final_final/' if LOAD_OLD_DATA_TEST else '../files/new_data/usecases/pcap_segments_final/'\n",
    "    \n",
    "    test_files = sorted(glob.glob(files_path))\n",
    "    print( \"found files : \" , len(test_files) )\n",
    "    \n",
    "    \n",
    "    for pick  in test_files:\n",
    "        fname  = os.path.basename(pick)\n",
    "        test_names.append( fname )\n",
    "        print(fname)\n",
    "        with open( os.path.join(test_y_dir , fname) ) as f:\n",
    "            y_data_test = json.load(f)\n",
    "\n",
    "        with open( os.path.join(test_x_dir, fname) ) as f:\n",
    "            x_data_test = json.load(f)\n",
    "\n",
    "\n",
    "        t_x,t_y, t_z= clean_data( x_data_test, y_data_test, False , Mapping=Mapper, include_direction= INCLUDE_DIRECTION )\n",
    "\n",
    "#         if test_files.index(pick) in add_to_trainig:\n",
    "#             x_test_t,y_test_t, y_test_service_t= clean_data( x_data_test, y_data_test, IgnoreEmpty , Mapping=Mapper)\n",
    "#             x_train.extend(x_test_t)\n",
    "#             y_train.extend(y_test_t)\n",
    "#             y_train_service.extend(y_test_service_t)\n",
    "\n",
    "\n",
    "        x_test.append(t_x)\n",
    "        y_test.append(t_y)\n",
    "        y_test_service.append(t_z)\n",
    "            \n",
    "#     x_test = x_data[ index_info[\"1\"][\"test\"]  ]\n",
    "#     y_test = y_data[ index_info[\"1\"][\"test\"]  ]\n",
    "    \n",
    "#     x_train = x_data[ index_info[\"1\"][\"train\"]  ]\n",
    "#     y_train = y_data[ index_info[\"1\"][\"train\"]  ]\n",
    "#     x.extend(t_x)\n",
    "#     y.extend(t_y)\n",
    "else:\n",
    "    for pick in sorted(glob.glob( '../files/train/hub_segments/*.json' )):\n",
    "        fname  = os.path.basename(pick)\n",
    "        test_names.append( fname )\n",
    "        with open( os.path.join( '../files/train/hub_segments/', fname) ) as f:\n",
    "            y_data = json.load(f)\n",
    "\n",
    "        with open( os.path.join('../files/train/pcap_segments/', fname) ) as f:\n",
    "            x_data = json.load(f)\n",
    "\n",
    "        if len( y_data ) != len(x_data) :\n",
    "            print( pick )\n",
    "            continue\n",
    "\n",
    "        t_x,t_y= clean_data( x_data, y_data, True, include_direction=INCLUDE_DIRECTION )\n",
    "\n",
    "        x.extend( t_x)\n",
    "        y.extend(t_y)\n",
    "\n",
    "x= np.array(x)\n",
    "y= np.array(y)\n",
    "\n",
    "# x_train = np.append( x_train, x_test[0] , axis=0)\n",
    "# x_train = np.append( x_train, x_test[2] , axis=0)\n",
    "\n",
    "# y_train = np.append( y_train, y_test[0] , axis=0)\n",
    "# y_train = np.append( y_train, y_test[2] , axis=0)\n",
    "\n",
    "\n",
    "len(x_train), len(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Mittigation Techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packet Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# days =[7,4,2,2]\n",
    "# t_sum =0\n",
    "# for ii in range(len(x_test)):\n",
    "#     p = x_test[ii]\n",
    "#     sizes = np.unique(np.concatenate(p), return_counts=True)\n",
    "#     sums= 0 \n",
    "#     for i in range(len(sizes[0])):\n",
    "# #         print( \"%d--> %d\" % ( sizes[0][i], sizes[1][i] ) )\n",
    "#         if  sizes[0][i] < 1000:\n",
    "#             sums+= (1000-sizes[0][i] )* sizes[1][i]\n",
    "#     t_sum +=(sums / days[ii] )/1000000 \n",
    "#     print ( (sums / days[ii] )/1000000)\n",
    "# print('--------')\n",
    "# print(t_sum/4)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# days =[7,4,2,2]\n",
    "# t_sum =0\n",
    "# d_sum = 0\n",
    "# import math\n",
    "# for ii in range(len(x_test)):\n",
    "\n",
    "#     p = x_test[ii]\n",
    "#     for i in p : \n",
    "#         t_sum += math.ceil(np.sum(i) / 2000)\n",
    "#         d_sum+= np.sum( i )\n",
    "# total_fixed  =  t_sum* 2000 / 15\n",
    "\n",
    "# print ( total_fixed , d_sum, d_sum-t_sum*2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packet Insertion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# days =[7,4,2,2]\n",
    "# t_sum =0\n",
    "# for ii in range(len(x_test)):\n",
    "#     p = x_test[ii]\n",
    "#     sizes = np.unique(np.concatenate(p), return_counts=True)\n",
    "#     sums= 0 \n",
    "#     for i in range(len(sizes[0])):\n",
    "# #         print( \"%d--> %d\" % ( sizes[0][i], sizes[1][i] ) )\n",
    "#         if  sizes[0][i] < 1000:\n",
    "#             sums+= (1000-sizes[0][i] )* sizes[1][i]\n",
    "#     t_sum +=(sums / days[ii] )/1000000 \n",
    "#     print ( (sums / days[ii] )/1000000)\n",
    "# print('--------')\n",
    "# print(t_sum/4)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sets the classes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 'acceleration'),\n",
       " (1, 'activity'),\n",
       " (2, 'battery'),\n",
       " (3, 'button'),\n",
       " (4, 'colorTemperature'),\n",
       " (5, 'contact'),\n",
       " (6, 'level'),\n",
       " (7, 'lock'),\n",
       " (8, 'motion'),\n",
       " (9, 'ping'),\n",
       " (10, 'status'),\n",
       " (11, 'switch'),\n",
       " (12, 'temperature'),\n",
       " (13, 'threeAxis'),\n",
       " (14, 'unknown'),\n",
       " (15, 'water')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = sorted(list(np.unique(  np.concatenate( y_train  ))))\n",
    "# print([ (i , classes[i]) for i in range( len(classes) ) ])\n",
    "\n",
    "service_classes = sorted(list(np.unique(  np.concatenate( y_train_service  ))))\n",
    "[ (i , service_classes[i]) for i in range( len(service_classes) ) ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter the records by service/event types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_clean_event( inp, return_clean= True  ):\n",
    "    return is_clean(inp, return_clean=return_clean, to_keep=[ 'no_logs', 'lock-unlocked', 'on/off-XXX', 'raw-XXX', 'read_attr_-_raw-XXX' ] )\n",
    "#     if return_clean:\n",
    "#         return  'no_logs' not in inp and 'lock-unlocked' not in inp and 'on/off-XXX' not in inp and 'raw-XXX' not in inp and 'read_attr_-_raw-XXX' not in inp\n",
    "#     else:\n",
    "#         return  'lock-locked' in inp or 'lock-unlocked'  in inp or 'on/off-XXX' in inp or  'raw-XXX' in inp  or 'read_attr_-_raw-XXX' in inp \n",
    "     \n",
    "def is_clean_service( inp, return_clean= True  ):\n",
    "    return is_clean(inp, to_keep=['no_logs','unknown', 'read_attr_-_raw'], return_clean=return_clean )\n",
    "    \n",
    "#     if return_clean:\n",
    "#         return  'no_logs' not in inp and 'unknown' not in inp and 'read_attr_-_raw' not in inp #and 'ping' not in inp \n",
    "#     else:\n",
    "#         return  'no_logs' in inp or  'unknown' in inp  or 'read_attr_-_raw' in inp #or 'ping' in inp \n",
    "\n",
    "def is_clean(inp, to_keep=[], return_clean=True):\n",
    "    ret = False \n",
    "    \n",
    "    for x  in to_keep:\n",
    "        if x in inp:\n",
    "            ret = True\n",
    "            \n",
    "    if not return_clean:\n",
    "        ret = not ret\n",
    "        \n",
    "    return ret\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "choose services to keep : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "services_to_keep = service_classes#[ 'contact', 'lock', 'motion',\"ping\", 'switch','unknown'] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "find records which need change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_indexes_to_change =  [ i for i in range(len(y_train)) if\n",
    "              is_clean( y_train[i],to_keep=services_to_keep, return_clean=False) ] \n",
    "\n",
    "y_train = [ ['unknown'] if i in train_indexes_to_change else y_train[i] \n",
    "           for i in range(len(y_train)) ] \n",
    "\n",
    "for t_index in range(len(y_test)):\n",
    "    test_indexes_to_change =  [ i for i in range(len(y_test[t_index])) if\n",
    "                  is_clean( y_test[t_index][i],to_keep=services_to_keep, return_clean=False) ] \n",
    "\n",
    "    y_test[t_index] = [ ['unknown'] if i in test_indexes_to_change else y_test[t_index][i] \n",
    "               for i in range(len(y_test[t_index])) ] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "known_unknown_y_train = [ [1,0] if (len(x) == 1 and \"unknown\" in x) else [0,1]   for x in y_train ]\n",
    "\n",
    "known_unknown_y_test= [] \n",
    "\n",
    "for i in range(len(y_test)):\n",
    "    \n",
    "    known_unknown_y_test.append( [ [1,0] if (len(x) == 1 and \"unknown\" in x) else [0,1]   for x in y_test[i] ])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "remove classes that are ignored from the services list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = services_to_keep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# toKeep = [ i for i in range(len(y_train)) if is_clean_event( y_train[i]) ] if Mapper=='SE' else [ i for i in range(len(y_train)) if is_clean_service( y_train[i]) ]\n",
    "# x_train= [ x_train[i] for i in toKeep ]\n",
    "# y_train= [ y_train[i] for i in toKeep ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for j in range(len(x_test)):\n",
    "#     toChange= [ i for i in range(len(y_test[j])) if is_clean_service( y_test[j][i], False) ]\n",
    "#     y_test[j] = [ (y_test[j][i] if i not in toChange else np.array( ['none'])) for i in range(len(y_test[j])) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classes.remove('read_attr_-_raw-XXX')\n",
    "# classes.remove('on/off-XXX')\n",
    "# classes.remove('raw-XXX')\n",
    "# classes.remove('lock-unlocked')\n",
    "# classes.remove('lock-locked')\n",
    "\n",
    "\n",
    "# classes.remove('read_attr_-_raw')\n",
    "# classes.remove('on/off')\n",
    "# classes.remove('raw')\n",
    "# classes.remove('unknown')\n",
    "\n",
    "# classes.remove('lock')\n",
    "# # classes.remove('lock')\n",
    "\n",
    "\n",
    "# classes.remove('switch-on')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ===== end of unknown packet control====="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process_raw( x_data,y_data, dim_size = 128, zero_pad = False, normalize = False ,\n",
    "                    classes=None, twoD= False, as_string=False ):\n",
    "#  y data \n",
    "# \"\"\"\n",
    "# this functino is in charge of preprocessing the records , the sourc e json contains a lot of extra stuff, this function tailors\n",
    "# the data and it fixes their lenghth\n",
    "# \"\"\"\n",
    "    if classes is None:\n",
    "        classes  = sorted(list(np.unique(  np.concatenate( y_data  ))))\n",
    "    else :\n",
    "        classes = sorted(classes)\n",
    "    y_data_categorical = []  \n",
    "\n",
    "    for x in y_data:\n",
    "        temp = np.zeros( len(classes) )\n",
    "        for y in x : \n",
    "            if y in classes:\n",
    "                temp[ classes.index( y ) ] = 1\n",
    "        y_data_categorical.append( temp )\n",
    "    y_data_categorical = np.vstack(y_data_categorical)\n",
    "\n",
    "#     x_data = np.array( x_data) / 1500.0\n",
    "    \n",
    "    x_data_temp = [] \n",
    "    \n",
    "    if not zero_pad:\n",
    "        if twoD:\n",
    "            for x in x_data:\n",
    "                temp = [] #list(x)\n",
    "                lst = list(x)\n",
    "                while dim_size**2 - len(temp )   > len(lst):\n",
    "                    temp.extend(lst)\n",
    "\n",
    "                while len(temp) < dim_size**2:\n",
    "                    temp.append( 0 )\n",
    "\n",
    "                x_data_temp.append(np.array( temp).reshape(dim_size,dim_size))\n",
    "\n",
    "\n",
    "            x_data_temp = np.array( x_data_temp )\n",
    "            x_data_temp=x_data_temp.reshape(x_data_temp.shape+(1,))\n",
    "        else: \n",
    "            temp = [] \n",
    "            lst = list(x)\n",
    "            for x in x_data:\n",
    "                temp = [] #list(x)\n",
    "                lst = list(x)\n",
    "                while dim_size - len(temp )   > len(lst):\n",
    "                    temp.extend(lst)\n",
    "\n",
    "                while len(temp) < dim_size:\n",
    "                    temp.append( 0 )\n",
    "                \n",
    "                x_data_temp.append(np.array( temp))\n",
    "            \n",
    "    else :\n",
    "        x_data_temp = sequence.pad_sequences(x_data, maxlen=dim_size)\n",
    "    \n",
    "    \n",
    "    \n",
    "    if normalize:\n",
    "        x_data_temp = np.array( x_data_temp) / (np.amax( x_data_temp) + 0.000000000001)\n",
    "    else :\n",
    "        x_data_temp = np.array(x_data_temp)\n",
    "    \n",
    "    \n",
    "    if as_string:\n",
    "        x_data_temp = [ ' '.join(list(map(str,x))) for x in x_data_temp ]\n",
    "    \n",
    "    return x_data_temp ,y_data_categorical , classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y,_=pre_process_raw( x_train, y_train , 15, zero_pad=True, normalize=True, classes=classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9999999999999997, 0.0)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.amax(x), np.amin(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_recall_shit( inp ):\n",
    "    tp = inp[1][1]\n",
    "    tn = inp[0][0]\n",
    "    fp = inp[0][1] \n",
    "    fn = inp[1][0]\n",
    "    \n",
    "    acc = (tp+tn)*1.0 / ( tp+tn+fp+fn)*1.0\n",
    "    recall = tp*1.0/ ( tp+fn ) *1.0\n",
    "    prec = tp*1.0 / ( tp+fp )*1.0\n",
    "    \n",
    "#     F= 2.0*( prec* recall )/ (prec+recall)\n",
    "    F= 2.0*( tp)/ (2*tp + fp + fn)\n",
    "    \n",
    "    return acc, recall, prec, F\n",
    "\n",
    "def acc_match( true, pred ):\n",
    "    \"\"\"\n",
    "    returns exact mathc accuracy\n",
    "    \"\"\"\n",
    " \n",
    "    return (len( [ x  for x  in  [np.sum(np.abs( true[i]- pred[i] )) for i in range(len(true))] if x  == 0]))*1.0 / len(true)\n",
    "\n",
    "\n",
    "# def acc_none_zero ( true, pred ):\n",
    "    \n",
    "\n",
    "def acc_match_wierd( true, pred ):\n",
    "    \"\"\"\n",
    "    returns exact mathc accuracy\n",
    "    \"\"\"\n",
    "    level = 6 \n",
    "    switch = 11\n",
    "    threeAxis=13\n",
    "    accel = 0 \n",
    "    status=10\n",
    "    contact=5\n",
    "    \n",
    "    counter  = 0 \n",
    "    for i in range( len (true) ):\n",
    "        if np.sum(np.abs( true[i]- pred[i] ))==0 :\n",
    "            counter+=1\n",
    "        else : \n",
    "            t_rec = np.array(list( pred[i]))\n",
    "            \n",
    "            if true[i][level]==1 and true[i][switch]==1 and t_rec[level]==1 :\n",
    "                t_rec[switch]=1\n",
    "            \n",
    "            if true[i][threeAxis]==1 and true[i][accel]==1 and t_rec[threeAxis]==1:\n",
    "                t_rec[accel] =1\n",
    "            \n",
    "            if true[i][status]==1 and true[i][contact]==1 and t_rec[status]==1:\n",
    "                t_rec[contact]=1\n",
    "#             print(t_rec , true[i])    \n",
    "            if np.sum(np.abs( true[i]- t_rec ))==0 :\n",
    "                counter+=1   \n",
    "            \n",
    "             \n",
    "            \n",
    "    \n",
    "    return counter*1.0 / len(true)\n",
    "\n",
    "\n",
    "def print_info(y_test, pred , classes , confidance=0.5, print_skf1=False):\n",
    "    \n",
    "    counts = np.sum( y_test.astype(int) , axis=0)\n",
    "    \n",
    "    pred[pred>=confidance] = 1\n",
    "    pred[pred<confidance] = 0\n",
    "    \n",
    "#     acc_wierd  =acc_match_wierd(y_test, pred)\n",
    "    \n",
    "    conf= multilabel_confusion_matrix( y_test , pred.astype(int), labels= range(len(classes)))\n",
    "    accs = [make_recall_shit(x) for x in conf]\n",
    "    print( \"%30s  %8s   %8s  %8s  %8s %8s %22s\"  %( \"Class\",\"Accuracy\", \"Recall\",\"Precision\",\"F Score\" , \"Count\", \"TP/TN/FP/FN\"))\n",
    "    print( \"------------------------------------------------------------------------\" )\n",
    "    ret  = [] \n",
    "    ret_description = [\"Class\",\"Accuracy\", \"Recall\",\"Precision\",\"F Score\" , \"Count\", \"TP\",\"TN\",\"FP\",\"FN\"]\n",
    "    for index in range(len(classes)):\n",
    "        tp = conf[index][1][1]\n",
    "        tn = conf[index][0][0]\n",
    "        fp = conf[index][0][1] \n",
    "        fn = conf[index][1][0]\n",
    "        item = (classes[index],\n",
    "              accs[index][0],\n",
    "              accs[index][1],\n",
    "              accs[index][2],\n",
    "              accs[index][3],\n",
    "              counts[index],\n",
    "                  tp ,\n",
    "                tn ,\n",
    "                fp ,\n",
    "                fn)\n",
    "        print( \"%30s  %8.3f   %8.3f  %8.3f  %8.3f  %8d %5d/%5d/%5d/%5d\"  %  item )\n",
    "        ret.append(item)\n",
    "        \n",
    "    n_zeros_true = len([ x  for x  in  [np.sum(np.abs( y_test[i] )) for i in range(len(y_test))] if x  == 0]  )\n",
    "    n_zeros_pred = len([ x  for x  in  [np.sum(np.abs( pred[i] )) for i in range(len(pred))] if x  == 0]  )\n",
    "    \n",
    "    accs = np.nan_to_num(accs)\n",
    "    \n",
    "    print (\"------------------------------------------------------------------------\")\n",
    "    print( \"%30s  %8.3f   %8.3f  %8.3f  %8.3f  %8d %5d/%5d/%5d/%5d\"  %\n",
    "             (\"AVERAGES\",\n",
    "              np.average( accs, axis=0)[0],\n",
    "              np.average( accs, axis=0)[1],\n",
    "              np.average( accs, axis=0)[2],\n",
    "              np.average( accs, axis=0)[3],\n",
    "              len(y_test),\n",
    "                  0 ,\n",
    "                0,\n",
    "                0 ,\n",
    "                0 ))\n",
    "    print (\"------------------------------------------------------------------------\")\n",
    "    print( \"%30s  %8.3f   %8.3f  %8.3f  %8.3f  %8d %5d/%5d/%5d/%5d\"  %\n",
    "             (\"Weighted AVERAGES\",\n",
    "              np.average( accs, weights=counts, axis=0)[0],\n",
    "              np.average( accs, weights=counts, axis=0)[1],\n",
    "              np.average( accs, weights=counts, axis=0)[2],\n",
    "              np.average( accs, weights=counts, axis=0)[3],\n",
    "              len(y_test),\n",
    "                  0 ,\n",
    "                0,\n",
    "                0 ,\n",
    "                0 ))\n",
    "    \n",
    "    print (\"------------------------------------------------------------------------\")\n",
    "    unknonw_index = [classes.index('unknown')]\n",
    "#     print(unknonw_index, len(accs))\n",
    "    accs_new = np.delete(accs,unknonw_index,0)\n",
    "    counts_new = [x for i,x in enumerate(counts) if i not in unknonw_index]\n",
    "#     print(unknonw_index, len(counts), len(counts_new),len(accs), len(accs_new))\n",
    "#     print(unknonw_index, len(accs))\n",
    "    print( \"%30s  %8.3f   %8.3f  %8.3f  %8.3f  %8d %5d/%5d/%5d/%5d\"  %\n",
    "             (\"known Weighted AVERAGES\",\n",
    "              np.average( accs_new, weights=counts_new, axis=0)[0],\n",
    "              np.average( accs_new, weights=counts_new, axis=0)[1],\n",
    "              np.average( accs_new, weights=counts_new, axis=0)[2],\n",
    "              np.average( accs_new, weights=counts_new, axis=0)[3],\n",
    "              len(y_test),\n",
    "                  0 ,\n",
    "                0,\n",
    "                0 ,\n",
    "                0 ))\n",
    "    \n",
    "    print (\"------------------------------------------------------------------------\")\n",
    "    if 'ping' in classes:\n",
    "        unknonw_index = [classes.index('unknown'), classes.index('ping')]\n",
    "    #     print(unknonw_index, len(accs))\n",
    "        accs_new = np.delete(accs,unknonw_index,0)\n",
    "        counts_new = [x for i,x in enumerate(counts) if i not in unknonw_index]\n",
    "    #     print(unknonw_index, len(counts), len(counts_new),len(accs), len(accs_new))\n",
    "    #     print(unknonw_index, len(accs))\n",
    "        print( \"%30s  %8.3f   %8.3f  %8.3f  %8.3f  %8d %5d/%5d/%5d/%5d\"  %\n",
    "                 (\"known -ping Weighted AVERAGES\",\n",
    "                  np.average( accs_new, weights=counts_new, axis=0)[0],\n",
    "                  np.average( accs_new, weights=counts_new, axis=0)[1],\n",
    "                  np.average( accs_new, weights=counts_new, axis=0)[2],\n",
    "                  np.average( accs_new, weights=counts_new, axis=0)[3],\n",
    "                  len(y_test),\n",
    "                      0 ,\n",
    "                    0,\n",
    "                    0 ,\n",
    "                    0 ))\n",
    "\n",
    "    print (\"------------------------------------------------------------------------\")\n",
    "    unknonw_index = classes.index('unknown')\n",
    "#     print(unknonw_index, len(accs))\n",
    "    to_delete = [i for i,x in enumerate(counts) if x == 0 ]\n",
    "    accs_new = np.delete(accs,to_delete,0)\n",
    "    counts_new = [x for i,x in enumerate(counts) if i not in  to_delete]\n",
    "#     print(unknonw_index, len(counts), len(counts_new),len(accs), len(accs_new))\n",
    "#     print(unknonw_index, len(accs))\n",
    "    print( \"%30s  %8.3f   %8.3f  %8.3f  %8.3f  %8d %5d/%5d/%5d/%5d\"  %\n",
    "             (\"non zero count AVERAGES\",\n",
    "              np.average( accs_new, axis=0)[0],\n",
    "              np.average( accs_new, axis=0)[1],\n",
    "              np.average( accs_new, axis=0)[2],\n",
    "              np.average( accs_new, axis=0)[3],\n",
    "              len(y_test),\n",
    "                  0 ,\n",
    "                0,\n",
    "                0 ,\n",
    "                0 ))\n",
    "    \n",
    "    print (\"------------------------------------------------------------------------\")\n",
    "    from sklearn.metrics import f1_score\n",
    "    f1 = f1_score(y_test, pred, average='macro')\n",
    "    print(\"Macro F1 : %f\" % f1)\n",
    "    f1 = f1_score(y_test, pred, average='samples')\n",
    "    print(\"sample F1 : %f\" % f1)\n",
    "    f1 = f1_score(y_test, pred, average='weighted')\n",
    "    print(\"weighted F1 : %f\" % f1)\n",
    "\n",
    "    \n",
    "    if 'ping' in classes and print_skf1:\n",
    "        unknonw_index = classes.index('unknown')\n",
    "        ping_index = classes.index('ping')\n",
    "        print (\"--------------------------removed ping and unknown----------------------------------------------\")\n",
    "        to_remove_indexes = [i for i,x in enumerate(pred) if x[ping_index]+x[unknonw_index] > 0.5]\n",
    "        new_pred   =np.array( [x for i,x  in enumerate(pred) if i not in to_remove_indexes ])\n",
    "        new_y_test = np.array([x for i,x  in enumerate(y_test) if i not in to_remove_indexes ])\n",
    "        f1 = f1_score(new_y_test, new_pred, average='macro')\n",
    "        print(\"Macro F1 : %f\" % f1)\n",
    "        f1 = f1_score(new_y_test, new_pred, average='samples')\n",
    "        print(\"sample F1 : %f\" % f1)\n",
    "        f1 = f1_score(new_y_test, new_pred, average='weighted')\n",
    "        print(\"weighted F1 : %f\" % f1)\n",
    "\n",
    "    \n",
    "    \n",
    "    print ( \"Exact Match ACC : %.5f \" % acc_match( y_test, pred )  )\n",
    "#     print ( \"Wierd Exact Match ACC : %.5f\" % acc_wierd)\n",
    "    print ( \"Total Records : %d \" % len(y_test)  )\n",
    "    print ( \"Total ZXeros in True : %d (%.3f)%%\" % (n_zeros_true ,  n_zeros_true * 1.0/ len(y_test)  ))\n",
    "    print ( \"Total ZXeros in Test : %d (%.3f)%%\" % (n_zeros_pred ,  n_zeros_pred * 1.0/ len(y_test)  ) )\n",
    "    print ('=============================================================================')\n",
    "    \n",
    "    return ret, ret_description\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def weighted_categorical_crossentropy(weights):\n",
    "    \"\"\"\n",
    "    A weighted version of keras.objectives.categorical_crossentropy\n",
    "    \n",
    "    Variables:\n",
    "        weights: numpy array of shape (C,) where C is the number of classes\n",
    "    \n",
    "    Usage:\n",
    "        weights = np.array([0.5,2,10]) # Class one at 0.5, class 2 twice the normal weights, class 3 10x.\n",
    "        loss = weighted_categorical_crossentropy(weights)\n",
    "        model.compile(loss=loss,optimizer='adam')\n",
    "    \"\"\"\n",
    "    \n",
    "    weights = K.variable(weights)\n",
    "        \n",
    "    def loss(y_true, y_pred):\n",
    "        # scale predictions so that the class probas of each sample sum to 1\n",
    "        y_pred /= K.sum(y_pred, axis=-1, keepdims=True)\n",
    "        # clip to prevent NaN's and Inf's\n",
    "        y_pred = K.clip(y_pred, K.epsilon(), 1 - K.epsilon())\n",
    "        # calc\n",
    "        loss = y_true * K.log(y_pred) * weights\n",
    "        loss = -K.sum(loss, -1)\n",
    "        return loss\n",
    "    \n",
    "    return loss\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "def f1_perRow(y_true, y_pred):\n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return K.mean(f1)\n",
    "\n",
    "\n",
    "def f1_perClass(y_true, y_pred):\n",
    "\n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=1)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=1)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=1)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=1)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return K.mean(f1)\n",
    "\n",
    "def f1_loss_perClass(y_true, y_pred):\n",
    "    \n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=1)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=1)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=1)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=1)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return (1 - K.mean(f1))**2\n",
    "\n",
    "def f1_loss_perRow(y_true, y_pred):\n",
    "    \n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return (1 - K.mean(f1))**2\n",
    "\n",
    "def make_readable_results ( inp , classes , conffidance=True):\n",
    "    ret = [] \n",
    "    inp =inp.astype(int)\n",
    "    for xx in range(len(inp)) :\n",
    "        u = inp[xx]\n",
    "        temp = []\n",
    "        for j in range(len(u)) : \n",
    "            if u[j] >0:\n",
    "                temp.append(classes[j])\n",
    "        ret.append(temp)\n",
    "    return ret\n",
    "\n",
    "\n",
    "def makeReadable( model , data, gt, path , classes, x, confidance=0.5):\n",
    "    #collect across multi models\n",
    "    from keras.models import load_model\n",
    "    x=[]\n",
    "    for i in range(0,16):\n",
    "        model=load_model('number'+str(i)+'.h5',custom_objects={'f1_perRow':f1_perRow,'f1_perClass':f1_perClass,'f1_loss_perRow':f1_loss_perRow,'f1_loss_perClass':f1_loss_perClass})\n",
    "        x.append(model.predict(data))\n",
    "    x=np.array(x)\n",
    "    x=np.transpose(x)\n",
    "    x=np.squeeze(x)\n",
    "    print(x.shape)\n",
    "        \n",
    "        \n",
    "    pred_temp  = x\n",
    "    #pred_temp = model.predict(data)\n",
    "    print_info(gt, x, classes , confidance=confidance)\n",
    "#     print( len(classes ), len( pred_temp[0] ) )\n",
    "#     xcc= make_readable_results(pred_temp , classes)\n",
    "#     y_gt = make_readable_results( gt, classes )\n",
    "#     temp_dic = {} \n",
    "#     for pick in range(len(xcc)): \n",
    "#         temp_dic[ pick +1 ] =  { 'seq': str(data[pick]),\n",
    "#                                'pred': xcc[pick],\n",
    "#                                 'true':y_gt[pick]\n",
    "#                                }   \n",
    "\n",
    "#     with open(path , 'w') as f:\n",
    "#         json.dump(temp_dic , f, indent=4)\n",
    "\n",
    "\n",
    "# def makeReadable( model , data, gt, path , classes, confidance=0.7, x):\n",
    "#     pred_temp = model.predict( data)\n",
    "#     print_info(gt, pred_temp, classes , confidance=confidance)\n",
    "#     xcc= make_readable_results( pred_temp , classes )\n",
    "#     temp_dic = {} \n",
    "#     for pick in range(len(xcc)): \n",
    "#         temp_dic[ pick +1 ] = xcc[pick]  \n",
    "\n",
    "#     with open(path , 'w') as f:\n",
    "#         json.dump(temp_dic , f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_unknowns_back(y_pred, original_y, indexes, classes):\n",
    "    unknown = [1 if classes[i] == 'unknown' else\n",
    "                        0  \n",
    "                       for i in range(len(classes))]\n",
    "    the_y = [unknown for i in range(len(original_y))]\n",
    "    for i, v in enumerate(indexes):\n",
    "#         print(v)\n",
    "        the_y[v] = y_pred[i]\n",
    "    return np.array(the_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get the data and preprocess train and test portions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_size= 20\n",
    "x_random_forest_train,y_random_forest_train, _ = pre_process_raw( x_train, y_train , dim_size, zero_pad=False, normalize=False, classes=classes, as_string=True)\n",
    "rf_tests  = [ pre_process_raw( x_test[i], y_test[i] , dim_size, zero_pad=False, normalize=False, classes=classes, as_string=True) for i in range(len(x_test)) ] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "vectorize the X vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(analyzer='word', ngram_range=(1, 5))\n",
    "x_random_forest_train = vectorizer.fit_transform(x_random_forest_train)\n",
    "for x in range(len(rf_tests)):\n",
    "    rf_tests[x] = ( vectorizer.transform(rf_tests[x][0]),\n",
    "                    rf_tests[x][1],\n",
    "                    rf_tests[x][2]\n",
    "                  )\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "xgb_known_unknown_separator_classifier = OneVsRestClassifier(XGBClassifier())\n",
    "\n",
    "xgb_known_unknown_separator_classifier.fit(x_random_forest_train, np.array(known_unknown_y_train))\n",
    "\n",
    "train_known_unknown_pred=xgb_known_unknown_separator_classifier.predict_proba(x_random_forest_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================HOME Case : home_os_final.json =============\n",
      "                         Class  Accuracy     Recall  Precision   F Score    Count            TP/TN/FP/FN\n",
      "------------------------------------------------------------------------\n",
      "                       unknown     0.787      0.723     0.940     0.817     12580  9097/ 5930/  580/ 3483\n",
      "                         known     0.787      0.911     0.630     0.745      6510  5930/ 9097/ 3483/  580\n",
      "------------------------------------------------------------------------\n",
      "                      AVERAGES     0.787      0.817     0.785     0.781     19090     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "             Weighted AVERAGES     0.787      0.787     0.834     0.793     19090     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "       known Weighted AVERAGES     0.787      0.911     0.630     0.745     19090     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------\n",
      "       non zero count AVERAGES     0.787      0.817     0.785     0.781     19090     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "Macro F1 : 0.781143\n",
      "sample F1 : 0.787166\n",
      "weighted F1 : 0.792687\n",
      "Exact Match ACC : 0.78717 \n",
      "Total Records : 19090 \n",
      "Total ZXeros in True : 0 (0.000)%\n",
      "Total ZXeros in Test : 0 (0.000)%\n",
      "=============================================================================\n",
      "==================HOME Case : test_data_light.json =============\n",
      "                         Class  Accuracy     Recall  Precision   F Score    Count            TP/TN/FP/FN\n",
      "------------------------------------------------------------------------\n",
      "                       unknown     0.808      0.621     0.988     0.763       132    82/  132/    1/   50\n",
      "                         known     0.808      0.992     0.725     0.838       133   132/   82/   50/    1\n",
      "------------------------------------------------------------------------\n",
      "                      AVERAGES     0.808      0.807     0.857     0.800       265     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "             Weighted AVERAGES     0.808      0.808     0.856     0.801       265     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "       known Weighted AVERAGES     0.808      0.992     0.725     0.838       265     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------\n",
      "       non zero count AVERAGES     0.808      0.807     0.857     0.800       265     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "Macro F1 : 0.800443\n",
      "sample F1 : 0.807547\n",
      "weighted F1 : 0.800585\n",
      "Exact Match ACC : 0.80755 \n",
      "Total Records : 265 \n",
      "Total ZXeros in True : 0 (0.000)%\n",
      "Total ZXeros in Test : 0 (0.000)%\n",
      "=============================================================================\n",
      "==================HOME Case : test_data_motion_2.json =============\n",
      "                         Class  Accuracy     Recall  Precision   F Score    Count            TP/TN/FP/FN\n",
      "------------------------------------------------------------------------\n",
      "                       unknown     0.808      0.751     0.966     0.845      7270  5458/ 2974/  192/ 1812\n",
      "                         known     0.808      0.939     0.621     0.748      3166  2974/ 5458/ 1812/  192\n",
      "------------------------------------------------------------------------\n",
      "                      AVERAGES     0.808      0.845     0.794     0.796     10436     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "             Weighted AVERAGES     0.808      0.808     0.861     0.815     10436     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "       known Weighted AVERAGES     0.808      0.939     0.621     0.748     10436     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------\n",
      "       non zero count AVERAGES     0.808      0.845     0.794     0.796     10436     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "Macro F1 : 0.796440\n",
      "sample F1 : 0.807972\n",
      "weighted F1 : 0.815494\n",
      "Exact Match ACC : 0.80797 \n",
      "Total Records : 10436 \n",
      "Total ZXeros in True : 0 (0.000)%\n",
      "Total ZXeros in Test : 0 (0.000)%\n",
      "=============================================================================\n"
     ]
    }
   ],
   "source": [
    "test_known_unknown_predicted = []\n",
    "for i in range(len(rf_tests)) :\n",
    "    print( \"==================HOME Case : %s =============\" % test_names[ i] )\n",
    "    rf_pred=xgb_known_unknown_separator_classifier.predict( rf_tests[i][0])\n",
    "    test_known_unknown_predicted.append(rf_pred)\n",
    "    print_info( np.array( known_unknown_y_test[i]), rf_pred, [\"unknown\",\"known\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "known_indexes_train  = [ i for i in range(len(train_known_unknown_pred)) if train_known_unknown_pred[i][1] ==1 ]\n",
    "\n",
    "x_train_known = x_random_forest_train[known_indexes_train]\n",
    "y_train_known = y_random_forest_train[known_indexes_train]\n",
    "\n",
    "rf_test_known = [] \n",
    "\n",
    "for test_index in range(len(test_known_unknown_predicted)):\n",
    "    known_indexes= [ i for i in range(len(test_known_unknown_predicted[test_index])) if test_known_unknown_predicted[test_index][i][1] ==1 ]\n",
    "    \n",
    "    rf_test_known.append(  (rf_tests[test_index][0][known_indexes], \n",
    "                            rf_tests[test_index][1][known_indexes],\n",
    "                            rf_tests[test_index][2],\n",
    "                            known_indexes\n",
    "                           ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneVsRestClassifier(estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                            colsample_bylevel=None,\n",
       "                                            colsample_bynode=None,\n",
       "                                            colsample_bytree=None, gamma=None,\n",
       "                                            gpu_id=None, importance_type='gain',\n",
       "                                            interaction_constraints=None,\n",
       "                                            learning_rate=None,\n",
       "                                            max_delta_step=None, max_depth=None,\n",
       "                                            min_child_weight=None, missing=nan,\n",
       "                                            monotone_constraints=None,\n",
       "                                            n_estimators=100, n_jobs=None,\n",
       "                                            num_parallel_tree=None,\n",
       "                                            objective='binary:logistic',\n",
       "                                            random_state=None, reg_alpha=None,\n",
       "                                            reg_lambda=None,\n",
       "                                            scale_pos_weight=None,\n",
       "                                            subsample=None, tree_method=None,\n",
       "                                            validate_parameters=False,\n",
       "                                            verbosity=None),\n",
       "                    n_jobs=None)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_classifier = OneVsRestClassifier(XGBClassifier())\n",
    "\n",
    "xgb_classifier.fit(x_random_forest_train, np.array(y_random_forest_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================HOME Case : home_os_final.json =============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/omid/.conda/envs/iot/lib/python3.6/site-packages/ipykernel_launcher.py:8: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         Class  Accuracy     Recall  Precision   F Score    Count            TP/TN/FP/FN\n",
      "------------------------------------------------------------------------\n",
      "                  acceleration     0.996      0.193     0.256     0.220        57    11/19001/   32/   46\n",
      "                      activity     0.999      0.625     0.714     0.667        16    10/19070/    4/    6\n",
      "                       battery     0.999      0.000     0.000     0.000         7     0/19075/    8/    7\n",
      "                        button     1.000      0.750     0.692     0.720        12     9/19074/    4/    3\n",
      "              colorTemperature     1.000      0.800     0.800     0.800         5     4/19084/    1/    1\n",
      "                       contact     0.993      0.570     0.534     0.551       151    86/18864/   75/   65\n",
      "                         level     0.986      0.800     0.057     0.106        20    16/18805/  265/    4\n",
      "                          lock     1.000      0.941     0.889     0.914        34    32/19052/    4/    2\n",
      "                        motion     0.971      0.493     0.312     0.382       343   169/18374/  373/  174\n",
      "                       no_logs     0.943        nan     0.000     0.000         0     0/17993/ 1097/    0\n",
      "                          ping     0.986      0.947     0.996     0.971      4814  4557/14258/   18/  257\n",
      "                        status     0.996      0.504     0.797     0.618       117    59/18958/   15/   58\n",
      "                        switch     0.999      0.571     0.857     0.686        21    12/19067/    2/    9\n",
      "                   temperature     0.908      0.446     0.307     0.364      1120   500/16841/ 1129/  620\n",
      "                     threeAxis     0.999      0.472     0.680     0.557        36    17/19046/    8/   19\n",
      "                       unknown     0.775      0.723     0.939     0.817     13223  9559/ 5242/  625/ 3664\n",
      "                         water     0.993        nan     0.000     0.000         0     0/18948/  142/    0\n",
      "------------------------------------------------------------------------\n",
      "                      AVERAGES     0.973      0.520     0.519     0.493     19090     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "             Weighted AVERAGES     0.842      0.753     0.898     0.815     19090     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "       known Weighted AVERAGES     0.973      0.812     0.819     0.810     19090     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      " known -ping Weighted AVERAGES     0.941      0.477     0.380     0.411     19090     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "       non zero count AVERAGES     0.974      0.589     0.589     0.558     19090     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "Macro F1 : 0.492506\n",
      "sample F1 : 0.760391\n",
      "weighted F1 : 0.814505\n",
      "--------------------------removed ping and unknown----------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/omid/.conda/envs/iot/lib/python3.6/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/home/omid/.conda/envs/iot/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/omid/.conda/envs/iot/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macro F1 : 0.408141\n",
      "sample F1 : 0.169925\n",
      "weighted F1 : 0.122055\n",
      "Exact Match ACC : 0.75600 \n",
      "Total Records : 19090 \n",
      "Total ZXeros in True : 0 (0.000)%\n",
      "Total ZXeros in Test : 900 (0.047)%\n",
      "=============================================================================\n",
      "==================HOME Case : test_data_light.json =============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/omid/.conda/envs/iot/lib/python3.6/site-packages/ipykernel_launcher.py:9: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  if __name__ == '__main__':\n",
      "/home/omid/.conda/envs/iot/lib/python3.6/site-packages/ipykernel_launcher.py:12: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         Class  Accuracy     Recall  Precision   F Score    Count            TP/TN/FP/FN\n",
      "------------------------------------------------------------------------\n",
      "                  acceleration     1.000        nan       nan       nan         0     0/  265/    0/    0\n",
      "                      activity     1.000        nan       nan       nan         0     0/  265/    0/    0\n",
      "                       battery     1.000        nan       nan       nan         0     0/  265/    0/    0\n",
      "                        button     1.000        nan       nan       nan         0     0/  265/    0/    0\n",
      "              colorTemperature     0.977      0.871     0.931     0.900        31    27/  232/    2/    4\n",
      "                       contact     1.000        nan       nan       nan         0     0/  265/    0/    0\n",
      "                         level     0.849      0.723     0.779     0.750        83    60/  165/   17/   23\n",
      "                          lock     1.000        nan       nan       nan         0     0/  265/    0/    0\n",
      "                        motion     0.974        nan     0.000     0.000         0     0/  258/    7/    0\n",
      "                       no_logs     0.951        nan     0.000     0.000         0     0/  252/   13/    0\n",
      "                          ping     1.000      1.000     1.000     1.000        26    26/  239/    0/    0\n",
      "                        status     1.000        nan       nan       nan         0     0/  265/    0/    0\n",
      "                        switch     0.947      0.417     1.000     0.588        24    10/  241/    0/   14\n",
      "                   temperature     0.970      0.000     0.000     0.000         2     0/  257/    6/    2\n",
      "                     threeAxis     1.000        nan       nan       nan         0     0/  265/    0/    0\n",
      "                       unknown     0.800      0.638     0.967     0.769       138    88/  124/    3/   50\n",
      "                         water     0.974        nan     0.000     0.000         0     0/  258/    7/    0\n",
      "------------------------------------------------------------------------\n",
      "                      AVERAGES     0.967      0.215     0.275     0.236       265     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "             Weighted AVERAGES     0.861      0.694     0.911     0.777       265     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "       known Weighted AVERAGES     0.912      0.741     0.865     0.785       265     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      " known -ping Weighted AVERAGES     0.896      0.693     0.840     0.745       265     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "       non zero count AVERAGES     0.924      0.608     0.780     0.668       265     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "Macro F1 : 0.235694\n",
      "sample F1 : 0.681761\n",
      "weighted F1 : 0.777397\n",
      "--------------------------removed ping and unknown----------------------------------------------\n",
      "Macro F1 : 0.131661\n",
      "sample F1 : 0.470085\n",
      "weighted F1 : 0.551681\n",
      "Exact Match ACC : 0.60377 \n",
      "Total Records : 265 \n",
      "Total ZXeros in True : 0 (0.000)%\n",
      "Total ZXeros in Test : 34 (0.128)%\n",
      "=============================================================================\n",
      "==================HOME Case : test_data_motion_2.json =============\n",
      "                         Class  Accuracy     Recall  Precision   F Score    Count            TP/TN/FP/FN\n",
      "------------------------------------------------------------------------\n",
      "                  acceleration     0.997      0.067     0.333     0.111        30     2/10402/    4/   28\n",
      "                      activity     1.000        nan       nan       nan         0     0/10436/    0/    0\n",
      "                       battery     1.000      0.000       nan     0.000         1     0/10435/    0/    1\n",
      "                        button     0.993        nan     0.000     0.000         0     0/10367/   69/    0\n",
      "              colorTemperature     1.000      1.000     1.000     1.000         3     3/10433/    0/    0\n",
      "                       contact     0.987      0.008     0.200     0.015       131     1/10301/    4/  130\n",
      "                         level     0.997      1.000     0.139     0.244         5     5/10400/   31/    0\n",
      "                          lock     0.999        nan     0.000     0.000         0     0/10425/   11/    0\n",
      "                        motion     0.921      0.286     0.136     0.185       325    93/ 9522/  589/  232\n",
      "                       no_logs     0.999      0.500     0.091     0.154         2     1/10424/   10/    1\n",
      "                          ping     0.986      0.974     0.971     0.973      2662  2594/ 7697/   77/   68\n",
      "                        status     1.000        nan       nan       nan         0     0/10436/    0/    0\n",
      "                        switch     1.000      0.500     1.000     0.667         2     1/10434/    0/    1\n",
      "                   temperature     0.973      0.420     0.076     0.128        50    21/10130/  256/   29\n",
      "                     threeAxis     0.998      0.000       nan     0.000        18     0/10418/    0/   18\n",
      "                       unknown     0.807      0.774     0.958     0.856      7744  5994/ 2432/  260/ 1750\n",
      "                         water     0.997        nan     0.000     0.000         0     0/10404/   32/    0\n",
      "------------------------------------------------------------------------\n",
      "                      AVERAGES     0.980      0.325     0.289     0.255     10436     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "             Weighted AVERAGES     0.858      0.794     0.920     0.847     10436     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "       known Weighted AVERAGES     0.980      0.843     0.829     0.826     10436     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      " known -ping Weighted AVERAGES     0.949      0.224     0.159     0.137     10436     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "       non zero count AVERAGES     0.972      0.461     0.409     0.361     10436     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "Macro F1 : 0.254859\n",
      "sample F1 : 0.790466\n",
      "weighted F1 : 0.847464\n",
      "--------------------------removed ping and unknown----------------------------------------------\n",
      "Macro F1 : 0.153879\n",
      "sample F1 : 0.057848\n",
      "weighted F1 : 0.024154\n",
      "Exact Match ACC : 0.78085 \n",
      "Total Records : 10436 \n",
      "Total ZXeros in True : 0 (0.000)%\n",
      "Total ZXeros in Test : 973 (0.093)%\n",
      "=============================================================================\n"
     ]
    }
   ],
   "source": [
    "xg_boost_results = []\n",
    "for i in range(len(rf_test_known)) :\n",
    "    print( \"==================HOME Case : %s =============\" % test_names[ i] )\n",
    "    rf_pred= xgb_classifier.predict( rf_test_known[i][0])\n",
    "    rf_pred = add_unknowns_back(rf_pred,rf_tests[i][1], rf_test_known[i][3] , classes)\n",
    "    xg_boost_results.append(print_info( rf_tests[i][1], rf_pred, classes, confidance=0.8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================HOME Case : home_os_final.json =============\n",
      "                         Class  Accuracy     Recall  Precision   F Score    Count            TP/TN/FP/FN\n",
      "------------------------------------------------------------------------\n",
      "                       unknown     0.787      0.723     0.940     0.817     12580  9097/ 5930/  580/ 3483\n",
      "                         known     0.787      0.911     0.630     0.745      6510  5930/ 9097/ 3483/  580\n",
      "------------------------------------------------------------------------\n",
      "                      AVERAGES     0.787      0.817     0.785     0.781     19090     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "             Weighted AVERAGES     0.787      0.787     0.834     0.793     19090     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "       known Weighted AVERAGES     0.787      0.911     0.630     0.745     19090     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------\n",
      "       non zero count AVERAGES     0.787      0.817     0.785     0.781     19090     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "Macro F1 : 0.781143\n",
      "sample F1 : 0.787166\n",
      "weighted F1 : 0.792687\n",
      "Exact Match ACC : 0.78717 \n",
      "Total Records : 19090 \n",
      "Total ZXeros in True : 0 (0.000)%\n",
      "Total ZXeros in Test : 0 (0.000)%\n",
      "=============================================================================\n",
      "==================HOME Case : test_data_light.json =============\n",
      "                         Class  Accuracy     Recall  Precision   F Score    Count            TP/TN/FP/FN\n",
      "------------------------------------------------------------------------\n",
      "                       unknown     0.808      0.621     0.988     0.763       132    82/  132/    1/   50\n",
      "                         known     0.808      0.992     0.725     0.838       133   132/   82/   50/    1\n",
      "------------------------------------------------------------------------\n",
      "                      AVERAGES     0.808      0.807     0.857     0.800       265     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "             Weighted AVERAGES     0.808      0.808     0.856     0.801       265     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "       known Weighted AVERAGES     0.808      0.992     0.725     0.838       265     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------\n",
      "       non zero count AVERAGES     0.808      0.807     0.857     0.800       265     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "Macro F1 : 0.800443\n",
      "sample F1 : 0.807547\n",
      "weighted F1 : 0.800585\n",
      "Exact Match ACC : 0.80755 \n",
      "Total Records : 265 \n",
      "Total ZXeros in True : 0 (0.000)%\n",
      "Total ZXeros in Test : 0 (0.000)%\n",
      "=============================================================================\n",
      "==================HOME Case : test_data_motion_2.json =============\n",
      "                         Class  Accuracy     Recall  Precision   F Score    Count            TP/TN/FP/FN\n",
      "------------------------------------------------------------------------\n",
      "                       unknown     0.808      0.751     0.966     0.845      7270  5458/ 2974/  192/ 1812\n",
      "                         known     0.808      0.939     0.621     0.748      3166  2974/ 5458/ 1812/  192\n",
      "------------------------------------------------------------------------\n",
      "                      AVERAGES     0.808      0.845     0.794     0.796     10436     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "             Weighted AVERAGES     0.808      0.808     0.861     0.815     10436     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "       known Weighted AVERAGES     0.808      0.939     0.621     0.748     10436     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------\n",
      "       non zero count AVERAGES     0.808      0.845     0.794     0.796     10436     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "Macro F1 : 0.796440\n",
      "sample F1 : 0.807972\n",
      "weighted F1 : 0.815494\n",
      "Exact Match ACC : 0.80797 \n",
      "Total Records : 10436 \n",
      "Total ZXeros in True : 0 (0.000)%\n",
      "Total ZXeros in Test : 0 (0.000)%\n",
      "=============================================================================\n"
     ]
    }
   ],
   "source": [
    "test_known_unknown_predicted = []\n",
    "for i in range(len(rf_tests)) :\n",
    "    print( \"==================HOME Case : %s =============\" % test_names[ i] )\n",
    "    rf_pred=xgb_known_unknown_separator_classifier.predict( rf_tests[i][0])\n",
    "    test_known_unknown_predicted.append(rf_pred)\n",
    "    print_info( np.array( known_unknown_y_test[i]), rf_pred, [\"unknown\",\"known\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "separate known and unknowns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "known_indexes_train  = [ i for i in range(len(train_known_unknown_pred)) if train_known_unknown_pred[i][1] ==1 ]\n",
    "\n",
    "x_train_known = x_random_forest_train[known_indexes_train]\n",
    "y_train_known = y_random_forest_train[known_indexes_train]\n",
    "\n",
    "rf_test_known = [] \n",
    "\n",
    "for test_index in range(len(test_known_unknown_predicted)):\n",
    "    known_indexes= [ i for i in range(len(test_known_unknown_predicted[test_index])) if test_known_unknown_predicted[test_index][i][1] ==1 ]\n",
    "    \n",
    "    rf_test_known.append(  (rf_tests[test_index][0][known_indexes], \n",
    "                            rf_tests[test_index][1][known_indexes],\n",
    "                            rf_tests[test_index][2],\n",
    "                            known_indexes\n",
    "                           ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneVsRestClassifier(estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                            colsample_bylevel=None,\n",
       "                                            colsample_bynode=None,\n",
       "                                            colsample_bytree=None, gamma=None,\n",
       "                                            gpu_id=None, importance_type='gain',\n",
       "                                            interaction_constraints=None,\n",
       "                                            learning_rate=None,\n",
       "                                            max_delta_step=None, max_depth=None,\n",
       "                                            min_child_weight=None, missing=nan,\n",
       "                                            monotone_constraints=None,\n",
       "                                            n_estimators=100, n_jobs=None,\n",
       "                                            num_parallel_tree=None,\n",
       "                                            objective='binary:logistic',\n",
       "                                            random_state=None, reg_alpha=None,\n",
       "                                            reg_lambda=None,\n",
       "                                            scale_pos_weight=None,\n",
       "                                            subsample=None, tree_method=None,\n",
       "                                            validate_parameters=False,\n",
       "                                            verbosity=None),\n",
       "                    n_jobs=None)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_classifier = OneVsRestClassifier(XGBClassifier())\n",
    "\n",
    "xgb_classifier.fit(x_random_forest_train, np.array(y_random_forest_train))\n",
    "\n",
    "# train_known_unknown_pred=xgb_classifier.predict_proba(x_random_forest_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with putting back teh unknowns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================HOME Case : home_os_final.json =============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/omid/.conda/envs/iot/lib/python3.6/site-packages/ipykernel_launcher.py:8: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         Class  Accuracy     Recall  Precision   F Score    Count            TP/TN/FP/FN\n",
      "------------------------------------------------------------------------\n",
      "                  acceleration     0.996      0.193     0.256     0.220        57    11/19001/   32/   46\n",
      "                      activity     0.999      0.625     0.714     0.667        16    10/19070/    4/    6\n",
      "                       battery     0.999      0.000     0.000     0.000         7     0/19075/    8/    7\n",
      "                        button     1.000      0.750     0.692     0.720        12     9/19074/    4/    3\n",
      "              colorTemperature     1.000      0.800     0.800     0.800         5     4/19084/    1/    1\n",
      "                       contact     0.993      0.570     0.534     0.551       151    86/18864/   75/   65\n",
      "                         level     0.986      0.800     0.057     0.106        20    16/18805/  265/    4\n",
      "                          lock     1.000      0.941     0.889     0.914        34    32/19052/    4/    2\n",
      "                        motion     0.971      0.493     0.312     0.382       343   169/18374/  373/  174\n",
      "                       no_logs     0.943        nan     0.000     0.000         0     0/17993/ 1097/    0\n",
      "                          ping     0.986      0.947     0.996     0.971      4814  4557/14258/   18/  257\n",
      "                        status     0.996      0.504     0.797     0.618       117    59/18958/   15/   58\n",
      "                        switch     0.999      0.571     0.857     0.686        21    12/19067/    2/    9\n",
      "                   temperature     0.908      0.446     0.307     0.364      1120   500/16841/ 1129/  620\n",
      "                     threeAxis     0.999      0.472     0.680     0.557        36    17/19046/    8/   19\n",
      "                       unknown     0.775      0.723     0.939     0.817     13223  9559/ 5242/  625/ 3664\n",
      "                         water     0.993        nan     0.000     0.000         0     0/18948/  142/    0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/omid/.conda/envs/iot/lib/python3.6/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/home/omid/.conda/envs/iot/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "                      AVERAGES     0.973      0.520     0.519     0.493     19090     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "             Weighted AVERAGES     0.842      0.753     0.898     0.815     19090     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "       known Weighted AVERAGES     0.973      0.812     0.819     0.810     19090     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      " known -ping Weighted AVERAGES     0.941      0.477     0.380     0.411     19090     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "       non zero count AVERAGES     0.974      0.589     0.589     0.558     19090     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "Macro F1 : 0.492506\n",
      "sample F1 : 0.760391\n",
      "weighted F1 : 0.814505\n",
      "--------------------------removed ping and unknown----------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/omid/.conda/envs/iot/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macro F1 : 0.408141\n",
      "sample F1 : 0.169925\n",
      "weighted F1 : 0.122055\n",
      "Exact Match ACC : 0.75600 \n",
      "Total Records : 19090 \n",
      "Total ZXeros in True : 0 (0.000)%\n",
      "Total ZXeros in Test : 900 (0.047)%\n",
      "=============================================================================\n",
      "==================HOME Case : test_data_light.json =============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/omid/.conda/envs/iot/lib/python3.6/site-packages/ipykernel_launcher.py:9: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  if __name__ == '__main__':\n",
      "/home/omid/.conda/envs/iot/lib/python3.6/site-packages/ipykernel_launcher.py:12: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         Class  Accuracy     Recall  Precision   F Score    Count            TP/TN/FP/FN\n",
      "------------------------------------------------------------------------\n",
      "                  acceleration     1.000        nan       nan       nan         0     0/  265/    0/    0\n",
      "                      activity     1.000        nan       nan       nan         0     0/  265/    0/    0\n",
      "                       battery     1.000        nan       nan       nan         0     0/  265/    0/    0\n",
      "                        button     1.000        nan       nan       nan         0     0/  265/    0/    0\n",
      "              colorTemperature     0.977      0.871     0.931     0.900        31    27/  232/    2/    4\n",
      "                       contact     1.000        nan       nan       nan         0     0/  265/    0/    0\n",
      "                         level     0.849      0.723     0.779     0.750        83    60/  165/   17/   23\n",
      "                          lock     1.000        nan       nan       nan         0     0/  265/    0/    0\n",
      "                        motion     0.974        nan     0.000     0.000         0     0/  258/    7/    0\n",
      "                       no_logs     0.951        nan     0.000     0.000         0     0/  252/   13/    0\n",
      "                          ping     1.000      1.000     1.000     1.000        26    26/  239/    0/    0\n",
      "                        status     1.000        nan       nan       nan         0     0/  265/    0/    0\n",
      "                        switch     0.947      0.417     1.000     0.588        24    10/  241/    0/   14\n",
      "                   temperature     0.970      0.000     0.000     0.000         2     0/  257/    6/    2\n",
      "                     threeAxis     1.000        nan       nan       nan         0     0/  265/    0/    0\n",
      "                       unknown     0.800      0.638     0.967     0.769       138    88/  124/    3/   50\n",
      "                         water     0.974        nan     0.000     0.000         0     0/  258/    7/    0\n",
      "------------------------------------------------------------------------\n",
      "                      AVERAGES     0.967      0.215     0.275     0.236       265     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "             Weighted AVERAGES     0.861      0.694     0.911     0.777       265     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "       known Weighted AVERAGES     0.912      0.741     0.865     0.785       265     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      " known -ping Weighted AVERAGES     0.896      0.693     0.840     0.745       265     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "       non zero count AVERAGES     0.924      0.608     0.780     0.668       265     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "Macro F1 : 0.235694\n",
      "sample F1 : 0.681761\n",
      "weighted F1 : 0.777397\n",
      "--------------------------removed ping and unknown----------------------------------------------\n",
      "Macro F1 : 0.131661\n",
      "sample F1 : 0.470085\n",
      "weighted F1 : 0.551681\n",
      "Exact Match ACC : 0.60377 \n",
      "Total Records : 265 \n",
      "Total ZXeros in True : 0 (0.000)%\n",
      "Total ZXeros in Test : 34 (0.128)%\n",
      "=============================================================================\n",
      "==================HOME Case : test_data_motion_2.json =============\n",
      "                         Class  Accuracy     Recall  Precision   F Score    Count            TP/TN/FP/FN\n",
      "------------------------------------------------------------------------\n",
      "                  acceleration     0.997      0.067     0.333     0.111        30     2/10402/    4/   28\n",
      "                      activity     1.000        nan       nan       nan         0     0/10436/    0/    0\n",
      "                       battery     1.000      0.000       nan     0.000         1     0/10435/    0/    1\n",
      "                        button     0.993        nan     0.000     0.000         0     0/10367/   69/    0\n",
      "              colorTemperature     1.000      1.000     1.000     1.000         3     3/10433/    0/    0\n",
      "                       contact     0.987      0.008     0.200     0.015       131     1/10301/    4/  130\n",
      "                         level     0.997      1.000     0.139     0.244         5     5/10400/   31/    0\n",
      "                          lock     0.999        nan     0.000     0.000         0     0/10425/   11/    0\n",
      "                        motion     0.921      0.286     0.136     0.185       325    93/ 9522/  589/  232\n",
      "                       no_logs     0.999      0.500     0.091     0.154         2     1/10424/   10/    1\n",
      "                          ping     0.986      0.974     0.971     0.973      2662  2594/ 7697/   77/   68\n",
      "                        status     1.000        nan       nan       nan         0     0/10436/    0/    0\n",
      "                        switch     1.000      0.500     1.000     0.667         2     1/10434/    0/    1\n",
      "                   temperature     0.973      0.420     0.076     0.128        50    21/10130/  256/   29\n",
      "                     threeAxis     0.998      0.000       nan     0.000        18     0/10418/    0/   18\n",
      "                       unknown     0.807      0.774     0.958     0.856      7744  5994/ 2432/  260/ 1750\n",
      "                         water     0.997        nan     0.000     0.000         0     0/10404/   32/    0\n",
      "------------------------------------------------------------------------\n",
      "                      AVERAGES     0.980      0.325     0.289     0.255     10436     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "             Weighted AVERAGES     0.858      0.794     0.920     0.847     10436     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "       known Weighted AVERAGES     0.980      0.843     0.829     0.826     10436     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      " known -ping Weighted AVERAGES     0.949      0.224     0.159     0.137     10436     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "       non zero count AVERAGES     0.972      0.461     0.409     0.361     10436     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "Macro F1 : 0.254859\n",
      "sample F1 : 0.790466\n",
      "weighted F1 : 0.847464\n",
      "--------------------------removed ping and unknown----------------------------------------------\n",
      "Macro F1 : 0.153879\n",
      "sample F1 : 0.057848\n",
      "weighted F1 : 0.024154\n",
      "Exact Match ACC : 0.78085 \n",
      "Total Records : 10436 \n",
      "Total ZXeros in True : 0 (0.000)%\n",
      "Total ZXeros in Test : 973 (0.093)%\n",
      "=============================================================================\n"
     ]
    }
   ],
   "source": [
    "xg_boost_results = []\n",
    "for i in range(len(rf_test_known)) :\n",
    "    print( \"==================HOME Case : %s =============\" % test_names[ i] )\n",
    "    rf_pred= xgb_classifier.predict( rf_test_known[i][0])\n",
    "    rf_pred = add_unknowns_back(rf_pred,rf_tests[i][1], rf_test_known[i][3] , classes)\n",
    "    xg_boost_results.append(print_info( rf_tests[i][1], rf_pred, classes, confidance=0.8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with out putting back the unknowns : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================HOME Case : home_os_final.json =============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/omid/.conda/envs/iot/lib/python3.6/site-packages/ipykernel_launcher.py:8: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         Class  Accuracy     Recall  Precision   F Score    Count            TP/TN/FP/FN\n",
      "------------------------------------------------------------------------\n",
      "                  acceleration     0.992      0.212     0.256     0.232        52    11/ 9329/   32/   41\n",
      "                      activity     0.999      0.667     0.714     0.690        15    10/ 9394/    4/    5\n",
      "                       battery     0.999      0.000     0.000     0.000         2     0/ 9403/    8/    2\n",
      "                        button     0.999      0.750     0.692     0.720        12     9/ 9397/    4/    3\n",
      "              colorTemperature     1.000      0.800     0.800     0.800         5     4/ 9407/    1/    1\n",
      "                       contact     0.986      0.597     0.534     0.564       144    86/ 9194/   75/   58\n",
      "                         level     0.971      0.800     0.057     0.106        20    16/ 9128/  265/    4\n",
      "                          lock     0.999      0.970     0.889     0.928        33    32/ 9376/    4/    1\n",
      "                        motion     0.954      0.741     0.312     0.439       228   169/ 8812/  373/   59\n",
      "                       no_logs     0.883        nan     0.000     0.000         0     0/ 8316/ 1097/    0\n",
      "                          ping     0.971      0.947     0.996     0.971      4814  4557/ 4581/   18/  257\n",
      "                        status     0.993      0.527     0.797     0.634       112    59/ 9286/   15/   53\n",
      "                        switch     0.999      0.571     0.857     0.686        21    12/ 9390/    2/    9\n",
      "                   temperature     0.862      0.745     0.307     0.435       671   500/ 7613/ 1129/  171\n",
      "                     threeAxis     0.998      0.548     0.680     0.607        31    17/ 9374/    8/   14\n",
      "                       unknown     0.606      0.112     0.911     0.199      4126   462/ 5242/   45/ 3664\n",
      "                         water     0.985        nan     0.000     0.000         0     0/ 9271/  142/    0\n",
      "------------------------------------------------------------------------\n",
      "                      AVERAGES     0.953      0.529     0.518     0.471      9413     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "             Weighted AVERAGES     0.818      0.578     0.885     0.597      9413     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "       known Weighted AVERAGES     0.960      0.890     0.868     0.863      9413     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      " known -ping Weighted AVERAGES     0.920      0.687     0.408     0.479      9413     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "       non zero count AVERAGES     0.955      0.599     0.587     0.534      9413     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "Macro F1 : 0.471187\n",
      "sample F1 : 0.575678\n",
      "weighted F1 : 0.597020\n",
      "--------------------------removed ping and unknown----------------------------------------------\n",
      "Macro F1 : 0.408141\n",
      "sample F1 : 0.169925\n",
      "weighted F1 : 0.122055\n",
      "Exact Match ACC : 0.56677 \n",
      "Total Records : 9413 \n",
      "Total ZXeros in True : 0 (0.000)%\n",
      "Total ZXeros in Test : 900 (0.096)%\n",
      "=============================================================================\n",
      "==================HOME Case : test_data_light.json =============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/omid/.conda/envs/iot/lib/python3.6/site-packages/ipykernel_launcher.py:9: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  if __name__ == '__main__':\n",
      "/home/omid/.conda/envs/iot/lib/python3.6/site-packages/ipykernel_launcher.py:12: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         Class  Accuracy     Recall  Precision   F Score    Count            TP/TN/FP/FN\n",
      "------------------------------------------------------------------------\n",
      "                  acceleration     1.000        nan       nan       nan         0     0/  182/    0/    0\n",
      "                      activity     1.000        nan       nan       nan         0     0/  182/    0/    0\n",
      "                       battery     1.000        nan       nan       nan         0     0/  182/    0/    0\n",
      "                        button     1.000        nan       nan       nan         0     0/  182/    0/    0\n",
      "              colorTemperature     0.967      0.871     0.931     0.900        31    27/  149/    2/    4\n",
      "                       contact     1.000        nan       nan       nan         0     0/  182/    0/    0\n",
      "                         level     0.780      0.723     0.779     0.750        83    60/   82/   17/   23\n",
      "                          lock     1.000        nan       nan       nan         0     0/  182/    0/    0\n",
      "                        motion     0.962        nan     0.000     0.000         0     0/  175/    7/    0\n",
      "                       no_logs     0.929        nan     0.000     0.000         0     0/  169/   13/    0\n",
      "                          ping     1.000      1.000     1.000     1.000        26    26/  156/    0/    0\n",
      "                        status     1.000        nan       nan       nan         0     0/  182/    0/    0\n",
      "                        switch     0.923      0.417     1.000     0.588        24    10/  158/    0/   14\n",
      "                   temperature     0.962      0.000     0.000     0.000         1     0/  175/    6/    1\n",
      "                     threeAxis     1.000        nan       nan       nan         0     0/  182/    0/    0\n",
      "                       unknown     0.714      0.107     0.750     0.188        56     6/  124/    2/   50\n",
      "                         water     0.962        nan     0.000     0.000         0     0/  175/    7/    0\n",
      "------------------------------------------------------------------------\n",
      "                      AVERAGES     0.953      0.183     0.262     0.202       182     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "             Weighted AVERAGES     0.832      0.584     0.840     0.637       182     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "       known Weighted AVERAGES     0.872      0.745     0.870     0.790       182     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      " known -ping Weighted AVERAGES     0.848      0.698     0.846     0.750       182     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "       non zero count AVERAGES     0.891      0.520     0.743     0.571       182     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "Macro F1 : 0.201514\n",
      "sample F1 : 0.542125\n",
      "weighted F1 : 0.636958\n",
      "--------------------------removed ping and unknown----------------------------------------------\n",
      "Macro F1 : 0.131661\n",
      "sample F1 : 0.470085\n",
      "weighted F1 : 0.551681\n",
      "Exact Match ACC : 0.42857 \n",
      "Total Records : 182 \n",
      "Total ZXeros in True : 0 (0.000)%\n",
      "Total ZXeros in Test : 34 (0.187)%\n",
      "=============================================================================\n",
      "==================HOME Case : test_data_motion_2.json =============\n",
      "                         Class  Accuracy     Recall  Precision   F Score    Count            TP/TN/FP/FN\n",
      "------------------------------------------------------------------------\n",
      "                  acceleration     0.995      0.100     0.333     0.154        20     2/ 4762/    4/   18\n",
      "                      activity     1.000        nan       nan       nan         0     0/ 4786/    0/    0\n",
      "                       battery     1.000      0.000       nan     0.000         1     0/ 4785/    0/    1\n",
      "                        button     0.986        nan     0.000     0.000         0     0/ 4717/   69/    0\n",
      "              colorTemperature     1.000      1.000     1.000     1.000         3     3/ 4783/    0/    0\n",
      "                       contact     0.977      0.009     0.200     0.018       107     1/ 4675/    4/  106\n",
      "                         level     0.994      1.000     0.139     0.244         5     5/ 4750/   31/    0\n",
      "                          lock     0.998        nan     0.000     0.000         0     0/ 4775/   11/    0\n",
      "                        motion     0.859      0.514     0.136     0.216       181    93/ 4016/  589/   88\n",
      "                       no_logs     0.998      1.000     0.091     0.167         1     1/ 4775/   10/    0\n",
      "                          ping     0.970      0.974     0.971     0.973      2662  2594/ 2047/   77/   68\n",
      "                        status     1.000        nan       nan       nan         0     0/ 4786/    0/    0\n",
      "                        switch     1.000      0.500     1.000     0.667         2     1/ 4784/    0/    1\n",
      "                   temperature     0.944      0.677     0.076     0.136        31    21/ 4499/  256/   10\n",
      "                     threeAxis     0.997      0.000       nan     0.000        13     0/ 4773/    0/   13\n",
      "                       unknown     0.620      0.234     0.887     0.371      2286   536/ 2432/   68/ 1750\n",
      "                         water     0.993        nan     0.000     0.000         0     0/ 4754/   32/    0\n",
      "------------------------------------------------------------------------\n",
      "                      AVERAGES     0.961      0.354     0.284     0.232      4786     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "             Weighted AVERAGES     0.816      0.613     0.880     0.657      4786     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "       known Weighted AVERAGES     0.963      0.899     0.874     0.874      4786     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      " known -ping Weighted AVERAGES     0.918      0.349     0.167     0.148      4786     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "       non zero count AVERAGES     0.946      0.501     0.403     0.329      4786     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "Macro F1 : 0.232034\n",
      "sample F1 : 0.583222\n",
      "weighted F1 : 0.657290\n",
      "--------------------------removed ping and unknown----------------------------------------------\n",
      "Macro F1 : 0.153879\n",
      "sample F1 : 0.057848\n",
      "weighted F1 : 0.024154\n",
      "Exact Match ACC : 0.56226 \n",
      "Total Records : 4786 \n",
      "Total ZXeros in True : 0 (0.000)%\n",
      "Total ZXeros in Test : 973 (0.203)%\n",
      "=============================================================================\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(rf_test_known)) :\n",
    "    print( \"==================HOME Case : %s =============\" % test_names[ i] )\n",
    "    rf_pred= xgb_classifier.predict( rf_test_known[i][0])\n",
    "    print_info( rf_test_known[i][1], rf_pred, classes, confidance=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## string encoding test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "knownity_rf =  RandomForestClassifier(n_estimators=100, max_depth=400,\n",
    "                             random_state=0 )\n",
    "knownity_rf_results = knownity_rf.fit(x_random_forest_train, known_unknown_y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_known_unknown_pred=knownity_rf.predict(x_random_forest_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================HOME Case : home_os_final.json =============\n",
      "                         Class  Accuracy     Recall  Precision   F Score    Count            TP/TN/FP/FN\n",
      "------------------------------------------------------------------------\n",
      "                       unknown     0.783      0.716     0.940     0.813     12580  9010/ 5938/  572/ 3570\n",
      "                         known     0.783      0.912     0.625     0.741      6510  5938/ 9010/ 3570/  572\n",
      "------------------------------------------------------------------------\n",
      "                      AVERAGES     0.783      0.814     0.782     0.777     19090     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "             Weighted AVERAGES     0.783      0.783     0.833     0.789     19090     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "       known Weighted AVERAGES     0.783      0.912     0.625     0.741     19090     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------\n",
      "       non zero count AVERAGES     0.783      0.814     0.782     0.777     19090     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "Macro F1 : 0.777260\n",
      "sample F1 : 0.783028\n",
      "weighted F1 : 0.788657\n",
      "Exact Match ACC : 0.78303 \n",
      "Total Records : 19090 \n",
      "Total ZXeros in True : 0 (0.000)%\n",
      "Total ZXeros in Test : 0 (0.000)%\n",
      "=============================================================================\n",
      "==================HOME Case : test_data_light.json =============\n",
      "                         Class  Accuracy     Recall  Precision   F Score    Count            TP/TN/FP/FN\n",
      "------------------------------------------------------------------------\n",
      "                       unknown     0.664      0.333     0.978     0.497       132    44/  132/    1/   88\n",
      "                         known     0.664      0.992     0.600     0.748       133   132/   44/   88/    1\n",
      "------------------------------------------------------------------------\n",
      "                      AVERAGES     0.664      0.663     0.789     0.623       265     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "             Weighted AVERAGES     0.664      0.664     0.788     0.623       265     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "       known Weighted AVERAGES     0.664      0.992     0.600     0.748       265     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------\n",
      "       non zero count AVERAGES     0.664      0.663     0.789     0.623       265     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "Macro F1 : 0.622525\n",
      "sample F1 : 0.664151\n",
      "weighted F1 : 0.622998\n",
      "Exact Match ACC : 0.66415 \n",
      "Total Records : 265 \n",
      "Total ZXeros in True : 0 (0.000)%\n",
      "Total ZXeros in Test : 0 (0.000)%\n",
      "=============================================================================\n",
      "==================HOME Case : test_data_motion_2.json =============\n",
      "                         Class  Accuracy     Recall  Precision   F Score    Count            TP/TN/FP/FN\n",
      "------------------------------------------------------------------------\n",
      "                       unknown     0.557      0.386     0.944     0.548      7270  2809/ 3000/  166/ 4461\n",
      "                         known     0.557      0.948     0.402     0.565      3166  3000/ 2809/ 4461/  166\n",
      "------------------------------------------------------------------------\n",
      "                      AVERAGES     0.557      0.667     0.673     0.556     10436     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "             Weighted AVERAGES     0.557      0.557     0.780     0.553     10436     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "       known Weighted AVERAGES     0.557      0.948     0.402     0.565     10436     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------\n",
      "       non zero count AVERAGES     0.557      0.667     0.673     0.556     10436     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "Macro F1 : 0.556482\n",
      "sample F1 : 0.556631\n",
      "weighted F1 : 0.553290\n",
      "Exact Match ACC : 0.55663 \n",
      "Total Records : 10436 \n",
      "Total ZXeros in True : 0 (0.000)%\n",
      "Total ZXeros in Test : 0 (0.000)%\n",
      "=============================================================================\n"
     ]
    }
   ],
   "source": [
    "test_known_unknown_predicted = []\n",
    "for i in range(len(rf_tests)) :\n",
    "    print( \"==================HOME Case : %s =============\" % test_names[ i] )\n",
    "    rf_pred=knownity_rf.predict( rf_tests[i][0])\n",
    "    test_known_unknown_predicted.append(rf_pred)\n",
    "    print_info( np.array( known_unknown_y_test[i]), rf_pred, [\"unknown\",\"known\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "known_indexes_train  = [ i for i in range(len(train_known_unknown_pred)) if train_known_unknown_pred[i][1] ==1 ]\n",
    "\n",
    "x_train_known = x_random_forest_train[known_indexes_train]\n",
    "y_train_known = y_random_forest_train[known_indexes_train]\n",
    "\n",
    "rf_test_known = [] \n",
    "\n",
    "for test_index in range(len(test_known_unknown_predicted)):\n",
    "    known_indexes= [ i for i in range(len(test_known_unknown_predicted[test_index])) if test_known_unknown_predicted[test_index][i][1] ==1 ]\n",
    "    \n",
    "    rf_test_known.append(  (rf_tests[test_index][0][known_indexes], \n",
    "                            rf_tests[test_index][1][known_indexes],\n",
    "                            rf_tests[test_index][2],\n",
    "                            known_indexes\n",
    "                           ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=200, max_depth=400,\n",
    "                             random_state=0 )\n",
    "t_hist = clf.fit(x_train_known, y_train_known)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================HOME Case : home_os_final.json =============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/omid/.conda/envs/iot/lib/python3.6/site-packages/ipykernel_launcher.py:8: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  \n",
      "/home/omid/.conda/envs/iot/lib/python3.6/site-packages/ipykernel_launcher.py:9: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         Class  Accuracy     Recall  Precision   F Score    Count            TP/TN/FP/FN\n",
      "------------------------------------------------------------------------\n",
      "                  acceleration     0.996      0.000     0.000     0.000        57     0/19020/   13/   57\n",
      "                      activity     0.999      0.062     1.000     0.118        16     1/19074/    0/   15\n",
      "                       battery     0.999      0.000     0.000     0.000         7     0/19073/   10/    7\n",
      "                        button     0.999      0.000     0.000     0.000        12     0/19077/    1/   12\n",
      "              colorTemperature     1.000      1.000     0.833     0.909         5     5/19084/    1/    0\n",
      "                       contact     0.991      0.391     0.431     0.410       151    59/18861/   78/   92\n",
      "                         level     0.985      0.750     0.050     0.094        20    15/18787/  283/    5\n",
      "                          lock     1.000      0.882     0.882     0.882        34    30/19052/    4/    4\n",
      "                        motion     0.973      0.449     0.327     0.378       343   154/18430/  317/  189\n",
      "                       no_logs     0.946        nan     0.000     0.000         0     0/18057/ 1033/    0\n",
      "                          ping     0.986      0.951     0.995     0.972      4814  4576/14254/   22/  238\n",
      "                        status     0.995      0.368     0.717     0.486       117    43/18956/   17/   74\n",
      "                        switch     0.999      0.429     0.818     0.562        21     9/19067/    2/   12\n",
      "                   temperature     0.908      0.440     0.302     0.358      1120   493/16832/ 1138/  627\n",
      "                     threeAxis     0.998      0.000       nan     0.000        36     0/19054/    0/   36\n",
      "                       unknown     0.769      0.713     0.939     0.810     13223  9426/ 5256/  611/ 3797\n",
      "                         water     0.995        nan     0.000     0.000         0     0/18992/   98/    0\n",
      "------------------------------------------------------------------------\n",
      "                      AVERAGES     0.973      0.378     0.429     0.352     19090     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "             Weighted AVERAGES     0.838      0.741     0.895     0.806     19090     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "       known Weighted AVERAGES     0.973      0.797     0.808     0.797     19090     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      " known -ping Weighted AVERAGES     0.941      0.417     0.344     0.361     19090     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "       non zero count AVERAGES     0.973      0.429     0.486     0.399     19090     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/omid/.conda/envs/iot/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/omid/.conda/envs/iot/lib/python3.6/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/home/omid/.conda/envs/iot/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macro F1 : 0.351835\n",
      "sample F1 : 0.750873\n",
      "weighted F1 : 0.805876\n",
      "--------------------------removed ping and unknown----------------------------------------------\n",
      "Macro F1 : 0.257943\n",
      "sample F1 : 0.152902\n",
      "weighted F1 : 0.102496\n",
      "Exact Match ACC : 0.74924 \n",
      "Total Records : 19090 \n",
      "Total ZXeros in True : 0 (0.000)%\n",
      "Total ZXeros in Test : 1210 (0.063)%\n",
      "=============================================================================\n",
      "==================HOME Case : test_data_light.json =============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/omid/.conda/envs/iot/lib/python3.6/site-packages/ipykernel_launcher.py:12: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         Class  Accuracy     Recall  Precision   F Score    Count            TP/TN/FP/FN\n",
      "------------------------------------------------------------------------\n",
      "                  acceleration     1.000        nan       nan       nan         0     0/  265/    0/    0\n",
      "                      activity     1.000        nan       nan       nan         0     0/  265/    0/    0\n",
      "                       battery     1.000        nan       nan       nan         0     0/  265/    0/    0\n",
      "                        button     1.000        nan       nan       nan         0     0/  265/    0/    0\n",
      "              colorTemperature     0.887      0.032     1.000     0.062        31     1/  234/    0/   30\n",
      "                       contact     1.000        nan       nan       nan         0     0/  265/    0/    0\n",
      "                         level     0.853      0.867     0.720     0.787        83    72/  154/   28/   11\n",
      "                          lock     1.000        nan       nan       nan         0     0/  265/    0/    0\n",
      "                        motion     0.977        nan     0.000     0.000         0     0/  259/    6/    0\n",
      "                       no_logs     0.974        nan     0.000     0.000         0     0/  258/    7/    0\n",
      "                          ping     1.000      1.000     1.000     1.000        26    26/  239/    0/    0\n",
      "                        status     1.000        nan       nan       nan         0     0/  265/    0/    0\n",
      "                        switch     0.943      0.417     0.909     0.571        24    10/  240/    1/   14\n",
      "                   temperature     0.974      0.000     0.000     0.000         2     0/  258/    5/    2\n",
      "                     threeAxis     1.000        nan       nan       nan         0     0/  265/    0/    0\n",
      "                       unknown     0.657      0.362     0.943     0.524       138    50/  124/    3/   88\n",
      "                         water     0.970        nan     0.000     0.000         0     0/  257/    8/    0\n",
      "------------------------------------------------------------------------\n",
      "                      AVERAGES     0.955      0.158     0.269     0.173       265     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "             Weighted AVERAGES     0.788      0.523     0.884     0.590       265     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "       known Weighted AVERAGES     0.897      0.657     0.835     0.644       265     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      " known -ping Weighted AVERAGES     0.878      0.593     0.804     0.578       265     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "       non zero count AVERAGES     0.886      0.446     0.762     0.491       265     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "Macro F1 : 0.173198\n",
      "sample F1 : 0.510692\n",
      "weighted F1 : 0.589522\n",
      "--------------------------removed ping and unknown----------------------------------------------\n",
      "Macro F1 : 0.083577\n",
      "sample F1 : 0.340206\n",
      "weighted F1 : 0.356666\n",
      "Exact Match ACC : 0.45283 \n",
      "Total Records : 265 \n",
      "Total ZXeros in True : 0 (0.000)%\n",
      "Total ZXeros in Test : 67 (0.253)%\n",
      "=============================================================================\n",
      "==================HOME Case : test_data_motion_2.json =============\n",
      "                         Class  Accuracy     Recall  Precision   F Score    Count            TP/TN/FP/FN\n",
      "------------------------------------------------------------------------\n",
      "                  acceleration     0.997      0.000     0.000     0.000        30     0/10404/    2/   30\n",
      "                      activity     1.000        nan       nan       nan         0     0/10436/    0/    0\n",
      "                       battery     1.000      0.000       nan     0.000         1     0/10435/    0/    1\n",
      "                        button     1.000        nan     0.000     0.000         0     0/10434/    2/    0\n",
      "              colorTemperature     1.000      0.667     1.000     0.800         3     2/10433/    0/    1\n",
      "                       contact     0.987      0.008     0.167     0.015       131     1/10300/    5/  130\n",
      "                         level     0.997      1.000     0.143     0.250         5     5/10401/   30/    0\n",
      "                          lock     0.999        nan     0.000     0.000         0     0/10428/    8/    0\n",
      "                        motion     0.929      0.268     0.146     0.189       325    87/ 9604/  507/  238\n",
      "                       no_logs     0.999      0.500     0.083     0.143         2     1/10423/   11/    1\n",
      "                          ping     0.986      0.977     0.970     0.974      2662  2601/ 7694/   80/   61\n",
      "                        status     1.000        nan       nan       nan         0     0/10436/    0/    0\n",
      "                        switch     1.000      0.500     1.000     0.667         2     1/10434/    0/    1\n",
      "                   temperature     0.972      0.400     0.072     0.122        50    20/10128/  258/   30\n",
      "                     threeAxis     0.998      0.000       nan     0.000        18     0/10418/    0/   18\n",
      "                       unknown     0.552      0.426     0.935     0.586      7744  3301/ 2463/  229/ 4443\n",
      "                         water     0.998        nan     0.000     0.000         0     0/10413/   23/    0\n",
      "------------------------------------------------------------------------\n",
      "                      AVERAGES     0.966      0.279     0.266     0.220     10436     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "             Weighted AVERAGES     0.678      0.549     0.902     0.656     10436     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "       known Weighted AVERAGES     0.981      0.842     0.824     0.826     10436     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      " known -ping Weighted AVERAGES     0.953      0.206     0.139     0.132     10436     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "       non zero count AVERAGES     0.951      0.395     0.376     0.312     10436     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "Macro F1 : 0.220271\n",
      "sample F1 : 0.531797\n",
      "weighted F1 : 0.656285\n",
      "--------------------------removed ping and unknown----------------------------------------------\n",
      "Macro F1 : 0.131741\n",
      "sample F1 : 0.023396\n",
      "weighted F1 : 0.010798\n",
      "Exact Match ACC : 0.52386 \n",
      "Total Records : 10436 \n",
      "Total ZXeros in True : 0 (0.000)%\n",
      "Total ZXeros in Test : 3837 (0.368)%\n",
      "=============================================================================\n"
     ]
    }
   ],
   "source": [
    "rf_results = []\n",
    "for i in range(len(rf_test_known)) :\n",
    "    print( \"==================HOME Case : %s =============\" % test_names[ i] )\n",
    "    rf_pred= clf.predict( rf_test_known[i][0])\n",
    "    rf_pred = add_unknowns_back(rf_pred,rf_tests[i][1], rf_test_known[i][3] , classes)\n",
    "    rf_results.append(print_info( rf_tests[i][1], rf_pred, classes, confidance=0.8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================HOME Case : home_os_final.json =============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/omid/.conda/envs/iot/lib/python3.6/site-packages/ipykernel_launcher.py:8: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  \n",
      "/home/omid/.conda/envs/iot/lib/python3.6/site-packages/ipykernel_launcher.py:9: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         Class  Accuracy     Recall  Precision   F Score    Count            TP/TN/FP/FN\n",
      "------------------------------------------------------------------------\n",
      "                  acceleration     0.993      0.000     0.000     0.000        52     0/ 9443/   13/   52\n",
      "                      activity     0.998      0.062     1.000     0.118        16     1/ 9492/    0/   15\n",
      "                       battery     0.999      0.000     0.000     0.000         3     0/ 9495/   10/    3\n",
      "                        button     0.999      0.000     0.000     0.000        12     0/ 9495/    1/   12\n",
      "              colorTemperature     1.000      1.000     0.833     0.909         5     5/ 9502/    1/    0\n",
      "                       contact     0.983      0.413     0.431     0.421       143    59/ 9287/   78/   84\n",
      "                         level     0.970      0.750     0.050     0.094        20    15/ 9205/  283/    5\n",
      "                          lock     0.999      0.909     0.882     0.896        33    30/ 9471/    4/    3\n",
      "                        motion     0.959      0.675     0.327     0.441       228   154/ 8963/  317/   74\n",
      "                       no_logs     0.891        nan     0.000     0.000         0     0/ 8475/ 1033/    0\n",
      "                          ping     0.973      0.951     0.995     0.972      4813  4576/ 4673/   22/  237\n",
      "                        status     0.991      0.387     0.717     0.503       111    43/ 9380/   17/   68\n",
      "                        switch     0.999      0.429     0.818     0.562        21     9/ 9485/    2/   12\n",
      "                   temperature     0.861      0.727     0.302     0.427       678   493/ 7692/ 1138/  185\n",
      "                     threeAxis     0.997      0.000       nan     0.000        32     0/ 9476/    0/   32\n",
      "                       unknown     0.596      0.099     0.912     0.178      4212   415/ 5256/   40/ 3797\n",
      "                         water     0.990        nan     0.000     0.000         0     0/ 9410/   98/    0\n",
      "------------------------------------------------------------------------\n",
      "                      AVERAGES     0.953      0.377     0.428     0.325      9508     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "             Weighted AVERAGES     0.813      0.559     0.879     0.577      9508     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "       known Weighted AVERAGES     0.961      0.873     0.856     0.849      9508     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      " known -ping Weighted AVERAGES     0.920      0.597     0.360     0.410      9508     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "       non zero count AVERAGES     0.954      0.427     0.485     0.368      9508     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "Macro F1 : 0.324790\n",
      "sample F1 : 0.559897\n",
      "weighted F1 : 0.576681\n",
      "--------------------------removed ping and unknown----------------------------------------------\n",
      "Macro F1 : 0.257943\n",
      "sample F1 : 0.152902\n",
      "weighted F1 : 0.102496\n",
      "Exact Match ACC : 0.55669 \n",
      "Total Records : 9508 \n",
      "Total ZXeros in True : 0 (0.000)%\n",
      "Total ZXeros in Test : 1210 (0.127)%\n",
      "=============================================================================\n",
      "==================HOME Case : test_data_light.json =============\n",
      "                         Class  Accuracy     Recall  Precision   F Score    Count            TP/TN/FP/FN\n",
      "------------------------------------------------------------------------\n",
      "                  acceleration     1.000        nan       nan       nan         0     0/  220/    0/    0\n",
      "                      activity     1.000        nan       nan       nan         0     0/  220/    0/    0\n",
      "                       battery     1.000        nan       nan       nan         0     0/  220/    0/    0\n",
      "                        button     1.000        nan       nan       nan         0     0/  220/    0/    0\n",
      "              colorTemperature     0.864      0.032     1.000     0.062        31     1/  189/    0/   30\n",
      "                       contact     1.000        nan       nan       nan         0     0/  220/    0/    0\n",
      "                         level     0.823      0.867     0.720     0.787        83    72/  109/   28/   11\n",
      "                          lock     1.000        nan       nan       nan         0     0/  220/    0/    0\n",
      "                        motion     0.973        nan     0.000     0.000         0     0/  214/    6/    0\n",
      "                       no_logs     0.968        nan     0.000     0.000         0     0/  213/    7/    0\n",
      "                          ping     1.000      1.000     1.000     1.000        26    26/  194/    0/    0\n",
      "                        status     1.000        nan       nan       nan         0     0/  220/    0/    0\n",
      "                        switch     0.932      0.417     0.909     0.571        24    10/  195/    1/   14\n",
      "                   temperature     0.973      0.000     0.000     0.000         1     0/  214/    5/    1\n",
      "                     threeAxis     1.000        nan       nan       nan         0     0/  220/    0/    0\n",
      "                       unknown     0.591      0.064     0.750     0.118        94     6/  124/    2/   88\n",
      "                         water     0.964        nan     0.000     0.000         0     0/  212/    8/    0\n",
      "------------------------------------------------------------------------\n",
      "                      AVERAGES     0.946      0.140     0.258     0.149       220     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "             Weighted AVERAGES     0.772      0.444     0.807     0.456       220     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "       known Weighted AVERAGES     0.875      0.661     0.840     0.648       220     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      " known -ping Weighted AVERAGES     0.852      0.597     0.810     0.582       220     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "       non zero count AVERAGES     0.864      0.397     0.730     0.423       220     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "Macro F1 : 0.149321\n",
      "sample F1 : 0.415152\n",
      "weighted F1 : 0.455684\n",
      "--------------------------removed ping and unknown----------------------------------------------\n",
      "Macro F1 : 0.083577\n",
      "sample F1 : 0.340206\n",
      "weighted F1 : 0.356666\n",
      "Exact Match ACC : 0.34545 \n",
      "Total Records : 220 \n",
      "Total ZXeros in True : 0 (0.000)%\n",
      "Total ZXeros in Test : 67 (0.305)%\n",
      "=============================================================================\n",
      "==================HOME Case : test_data_motion_2.json =============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/omid/.conda/envs/iot/lib/python3.6/site-packages/ipykernel_launcher.py:12: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         Class  Accuracy     Recall  Precision   F Score    Count            TP/TN/FP/FN\n",
      "------------------------------------------------------------------------\n",
      "                  acceleration     0.996      0.000     0.000     0.000        25     0/ 7434/    2/   25\n",
      "                      activity     1.000        nan       nan       nan         0     0/ 7461/    0/    0\n",
      "                       battery     1.000      0.000       nan     0.000         1     0/ 7460/    0/    1\n",
      "                        button     1.000        nan     0.000     0.000         0     0/ 7459/    2/    0\n",
      "              colorTemperature     1.000      0.667     1.000     0.800         3     2/ 7458/    0/    1\n",
      "                       contact     0.985      0.009     0.167     0.017       110     1/ 7346/    5/  109\n",
      "                         level     0.996      1.000     0.143     0.250         5     5/ 7426/   30/    0\n",
      "                          lock     0.999        nan     0.000     0.000         0     0/ 7453/    8/    0\n",
      "                        motion     0.917      0.442     0.146     0.220       197    87/ 6757/  507/  110\n",
      "                       no_logs     0.999      1.000     0.083     0.154         1     1/ 7449/   11/    0\n",
      "                          ping     0.981      0.977     0.970     0.974      2662  2601/ 4719/   80/   61\n",
      "                        status     1.000        nan       nan       nan         0     0/ 7461/    0/    0\n",
      "                        switch     1.000      0.500     1.000     0.667         2     1/ 7459/    0/    1\n",
      "                   temperature     0.964      0.588     0.072     0.128        34    20/ 7169/  258/   14\n",
      "                     threeAxis     0.998      0.000       nan     0.000        18     0/ 7443/    0/   18\n",
      "                       unknown     0.396      0.100     0.886     0.179      4935   492/ 2463/   63/ 4443\n",
      "                         water     0.997        nan     0.000     0.000         0     0/ 7438/   23/    0\n",
      "------------------------------------------------------------------------\n",
      "                      AVERAGES     0.954      0.311     0.263     0.199      7461     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "             Weighted AVERAGES     0.618      0.402     0.877     0.442      7461     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "       known Weighted AVERAGES     0.977      0.889     0.863     0.865      7461     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      " known -ping Weighted AVERAGES     0.951      0.295     0.140     0.138      7461     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "       non zero count AVERAGES     0.936      0.440     0.372     0.282      7461     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "Macro F1 : 0.199340\n",
      "sample F1 : 0.367355\n",
      "weighted F1 : 0.441762\n",
      "--------------------------removed ping and unknown----------------------------------------------\n",
      "Macro F1 : 0.131741\n",
      "sample F1 : 0.023396\n",
      "weighted F1 : 0.010798\n",
      "Exact Match ACC : 0.35625 \n",
      "Total Records : 7461 \n",
      "Total ZXeros in True : 0 (0.000)%\n",
      "Total ZXeros in Test : 3837 (0.514)%\n",
      "=============================================================================\n"
     ]
    }
   ],
   "source": [
    "# for i in range(len(rf_test_known)) :\n",
    "#     print( \"==================HOME Case : %s =============\" % test_names[ i] )\n",
    "#     rf_pred= clf.predict( rf_test_known[i][0])\n",
    "#     print_info( rf_test_known[i][1], rf_pred, classes, confidance=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         Class  Accuracy     Recall  Precision   F Score    Count            TP/TN/FP/FN\n",
      "------------------------------------------------------------------------\n",
      "                  acceleration     0.997      0.000       nan     0.000        10     0/ 3180/    0/   10\n",
      "                      activity     1.000        nan       nan       nan         0     0/ 3190/    0/    0\n",
      "                       battery     1.000        nan       nan       nan         0     0/ 3190/    0/    0\n",
      "                        button     1.000        nan       nan       nan         0     0/ 3190/    0/    0\n",
      "              colorTemperature     1.000      0.667     1.000     0.800         3     2/ 3187/    0/    1\n",
      "                       contact     0.990      0.000       nan     0.000        33     0/ 3157/    0/   33\n",
      "                         level     0.991      1.000     0.147     0.256         5     5/ 3156/   29/    0\n",
      "                          lock     0.997        nan     0.000     0.000         0     0/ 3182/    8/    0\n",
      "                        motion     0.916      0.377     0.078     0.130        53    20/ 2902/  235/   33\n",
      "                          ping     0.966      0.993     0.967     0.980      2662  2644/  439/   89/   18\n",
      "                        status     1.000        nan       nan       nan         0     0/ 3190/    0/    0\n",
      "                        switch     0.999      0.500     0.500     0.500         2     1/ 3187/    1/    1\n",
      "                   temperature     0.985      0.091     0.025     0.039        11     1/ 3140/   39/   10\n",
      "                     threeAxis     0.986      0.250     0.049     0.082         8     2/ 3143/   39/    6\n",
      "                       unknown     0.860      0.594     0.867     0.705       900   535/ 2208/   82/  365\n",
      "                         water     1.000        nan     0.000     0.000         0     0/ 3189/    1/    0\n",
      "------------------------------------------------------------------------\n",
      "                      AVERAGES     0.980      0.280     0.227     0.218      3190     0/    0/    0/    0\n",
      "Exact Match ACC : 0.81881 \n",
      "Total Records : 3190 \n",
      "Total ZXeros in True : 0 (0.000)%\n",
      "Total ZXeros in Test : 66 (0.021)%\n",
      "=============================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/omid/.conda/envs/iot/lib/python3.6/site-packages/ipykernel_launcher.py:9: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  if __name__ == '__main__':\n",
      "/home/omid/.conda/envs/iot/lib/python3.6/site-packages/ipykernel_launcher.py:8: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  \n",
      "/home/omid/.conda/envs/iot/lib/python3.6/site-packages/ipykernel_launcher.py:12: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "values, desc = print_info( rf_test_known[i][1], rf_pred, classes, confidance=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_nan(inp):\n",
    "    if np.isnan(inp):\n",
    "        return 0\n",
    "    else:\n",
    "        return inp\n",
    "desc = xg_boost_results[0][1]\n",
    "index = 0 \n",
    "for index in range(len(test_names)):\n",
    "    plt.figure(figsize=(14,4))\n",
    "    plt.plot( [x[0] for x in xg_boost_results[index][0]] , \n",
    "         [fix_nan(x[desc.index(\"F Score\")]) for x in xg_boost_results[index][0]],\n",
    "        label=\"XGBoost\",\n",
    "         color=\"red\" ,\n",
    "             alpha=0.5\n",
    "        )\n",
    "    plt.plot( [x[0] for x in rf_results[index][0]] , \n",
    "         [fix_nan(x[desc.index(\"F Score\")]) for x in rf_results[index][0]],\n",
    "        label=\"RF\",\n",
    "         color=\"blue\" ,\n",
    "             alpha=0.5\n",
    "        )\n",
    "    \n",
    "    plt.plot( [x[0] for x in xg_boost_results[index][0]] , \n",
    "         [fix_nan(x[desc.index(\"Precision\")]) for x in xg_boost_results[index][0]],\n",
    "        label=\"XGBoost - Precision\",\n",
    "         color=\"red\" ,\n",
    "             marker=\"s\",\n",
    "             alpha=0.5\n",
    "        )\n",
    "    plt.plot( [x[0] for x in rf_results[index][0]] , \n",
    "         [fix_nan(x[desc.index(\"Precision\")]) for x in rf_results[index][0]],\n",
    "        label=\"RF - Precision\",\n",
    "         color=\"blue\" ,\n",
    "             marker=\"s\",\n",
    "             alpha=0.5\n",
    "        )\n",
    "    plt.plot( [x[0] for x in xg_boost_results[index][0]] , \n",
    "         [fix_nan(x[desc.index(\"Recall\")]) for x in xg_boost_results[index][0]],\n",
    "        label=\"XGBoost - Recall\",\n",
    "         color=\"red\" ,\n",
    "             marker=\"+\",\n",
    "             alpha=0.5\n",
    "        )\n",
    "    plt.plot( [x[0] for x in rf_results[index][0]] , \n",
    "         [fix_nan(x[desc.index(\"Recall\")]) for x in rf_results[index][0]],\n",
    "        label=\"RF - Recall\",\n",
    "         color=\"blue\" ,\n",
    "             marker=\"+\",\n",
    "             alpha=0.5\n",
    "        )\n",
    "\n",
    "    # plt.plot( )\n",
    "    plt.legend()\n",
    "    plt.xticks(rotation=90, ha='right')\n",
    "    plt.title(test_names[ index] )\n",
    "    plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ok ... bye bye now ... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest baseline calc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "preproicess the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_size= 50\n",
    "x_random_forest_train,y_random_forest_train, _ = pre_process_raw( x_train, y_train , dim_size, zero_pad=True, normalize=False, classes=classes)\n",
    "rf_tests  = [ pre_process_raw( x_test[i], y_test[i] , dim_size, zero_pad=True, normalize=False, classes=classes) for i in range(len(x_test)) ] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "first stage RF will learn if it is a known or unknown instance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "knownity_rf =  RandomForestClassifier(n_estimators=960, max_depth=9050,\n",
    "                             random_state=0 )\n",
    "knownity_rf_results = knownity_rf.fit(x_random_forest_train, known_unknown_y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_known_unknown_pred=knownity_rf.predict(x_random_forest_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_known_unknown_predicted = []\n",
    "for i in range(len(rf_tests)) :\n",
    "    print( \"==================HOME Case : %s =============\" % test_names[ i] )\n",
    "    rf_pred=knownity_rf.predict( rf_tests[i][0])\n",
    "    test_known_unknown_predicted.append(rf_pred)\n",
    "    print_info( np.array( known_unknown_y_test[i]), rf_pred, [\"unknown\",\"known\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "known_indexes_train  = [ i for i in range(len(train_known_unknown_pred)) if train_known_unknown_pred[i][1] ==1 ]\n",
    "\n",
    "x_train_known = x_random_forest_train[known_indexes_train]\n",
    "y_train_known = y_random_forest_train[known_indexes_train]\n",
    "\n",
    "rf_test_known = [] \n",
    "\n",
    "for test_index in range(len(rf_tests)):\n",
    "    known_indexes= [ i for i in range(len(test_known_unknown_predicted[test_index])) if test_known_unknown_predicted[test_index][i][1] ==1 ]\n",
    "    \n",
    "    rf_test_known.append(  (rf_tests[test_index][0][known_indexes], \n",
    "                            rf_tests[test_index][1][known_indexes],\n",
    "                            rf_tests[test_index][2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=960, max_depth=9050,\n",
    "                             random_state=0 )\n",
    "t_hist = clf.fit(x_train_known, y_train_known)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(rf_test_known)) :\n",
    "    print( \"==================HOME Case : %s =============\" % test_names[ i] )\n",
    "    rf_pred= clf.predict( rf_test_known[i][0])\n",
    "    print_info( rf_test_known[i][1], rf_pred, classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the model\n",
    "dim_size =20\n",
    "x_lstm_prossed_train,y_lstm_prossed_train, _ = pre_process_raw( x_train, y_train , dim_size, zero_pad=False, normalize=False,classes=classes, as_string=True)\n",
    "_, y_s_lstm_processed_train ,_ =  pre_process_raw( x_train, y_train_service , dim_size, zero_pad=False, normalize=False,classes=service_classes, as_string=True)\n",
    "# x_lstm_prossed_test,y_lstm_prossed_test, _ = pre_process_raw( x_test, y_test_2 , dim_size, zero_pad=True, normalize=False,classes=classes)\n",
    "lstm_tests  = [ pre_process_raw( x_test[i], y_test[i] , dim_size, zero_pad=False, normalize=False, classes=classes) for i in range(len(x_test)) ] \n",
    "lstm_tests_services  = [ pre_process_raw( x_test[i], y_test_service[i] , dim_size, zero_pad=False, normalize=True, classes=service_classes) for i in range(len(x_test)) ] \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50,)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " x_random_forest_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(x_lstm_prossed_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "known_indexes_train  = [ i for i in range(len(train_known_unknown_pred)) if train_known_unknown_pred[i][1] ==1 ]\n",
    "\n",
    "# x_lstm_prossed_train = x_lstm_prossed_train[known_indexes_train]\n",
    "y_lstm_prossed_train = y_lstm_prossed_train[known_indexes_train]\n",
    "\n",
    "lstm_tests_known = [] \n",
    "\n",
    "for test_index in range(len(rf_tests)):\n",
    "    known_indexes= [ i for i in range(len(test_known_unknown_predicted[test_index])) if test_known_unknown_predicted[test_index][i][1] ==1 ]\n",
    "    \n",
    "    lstm_tests_known.append(  (lstm_tests[test_index][0][known_indexes], \n",
    "                            lstm_tests[test_index][1][known_indexes],\n",
    "                            lstm_tests[test_index][2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_lstm_prossed_test2 = np.expand_dims(x_lstm_prossed_test,axis=1)\n",
    "# x_lstm_prossed_train2 =np.expand_dims(x_random_forest_train,axis=1)\n",
    "# x_lstm_prossed_train2 =x_random_forest_train\n",
    "\n",
    "\n",
    "# x_lstm_prossed_test2 = x_lstm_prossed_test.reshape(len(x_lstm_prossed_test),dim_size,1)\n",
    "x_lstm_prossed_train2 =x_train_known.toarray().reshape((x_train_known.shape[0],x_train_known.shape[1],1))\n",
    "\n",
    "# y_lstm_prossed_test2 = y_lstm_prossed_test.reshape(len(y_lstm_prossed_test),len(classes),1)\n",
    "# y_lstm_prossed_train2 =y_lstm_prossed_train.reshape(len(y_lstm_prossed_train),len(classes),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tt  in range( len(rf_test_known) ):\n",
    "    rf_test_known[tt]= (rf_test_known[tt][0].toarray().reshape(rf_test_known[tt][0].shape[0],\n",
    "                                                     rf_test_known[tt][0].shape[1],\n",
    "                                                     1) ,\n",
    "                           rf_test_known[tt][1],\n",
    "                           rf_test_known[tt][1] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_lstm_prossed_train22' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-04cb5c2abf27>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx_random_forest_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_lstm_prossed_train22\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'x_lstm_prossed_train22' is not defined"
     ]
    }
   ],
   "source": [
    "x_random_forest_train.shape, x_lstm_prossed_train22.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 14, 16)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes.index('ping'), classes.index('unknown'), len(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Bidirectional LSTM :D \n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers import Bidirectional\n",
    "from keras.layers import Flatten\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from keras.models import Model\n",
    "\n",
    "from keras.layers import Input, merge, concatenate, Conv2D, MaxPooling2D, Activation, UpSampling2D, Dropout, Conv2DTranspose, UpSampling2D, Lambda\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers.normalization import BatchNormalization as bn\n",
    "from keras.layers.merge import add\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from keras.optimizers import RMSprop\n",
    "from keras import regularizers\n",
    "from keras import backend as K\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers.merge import add\n",
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "from keras.regularizers import l2\n",
    "from keras.layers import Conv1D\n",
    "from keras.layers.merge import add\n",
    "from keras.layers import Dense,Conv1D,Dropout,Activation,BatchNormalization,MaxPooling1D,Flatten,Masking,TimeDistributed\n",
    "from keras.layers.recurrent import LSTM,GRU,SimpleRNN\n",
    "from keras.models import Input,Sequential,Model\n",
    "from keras.layers.merge import add\n",
    "from keras.optimizers import Adam\n",
    "from keras.losses import MSE,MSLE\n",
    "model2 = Sequential()\n",
    "\n",
    "\n",
    "def weighted_categorical_crossentropy(weights):\n",
    "    \"\"\"\n",
    "    A weighted version of keras.objectives.categorical_crossentropy\n",
    "    \n",
    "    Variables:\n",
    "        weights: numpy array of shape (C,) where C is the number of classes\n",
    "    \n",
    "    Usage:\n",
    "        weights = np.array([0.5,2,10]) # Class one at 0.5, class 2 twice the normal weights, class 3 10x.\n",
    "        loss = weighted_categorical_crossentropy(weights)\n",
    "        model.compile(loss=loss,optimizer='adam')\n",
    "    \"\"\"\n",
    "    \n",
    "    weights = K.variable(weights)\n",
    "        \n",
    "    def loss(y_true, y_pred):\n",
    "        # scale predictions so that the class probas of each sample sum to 1\n",
    "        y_pred /= K.sum(y_pred, axis=-1, keepdims=True)\n",
    "        # clip to prevent NaN's and Inf's\n",
    "        y_pred = K.clip(y_pred, K.epsilon(), 1 - K.epsilon())\n",
    "        # calc\n",
    "        loss = y_true * K.log(y_pred) * weights\n",
    "        loss = -K.sum(loss, -1)\n",
    "        return loss\n",
    "    \n",
    "    return loss\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "def f1_perClass(y_true, y_pred):\n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return K.mean(f1)\n",
    "\n",
    "\n",
    "def f1_perRow(y_true, y_pred):\n",
    "\n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=1)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=1)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=1)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=1)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return K.mean(f1)\n",
    "\n",
    "def f1_loss_perRow(y_true, y_pred):\n",
    "    \n",
    "#     y_true = y_true * \n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=1) \n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=1) \n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=1) \n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=1) \n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "#     f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return (1 - K.mean(f1))**2\n",
    "\n",
    "def f1_loss_perClass(y_true, y_pred):\n",
    "    key = K.variable([1,1,1,1,1,1,1,1,1,0,1,1,1,1,0,1])\n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = (2*p*r / (p+r+K.epsilon()))*key\n",
    "    \n",
    "#     f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return (1 - K.mean(f1))**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15, 1)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_lstm_prossed_train2[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_15 (InputLayer)        (None, 15, 1)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_53 (Conv1D)           (None, 15, 128)           512       \n",
      "_________________________________________________________________\n",
      "batch_normalization_27 (Batc (None, 15, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_27 (Activation)   (None, 15, 128)           0         \n",
      "_________________________________________________________________\n",
      "dropout_53 (Dropout)         (None, 15, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_54 (Conv1D)           (None, 15, 64)            24640     \n",
      "_________________________________________________________________\n",
      "dropout_54 (Dropout)         (None, 15, 64)            0         \n",
      "_________________________________________________________________\n",
      "dense_55 (Dense)             (None, 15, 32)            2080      \n",
      "_________________________________________________________________\n",
      "flatten_23 (Flatten)         (None, 480)               0         \n",
      "_________________________________________________________________\n",
      "Event_output (Dense)         (None, 16)                7696      \n",
      "=================================================================\n",
      "Total params: 35,440\n",
      "Trainable params: 35,184\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/70\n",
      "57867/57867 [==============================] - 6s 102us/step - loss: 16.8246 - f1_perRow: 0.0835 - f1_perClass: 0.0701 - acc: 0.0036\n",
      "Epoch 2/70\n",
      "57867/57867 [==============================] - 2s 36us/step - loss: 14.2516 - f1_perRow: 0.1275 - f1_perClass: 0.0847 - acc: 0.0260\n",
      "Epoch 3/70\n",
      "57867/57867 [==============================] - 2s 36us/step - loss: 13.0116 - f1_perRow: 0.1631 - f1_perClass: 0.0917 - acc: 0.2502\n",
      "Epoch 4/70\n",
      "57867/57867 [==============================] - 2s 35us/step - loss: 12.3008 - f1_perRow: 0.1886 - f1_perClass: 0.0944 - acc: 0.4555\n",
      "Epoch 5/70\n",
      "57867/57867 [==============================] - 2s 36us/step - loss: 11.7385 - f1_perRow: 0.2118 - f1_perClass: 0.0965 - acc: 0.5135\n",
      "Epoch 6/70\n",
      "57867/57867 [==============================] - 2s 36us/step - loss: 11.2397 - f1_perRow: 0.2352 - f1_perClass: 0.0978 - acc: 0.5311\n",
      "Epoch 7/70\n",
      "57867/57867 [==============================] - 2s 36us/step - loss: 10.7732 - f1_perRow: 0.2595 - f1_perClass: 0.0993 - acc: 0.5445\n",
      "Epoch 8/70\n",
      "57867/57867 [==============================] - 2s 36us/step - loss: 10.3523 - f1_perRow: 0.2843 - f1_perClass: 0.1005 - acc: 0.5539\n",
      "Epoch 9/70\n",
      "57867/57867 [==============================] - 2s 36us/step - loss: 9.9767 - f1_perRow: 0.3097 - f1_perClass: 0.1012 - acc: 0.5520\n",
      "Epoch 10/70\n",
      "57867/57867 [==============================] - 2s 35us/step - loss: 9.5498 - f1_perRow: 0.3382 - f1_perClass: 0.1023 - acc: 0.5447\n",
      "Epoch 11/70\n",
      "57867/57867 [==============================] - 2s 35us/step - loss: 9.1152 - f1_perRow: 0.3700 - f1_perClass: 0.1039 - acc: 0.5302\n",
      "Epoch 12/70\n",
      "57867/57867 [==============================] - 2s 36us/step - loss: 8.6575 - f1_perRow: 0.4056 - f1_perClass: 0.1060 - acc: 0.5077\n",
      "Epoch 13/70\n",
      "57867/57867 [==============================] - 2s 35us/step - loss: 8.2243 - f1_perRow: 0.4417 - f1_perClass: 0.1100 - acc: 0.4860\n",
      "Epoch 14/70\n",
      "57867/57867 [==============================] - 2s 36us/step - loss: 7.8311 - f1_perRow: 0.4766 - f1_perClass: 0.1143 - acc: 0.4725\n",
      "Epoch 15/70\n",
      "57867/57867 [==============================] - 2s 36us/step - loss: 7.4053 - f1_perRow: 0.5101 - f1_perClass: 0.1226 - acc: 0.4682\n",
      "Epoch 16/70\n",
      "57867/57867 [==============================] - 2s 35us/step - loss: 7.0073 - f1_perRow: 0.5392 - f1_perClass: 0.1323 - acc: 0.4669\n",
      "Epoch 17/70\n",
      "57867/57867 [==============================] - 2s 36us/step - loss: 6.6994 - f1_perRow: 0.5595 - f1_perClass: 0.1430 - acc: 0.4668\n",
      "Epoch 18/70\n",
      "57867/57867 [==============================] - 2s 35us/step - loss: 6.5096 - f1_perRow: 0.5705 - f1_perClass: 0.1530 - acc: 0.4668\n",
      "Epoch 19/70\n",
      "57867/57867 [==============================] - 2s 36us/step - loss: 6.4161 - f1_perRow: 0.5772 - f1_perClass: 0.1631 - acc: 0.4668\n",
      "Epoch 20/70\n",
      "57867/57867 [==============================] - 2s 36us/step - loss: 6.3484 - f1_perRow: 0.5822 - f1_perClass: 0.1724 - acc: 0.4668\n",
      "Epoch 21/70\n",
      "57867/57867 [==============================] - 2s 35us/step - loss: 6.2920 - f1_perRow: 0.5861 - f1_perClass: 0.1804 - acc: 0.4668\n",
      "Epoch 22/70\n",
      "57867/57867 [==============================] - 2s 36us/step - loss: 6.2420 - f1_perRow: 0.5895 - f1_perClass: 0.1909 - acc: 0.4668\n",
      "Epoch 23/70\n",
      "57867/57867 [==============================] - 2s 36us/step - loss: 6.2069 - f1_perRow: 0.5919 - f1_perClass: 0.2001 - acc: 0.4668\n",
      "Epoch 24/70\n",
      "57867/57867 [==============================] - 2s 35us/step - loss: 6.1667 - f1_perRow: 0.5943 - f1_perClass: 0.2072 - acc: 0.4668\n",
      "Epoch 25/70\n",
      "57867/57867 [==============================] - 2s 36us/step - loss: 6.1341 - f1_perRow: 0.5975 - f1_perClass: 0.2140 - acc: 0.4668\n",
      "Epoch 26/70\n",
      "57867/57867 [==============================] - 2s 36us/step - loss: 6.1027 - f1_perRow: 0.6022 - f1_perClass: 0.2195 - acc: 0.4668\n",
      "Epoch 27/70\n",
      "57867/57867 [==============================] - 2s 36us/step - loss: 6.0542 - f1_perRow: 0.6080 - f1_perClass: 0.2244 - acc: 0.4667\n",
      "Epoch 28/70\n",
      "57867/57867 [==============================] - 2s 36us/step - loss: 6.0149 - f1_perRow: 0.6139 - f1_perClass: 0.2281 - acc: 0.4668\n",
      "Epoch 29/70\n",
      "57867/57867 [==============================] - 2s 36us/step - loss: 5.9621 - f1_perRow: 0.6188 - f1_perClass: 0.2323 - acc: 0.4668\n",
      "Epoch 30/70\n",
      "57867/57867 [==============================] - 2s 36us/step - loss: 5.9214 - f1_perRow: 0.6216 - f1_perClass: 0.2348 - acc: 0.4668\n",
      "Epoch 31/70\n",
      "57867/57867 [==============================] - 2s 36us/step - loss: 5.8849 - f1_perRow: 0.6218 - f1_perClass: 0.2369 - acc: 0.4668\n",
      "Epoch 32/70\n",
      "57867/57867 [==============================] - 2s 36us/step - loss: 5.8398 - f1_perRow: 0.6208 - f1_perClass: 0.2388 - acc: 0.4667\n",
      "Epoch 33/70\n",
      "57867/57867 [==============================] - 2s 36us/step - loss: 5.7844 - f1_perRow: 0.6198 - f1_perClass: 0.2410 - acc: 0.4667\n",
      "Epoch 34/70\n",
      "57867/57867 [==============================] - 2s 36us/step - loss: 5.7658 - f1_perRow: 0.6185 - f1_perClass: 0.2419 - acc: 0.4667\n",
      "Epoch 35/70\n",
      "57867/57867 [==============================] - 2s 36us/step - loss: 5.7260 - f1_perRow: 0.6194 - f1_perClass: 0.2441 - acc: 0.4667\n",
      "Epoch 36/70\n",
      "57867/57867 [==============================] - 2s 36us/step - loss: 5.6942 - f1_perRow: 0.6210 - f1_perClass: 0.2471 - acc: 0.4668\n",
      "Epoch 37/70\n",
      "57867/57867 [==============================] - 2s 36us/step - loss: 5.6470 - f1_perRow: 0.6241 - f1_perClass: 0.2492 - acc: 0.4667\n",
      "Epoch 38/70\n",
      "57867/57867 [==============================] - 2s 36us/step - loss: 5.6131 - f1_perRow: 0.6274 - f1_perClass: 0.2523 - acc: 0.4667\n",
      "Epoch 39/70\n",
      "57867/57867 [==============================] - 2s 36us/step - loss: 5.5859 - f1_perRow: 0.6296 - f1_perClass: 0.2541 - acc: 0.4667\n",
      "Epoch 40/70\n",
      "57867/57867 [==============================] - 2s 36us/step - loss: 5.5580 - f1_perRow: 0.6316 - f1_perClass: 0.2556 - acc: 0.4668\n",
      "Epoch 41/70\n",
      "57867/57867 [==============================] - 2s 37us/step - loss: 5.5329 - f1_perRow: 0.6327 - f1_perClass: 0.2577 - acc: 0.4667\n",
      "Epoch 42/70\n",
      "57867/57867 [==============================] - 2s 36us/step - loss: 5.5076 - f1_perRow: 0.6329 - f1_perClass: 0.2600 - acc: 0.4667\n",
      "Epoch 43/70\n",
      "57867/57867 [==============================] - 2s 35us/step - loss: 5.4819 - f1_perRow: 0.6328 - f1_perClass: 0.2614 - acc: 0.4667\n",
      "Epoch 44/70\n",
      "57867/57867 [==============================] - 2s 36us/step - loss: 5.4646 - f1_perRow: 0.6328 - f1_perClass: 0.2624 - acc: 0.4667\n",
      "Epoch 45/70\n",
      "57867/57867 [==============================] - 2s 36us/step - loss: 5.4419 - f1_perRow: 0.6327 - f1_perClass: 0.2638 - acc: 0.4667\n",
      "Epoch 46/70\n",
      "57867/57867 [==============================] - 2s 35us/step - loss: 5.4204 - f1_perRow: 0.6332 - f1_perClass: 0.2649 - acc: 0.4667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/70\n",
      "57867/57867 [==============================] - 2s 36us/step - loss: 5.4000 - f1_perRow: 0.6338 - f1_perClass: 0.2655 - acc: 0.4667\n",
      "Epoch 48/70\n",
      "57867/57867 [==============================] - 2s 36us/step - loss: 5.3832 - f1_perRow: 0.6346 - f1_perClass: 0.2666 - acc: 0.4667\n",
      "Epoch 49/70\n",
      "57867/57867 [==============================] - 2s 36us/step - loss: 5.3703 - f1_perRow: 0.6353 - f1_perClass: 0.2675 - acc: 0.4667\n",
      "Epoch 50/70\n",
      "57867/57867 [==============================] - 2s 36us/step - loss: 5.3431 - f1_perRow: 0.6358 - f1_perClass: 0.2688 - acc: 0.4667\n",
      "Epoch 51/70\n",
      "57867/57867 [==============================] - 2s 36us/step - loss: 5.3391 - f1_perRow: 0.6355 - f1_perClass: 0.2687 - acc: 0.4667\n",
      "Epoch 52/70\n",
      "57867/57867 [==============================] - 2s 36us/step - loss: 5.3322 - f1_perRow: 0.6360 - f1_perClass: 0.2710 - acc: 0.4668\n",
      "Epoch 53/70\n",
      "57867/57867 [==============================] - 2s 36us/step - loss: 5.3343 - f1_perRow: 0.6362 - f1_perClass: 0.2713 - acc: 0.4667\n",
      "Epoch 54/70\n",
      "57867/57867 [==============================] - 2s 36us/step - loss: 5.3123 - f1_perRow: 0.6363 - f1_perClass: 0.2728 - acc: 0.4667\n",
      "Epoch 55/70\n",
      "57867/57867 [==============================] - 2s 36us/step - loss: 5.2949 - f1_perRow: 0.6366 - f1_perClass: 0.2742 - acc: 0.4667\n",
      "Epoch 56/70\n",
      "57867/57867 [==============================] - 2s 36us/step - loss: 5.2925 - f1_perRow: 0.6365 - f1_perClass: 0.2739 - acc: 0.4668\n",
      "Epoch 57/70\n",
      "57867/57867 [==============================] - 2s 35us/step - loss: 5.2722 - f1_perRow: 0.6372 - f1_perClass: 0.2749 - acc: 0.4668\n",
      "Epoch 58/70\n",
      "57867/57867 [==============================] - 2s 36us/step - loss: 5.2682 - f1_perRow: 0.6373 - f1_perClass: 0.2764 - acc: 0.4667\n",
      "Epoch 59/70\n",
      "57867/57867 [==============================] - 2s 36us/step - loss: 5.2570 - f1_perRow: 0.6377 - f1_perClass: 0.2775 - acc: 0.4667\n",
      "Epoch 60/70\n",
      "57867/57867 [==============================] - 2s 36us/step - loss: 5.2492 - f1_perRow: 0.6382 - f1_perClass: 0.2781 - acc: 0.4667\n",
      "Epoch 61/70\n",
      "57867/57867 [==============================] - 2s 35us/step - loss: 5.2398 - f1_perRow: 0.6386 - f1_perClass: 0.2790 - acc: 0.4667\n",
      "Epoch 62/70\n",
      "57867/57867 [==============================] - 2s 36us/step - loss: 5.2346 - f1_perRow: 0.6393 - f1_perClass: 0.2792 - acc: 0.4667\n",
      "Epoch 63/70\n",
      "57867/57867 [==============================] - 2s 36us/step - loss: 5.2295 - f1_perRow: 0.6397 - f1_perClass: 0.2797 - acc: 0.4667\n",
      "Epoch 64/70\n",
      "57867/57867 [==============================] - 2s 36us/step - loss: 5.2217 - f1_perRow: 0.6400 - f1_perClass: 0.2801 - acc: 0.4667\n",
      "Epoch 65/70\n",
      "57867/57867 [==============================] - 2s 35us/step - loss: 5.2095 - f1_perRow: 0.6402 - f1_perClass: 0.2815 - acc: 0.4668\n",
      "Epoch 66/70\n",
      "57867/57867 [==============================] - 2s 35us/step - loss: 5.2163 - f1_perRow: 0.6404 - f1_perClass: 0.2818 - acc: 0.4667\n",
      "Epoch 67/70\n",
      "57867/57867 [==============================] - 2s 35us/step - loss: 5.2105 - f1_perRow: 0.6406 - f1_perClass: 0.2830 - acc: 0.4668\n",
      "Epoch 68/70\n",
      "57867/57867 [==============================] - 2s 36us/step - loss: 5.1973 - f1_perRow: 0.6409 - f1_perClass: 0.2841 - acc: 0.4667\n",
      "Epoch 69/70\n",
      "57867/57867 [==============================] - 2s 36us/step - loss: 5.1876 - f1_perRow: 0.6412 - f1_perClass: 0.2843 - acc: 0.4668\n",
      "Epoch 70/70\n",
      "57867/57867 [==============================] - 2s 36us/step - loss: 5.1804 - f1_perRow: 0.6418 - f1_perClass: 0.2854 - acc: 0.4668\n"
     ]
    }
   ],
   "source": [
    "inputs  = Input(  (x_lstm_prossed_train2[0].shape[0]  ,1) )\n",
    "\n",
    "out = Conv1D(128,3,padding='same')(inputs)\n",
    "out = BatchNormalization()(out)\n",
    "out = Activation('relu')(out)\n",
    "out = Dropout(0.2)(out)\n",
    "out = Conv1D(64,3,padding='same')(out)\n",
    "\n",
    "dout_1  = Dropout(0.2)(out)\n",
    "# flt_1   = Flatten()(dout_1)\n",
    "dense_1 = Dense(32, activation='relu')(dout_1)\n",
    "# dout_3  = Dropout(0.2)(dense_1)\n",
    "flt_1   = Flatten()(dense_1)\n",
    "\n",
    "out_put_final = Dense(len(classes), activation='sigmoid', name='Event_output')(flt_1)\n",
    "\n",
    "\n",
    "model2 = Model(inputs=[inputs], outputs=[out_put_final])\n",
    "\n",
    "\n",
    "losses = {\n",
    "    \"Event_output\": f1_loss_perClass ,\n",
    "#     \"Event_output\": f1_loss_perRow \n",
    "    \"Event_output\": \"categorical_crossentropy\",\n",
    "}\n",
    "lossWeights = {\"Event_output\": 200,\n",
    "#                \"Event_output\": 30.0 \n",
    "    \"Event_output\": 5\n",
    "              }\n",
    " \n",
    "\n",
    "\n",
    "model2.compile(loss=losses,loss_weights=lossWeights, optimizer='adam', metrics=[f1_perRow,f1_perClass,'acc'])\n",
    "# model2.compile(loss=losses, loss_weights=lossWeights, optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "checkpoint = ModelCheckpoint('IoTDownNet_cnn_newloss', monitor='loss', verbose=0, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "print(model2.summary())\n",
    "hist2 = model2.fit(x_lstm_prossed_train2, y_lstm_prossed_train, epochs=70, batch_size=60000, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "losses = {\n",
    "    \"Event_output\": f1_loss_perClass ,\n",
    "#     \"Event_output\": f1_loss_perRow \n",
    "#     \"Event_output\": \"categorical_crossentropy\",\n",
    "}\n",
    "lossWeights = {\"Event_output\": 20,\n",
    "#                \"Event_output\": 30.0 \n",
    "#     \"Event_output\": 20\n",
    "              }\n",
    " \n",
    "\n",
    "\n",
    "model2.compile(loss=losses,loss_weights=lossWeights, optimizer='adam', metrics=[f1_perRow,f1_perClass,'acc'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "57867/57867 [==============================] - 2s 37us/step - loss: 2.5613 - f1_perRow: 0.7625 - f1_perClass: 0.3735 - acc: 0.8722\n",
      "Epoch 2/100\n",
      "57867/57867 [==============================] - 2s 37us/step - loss: 2.5580 - f1_perRow: 0.7693 - f1_perClass: 0.3732 - acc: 0.8727\n",
      "Epoch 3/100\n",
      "57867/57867 [==============================] - 2s 37us/step - loss: 2.5561 - f1_perRow: 0.7636 - f1_perClass: 0.3678 - acc: 0.8738\n",
      "Epoch 4/100\n",
      "57867/57867 [==============================] - 2s 37us/step - loss: 2.5451 - f1_perRow: 0.7672 - f1_perClass: 0.3693 - acc: 0.8729\n",
      "Epoch 5/100\n",
      "57867/57867 [==============================] - 2s 37us/step - loss: 2.5957 - f1_perRow: 0.7698 - f1_perClass: 0.3690 - acc: 0.8716\n",
      "Epoch 6/100\n",
      "57867/57867 [==============================] - 2s 35us/step - loss: 2.5453 - f1_perRow: 0.7753 - f1_perClass: 0.3697 - acc: 0.8747\n",
      "Epoch 7/100\n",
      "57867/57867 [==============================] - 2s 37us/step - loss: 2.5414 - f1_perRow: 0.7707 - f1_perClass: 0.3746 - acc: 0.8728\n",
      "Epoch 8/100\n",
      "57867/57867 [==============================] - 2s 37us/step - loss: 2.5232 - f1_perRow: 0.7714 - f1_perClass: 0.3799 - acc: 0.8738\n",
      "Epoch 9/100\n",
      "57867/57867 [==============================] - 2s 37us/step - loss: 2.5415 - f1_perRow: 0.7637 - f1_perClass: 0.3758 - acc: 0.8727\n",
      "Epoch 10/100\n",
      "57867/57867 [==============================] - 2s 37us/step - loss: 2.5425 - f1_perRow: 0.7684 - f1_perClass: 0.3751 - acc: 0.8739\n",
      "Epoch 11/100\n",
      "57867/57867 [==============================] - 2s 36us/step - loss: 2.5374 - f1_perRow: 0.7760 - f1_perClass: 0.3718 - acc: 0.8737\n",
      "Epoch 12/100\n",
      "57867/57867 [==============================] - 2s 37us/step - loss: 2.5400 - f1_perRow: 0.7656 - f1_perClass: 0.3786 - acc: 0.8717\n",
      "Epoch 13/100\n",
      "57867/57867 [==============================] - 2s 37us/step - loss: 2.5220 - f1_perRow: 0.7678 - f1_perClass: 0.3781 - acc: 0.8728\n",
      "Epoch 14/100\n",
      "57867/57867 [==============================] - 2s 37us/step - loss: 2.5308 - f1_perRow: 0.7740 - f1_perClass: 0.3739 - acc: 0.8735\n",
      "Epoch 15/100\n",
      "57867/57867 [==============================] - 2s 36us/step - loss: 2.5440 - f1_perRow: 0.7723 - f1_perClass: 0.3790 - acc: 0.8722\n",
      "Epoch 16/100\n",
      "57867/57867 [==============================] - 2s 37us/step - loss: 2.5301 - f1_perRow: 0.7667 - f1_perClass: 0.3867 - acc: 0.8724\n",
      "Epoch 17/100\n",
      "57867/57867 [==============================] - 2s 37us/step - loss: 2.5413 - f1_perRow: 0.7872 - f1_perClass: 0.3774 - acc: 0.8720\n",
      "Epoch 18/100\n",
      "57867/57867 [==============================] - 2s 37us/step - loss: 2.5290 - f1_perRow: 0.7815 - f1_perClass: 0.3861 - acc: 0.8740\n",
      "Epoch 19/100\n",
      "57867/57867 [==============================] - 2s 37us/step - loss: 2.5200 - f1_perRow: 0.7759 - f1_perClass: 0.3812 - acc: 0.8735\n",
      "Epoch 20/100\n",
      "57867/57867 [==============================] - 2s 37us/step - loss: 2.5142 - f1_perRow: 0.7725 - f1_perClass: 0.3743 - acc: 0.8749\n",
      "Epoch 21/100\n",
      "57867/57867 [==============================] - 2s 37us/step - loss: 2.5200 - f1_perRow: 0.7643 - f1_perClass: 0.3806 - acc: 0.8739\n",
      "Epoch 22/100\n",
      "57867/57867 [==============================] - 2s 37us/step - loss: 2.5133 - f1_perRow: 0.7695 - f1_perClass: 0.3791 - acc: 0.8730\n",
      "Epoch 23/100\n",
      "57867/57867 [==============================] - 2s 37us/step - loss: 2.5279 - f1_perRow: 0.7748 - f1_perClass: 0.3796 - acc: 0.8730\n",
      "Epoch 24/100\n",
      "57867/57867 [==============================] - 2s 37us/step - loss: 2.5165 - f1_perRow: 0.7786 - f1_perClass: 0.3790 - acc: 0.8743\n",
      "Epoch 25/100\n",
      "57867/57867 [==============================] - 2s 37us/step - loss: 2.5015 - f1_perRow: 0.7725 - f1_perClass: 0.3776 - acc: 0.8754\n",
      "Epoch 26/100\n",
      "57867/57867 [==============================] - 2s 37us/step - loss: 2.4961 - f1_perRow: 0.7770 - f1_perClass: 0.3856 - acc: 0.8756\n",
      "Epoch 27/100\n",
      "57867/57867 [==============================] - 2s 37us/step - loss: 2.5146 - f1_perRow: 0.7765 - f1_perClass: 0.3800 - acc: 0.8767\n",
      "Epoch 28/100\n",
      "57867/57867 [==============================] - 2s 37us/step - loss: 2.5150 - f1_perRow: 0.7799 - f1_perClass: 0.3821 - acc: 0.8740\n",
      "Epoch 29/100\n",
      "57867/57867 [==============================] - 2s 37us/step - loss: 2.5004 - f1_perRow: 0.7791 - f1_perClass: 0.3827 - acc: 0.8741\n",
      "Epoch 30/100\n",
      "57867/57867 [==============================] - 2s 37us/step - loss: 2.5163 - f1_perRow: 0.7822 - f1_perClass: 0.3896 - acc: 0.8735\n",
      "Epoch 31/100\n",
      "57867/57867 [==============================] - 2s 37us/step - loss: 2.4887 - f1_perRow: 0.7787 - f1_perClass: 0.3889 - acc: 0.8751\n",
      "Epoch 32/100\n",
      "57867/57867 [==============================] - 2s 37us/step - loss: 2.5075 - f1_perRow: 0.7732 - f1_perClass: 0.3826 - acc: 0.8742\n",
      "Epoch 33/100\n",
      "  510/57867 [..............................] - ETA: 2s - loss: 2.0339 - f1_perRow: 0.8155 - f1_perClass: 0.3596 - acc: 0.9020"
     ]
    }
   ],
   "source": [
    "hist2 = model2.fit(x_lstm_prossed_train2, y_lstm_prossed_train, epochs=100, batch_size=510, shuffle=True, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.load_weights('IoTDownNet_cnn_nocca')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================HOME Case : home_os_final.json =============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/omid/.conda/envs/iot/lib/python3.6/site-packages/ipykernel_launcher.py:9: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  if __name__ == '__main__':\n",
      "/home/omid/.conda/envs/iot/lib/python3.6/site-packages/ipykernel_launcher.py:8: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  \n",
      "/home/omid/.conda/envs/iot/lib/python3.6/site-packages/ipykernel_launcher.py:12: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         Class  Accuracy     Recall  Precision   F Score    Count            TP/TN/FP/FN\n",
      "------------------------------------------------------------------------\n",
      "                  acceleration     0.997      0.298     0.459     0.362        57    17/19013/   20/   40\n",
      "                      activity     1.000      0.625     0.769     0.690        16    10/19071/    3/    6\n",
      "                       battery     1.000      0.000       nan     0.000         7     0/19083/    0/    7\n",
      "                        button     0.999      0.500     0.600     0.545        12     6/19074/    4/    6\n",
      "              colorTemperature     1.000      0.600     0.750     0.667         5     3/19084/    1/    2\n",
      "                       contact     0.995      0.550     0.783     0.646       151    83/18916/   23/   68\n",
      "                         level     0.999      0.500     0.667     0.571        20    10/19065/    5/   10\n",
      "                          lock     0.996      0.706     0.270     0.390        34    24/18991/   65/   10\n",
      "                        motion     0.982      0.000     0.000     0.000       343     0/18746/    1/  343\n",
      "                          ping     0.995      0.998     0.982     0.990      4814  4804/14187/   89/   10\n",
      "                        status     0.997      0.718     0.778     0.747       117    84/18949/   24/   33\n",
      "                        switch     1.000      0.810     0.850     0.829        21    17/19066/    3/    4\n",
      "                   temperature     0.941      0.000     0.000     0.000      1120     0/17968/    2/ 1120\n",
      "                     threeAxis     0.998      0.806     0.453     0.580        36    29/19019/   35/    7\n",
      "                       unknown     0.850      0.900     0.885     0.893     13223 11906/ 4326/ 1541/ 1317\n",
      "                         water     1.000        nan       nan       nan         0     0/19090/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "                      AVERAGES     0.984      0.501     0.515     0.494     19090     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "             Weighted AVERAGES     0.896      0.851     0.838     0.844     19090     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "       known Weighted AVERAGES     0.985      0.753     0.747     0.748     19090     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      " known -ping Weighted AVERAGES     0.962      0.146     0.163     0.149     19090     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "       non zero count AVERAGES     0.983      0.534     0.550     0.527     19090     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "Macro F1 : 0.494352\n",
      "sample F1 : 0.848024\n",
      "weighted F1 : 0.844029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/omid/.conda/envs/iot/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exact Match ACC : 0.84390 \n",
      "Total Records : 19090 \n",
      "Total ZXeros in True : 0 (0.000)%\n",
      "Total ZXeros in Test : 1272 (0.067)%\n",
      "=============================================================================\n",
      "==================HOME Case : test_data_light.json =============\n",
      "                         Class  Accuracy     Recall  Precision   F Score    Count            TP/TN/FP/FN\n",
      "------------------------------------------------------------------------\n",
      "                  acceleration     1.000        nan       nan       nan         0     0/  265/    0/    0\n",
      "                      activity     1.000        nan       nan       nan         0     0/  265/    0/    0\n",
      "                       battery     1.000        nan       nan       nan         0     0/  265/    0/    0\n",
      "                        button     0.989        nan     0.000     0.000         0     0/  262/    3/    0\n",
      "              colorTemperature     0.845      0.000     0.000     0.000        31     0/  224/   10/   31\n",
      "                       contact     1.000        nan       nan       nan         0     0/  265/    0/    0\n",
      "                         level     0.660      0.048     0.267     0.082        83     4/  171/   11/   79\n",
      "                          lock     1.000        nan       nan       nan         0     0/  265/    0/    0\n",
      "                        motion     1.000        nan       nan       nan         0     0/  265/    0/    0\n",
      "                          ping     0.974      0.769     0.952     0.851        26    20/  238/    1/    6\n",
      "                        status     1.000        nan       nan       nan         0     0/  265/    0/    0\n",
      "                        switch     0.872      0.083     0.143     0.105        24     2/  229/   12/   22\n",
      "                   temperature     0.992      0.000       nan     0.000         2     0/  263/    0/    2\n",
      "                     threeAxis     1.000        nan       nan       nan         0     0/  265/    0/    0\n",
      "                       unknown     0.532      0.645     0.543     0.589       138    89/   52/   75/   49\n",
      "                         water     1.000        nan       nan       nan         0     0/  265/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "                      AVERAGES     0.929      0.097     0.119     0.102       265     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "             Weighted AVERAGES     0.667      0.378     0.412     0.371       265     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "       known Weighted AVERAGES     0.779      0.157     0.303     0.189       265     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      " known -ping Weighted AVERAGES     0.742      0.043     0.183     0.066       265     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "       non zero count AVERAGES     0.813      0.258     0.317     0.271       265     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "Macro F1 : 0.101710\n",
      "sample F1 : 0.403774\n",
      "weighted F1 : 0.370945\n",
      "Exact Match ACC : 0.36604 \n",
      "Total Records : 265 \n",
      "Total ZXeros in True : 0 (0.000)%\n",
      "Total ZXeros in Test : 75 (0.283)%\n",
      "=============================================================================\n",
      "==================HOME Case : test_data_motion_2.json =============\n",
      "                         Class  Accuracy     Recall  Precision   F Score    Count            TP/TN/FP/FN\n",
      "------------------------------------------------------------------------\n",
      "                  acceleration     0.997      0.000       nan     0.000        30     0/10406/    0/   30\n",
      "                      activity     1.000        nan       nan       nan         0     0/10436/    0/    0\n",
      "                       battery     1.000      0.000     0.000     0.000         1     0/10434/    1/    1\n",
      "                        button     0.999        nan     0.000     0.000         0     0/10430/    6/    0\n",
      "              colorTemperature     0.980      0.000     0.000     0.000         3     0/10225/  208/    3\n",
      "                       contact     0.987      0.000       nan     0.000       131     0/10305/    0/  131\n",
      "                         level     1.000      0.400     0.667     0.500         5     2/10430/    1/    3\n",
      "                          lock     0.999        nan     0.000     0.000         0     0/10426/   10/    0\n",
      "                        motion     0.969      0.000       nan     0.000       325     0/10111/    0/  325\n",
      "                          ping     0.972      0.910     0.980     0.944      2662  2423/ 7725/   49/  239\n",
      "                        status     1.000        nan       nan       nan         0     0/10436/    0/    0\n",
      "                        switch     1.000      1.000     0.500     0.667         2     2/10432/    2/    0\n",
      "                   temperature     0.994      0.000     0.000     0.000        50     0/10377/    9/   50\n",
      "                     threeAxis     0.998      0.000     0.000     0.000        18     0/10417/    1/   18\n",
      "                       unknown     0.694      0.655     0.907     0.761      7746  5071/ 2173/  517/ 2675\n",
      "                         water     1.000        nan       nan       nan         0     0/10436/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "                      AVERAGES     0.974      0.185     0.191     0.179     10436     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "             Weighted AVERAGES     0.776      0.683     0.879     0.766     10436     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "       known Weighted AVERAGES     0.973      0.752     0.810     0.780     10436     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      " known -ping Weighted AVERAGES     0.978      0.007     0.008     0.007     10436     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "       non zero count AVERAGES     0.963      0.270     0.278     0.261     10436     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "Macro F1 : 0.179449\n",
      "sample F1 : 0.683650\n",
      "weighted F1 : 0.766263\n",
      "Exact Match ACC : 0.66117 \n",
      "Total Records : 10436 \n",
      "Total ZXeros in True : 0 (0.000)%\n",
      "Total ZXeros in Test : 2532 (0.243)%\n",
      "=============================================================================\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(lstm_tests_known)) :\n",
    "    print( \"==================HOME Case : %s =============\" % test_names[i])\n",
    "    lstm_pred= model2.predict( lstm_tests_known[i][0])\n",
    "    \n",
    "#     print_info( lstm_tests[i][1], lstm_pred, classes , confidance=0.7)\n",
    "    print_info( lstm_tests_known[i][1], lstm_pred, classes , confidance=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_tests_known[0][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def describe_output(classes, instance):\n",
    "    ret = [] \n",
    "    for x in range(len(instance)):\n",
    "        if instance[x] > 0.6:\n",
    "            ret.append(classes[x])\n",
    "    return ret\n",
    "def save_resutls(inp, y, y_hat, classes,the_name):\n",
    "    items = [] \n",
    "    for i in range(len(inp)):\n",
    "#         print(describe_output(classes, y[i]))\n",
    "        items.append({'inp': str(list(inp[i])),\n",
    "                     'true': list(describe_output(classes, y[i])),\n",
    "                     'pred': list(describe_output(classes, y_hat[i]))\n",
    "                     })\n",
    "#         print(items[-1])\n",
    "#         return\n",
    "    with open('cnn_for_karthika_'+the_name +'.json', 'w') as outfile:\n",
    "        json.dump(items, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "describe_output(['a','b'],[1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================HOME Case : home_os_final.json =============\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'rf_test_known' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-f12f6b9df906>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlstm_tests_known\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m\"==================HOME Case : %s =============\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mtest_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mlstm_pred\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mmodel2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mrf_test_known\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;31m#     save_resutls( lstm_tests_known[i][0], rf_test_known[i][1], lstm_pred,  classes, test_names[i] )\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#     break\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'rf_test_known' is not defined"
     ]
    }
   ],
   "source": [
    "lstm_pred = []\n",
    "for i in range(len(lstm_tests_known)) :\n",
    "    print( \"==================HOME Case : %s =============\" % test_names[i])\n",
    "    lstm_pred= model2.predict( rf_test_known[i][0])\n",
    "#     save_resutls( lstm_tests_known[i][0], rf_test_known[i][1], lstm_pred,  classes, test_names[i] )\n",
    "#     break \n",
    "#     print_info( lstm_tests[i][1], lstm_pred, classes , confidance=0.7)\n",
    "    print_info( rf_test_known[i][1], lstm_pred, classes , confidance=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_resutls( lstm_tests_known[0][0], rf_test_known[0][1], lstm_pred, classes, test_names[0] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "describe_output(classes, rf_test_known[0][1][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 10552, 1)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 10552, 128)        512       \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 10552, 128)        512       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 10552, 128)        0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 10552, 128)        0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 10552, 64)         24640     \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 10552, 30)         11400     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10552, 64)         1984      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10552, 32)         2080      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10552, 16)         528       \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 10552, 16)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 168832)            0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 16)                2701328   \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "Event_output (Dense)         (None, 17)                289       \n",
      "=================================================================\n",
      "Total params: 2,743,273\n",
      "Trainable params: 2,743,017\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/80\n",
      "  490/18925 [..............................] - ETA: 1:11:20 - loss: 55.6061 - f1_perRow: 0.0907 - f1_perClass: 0.1798 - acc: 0.3286"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-d0edcebc01ce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m \u001b[0mhist2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_lstm_prossed_train2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_lstm_prossed_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m80\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m70\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.conda/envs/iot/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/.conda/envs/iot/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/iot/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/iot/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/iot/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "inputs  = Input(  (x_lstm_prossed_train2[0].shape[0]  ,1) )\n",
    "\n",
    "\n",
    "out = Conv1D(128,3,padding='same')(inputs)\n",
    "out = BatchNormalization()(out)\n",
    "out = Activation('relu')(out)\n",
    "out = Dropout(0.2)(out)\n",
    "out = Conv1D(64,3,padding='same')(out)\n",
    "# bi_d_1 = Bidirectional( LSTM(200 ,  recurrent_dropout=0.12, return_sequences=True),input_shape=[dim_size,1],merge_mode='concat') (inputs)\n",
    "lstm_1 =  LSTM(30 ,  recurrent_dropout=0.04, return_sequences=True)(out)\n",
    "# lstm_2 = LSTM(30 ,  recurrent_dropout=0.14, return_sequences=True)(lstm_1)\n",
    "\n",
    "bi_d_1 =Dense(64, activation='relu')  (lstm_1)\n",
    "lstm_1 =  Dense(32, activation='relu')(bi_d_1)\n",
    "lstm_2 = Dense(16, activation='relu')(lstm_1)\n",
    "\n",
    "\n",
    "\n",
    "# td_1    = TimeDistributed(Dense(256, activation='relu'))(lstm_2)\n",
    "# dout_1  = Dropout(0.1)(td_1)\n",
    "dout_1  = Dropout(0.1)(lstm_2)\n",
    "flt_1   = Flatten()(dout_1)\n",
    "dense_1 = Dense(16, activation='relu')(flt_1)\n",
    "dout_2  = Dropout(0.2)(dense_1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # bi_d_1 = Bidirectional( LSTM(200 ,  recurrent_dropout=0.12, return_sequences=True),input_shape=[dim_size,1],merge_mode='concat') (inputs)\n",
    "# lstm_1 =  LSTM(100 ,  recurrent_dropout=0.04, return_sequences=True)(inputs)\n",
    "# # lstm_1 = LSTM(40 ,  recurrent_dropout=0.14, return_sequences=True)(lstm_1)\n",
    "\n",
    "# bi_d_raw_1 =Dense(128, activation='relu')  (lstm_1)\n",
    "# lstm_raw_1 =  Dense(128, activation='relu')(bi_d_raw_1)\n",
    "# lstm_raw_2 = Dense(128, activation='relu')(lstm_raw_1)\n",
    "\n",
    "# dout_1  = Dropout(0.1)(lstm_raw_2)\n",
    "# flt_1   = Flatten()(dout_1)\n",
    "# dense_1 = Dense(128, activation='relu')(flt_1)\n",
    "# dout_3  = Dropout(0.2)(dense_1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# out = Conv1D(128,3,padding='same')(inputs)\n",
    "# out = BatchNormalization()(out)\n",
    "# out = Activation('relu')(out)\n",
    "# out = Dropout(0.2)(out)\n",
    "# out = Conv1D(128,3,padding='same')(out)\n",
    "# # out = Flatten()(out)\n",
    "# # out = MaxPooling1D(2,padding='same', name ='pooling')(out)\n",
    "\n",
    "\n",
    "# out = Conv1D(128,3,padding='same')(out)\n",
    "# out = BatchNormalization()(out)\n",
    "# out = Activation('relu')(out)\n",
    "# out = Dropout(0.2)(out)\n",
    "# out = Conv1D(128,3,padding='same')(out)\n",
    "# # out = Flatten()(out)\n",
    "# # out = MaxPooling1D(2,padding='same', name ='pooling2')(out)\n",
    "\n",
    "\n",
    "# out = Conv1D(128,3,padding='same')(out)\n",
    "# out = BatchNormalization()(out)\n",
    "# out = Activation('relu')(out)\n",
    "# out = Dropout(0.2)(out)\n",
    "# out = Conv1D(128,3,padding='same')(out)\n",
    "\n",
    "\n",
    "# out = Flatten()(out)\n",
    "# out = MaxPooling1D(2,padding='same', name ='pooling')(out)\n",
    "\n",
    "\n",
    "\n",
    "# fl_out_1 = Flatten()(dout_2)\n",
    "\n",
    "# fl_out_cnn = Flatten()(out)\n",
    "\n",
    "# out_new = concatenate( [fl_out_1, fl_out_cnn] , name='mergerguy')\n",
    "# out_new = concatenate( [dout_2, fl_out_cnn,dout_3] , name='mergerguy')\n",
    "# out_new = concatenate( [dout_2] , name='mergerguy')\n",
    "\n",
    "# dens_out_1 = Dense( 128, activation='relu' )(out_new)\n",
    "# dens_out_2 = Dense( 128, activation='relu' )(dens_out_1)\n",
    "# dens_out_3 = Dense( 128, activation='relu' )(dens_out_2)\n",
    "\n",
    "# fl2  = Flatten()(out_new)\n",
    "\n",
    "out_put_final = Dense(len(classes), activation='sigmoid', name='Event_output')(dout_2)\n",
    "\n",
    "# toService_1 = Dense( 130, name=\"to_service1\" )(dens_out_3)\n",
    "# toService_1 = Dense( 130, name=\"to_service2\" )(toService_1)\n",
    "\n",
    "# service_output = Dense(len(classes  ), activation=\"sigmoid\", name = 'service_output')(toService_1)\n",
    "\n",
    "\n",
    "\n",
    "model2 = Model(inputs=[inputs], outputs=[out_put_final])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# model2.add(Bidirectional( LSTM(200 ,  recurrent_dropout=0.12, return_sequences=True),input_shape=[dim_size,1],merge_mode='concat'))\n",
    "# model2.add( LSTM(60 ,  recurrent_dropout=0.04, return_sequences=True))\n",
    "# model2.add( LSTM(30 ,  recurrent_dropout=0.14, return_sequences=True))\n",
    "# # model2.add(Bidirectional( LSTM(100 ,  recurrent_dropout=0.04, return_sequences=True),merge_mode='concat'))\n",
    "# model2.add(TimeDistributed(Dense(256, activation='relu')))\n",
    "# model2.add(Dropout(0.1))\n",
    "# model2.add(Flatten())\n",
    "# model2.add(Dense(128, activation='relu'))\n",
    "# model2.add(Dropout(0.2))\n",
    "# model2.add(Dense(len(classes), activation='sigmoid'))\n",
    "\n",
    "# model2.compile(loss=weighted_categorical_crossentropy(weights=weights), optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "losses = {\n",
    "#     \"service_output\": f1_loss_perClass ,\n",
    "    \"Event_output\": f1_loss_perRow ,\n",
    "    \"Event_output\": \"categorical_crossentropy\",\n",
    "}\n",
    "lossWeights = {#\"service_output\": 20,\n",
    "               \"Event_output\": 30.0 ,\n",
    "    \"Event_output\": 20}\n",
    " \n",
    "\n",
    "\n",
    "model2.compile(loss=losses,loss_weights=lossWeights, optimizer='adam', metrics=[f1_perRow,f1_perClass,'acc'])\n",
    "# model2.compile(loss=losses, loss_weights=lossWeights, optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "checkpoint = ModelCheckpoint('IoTDownNet', monitor='loss', verbose=0, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "print(model2.summary())\n",
    "hist2 = model2.fit(x_lstm_prossed_train2, y_lstm_prossed_train, epochs=80, batch_size=70, shuffle=True, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(lstm_tests_known)) :\n",
    "    print( \"==================HOME Case : %s =============\" % test_names[i])\n",
    "    lstm_pred= model2.predict( rf_test_known[i][0])\n",
    "    \n",
    "#     print_info( lstm_tests[i][1], lstm_pred, classes , confidance=0.7)\n",
    "    print_info( rf_test_known[i][1], lstm_pred, classes , confidance=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the model\n",
    "dim_size =15\n",
    "x_lstm_prossed_train,y_lstm_prossed_train, _ = pre_process_raw( x_train, y_train , dim_size, zero_pad=False, normalize=False,classes=classes)\n",
    "_, y_s_lstm_processed_train ,_ =  pre_process_raw( x_train, y_train_service , dim_size, zero_pad=False, normalize=False,classes=service_classes)\n",
    "# x_lstm_prossed_test,y_lstm_prossed_test, _ = pre_process_raw( x_test, y_test_2 , dim_size, zero_pad=True, normalize=False,classes=classes)\n",
    "lstm_tests  = [ pre_process_raw( x_test[i], y_test[i] , dim_size, zero_pad=False, normalize=False, classes=classes) for i in range(len(x_test)) ] \n",
    "lstm_tests_services  = [ pre_process_raw( x_test[i], y_test_service[i] , dim_size, zero_pad=False, normalize=True, classes=service_classes) for i in range(len(x_test)) ] \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# known_indexes_train  = [ i for i in range(len(train_known_unknown_pred)) if train_known_unknown_pred[i][1] ==1 ]\n",
    "\n",
    "# x_lstm_prossed_train = x_lstm_prossed_train[known_indexes_train]\n",
    "# y_lstm_prossed_train = y_lstm_prossed_train[known_indexes_train]\n",
    "\n",
    "lstm_tests_known = [] \n",
    "\n",
    "for test_index in range(len(rf_tests)):\n",
    "#     known_indexes= [ i for i in range(len(test_known_unknown_predicted[test_index])) if test_known_unknown_predicted[test_index][i][1] ==1 ]\n",
    "    \n",
    "    lstm_tests_known.append(  (lstm_tests[test_index][0], \n",
    "                            lstm_tests[test_index][1],\n",
    "                            lstm_tests[test_index][2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_known_unknown_pred' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-f28c5aa0548a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mknown_indexes_train\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_known_unknown_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtrain_known_unknown_pred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mx_lstm_prossed_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_lstm_prossed_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mknown_indexes_train\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0my_lstm_prossed_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_lstm_prossed_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mknown_indexes_train\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_known_unknown_pred' is not defined"
     ]
    }
   ],
   "source": [
    "known_indexes_train  = [ i for i in range(len(train_known_unknown_pred)) if train_known_unknown_pred[i][1] ==1 ]\n",
    "\n",
    "x_lstm_prossed_train = x_lstm_prossed_train[known_indexes_train]\n",
    "y_lstm_prossed_train = y_lstm_prossed_train[known_indexes_train]\n",
    "\n",
    "lstm_tests_known = [] \n",
    "\n",
    "for test_index in range(len(rf_tests)):\n",
    "    known_indexes= [ i for i in range(len(test_known_unknown_predicted[test_index])) if test_known_unknown_predicted[test_index][i][1] ==1 ]\n",
    "    \n",
    "    lstm_tests_known.append(  (lstm_tests[test_index][0][known_indexes], \n",
    "                            lstm_tests[test_index][1][known_indexes],\n",
    "                            lstm_tests[test_index][2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_lstm_prossed_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-359fd4fa294f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx_lstm_prossed_test2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_lstm_prossed_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mx_lstm_prossed_train2\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_lstm_prossed_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'x_lstm_prossed_test' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_lstm_prossed_test2 = np.expand_dims(x_lstm_prossed_test,axis=1)\n",
    "# x_lstm_prossed_train2 =np.expand_dims(x_lstm_prossed_train,axis=1)\n",
    "\n",
    "for tt  in range( len(lstm_tests_known) ):\n",
    "    lstm_tests_known[tt]= (lstm_tests_known[tt][0].reshape(len(lstm_tests_known[tt][0]),dim_size,1) ,\n",
    "                           lstm_tests_known[tt][1],\n",
    "                           lstm_tests_services[tt][1] )\n",
    "# x_lstm_prossed_test2 = x_lstm_prossed_test.reshape(len(x_lstm_prossed_test),dim_size,1)\n",
    "x_lstm_prossed_train2 =x_lstm_prossed_train.reshape(len(x_lstm_prossed_train),dim_size,1)\n",
    "\n",
    "# y_lstm_prossed_test2 = y_lstm_prossed_test.reshape(len(y_lstm_prossed_test),len(classes),1)\n",
    "# y_lstm_prossed_train2 =y_lstm_prossed_train.reshape(len(y_lstm_prossed_train),len(classes),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0406 23:30:10.097258 139895529674560 deprecation_wrapper.py:119] From /home/omid/.conda/envs/iot/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Bidirectional LSTM :D \n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers import Bidirectional\n",
    "from keras.layers import Flatten\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from keras.models import Model\n",
    "\n",
    "from keras.layers import Input, merge, concatenate, Conv2D, MaxPooling2D, Activation, UpSampling2D, Dropout, Conv2DTranspose, UpSampling2D, Lambda\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers.normalization import BatchNormalization as bn\n",
    "from keras.layers.merge import add\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from keras.optimizers import RMSprop\n",
    "from keras import regularizers\n",
    "from keras import backend as K\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers.merge import add\n",
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "from keras.regularizers import l2\n",
    "from keras.layers import Conv1D\n",
    "from keras.layers.merge import add\n",
    "from keras.layers import Dense,Conv1D,Dropout,Activation,BatchNormalization,MaxPooling1D,Flatten,Masking,TimeDistributed\n",
    "from keras.layers.recurrent import LSTM,GRU,SimpleRNN\n",
    "from keras.models import Input,Sequential,Model\n",
    "from keras.layers.merge import add\n",
    "from keras.optimizers import Adam\n",
    "from keras.losses import MSE,MSLE\n",
    "model2 = Sequential()\n",
    "\n",
    "\n",
    "def weighted_categorical_crossentropy(weights):\n",
    "    \"\"\"\n",
    "    A weighted version of keras.objectives.categorical_crossentropy\n",
    "    \n",
    "    Variables:\n",
    "        weights: numpy array of shape (C,) where C is the number of classes\n",
    "    \n",
    "    Usage:\n",
    "        weights = np.array([0.5,2,10]) # Class one at 0.5, class 2 twice the normal weights, class 3 10x.\n",
    "        loss = weighted_categorical_crossentropy(weights)\n",
    "        model.compile(loss=loss,optimizer='adam')\n",
    "    \"\"\"\n",
    "    \n",
    "    weights = K.variable(weights)\n",
    "        \n",
    "    def loss(y_true, y_pred):\n",
    "        # scale predictions so that the class probas of each sample sum to 1\n",
    "        y_pred /= K.sum(y_pred, axis=-1, keepdims=True)\n",
    "        # clip to prevent NaN's and Inf's\n",
    "        y_pred = K.clip(y_pred, K.epsilon(), 1 - K.epsilon())\n",
    "        # calc\n",
    "        loss = y_true * K.log(y_pred) * weights\n",
    "        loss = -K.sum(loss, -1)\n",
    "        return loss\n",
    "    \n",
    "    return loss\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "def f1_perRow(y_true, y_pred):\n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return K.mean(f1)\n",
    "\n",
    "\n",
    "def f1_perClass(y_true, y_pred):\n",
    "\n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=1)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=1)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=1)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=1)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return K.mean(f1)\n",
    "\n",
    "def f1_loss_perClass(y_true, y_pred):\n",
    "    \n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=1)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=1)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=1)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=1)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return (1 - K.mean(f1))**2\n",
    "\n",
    "def f1_loss_perRow(y_true, y_pred):\n",
    "    \n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return (1 - K.mean(f1))**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57867"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            (None, 15, 1)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_27 (Conv1D)              (None, 15, 128)      512         input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 15, 128)      512         conv1d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 15, 128)      0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_25 (Conv1D)              (None, 15, 128)      512         input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_30 (Dropout)            (None, 15, 128)      0           activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 15, 128)      512         conv1d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_28 (Conv1D)              (None, 15, 128)      49280       dropout_30[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 15, 128)      0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_29 (Conv1D)              (None, 15, 128)      49280       conv1d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_25 (Dropout)            (None, 15, 128)      0           activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 15, 128)      512         conv1d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_26 (Conv1D)              (None, 15, 128)      49280       dropout_25[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 15, 128)      0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_7 (LSTM)                   (None, 15, 100)      91600       conv1d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_31 (Dropout)            (None, 15, 128)      0           activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lstm_8 (LSTM)                   (None, 15, 100)      40800       input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_34 (Dense)                (None, 15, 128)      12928       lstm_7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_30 (Conv1D)              (None, 15, 128)      49280       dropout_31[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_38 (Dense)                (None, 15, 128)      12928       lstm_8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_35 (Dense)                (None, 15, 128)      16512       dense_34[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_31 (Conv1D)              (None, 15, 128)      49280       conv1d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_39 (Dense)                (None, 15, 128)      16512       dense_38[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_36 (Dense)                (None, 15, 128)      16512       dense_35[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 15, 128)      512         conv1d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_40 (Dense)                (None, 15, 128)      16512       dense_39[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_26 (Dropout)            (None, 15, 128)      0           dense_36[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 15, 128)      0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_28 (Dropout)            (None, 15, 128)      0           dense_40[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_10 (Flatten)            (None, 1920)         0           dropout_26[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_32 (Dropout)            (None, 15, 128)      0           activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_11 (Flatten)            (None, 1920)         0           dropout_28[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_37 (Dense)                (None, 128)          245888      flatten_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_32 (Conv1D)              (None, 15, 128)      49280       dropout_32[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_41 (Dense)                (None, 128)          245888      flatten_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_27 (Dropout)            (None, 128)          0           dense_37[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_12 (Flatten)            (None, 1920)         0           conv1d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_29 (Dropout)            (None, 128)          0           dense_41[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "mergerguy (Concatenate)         (None, 2176)         0           dropout_27[0][0]                 \n",
      "                                                                 flatten_12[0][0]                 \n",
      "                                                                 dropout_29[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_42 (Dense)                (None, 128)          278656      mergerguy[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_43 (Dense)                (None, 128)          16512       dense_42[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_44 (Dense)                (None, 128)          16512       dense_43[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "to_service1 (Dense)             (None, 130)          16770       dense_44[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "to_service2 (Dense)             (None, 130)          17030       to_service1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "service_output (Dense)          (None, 16)           2096        to_service2[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 1,362,408\n",
      "Trainable params: 1,361,384\n",
      "Non-trainable params: 1,024\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "57867/57867 [==============================] - 22s 381us/step - loss: 56.2900 - f1_perRow: 0.0870 - f1_perClass: 0.1274 - acc: 0.0916\n",
      "Epoch 2/100\n",
      "57867/57867 [==============================] - 17s 294us/step - loss: 48.8828 - f1_perRow: 0.0992 - f1_perClass: 0.1853 - acc: 0.4680\n",
      "Epoch 3/100\n",
      "57867/57867 [==============================] - 17s 294us/step - loss: 44.5066 - f1_perRow: 0.0992 - f1_perClass: 0.2381 - acc: 0.4668\n",
      "Epoch 4/100\n",
      "57867/57867 [==============================] - 17s 291us/step - loss: 40.7271 - f1_perRow: 0.0997 - f1_perClass: 0.2978 - acc: 0.4609\n",
      "Epoch 5/100\n",
      "57867/57867 [==============================] - 16s 285us/step - loss: 35.4866 - f1_perRow: 0.1105 - f1_perClass: 0.3696 - acc: 0.4611\n",
      "Epoch 6/100\n",
      "57867/57867 [==============================] - 17s 289us/step - loss: 33.9612 - f1_perRow: 0.1155 - f1_perClass: 0.4113 - acc: 0.4668\n",
      "Epoch 7/100\n",
      "57867/57867 [==============================] - 17s 289us/step - loss: 31.0059 - f1_perRow: 0.1205 - f1_perClass: 0.4585 - acc: 0.5015\n",
      "Epoch 8/100\n",
      "57867/57867 [==============================] - 17s 287us/step - loss: 29.1939 - f1_perRow: 0.1271 - f1_perClass: 0.4982 - acc: 0.4684\n",
      "Epoch 9/100\n",
      "57867/57867 [==============================] - 17s 289us/step - loss: 28.6266 - f1_perRow: 0.1351 - f1_perClass: 0.5081 - acc: 0.4668\n",
      "Epoch 10/100\n",
      "57867/57867 [==============================] - 16s 285us/step - loss: 28.3994 - f1_perRow: 0.1440 - f1_perClass: 0.5133 - acc: 0.4668\n",
      "Epoch 11/100\n",
      "57867/57867 [==============================] - 16s 285us/step - loss: 28.0619 - f1_perRow: 0.1509 - f1_perClass: 0.5166 - acc: 0.4668\n",
      "Epoch 12/100\n",
      "57867/57867 [==============================] - 16s 282us/step - loss: 27.4160 - f1_perRow: 0.1558 - f1_perClass: 0.5202 - acc: 0.4668\n",
      "Epoch 13/100\n",
      "57867/57867 [==============================] - 17s 291us/step - loss: 26.9330 - f1_perRow: 0.1651 - f1_perClass: 0.5223 - acc: 0.4668\n",
      "Epoch 14/100\n",
      "57867/57867 [==============================] - 17s 295us/step - loss: 26.2698 - f1_perRow: 0.1801 - f1_perClass: 0.5286 - acc: 0.4668\n",
      "Epoch 15/100\n",
      "57867/57867 [==============================] - 17s 292us/step - loss: 25.3498 - f1_perRow: 0.1970 - f1_perClass: 0.5396 - acc: 0.4668\n",
      "Epoch 16/100\n",
      "57867/57867 [==============================] - 17s 294us/step - loss: 23.4579 - f1_perRow: 0.2109 - f1_perClass: 0.5685 - acc: 0.4668\n",
      "Epoch 17/100\n",
      "57867/57867 [==============================] - 17s 290us/step - loss: 22.8934 - f1_perRow: 0.2192 - f1_perClass: 0.5823 - acc: 0.4668\n",
      "Epoch 18/100\n",
      "57867/57867 [==============================] - 17s 288us/step - loss: 21.8965 - f1_perRow: 0.2362 - f1_perClass: 0.6338 - acc: 0.4668\n",
      "Epoch 19/100\n",
      "57867/57867 [==============================] - 17s 289us/step - loss: 21.6901 - f1_perRow: 0.2472 - f1_perClass: 0.6397 - acc: 0.4668\n",
      "Epoch 20/100\n",
      "57867/57867 [==============================] - 17s 287us/step - loss: 21.3167 - f1_perRow: 0.2505 - f1_perClass: 0.6338 - acc: 0.4668\n",
      "Epoch 21/100\n",
      "57867/57867 [==============================] - 17s 294us/step - loss: 21.0668 - f1_perRow: 0.2490 - f1_perClass: 0.6285 - acc: 0.4668\n",
      "Epoch 22/100\n",
      "57867/57867 [==============================] - 17s 287us/step - loss: 20.9527 - f1_perRow: 0.2562 - f1_perClass: 0.6328 - acc: 0.4668\n",
      "Epoch 23/100\n",
      "57867/57867 [==============================] - 17s 289us/step - loss: 20.8836 - f1_perRow: 0.2674 - f1_perClass: 0.6410 - acc: 0.4668\n",
      "Epoch 24/100\n",
      "57867/57867 [==============================] - 17s 288us/step - loss: 20.7294 - f1_perRow: 0.2751 - f1_perClass: 0.6461 - acc: 0.4668\n",
      "Epoch 25/100\n",
      "57867/57867 [==============================] - 17s 286us/step - loss: 20.5833 - f1_perRow: 0.2773 - f1_perClass: 0.6451 - acc: 0.4668\n",
      "Epoch 26/100\n",
      "57867/57867 [==============================] - 17s 291us/step - loss: 20.4773 - f1_perRow: 0.2757 - f1_perClass: 0.6441 - acc: 0.4668\n",
      "Epoch 27/100\n",
      "57867/57867 [==============================] - 17s 285us/step - loss: 20.3174 - f1_perRow: 0.2788 - f1_perClass: 0.6478 - acc: 0.4668\n",
      "Epoch 28/100\n",
      "57867/57867 [==============================] - 17s 292us/step - loss: 20.1829 - f1_perRow: 0.2891 - f1_perClass: 0.6507 - acc: 0.4668\n",
      "Epoch 29/100\n",
      "57867/57867 [==============================] - 17s 286us/step - loss: 20.0686 - f1_perRow: 0.2968 - f1_perClass: 0.6493 - acc: 0.4668\n",
      "Epoch 30/100\n",
      "57867/57867 [==============================] - 17s 287us/step - loss: 19.9641 - f1_perRow: 0.2998 - f1_perClass: 0.6479 - acc: 0.4668\n",
      "Epoch 31/100\n",
      "57867/57867 [==============================] - 16s 285us/step - loss: 19.8632 - f1_perRow: 0.2995 - f1_perClass: 0.6487 - acc: 0.4668\n",
      "Epoch 32/100\n",
      "57867/57867 [==============================] - 17s 287us/step - loss: 19.7548 - f1_perRow: 0.3017 - f1_perClass: 0.6512 - acc: 0.4668\n",
      "Epoch 33/100\n",
      "57867/57867 [==============================] - 16s 285us/step - loss: 19.6748 - f1_perRow: 0.3056 - f1_perClass: 0.6525 - acc: 0.4668\n",
      "Epoch 34/100\n",
      "57867/57867 [==============================] - 16s 285us/step - loss: 19.6408 - f1_perRow: 0.3103 - f1_perClass: 0.6515 - acc: 0.4668\n",
      "Epoch 35/100\n",
      "57867/57867 [==============================] - 16s 281us/step - loss: 19.5438 - f1_perRow: 0.3154 - f1_perClass: 0.6510 - acc: 0.4668\n",
      "Epoch 36/100\n",
      "57867/57867 [==============================] - 16s 284us/step - loss: 19.4623 - f1_perRow: 0.3194 - f1_perClass: 0.6529 - acc: 0.4668\n",
      "Epoch 37/100\n",
      "57867/57867 [==============================] - 17s 286us/step - loss: 19.3644 - f1_perRow: 0.3245 - f1_perClass: 0.6575 - acc: 0.4668\n",
      "Epoch 38/100\n",
      "57867/57867 [==============================] - 16s 284us/step - loss: 19.2631 - f1_perRow: 0.3295 - f1_perClass: 0.6608 - acc: 0.4668\n",
      "Epoch 39/100\n",
      "57867/57867 [==============================] - 17s 286us/step - loss: 19.2190 - f1_perRow: 0.3313 - f1_perClass: 0.6608 - acc: 0.4668\n",
      "Epoch 40/100\n",
      "57867/57867 [==============================] - 16s 283us/step - loss: 19.1350 - f1_perRow: 0.3306 - f1_perClass: 0.6603 - acc: 0.4668\n",
      "Epoch 41/100\n",
      "57867/57867 [==============================] - 17s 285us/step - loss: 19.0705 - f1_perRow: 0.3327 - f1_perClass: 0.6603 - acc: 0.4668\n",
      "Epoch 42/100\n",
      "57867/57867 [==============================] - 16s 285us/step - loss: 19.0091 - f1_perRow: 0.3363 - f1_perClass: 0.6619 - acc: 0.4668\n",
      "Epoch 43/100\n",
      "57867/57867 [==============================] - 16s 285us/step - loss: 18.9624 - f1_perRow: 0.3377 - f1_perClass: 0.6632 - acc: 0.4668\n",
      "Epoch 44/100\n",
      "57867/57867 [==============================] - 16s 281us/step - loss: 18.9078 - f1_perRow: 0.3363 - f1_perClass: 0.6631 - acc: 0.4668\n",
      "Epoch 45/100\n",
      "57867/57867 [==============================] - 16s 278us/step - loss: 18.8777 - f1_perRow: 0.3366 - f1_perClass: 0.6630 - acc: 0.4668\n",
      "Epoch 46/100\n",
      "57867/57867 [==============================] - 16s 282us/step - loss: 18.8192 - f1_perRow: 0.3404 - f1_perClass: 0.6640 - acc: 0.4668\n",
      "Epoch 47/100\n",
      "57867/57867 [==============================] - 16s 280us/step - loss: 18.8007 - f1_perRow: 0.3416 - f1_perClass: 0.6644 - acc: 0.4668\n",
      "Epoch 48/100\n",
      "57867/57867 [==============================] - 16s 283us/step - loss: 18.7401 - f1_perRow: 0.3403 - f1_perClass: 0.6643 - acc: 0.4668\n",
      "Epoch 49/100\n",
      "57867/57867 [==============================] - 16s 284us/step - loss: 18.7267 - f1_perRow: 0.3409 - f1_perClass: 0.6653 - acc: 0.4668\n",
      "Epoch 50/100\n",
      "57867/57867 [==============================] - 16s 277us/step - loss: 18.7049 - f1_perRow: 0.3416 - f1_perClass: 0.6663 - acc: 0.4668\n",
      "Epoch 51/100\n",
      "57867/57867 [==============================] - 16s 282us/step - loss: 18.6647 - f1_perRow: 0.3418 - f1_perClass: 0.6660 - acc: 0.4668\n",
      "Epoch 52/100\n",
      "57867/57867 [==============================] - 16s 280us/step - loss: 18.6476 - f1_perRow: 0.3417 - f1_perClass: 0.6655 - acc: 0.4668\n",
      "Epoch 53/100\n",
      "57867/57867 [==============================] - 17s 285us/step - loss: 18.5893 - f1_perRow: 0.3432 - f1_perClass: 0.6663 - acc: 0.4668\n",
      "Epoch 54/100\n",
      "57867/57867 [==============================] - 16s 281us/step - loss: 18.5676 - f1_perRow: 0.3448 - f1_perClass: 0.6675 - acc: 0.4668\n",
      "Epoch 55/100\n",
      "57867/57867 [==============================] - 16s 283us/step - loss: 18.5331 - f1_perRow: 0.3445 - f1_perClass: 0.6678 - acc: 0.4668\n",
      "Epoch 56/100\n",
      "57867/57867 [==============================] - 16s 282us/step - loss: 18.4900 - f1_perRow: 0.3457 - f1_perClass: 0.6676 - acc: 0.4668\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "57867/57867 [==============================] - 16s 281us/step - loss: 18.4514 - f1_perRow: 0.3474 - f1_perClass: 0.6679 - acc: 0.4668\n",
      "Epoch 58/100\n",
      "57867/57867 [==============================] - 17s 289us/step - loss: 18.4252 - f1_perRow: 0.3485 - f1_perClass: 0.6685 - acc: 0.4668\n",
      "Epoch 59/100\n",
      "57867/57867 [==============================] - 16s 282us/step - loss: 18.2753 - f1_perRow: 0.3502 - f1_perClass: 0.6709 - acc: 0.4668\n",
      "Epoch 60/100\n",
      "57867/57867 [==============================] - 16s 282us/step - loss: 18.0914 - f1_perRow: 0.3509 - f1_perClass: 0.6717 - acc: 0.4668\n",
      "Epoch 61/100\n",
      "57867/57867 [==============================] - 16s 284us/step - loss: 17.9088 - f1_perRow: 0.3588 - f1_perClass: 0.6823 - acc: 0.4668\n",
      "Epoch 62/100\n",
      "57867/57867 [==============================] - 16s 281us/step - loss: 17.7558 - f1_perRow: 0.3574 - f1_perClass: 0.6848 - acc: 0.4668\n",
      "Epoch 63/100\n",
      "57867/57867 [==============================] - 16s 281us/step - loss: 17.7027 - f1_perRow: 0.3646 - f1_perClass: 0.6883 - acc: 0.4668\n",
      "Epoch 64/100\n",
      "57867/57867 [==============================] - 16s 275us/step - loss: 17.5936 - f1_perRow: 0.3645 - f1_perClass: 0.6904 - acc: 0.4668\n",
      "Epoch 65/100\n",
      "57867/57867 [==============================] - 17s 286us/step - loss: 17.5093 - f1_perRow: 0.3616 - f1_perClass: 0.6905 - acc: 0.4668\n",
      "Epoch 66/100\n",
      "57867/57867 [==============================] - 16s 281us/step - loss: 17.3306 - f1_perRow: 0.3652 - f1_perClass: 0.6936 - acc: 0.4668\n",
      "Epoch 67/100\n",
      "57867/57867 [==============================] - 17s 285us/step - loss: 17.3060 - f1_perRow: 0.3661 - f1_perClass: 0.6895 - acc: 0.4668\n",
      "Epoch 68/100\n",
      "57867/57867 [==============================] - 16s 280us/step - loss: 17.2678 - f1_perRow: 0.3667 - f1_perClass: 0.6934 - acc: 0.4668\n",
      "Epoch 69/100\n",
      "57867/57867 [==============================] - 16s 281us/step - loss: 17.2044 - f1_perRow: 0.3677 - f1_perClass: 0.6940 - acc: 0.4668\n",
      "Epoch 70/100\n",
      "57867/57867 [==============================] - 16s 280us/step - loss: 17.1763 - f1_perRow: 0.3661 - f1_perClass: 0.6963 - acc: 0.4668\n",
      "Epoch 71/100\n",
      "57867/57867 [==============================] - 17s 286us/step - loss: 16.9698 - f1_perRow: 0.3633 - f1_perClass: 0.6993 - acc: 0.4668\n",
      "Epoch 72/100\n",
      "57867/57867 [==============================] - 17s 287us/step - loss: 16.9157 - f1_perRow: 0.3637 - f1_perClass: 0.6989 - acc: 0.4668\n",
      "Epoch 73/100\n",
      "57867/57867 [==============================] - 16s 283us/step - loss: 16.9858 - f1_perRow: 0.3700 - f1_perClass: 0.6993 - acc: 0.4668\n",
      "Epoch 74/100\n",
      "57867/57867 [==============================] - 16s 281us/step - loss: 16.8244 - f1_perRow: 0.3766 - f1_perClass: 0.7039 - acc: 0.4668\n",
      "Epoch 75/100\n",
      "57867/57867 [==============================] - 16s 281us/step - loss: 16.8027 - f1_perRow: 0.3796 - f1_perClass: 0.7045 - acc: 0.4668\n",
      "Epoch 76/100\n",
      "57867/57867 [==============================] - 16s 283us/step - loss: 16.8450 - f1_perRow: 0.3786 - f1_perClass: 0.7043 - acc: 0.4668\n",
      "Epoch 77/100\n",
      "57867/57867 [==============================] - 16s 281us/step - loss: 16.7765 - f1_perRow: 0.3726 - f1_perClass: 0.7008 - acc: 0.4668\n",
      "Epoch 78/100\n",
      "57867/57867 [==============================] - 16s 284us/step - loss: 16.6966 - f1_perRow: 0.3767 - f1_perClass: 0.7059 - acc: 0.4668\n",
      "Epoch 79/100\n",
      "57867/57867 [==============================] - 16s 279us/step - loss: 16.6322 - f1_perRow: 0.3812 - f1_perClass: 0.7071 - acc: 0.4668\n",
      "Epoch 80/100\n",
      "57867/57867 [==============================] - 16s 282us/step - loss: 16.6518 - f1_perRow: 0.3823 - f1_perClass: 0.7066 - acc: 0.4668\n",
      "Epoch 81/100\n",
      "57867/57867 [==============================] - 16s 281us/step - loss: 16.6096 - f1_perRow: 0.3835 - f1_perClass: 0.7078 - acc: 0.4668\n",
      "Epoch 82/100\n",
      "57867/57867 [==============================] - 16s 278us/step - loss: 16.6701 - f1_perRow: 0.3782 - f1_perClass: 0.7030 - acc: 0.4668\n",
      "Epoch 83/100\n",
      "57867/57867 [==============================] - 16s 285us/step - loss: 16.7718 - f1_perRow: 0.3849 - f1_perClass: 0.7079 - acc: 0.4668\n",
      "Epoch 84/100\n",
      "57867/57867 [==============================] - 16s 279us/step - loss: 16.5254 - f1_perRow: 0.3860 - f1_perClass: 0.7086 - acc: 0.4668\n",
      "Epoch 85/100\n",
      "57867/57867 [==============================] - 16s 281us/step - loss: 16.5794 - f1_perRow: 0.3824 - f1_perClass: 0.7054 - acc: 0.4668\n",
      "Epoch 86/100\n",
      "57867/57867 [==============================] - 16s 282us/step - loss: 16.6188 - f1_perRow: 0.3852 - f1_perClass: 0.7085 - acc: 0.4668\n",
      "Epoch 87/100\n",
      "57867/57867 [==============================] - 16s 279us/step - loss: 16.4512 - f1_perRow: 0.3848 - f1_perClass: 0.7093 - acc: 0.4668\n",
      "Epoch 88/100\n",
      "57867/57867 [==============================] - 17s 290us/step - loss: 16.6294 - f1_perRow: 0.3805 - f1_perClass: 0.7027 - acc: 0.4668\n",
      "Epoch 89/100\n",
      "57867/57867 [==============================] - 16s 278us/step - loss: 16.4172 - f1_perRow: 0.3886 - f1_perClass: 0.7097 - acc: 0.4668\n",
      "Epoch 90/100\n",
      "57867/57867 [==============================] - 16s 277us/step - loss: 16.4997 - f1_perRow: 0.3923 - f1_perClass: 0.7098 - acc: 0.4668\n",
      "Epoch 91/100\n",
      "57867/57867 [==============================] - 16s 280us/step - loss: 16.4021 - f1_perRow: 0.3926 - f1_perClass: 0.7089 - acc: 0.4668\n",
      "Epoch 92/100\n",
      "57867/57867 [==============================] - 16s 281us/step - loss: 16.4311 - f1_perRow: 0.3901 - f1_perClass: 0.7071 - acc: 0.4668\n",
      "Epoch 93/100\n",
      "57867/57867 [==============================] - 16s 277us/step - loss: 16.3548 - f1_perRow: 0.3895 - f1_perClass: 0.7113 - acc: 0.4668\n",
      "Epoch 94/100\n",
      "57867/57867 [==============================] - 17s 288us/step - loss: 16.3977 - f1_perRow: 0.3871 - f1_perClass: 0.7106 - acc: 0.4668\n",
      "Epoch 95/100\n",
      "57867/57867 [==============================] - 17s 287us/step - loss: 16.3136 - f1_perRow: 0.3875 - f1_perClass: 0.7080 - acc: 0.4668\n",
      "Epoch 96/100\n",
      "57867/57867 [==============================] - 16s 278us/step - loss: 16.3167 - f1_perRow: 0.3909 - f1_perClass: 0.7081 - acc: 0.4668\n",
      "Epoch 97/100\n",
      "57867/57867 [==============================] - 16s 280us/step - loss: 16.2972 - f1_perRow: 0.3962 - f1_perClass: 0.7112 - acc: 0.4668\n",
      "Epoch 98/100\n",
      "57867/57867 [==============================] - 16s 281us/step - loss: 16.2248 - f1_perRow: 0.3965 - f1_perClass: 0.7121 - acc: 0.4668\n",
      "Epoch 99/100\n",
      "57867/57867 [==============================] - 16s 281us/step - loss: 16.2854 - f1_perRow: 0.3926 - f1_perClass: 0.7096 - acc: 0.4668\n",
      "Epoch 100/100\n",
      "57867/57867 [==============================] - 16s 280us/step - loss: 16.2792 - f1_perRow: 0.3956 - f1_perClass: 0.7106 - acc: 0.4668\n"
     ]
    }
   ],
   "source": [
    "inputs  = Input( ( dim_size,1 ) )\n",
    "\n",
    "\n",
    "out = Conv1D(128,3,padding='same')(inputs)\n",
    "out = BatchNormalization()(out)\n",
    "out = Activation('relu')(out)\n",
    "out = Dropout(0.2)(out)\n",
    "out = Conv1D(128,3,padding='same')(out)\n",
    "# bi_d_1 = Bidirectional( LSTM(200 ,  recurrent_dropout=0.12, return_sequences=True),input_shape=[dim_size,1],merge_mode='concat') (inputs)\n",
    "lstm_1 =  LSTM(100 ,  recurrent_dropout=0.04, return_sequences=True)(out)\n",
    "# lstm_2 = LSTM(30 ,  recurrent_dropout=0.14, return_sequences=True)(lstm_1)\n",
    "\n",
    "bi_d_1 =Dense(128, activation='relu')  (lstm_1)\n",
    "lstm_1 =  Dense(128, activation='relu')(bi_d_1)\n",
    "lstm_2 = Dense(128, activation='relu')(lstm_1)\n",
    "\n",
    "\n",
    "\n",
    "# td_1    = TimeDistributed(Dense(256, activation='relu'))(lstm_2)\n",
    "# dout_1  = Dropout(0.1)(td_1)\n",
    "dout_1  = Dropout(0.1)(lstm_2)\n",
    "flt_1   = Flatten()(dout_1)\n",
    "dense_1 = Dense(128, activation='relu')(flt_1)\n",
    "dout_2  = Dropout(0.2)(dense_1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# bi_d_1 = Bidirectional( LSTM(200 ,  recurrent_dropout=0.12, return_sequences=True),input_shape=[dim_size,1],merge_mode='concat') (inputs)\n",
    "lstm_1 =  LSTM(100 ,  recurrent_dropout=0.04, return_sequences=True)(inputs)\n",
    "# lstm_1 = LSTM(40 ,  recurrent_dropout=0.14, return_sequences=True)(lstm_1)\n",
    "\n",
    "bi_d_raw_1 =Dense(128, activation='relu')  (lstm_1)\n",
    "lstm_raw_1 =  Dense(128, activation='relu')(bi_d_raw_1)\n",
    "lstm_raw_2 = Dense(128, activation='relu')(lstm_raw_1)\n",
    "\n",
    "dout_1  = Dropout(0.1)(lstm_raw_2)\n",
    "flt_1   = Flatten()(dout_1)\n",
    "dense_1 = Dense(128, activation='relu')(flt_1)\n",
    "dout_3  = Dropout(0.2)(dense_1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "out = Conv1D(128,3,padding='same')(inputs)\n",
    "out = BatchNormalization()(out)\n",
    "out = Activation('relu')(out)\n",
    "out = Dropout(0.2)(out)\n",
    "out = Conv1D(128,3,padding='same')(out)\n",
    "# out = Flatten()(out)\n",
    "# out = MaxPooling1D(2,padding='same', name ='pooling')(out)\n",
    "\n",
    "\n",
    "out = Conv1D(128,3,padding='same')(out)\n",
    "out = BatchNormalization()(out)\n",
    "out = Activation('relu')(out)\n",
    "out = Dropout(0.2)(out)\n",
    "out = Conv1D(128,3,padding='same')(out)\n",
    "# out = Flatten()(out)\n",
    "# out = MaxPooling1D(2,padding='same', name ='pooling2')(out)\n",
    "\n",
    "\n",
    "out = Conv1D(128,3,padding='same')(out)\n",
    "out = BatchNormalization()(out)\n",
    "out = Activation('relu')(out)\n",
    "out = Dropout(0.2)(out)\n",
    "out = Conv1D(128,3,padding='same')(out)\n",
    "# out = Flatten()(out)\n",
    "# out = MaxPooling1D(2,padding='same', name ='pooling')(out)\n",
    "\n",
    "\n",
    "\n",
    "# fl_out_1 = Flatten()(dout_2)\n",
    "\n",
    "fl_out_cnn = Flatten()(out)\n",
    "\n",
    "# out_new = concatenate( [fl_out_1, fl_out_cnn] , name='mergerguy')\n",
    "out_new = concatenate( [dout_2, fl_out_cnn,dout_3] , name='mergerguy')\n",
    "\n",
    "dens_out_1 = Dense( 128, activation='relu' )(out_new)\n",
    "dens_out_2 = Dense( 128, activation='relu' )(dens_out_1)\n",
    "dens_out_3 = Dense( 128, activation='relu' )(dens_out_2)\n",
    "\n",
    "# fl2  = Flatten()(out_new)\n",
    "\n",
    "out_put_final = Dense(len(classes), activation='sigmoid', name='Event_output')(dens_out_3)\n",
    "\n",
    "toService_1 = Dense( 130, name=\"to_service1\" )(dens_out_3)\n",
    "toService_1 = Dense( 130, name=\"to_service2\" )(toService_1)\n",
    "\n",
    "service_output = Dense(len(classes  ), activation=\"sigmoid\", name = 'service_output')(toService_1)\n",
    "\n",
    "\n",
    "\n",
    "model2 = Model(inputs=[inputs], outputs=[service_output])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# model2.add(Bidirectional( LSTM(200 ,  recurrent_dropout=0.12, return_sequences=True),input_shape=[dim_size,1],merge_mode='concat'))\n",
    "# model2.add( LSTM(60 ,  recurrent_dropout=0.04, return_sequences=True))\n",
    "# model2.add( LSTM(30 ,  recurrent_dropout=0.14, return_sequences=True))\n",
    "# # model2.add(Bidirectional( LSTM(100 ,  recurrent_dropout=0.04, return_sequences=True),merge_mode='concat'))\n",
    "# model2.add(TimeDistributed(Dense(256, activation='relu')))\n",
    "# model2.add(Dropout(0.1))\n",
    "# model2.add(Flatten())\n",
    "# model2.add(Dense(128, activation='relu'))\n",
    "# model2.add(Dropout(0.2))\n",
    "# model2.add(Dense(len(classes), activation='sigmoid'))\n",
    "\n",
    " \n",
    "weights = [\n",
    "1.0/(57.0 / len(y_train)),\n",
    "1.0/(19.0 / len(y_train)),\n",
    "1.0/(7.0 / len(y_train)),\n",
    "1.0/(14.0 / len(y_train)),\n",
    "1.0/(6.0 / len(y_train)),\n",
    "1.0/(176.0 / len(y_train)),\n",
    "1.0/(27.0 / len(y_train)),\n",
    "1.0/(35.0 / len(y_train)),\n",
    "1.0/(371.0 / len(y_train)),\n",
    "1.0/(11111.0 / len(y_train)),\n",
    "1.0/(4842.0 / len(y_train)),\n",
    "1.0/(119.0 / len(y_train)),\n",
    "1.0/(21.0 / len(y_train)),\n",
    "1.0/(1168.0 / len(y_train)),\n",
    "1.0/(63.0 / len(y_train)),\n",
    "1.0/(13305.0 / len(y_train)),\n",
    "1.0/(11111.0 / len(y_train)),\n",
    "]\n",
    "    \n",
    "\n",
    "\n",
    "# model2.compile(loss=weighted_categorical_crossentropy(weights=weights), optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "losses = {\n",
    "#     \"service_output\": f1_loss_perClass ,\n",
    "    \"service_output\": f1_loss_perRow ,\n",
    "    \"service_output\": \"categorical_crossentropy\",\n",
    "}\n",
    "lossWeights = {#\"service_output\": 20,\n",
    "               \"service_output\": 30.0 ,\n",
    "    \"service_output\": 20}\n",
    " \n",
    "\n",
    "\n",
    "model2.compile(loss=losses,loss_weights=lossWeights, optimizer='adam', metrics=[f1_perRow,f1_perClass,'acc'])\n",
    "# model2.compile(loss=losses, loss_weights=lossWeights, optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "checkpoint = ModelCheckpoint('IoTDownNet_old_data', monitor='loss', verbose=0, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "print(model2.summary())\n",
    "hist2 = model2.fit(x_lstm_prossed_train2, y_lstm_prossed_train, epochs=100, batch_size=58500, shuffle=True, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "18925/18925 [==============================] - 7s 346us/step - loss: 11.5165 - f1_perRow: 0.5149 - f1_perClass: 0.8158 - acc: 0.8463\n",
      "Epoch 2/200\n",
      "18925/18925 [==============================] - 6s 342us/step - loss: 11.3196 - f1_perRow: 0.5214 - f1_perClass: 0.8211 - acc: 0.8483\n",
      "Epoch 3/200\n",
      "18925/18925 [==============================] - 7s 355us/step - loss: 11.2126 - f1_perRow: 0.5239 - f1_perClass: 0.8188 - acc: 0.8447\n",
      "Epoch 4/200\n",
      "18925/18925 [==============================] - 7s 346us/step - loss: 11.1527 - f1_perRow: 0.5222 - f1_perClass: 0.8098 - acc: 0.8385\n",
      "Epoch 5/200\n",
      "18925/18925 [==============================] - 7s 351us/step - loss: 11.1816 - f1_perRow: 0.5199 - f1_perClass: 0.8031 - acc: 0.8283\n",
      "Epoch 6/200\n",
      "18925/18925 [==============================] - 6s 342us/step - loss: 11.1149 - f1_perRow: 0.5206 - f1_perClass: 0.8021 - acc: 0.8123\n",
      "Epoch 7/200\n",
      "18925/18925 [==============================] - 7s 348us/step - loss: 11.0325 - f1_perRow: 0.5220 - f1_perClass: 0.7949 - acc: 0.8090\n",
      "Epoch 8/200\n",
      "18925/18925 [==============================] - 7s 344us/step - loss: 10.9495 - f1_perRow: 0.5267 - f1_perClass: 0.7804 - acc: 0.8057\n",
      "Epoch 9/200\n",
      "18925/18925 [==============================] - 7s 353us/step - loss: 10.8679 - f1_perRow: 0.5286 - f1_perClass: 0.7758 - acc: 0.8126\n",
      "Epoch 10/200\n",
      "18925/18925 [==============================] - 7s 347us/step - loss: 10.8058 - f1_perRow: 0.5321 - f1_perClass: 0.7863 - acc: 0.8200\n",
      "Epoch 11/200\n",
      "18925/18925 [==============================] - 6s 342us/step - loss: 10.7698 - f1_perRow: 0.5312 - f1_perClass: 0.7875 - acc: 0.8290\n",
      "Epoch 12/200\n",
      "18925/18925 [==============================] - 6s 342us/step - loss: 10.7682 - f1_perRow: 0.5227 - f1_perClass: 0.7803 - acc: 0.8362\n",
      "Epoch 13/200\n",
      "18925/18925 [==============================] - 7s 346us/step - loss: 10.7368 - f1_perRow: 0.5241 - f1_perClass: 0.7882 - acc: 0.8449\n",
      "Epoch 14/200\n",
      "18925/18925 [==============================] - 7s 348us/step - loss: 10.6861 - f1_perRow: 0.5193 - f1_perClass: 0.7884 - acc: 0.8530\n",
      "Epoch 15/200\n",
      "18925/18925 [==============================] - 7s 348us/step - loss: 10.6579 - f1_perRow: 0.5186 - f1_perClass: 0.7801 - acc: 0.8533\n",
      "Epoch 16/200\n",
      "18925/18925 [==============================] - 7s 351us/step - loss: 10.6629 - f1_perRow: 0.5222 - f1_perClass: 0.7822 - acc: 0.8527\n",
      "Epoch 17/200\n",
      "18925/18925 [==============================] - 7s 351us/step - loss: 10.5860 - f1_perRow: 0.5296 - f1_perClass: 0.7861 - acc: 0.8505\n",
      "Epoch 18/200\n",
      "18925/18925 [==============================] - 7s 348us/step - loss: 10.5214 - f1_perRow: 0.5334 - f1_perClass: 0.7828 - acc: 0.8538\n",
      "Epoch 19/200\n",
      "18925/18925 [==============================] - 7s 351us/step - loss: 10.6292 - f1_perRow: 0.5219 - f1_perClass: 0.7742 - acc: 0.8545\n",
      "Epoch 20/200\n",
      "18925/18925 [==============================] - 7s 348us/step - loss: 11.1343 - f1_perRow: 0.5265 - f1_perClass: 0.7783 - acc: 0.8459\n",
      "Epoch 21/200\n",
      "18925/18925 [==============================] - 7s 352us/step - loss: 12.3564 - f1_perRow: 0.5109 - f1_perClass: 0.7884 - acc: 0.8470\n",
      "Epoch 22/200\n",
      "18925/18925 [==============================] - 7s 348us/step - loss: 10.8236 - f1_perRow: 0.5343 - f1_perClass: 0.7903 - acc: 0.8476\n",
      "Epoch 23/200\n",
      "18925/18925 [==============================] - 7s 345us/step - loss: 10.8250 - f1_perRow: 0.5279 - f1_perClass: 0.7943 - acc: 0.8499\n",
      "Epoch 24/200\n",
      "18925/18925 [==============================] - 7s 350us/step - loss: 10.9483 - f1_perRow: 0.5151 - f1_perClass: 0.7944 - acc: 0.8272\n",
      "Epoch 25/200\n",
      "18925/18925 [==============================] - 7s 345us/step - loss: 11.0737 - f1_perRow: 0.5049 - f1_perClass: 0.7933 - acc: 0.8245\n",
      "Epoch 26/200\n",
      "18925/18925 [==============================] - 7s 350us/step - loss: 10.9402 - f1_perRow: 0.5210 - f1_perClass: 0.7990 - acc: 0.8291\n",
      "Epoch 27/200\n",
      "18925/18925 [==============================] - 7s 351us/step - loss: 10.8536 - f1_perRow: 0.5264 - f1_perClass: 0.8044 - acc: 0.8356\n",
      "Epoch 28/200\n",
      "18925/18925 [==============================] - 7s 348us/step - loss: 10.7602 - f1_perRow: 0.5384 - f1_perClass: 0.8084 - acc: 0.8414\n",
      "Epoch 29/200\n",
      "18925/18925 [==============================] - 7s 348us/step - loss: 10.7595 - f1_perRow: 0.5374 - f1_perClass: 0.8077 - acc: 0.8441\n",
      "Epoch 30/200\n",
      "18925/18925 [==============================] - 7s 354us/step - loss: 10.7725 - f1_perRow: 0.5433 - f1_perClass: 0.8073 - acc: 0.8451\n",
      "Epoch 31/200\n",
      "18925/18925 [==============================] - 7s 346us/step - loss: 10.7437 - f1_perRow: 0.5483 - f1_perClass: 0.8095 - acc: 0.8426\n",
      "Epoch 32/200\n",
      "18925/18925 [==============================] - 7s 350us/step - loss: 10.7244 - f1_perRow: 0.5508 - f1_perClass: 0.8107 - acc: 0.8413\n",
      "Epoch 33/200\n",
      "18925/18925 [==============================] - 7s 348us/step - loss: 10.7649 - f1_perRow: 0.5523 - f1_perClass: 0.8083 - acc: 0.8413\n",
      "Epoch 34/200\n",
      "18925/18925 [==============================] - 7s 345us/step - loss: 10.6538 - f1_perRow: 0.5541 - f1_perClass: 0.8110 - acc: 0.8395\n",
      "Epoch 35/200\n",
      "18925/18925 [==============================] - 7s 352us/step - loss: 10.6861 - f1_perRow: 0.5564 - f1_perClass: 0.8143 - acc: 0.8379\n",
      "Epoch 36/200\n",
      "18925/18925 [==============================] - 7s 351us/step - loss: 10.6671 - f1_perRow: 0.5538 - f1_perClass: 0.8117 - acc: 0.8375\n",
      "Epoch 37/200\n",
      "18925/18925 [==============================] - 7s 353us/step - loss: 10.6103 - f1_perRow: 0.5520 - f1_perClass: 0.8128 - acc: 0.8385\n",
      "Epoch 38/200\n",
      "18925/18925 [==============================] - 7s 349us/step - loss: 10.5836 - f1_perRow: 0.5459 - f1_perClass: 0.8149 - acc: 0.8375\n",
      "Epoch 39/200\n",
      "18925/18925 [==============================] - 7s 351us/step - loss: 10.5791 - f1_perRow: 0.5499 - f1_perClass: 0.8145 - acc: 0.8386\n",
      "Epoch 40/200\n",
      "18925/18925 [==============================] - 7s 349us/step - loss: 10.5632 - f1_perRow: 0.5529 - f1_perClass: 0.8143 - acc: 0.8388\n",
      "Epoch 41/200\n",
      "18925/18925 [==============================] - 7s 364us/step - loss: 10.5773 - f1_perRow: 0.5538 - f1_perClass: 0.8139 - acc: 0.8396\n",
      "Epoch 42/200\n",
      "18925/18925 [==============================] - 7s 350us/step - loss: 10.5199 - f1_perRow: 0.5539 - f1_perClass: 0.8149 - acc: 0.8419\n",
      "Epoch 43/200\n",
      "18925/18925 [==============================] - 7s 365us/step - loss: 10.5379 - f1_perRow: 0.5488 - f1_perClass: 0.8093 - acc: 0.8412\n",
      "Epoch 44/200\n",
      "18925/18925 [==============================] - 7s 348us/step - loss: 10.4931 - f1_perRow: 0.5496 - f1_perClass: 0.8103 - acc: 0.8411\n",
      "Epoch 45/200\n",
      "18925/18925 [==============================] - 7s 349us/step - loss: 10.4967 - f1_perRow: 0.5491 - f1_perClass: 0.8101 - acc: 0.8424\n",
      "Epoch 46/200\n",
      "18925/18925 [==============================] - 7s 346us/step - loss: 10.5082 - f1_perRow: 0.5508 - f1_perClass: 0.8122 - acc: 0.8434\n",
      "Epoch 47/200\n",
      "18925/18925 [==============================] - 7s 352us/step - loss: 10.4516 - f1_perRow: 0.5508 - f1_perClass: 0.8126 - acc: 0.8449\n",
      "Epoch 48/200\n",
      "18925/18925 [==============================] - 7s 353us/step - loss: 10.4481 - f1_perRow: 0.5527 - f1_perClass: 0.8106 - acc: 0.8442\n",
      "Epoch 49/200\n",
      "18925/18925 [==============================] - 7s 349us/step - loss: 10.4557 - f1_perRow: 0.5492 - f1_perClass: 0.8111 - acc: 0.8442\n",
      "Epoch 50/200\n",
      "18925/18925 [==============================] - 7s 350us/step - loss: 10.4226 - f1_perRow: 0.5499 - f1_perClass: 0.8133 - acc: 0.8454\n",
      "Epoch 51/200\n",
      "18925/18925 [==============================] - 7s 350us/step - loss: 10.4780 - f1_perRow: 0.5493 - f1_perClass: 0.8123 - acc: 0.8452\n",
      "Epoch 52/200\n",
      "18925/18925 [==============================] - 7s 350us/step - loss: 10.4878 - f1_perRow: 0.5490 - f1_perClass: 0.8085 - acc: 0.8462\n",
      "Epoch 53/200\n",
      "18925/18925 [==============================] - 7s 350us/step - loss: 10.4201 - f1_perRow: 0.5477 - f1_perClass: 0.8095 - acc: 0.8491\n",
      "Epoch 54/200\n",
      "18925/18925 [==============================] - 7s 348us/step - loss: 10.5455 - f1_perRow: 0.5472 - f1_perClass: 0.8088 - acc: 0.8510\n",
      "Epoch 55/200\n",
      "18925/18925 [==============================] - 7s 349us/step - loss: 10.5561 - f1_perRow: 0.5511 - f1_perClass: 0.8066 - acc: 0.8552\n",
      "Epoch 56/200\n",
      "18925/18925 [==============================] - 7s 349us/step - loss: 10.6438 - f1_perRow: 0.5473 - f1_perClass: 0.8071 - acc: 0.8618\n",
      "Epoch 57/200\n",
      "18925/18925 [==============================] - 7s 348us/step - loss: 10.6382 - f1_perRow: 0.5450 - f1_perClass: 0.8082 - acc: 0.8547\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/200\n",
      "18925/18925 [==============================] - 7s 353us/step - loss: 10.6554 - f1_perRow: 0.5459 - f1_perClass: 0.8050 - acc: 0.8543\n",
      "Epoch 59/200\n",
      "18925/18925 [==============================] - 8s 402us/step - loss: 10.6493 - f1_perRow: 0.5435 - f1_perClass: 0.8071 - acc: 0.8546\n",
      "Epoch 60/200\n",
      "18925/18925 [==============================] - 7s 357us/step - loss: 10.6430 - f1_perRow: 0.5414 - f1_perClass: 0.8076 - acc: 0.8552\n",
      "Epoch 61/200\n",
      "18925/18925 [==============================] - 7s 352us/step - loss: 10.6253 - f1_perRow: 0.5423 - f1_perClass: 0.8075 - acc: 0.8552\n",
      "Epoch 62/200\n",
      "18925/18925 [==============================] - 7s 347us/step - loss: 10.5844 - f1_perRow: 0.5403 - f1_perClass: 0.8071 - acc: 0.8544\n",
      "Epoch 63/200\n",
      "18925/18925 [==============================] - 7s 350us/step - loss: 10.5746 - f1_perRow: 0.5393 - f1_perClass: 0.8076 - acc: 0.8516\n",
      "Epoch 64/200\n",
      "18925/18925 [==============================] - 7s 346us/step - loss: 10.5508 - f1_perRow: 0.5405 - f1_perClass: 0.8071 - acc: 0.8511\n",
      "Epoch 65/200\n",
      "18925/18925 [==============================] - 7s 347us/step - loss: 10.5249 - f1_perRow: 0.5463 - f1_perClass: 0.8060 - acc: 0.8482\n",
      "Epoch 66/200\n",
      "18925/18925 [==============================] - 7s 348us/step - loss: 10.4953 - f1_perRow: 0.5467 - f1_perClass: 0.8038 - acc: 0.8458\n",
      "Epoch 67/200\n",
      "18925/18925 [==============================] - 7s 349us/step - loss: 10.4690 - f1_perRow: 0.5449 - f1_perClass: 0.8023 - acc: 0.8464\n",
      "Epoch 68/200\n",
      "18925/18925 [==============================] - 7s 351us/step - loss: 10.3593 - f1_perRow: 0.5463 - f1_perClass: 0.7993 - acc: 0.8424\n",
      "Epoch 69/200\n",
      "18925/18925 [==============================] - 7s 351us/step - loss: 10.4099 - f1_perRow: 0.5465 - f1_perClass: 0.7929 - acc: 0.8426\n",
      "Epoch 70/200\n",
      "18925/18925 [==============================] - 7s 345us/step - loss: 10.4511 - f1_perRow: 0.5462 - f1_perClass: 0.8072 - acc: 0.8477\n",
      "Epoch 71/200\n",
      "18925/18925 [==============================] - 7s 353us/step - loss: 10.3518 - f1_perRow: 0.5520 - f1_perClass: 0.8055 - acc: 0.8490\n",
      "Epoch 72/200\n",
      "18925/18925 [==============================] - 7s 359us/step - loss: 10.4125 - f1_perRow: 0.5423 - f1_perClass: 0.7930 - acc: 0.8461\n",
      "Epoch 73/200\n",
      "18925/18925 [==============================] - 7s 382us/step - loss: 10.3766 - f1_perRow: 0.5464 - f1_perClass: 0.8090 - acc: 0.8520\n",
      "Epoch 74/200\n",
      "18925/18925 [==============================] - 7s 349us/step - loss: 10.2621 - f1_perRow: 0.5467 - f1_perClass: 0.8055 - acc: 0.8530\n",
      "Epoch 75/200\n",
      "18925/18925 [==============================] - 7s 350us/step - loss: 10.3883 - f1_perRow: 0.5435 - f1_perClass: 0.7966 - acc: 0.8456\n",
      "Epoch 76/200\n",
      "18925/18925 [==============================] - 7s 355us/step - loss: 10.4860 - f1_perRow: 0.5485 - f1_perClass: 0.8185 - acc: 0.8545\n",
      "Epoch 77/200\n",
      "18925/18925 [==============================] - 7s 346us/step - loss: 10.4245 - f1_perRow: 0.5510 - f1_perClass: 0.8119 - acc: 0.8548\n",
      "Epoch 78/200\n",
      "18925/18925 [==============================] - 7s 380us/step - loss: 10.3530 - f1_perRow: 0.5491 - f1_perClass: 0.8087 - acc: 0.8562\n",
      "Epoch 79/200\n",
      "18925/18925 [==============================] - 7s 351us/step - loss: 10.4023 - f1_perRow: 0.5465 - f1_perClass: 0.8183 - acc: 0.8536\n",
      "Epoch 80/200\n",
      "18925/18925 [==============================] - 7s 353us/step - loss: 10.3053 - f1_perRow: 0.5438 - f1_perClass: 0.8188 - acc: 0.8501\n",
      "Epoch 81/200\n",
      "18925/18925 [==============================] - 7s 374us/step - loss: 10.3782 - f1_perRow: 0.5415 - f1_perClass: 0.8075 - acc: 0.8454\n",
      "Epoch 82/200\n",
      "18925/18925 [==============================] - 7s 349us/step - loss: 10.2220 - f1_perRow: 0.5470 - f1_perClass: 0.8166 - acc: 0.8429\n",
      "Epoch 83/200\n",
      "18925/18925 [==============================] - 7s 351us/step - loss: 10.3546 - f1_perRow: 0.5437 - f1_perClass: 0.8154 - acc: 0.8397\n",
      "Epoch 84/200\n",
      "18925/18925 [==============================] - 7s 352us/step - loss: 10.2291 - f1_perRow: 0.5520 - f1_perClass: 0.8192 - acc: 0.8456\n",
      "Epoch 85/200\n",
      "18925/18925 [==============================] - 7s 353us/step - loss: 10.3012 - f1_perRow: 0.5531 - f1_perClass: 0.8132 - acc: 0.8484\n",
      "Epoch 86/200\n",
      "18925/18925 [==============================] - 7s 344us/step - loss: 10.2319 - f1_perRow: 0.5564 - f1_perClass: 0.8233 - acc: 0.8485\n",
      "Epoch 87/200\n",
      "18925/18925 [==============================] - 7s 349us/step - loss: 10.1846 - f1_perRow: 0.5548 - f1_perClass: 0.8253 - acc: 0.8486\n",
      "Epoch 88/200\n",
      "18925/18925 [==============================] - 7s 350us/step - loss: 10.2294 - f1_perRow: 0.5486 - f1_perClass: 0.8168 - acc: 0.8476\n",
      "Epoch 89/200\n",
      "18925/18925 [==============================] - 7s 346us/step - loss: 10.1363 - f1_perRow: 0.5606 - f1_perClass: 0.8181 - acc: 0.8451\n",
      "Epoch 90/200\n",
      "18925/18925 [==============================] - 7s 347us/step - loss: 10.2730 - f1_perRow: 0.5537 - f1_perClass: 0.8204 - acc: 0.8393\n",
      "Epoch 91/200\n",
      "18925/18925 [==============================] - 7s 350us/step - loss: 10.1766 - f1_perRow: 0.5599 - f1_perClass: 0.8259 - acc: 0.8490\n",
      "Epoch 92/200\n",
      "18925/18925 [==============================] - 7s 349us/step - loss: 10.1387 - f1_perRow: 0.5598 - f1_perClass: 0.8184 - acc: 0.8505\n",
      "Epoch 93/200\n",
      "18925/18925 [==============================] - 7s 349us/step - loss: 10.1467 - f1_perRow: 0.5525 - f1_perClass: 0.8141 - acc: 0.8458\n",
      "Epoch 94/200\n",
      "18925/18925 [==============================] - 7s 354us/step - loss: 10.1041 - f1_perRow: 0.5536 - f1_perClass: 0.8242 - acc: 0.8517\n",
      "Epoch 95/200\n",
      "18925/18925 [==============================] - 7s 351us/step - loss: 10.0641 - f1_perRow: 0.5559 - f1_perClass: 0.8210 - acc: 0.8533\n",
      "Epoch 96/200\n",
      "18925/18925 [==============================] - 7s 345us/step - loss: 10.1393 - f1_perRow: 0.5481 - f1_perClass: 0.8070 - acc: 0.8481\n",
      "Epoch 97/200\n",
      "18925/18925 [==============================] - 7s 348us/step - loss: 10.1978 - f1_perRow: 0.5482 - f1_perClass: 0.8115 - acc: 0.8526\n",
      "Epoch 98/200\n",
      "18925/18925 [==============================] - 7s 349us/step - loss: 10.2994 - f1_perRow: 0.5477 - f1_perClass: 0.8096 - acc: 0.8446\n",
      "Epoch 99/200\n",
      "18925/18925 [==============================] - 7s 347us/step - loss: 10.0934 - f1_perRow: 0.5530 - f1_perClass: 0.8231 - acc: 0.8549\n",
      "Epoch 100/200\n",
      "18925/18925 [==============================] - 7s 349us/step - loss: 10.1376 - f1_perRow: 0.5502 - f1_perClass: 0.8179 - acc: 0.8563\n",
      "Epoch 101/200\n",
      "18925/18925 [==============================] - 7s 351us/step - loss: 10.0960 - f1_perRow: 0.5524 - f1_perClass: 0.8180 - acc: 0.8491\n",
      "Epoch 102/200\n",
      "18925/18925 [==============================] - 7s 350us/step - loss: 10.0159 - f1_perRow: 0.5595 - f1_perClass: 0.8272 - acc: 0.8505\n",
      "Epoch 103/200\n",
      "18925/18925 [==============================] - 7s 348us/step - loss: 10.1161 - f1_perRow: 0.5507 - f1_perClass: 0.8263 - acc: 0.8537\n",
      "Epoch 104/200\n",
      "18925/18925 [==============================] - 7s 347us/step - loss: 10.0415 - f1_perRow: 0.5518 - f1_perClass: 0.8200 - acc: 0.8510\n",
      "Epoch 105/200\n",
      "18925/18925 [==============================] - 7s 351us/step - loss: 10.0492 - f1_perRow: 0.5530 - f1_perClass: 0.8188 - acc: 0.8510\n",
      "Epoch 106/200\n",
      "18925/18925 [==============================] - 7s 351us/step - loss: 10.0811 - f1_perRow: 0.5540 - f1_perClass: 0.8266 - acc: 0.8618\n",
      "Epoch 107/200\n",
      "18925/18925 [==============================] - 7s 352us/step - loss: 9.9331 - f1_perRow: 0.5575 - f1_perClass: 0.8247 - acc: 0.8591\n",
      "Epoch 108/200\n",
      "18925/18925 [==============================] - 7s 351us/step - loss: 10.0357 - f1_perRow: 0.5467 - f1_perClass: 0.8094 - acc: 0.8553\n",
      "Epoch 109/200\n",
      "18925/18925 [==============================] - 7s 347us/step - loss: 11.0098 - f1_perRow: 0.5340 - f1_perClass: 0.8032 - acc: 0.8370\n",
      "Epoch 110/200\n",
      "18925/18925 [==============================] - 7s 347us/step - loss: 15.3626 - f1_perRow: 0.4962 - f1_perClass: 0.7443 - acc: 0.7869\n",
      "Epoch 111/200\n",
      "18925/18925 [==============================] - 7s 344us/step - loss: 11.5026 - f1_perRow: 0.5418 - f1_perClass: 0.8146 - acc: 0.8208\n",
      "Epoch 112/200\n",
      "18925/18925 [==============================] - 7s 350us/step - loss: 12.4124 - f1_perRow: 0.5087 - f1_perClass: 0.7798 - acc: 0.8082\n",
      "Epoch 113/200\n",
      "18925/18925 [==============================] - 7s 350us/step - loss: 12.5154 - f1_perRow: 0.5114 - f1_perClass: 0.7668 - acc: 0.8130\n",
      "Epoch 114/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18925/18925 [==============================] - 7s 349us/step - loss: 11.6367 - f1_perRow: 0.5253 - f1_perClass: 0.8068 - acc: 0.8294\n",
      "Epoch 115/200\n",
      "18925/18925 [==============================] - 7s 347us/step - loss: 11.7798 - f1_perRow: 0.5297 - f1_perClass: 0.8206 - acc: 0.8323\n",
      "Epoch 116/200\n",
      "18925/18925 [==============================] - 7s 349us/step - loss: 11.4305 - f1_perRow: 0.5366 - f1_perClass: 0.8173 - acc: 0.8350\n",
      "Epoch 117/200\n",
      "18925/18925 [==============================] - 7s 349us/step - loss: 11.5306 - f1_perRow: 0.5287 - f1_perClass: 0.8012 - acc: 0.8401\n",
      "Epoch 118/200\n",
      "18925/18925 [==============================] - 7s 348us/step - loss: 11.3565 - f1_perRow: 0.5253 - f1_perClass: 0.8116 - acc: 0.8439\n",
      "Epoch 119/200\n",
      "18925/18925 [==============================] - 7s 350us/step - loss: 11.4751 - f1_perRow: 0.5225 - f1_perClass: 0.8202 - acc: 0.8448\n",
      "Epoch 120/200\n",
      "18925/18925 [==============================] - 6s 343us/step - loss: 11.2313 - f1_perRow: 0.5256 - f1_perClass: 0.8146 - acc: 0.8492\n",
      "Epoch 121/200\n",
      "18925/18925 [==============================] - 7s 349us/step - loss: 11.2734 - f1_perRow: 0.5217 - f1_perClass: 0.7963 - acc: 0.8504\n",
      "Epoch 122/200\n",
      "18925/18925 [==============================] - 7s 352us/step - loss: 10.8398 - f1_perRow: 0.5425 - f1_perClass: 0.8278 - acc: 0.8504\n",
      "Epoch 123/200\n",
      "18925/18925 [==============================] - 7s 345us/step - loss: 10.8816 - f1_perRow: 0.5456 - f1_perClass: 0.8318 - acc: 0.8506\n",
      "Epoch 124/200\n",
      "18925/18925 [==============================] - 7s 350us/step - loss: 10.7672 - f1_perRow: 0.5383 - f1_perClass: 0.8229 - acc: 0.8483\n",
      "Epoch 125/200\n",
      "18925/18925 [==============================] - 7s 354us/step - loss: 10.8432 - f1_perRow: 0.5346 - f1_perClass: 0.8179 - acc: 0.8464\n",
      "Epoch 126/200\n",
      "18925/18925 [==============================] - 7s 349us/step - loss: 10.6707 - f1_perRow: 0.5335 - f1_perClass: 0.8261 - acc: 0.8472\n",
      "Epoch 127/200\n",
      "18925/18925 [==============================] - 7s 349us/step - loss: 10.6330 - f1_perRow: 0.5340 - f1_perClass: 0.8265 - acc: 0.8468\n",
      "Epoch 128/200\n",
      "18925/18925 [==============================] - 7s 347us/step - loss: 10.5926 - f1_perRow: 0.5330 - f1_perClass: 0.8184 - acc: 0.8539\n",
      "Epoch 129/200\n",
      "18925/18925 [==============================] - 7s 354us/step - loss: 10.5973 - f1_perRow: 0.5240 - f1_perClass: 0.8124 - acc: 0.8553\n",
      "Epoch 130/200\n",
      "18925/18925 [==============================] - 7s 352us/step - loss: 10.4669 - f1_perRow: 0.5231 - f1_perClass: 0.8206 - acc: 0.8576\n",
      "Epoch 131/200\n",
      "18925/18925 [==============================] - 7s 353us/step - loss: 10.5363 - f1_perRow: 0.5215 - f1_perClass: 0.8232 - acc: 0.8572\n",
      "Epoch 132/200\n",
      "18925/18925 [==============================] - 7s 352us/step - loss: 10.3651 - f1_perRow: 0.5255 - f1_perClass: 0.8194 - acc: 0.8581\n",
      "Epoch 133/200\n",
      "18925/18925 [==============================] - 7s 350us/step - loss: 10.4010 - f1_perRow: 0.5207 - f1_perClass: 0.8138 - acc: 0.8537\n",
      "Epoch 134/200\n",
      "18925/18925 [==============================] - 7s 347us/step - loss: 10.3284 - f1_perRow: 0.5127 - f1_perClass: 0.8187 - acc: 0.8541\n",
      "Epoch 135/200\n",
      "18925/18925 [==============================] - 7s 348us/step - loss: 10.3614 - f1_perRow: 0.5193 - f1_perClass: 0.8211 - acc: 0.8523\n",
      "Epoch 136/200\n",
      "18925/18925 [==============================] - 7s 352us/step - loss: 10.4582 - f1_perRow: 0.5148 - f1_perClass: 0.8207 - acc: 0.8510\n",
      "Epoch 137/200\n",
      "18925/18925 [==============================] - 7s 349us/step - loss: 10.4358 - f1_perRow: 0.5243 - f1_perClass: 0.8186 - acc: 0.8568\n",
      "Epoch 138/200\n",
      "18925/18925 [==============================] - 7s 355us/step - loss: 10.2301 - f1_perRow: 0.5254 - f1_perClass: 0.8241 - acc: 0.8606\n",
      "Epoch 139/200\n",
      "18925/18925 [==============================] - 7s 347us/step - loss: 10.3146 - f1_perRow: 0.5372 - f1_perClass: 0.8245 - acc: 0.8561\n",
      "Epoch 140/200\n",
      "18925/18925 [==============================] - 7s 348us/step - loss: 10.3139 - f1_perRow: 0.5383 - f1_perClass: 0.8230 - acc: 0.8562\n",
      "Epoch 141/200\n",
      "18925/18925 [==============================] - 7s 350us/step - loss: 10.2046 - f1_perRow: 0.5423 - f1_perClass: 0.8226 - acc: 0.8615\n",
      "Epoch 142/200\n",
      "18925/18925 [==============================] - 7s 349us/step - loss: 10.2668 - f1_perRow: 0.5396 - f1_perClass: 0.8237 - acc: 0.8594\n",
      "Epoch 143/200\n",
      "18925/18925 [==============================] - 7s 355us/step - loss: 10.1428 - f1_perRow: 0.5472 - f1_perClass: 0.8257 - acc: 0.8579\n",
      "Epoch 144/200\n",
      "18925/18925 [==============================] - 7s 348us/step - loss: 10.0554 - f1_perRow: 0.5404 - f1_perClass: 0.8244 - acc: 0.8618\n",
      "Epoch 145/200\n",
      "18925/18925 [==============================] - 7s 350us/step - loss: 10.2012 - f1_perRow: 0.5335 - f1_perClass: 0.8199 - acc: 0.8557\n",
      "Epoch 146/200\n",
      "18925/18925 [==============================] - 7s 352us/step - loss: 10.2616 - f1_perRow: 0.5208 - f1_perClass: 0.8216 - acc: 0.8546\n",
      "Epoch 147/200\n",
      "18925/18925 [==============================] - 7s 346us/step - loss: 10.0869 - f1_perRow: 0.5420 - f1_perClass: 0.8249 - acc: 0.8587\n",
      "Epoch 148/200\n",
      "18925/18925 [==============================] - 7s 349us/step - loss: 9.9757 - f1_perRow: 0.5433 - f1_perClass: 0.8239 - acc: 0.8594\n",
      "Epoch 149/200\n",
      "18925/18925 [==============================] - 7s 345us/step - loss: 10.0765 - f1_perRow: 0.5412 - f1_perClass: 0.8185 - acc: 0.8569\n",
      "Epoch 150/200\n",
      "18925/18925 [==============================] - 7s 347us/step - loss: 9.9234 - f1_perRow: 0.5513 - f1_perClass: 0.8244 - acc: 0.8601\n",
      "Epoch 151/200\n",
      "18925/18925 [==============================] - 7s 350us/step - loss: 9.8959 - f1_perRow: 0.5506 - f1_perClass: 0.8274 - acc: 0.8630\n",
      "Epoch 152/200\n",
      "18925/18925 [==============================] - 7s 346us/step - loss: 9.8983 - f1_perRow: 0.5587 - f1_perClass: 0.8256 - acc: 0.8630\n",
      "Epoch 153/200\n",
      "18925/18925 [==============================] - 7s 347us/step - loss: 10.0439 - f1_perRow: 0.5569 - f1_perClass: 0.8219 - acc: 0.8596\n",
      "Epoch 154/200\n",
      "18925/18925 [==============================] - 7s 347us/step - loss: 10.6492 - f1_perRow: 0.5359 - f1_perClass: 0.8191 - acc: 0.8535\n",
      "Epoch 155/200\n",
      "18925/18925 [==============================] - 7s 350us/step - loss: 9.9319 - f1_perRow: 0.5558 - f1_perClass: 0.8290 - acc: 0.8610\n",
      "Epoch 156/200\n",
      "18925/18925 [==============================] - 7s 354us/step - loss: 10.1551 - f1_perRow: 0.5462 - f1_perClass: 0.8245 - acc: 0.8573\n",
      "Epoch 157/200\n",
      "18925/18925 [==============================] - 7s 352us/step - loss: 10.0492 - f1_perRow: 0.5606 - f1_perClass: 0.8223 - acc: 0.8596\n",
      "Epoch 158/200\n",
      "18925/18925 [==============================] - 7s 345us/step - loss: 10.1379 - f1_perRow: 0.5538 - f1_perClass: 0.8240 - acc: 0.8553\n",
      "Epoch 159/200\n",
      "18925/18925 [==============================] - 7s 348us/step - loss: 10.0084 - f1_perRow: 0.5611 - f1_perClass: 0.8276 - acc: 0.8608\n",
      "Epoch 160/200\n",
      "18925/18925 [==============================] - 7s 345us/step - loss: 10.0890 - f1_perRow: 0.5537 - f1_perClass: 0.8252 - acc: 0.8660\n",
      "Epoch 161/200\n",
      "18925/18925 [==============================] - 6s 343us/step - loss: 9.9430 - f1_perRow: 0.5525 - f1_perClass: 0.8256 - acc: 0.8656\n",
      "Epoch 162/200\n",
      "18925/18925 [==============================] - 7s 350us/step - loss: 9.9771 - f1_perRow: 0.5579 - f1_perClass: 0.8261 - acc: 0.8636\n",
      "Epoch 163/200\n",
      "18925/18925 [==============================] - 7s 346us/step - loss: 9.8518 - f1_perRow: 0.5574 - f1_perClass: 0.8282 - acc: 0.8597\n",
      "Epoch 164/200\n",
      "18925/18925 [==============================] - 7s 348us/step - loss: 9.8488 - f1_perRow: 0.5617 - f1_perClass: 0.8278 - acc: 0.8608\n",
      "Epoch 165/200\n",
      "18925/18925 [==============================] - 7s 350us/step - loss: 9.8665 - f1_perRow: 0.5531 - f1_perClass: 0.8289 - acc: 0.8597\n",
      "Epoch 166/200\n",
      "18925/18925 [==============================] - 7s 347us/step - loss: 9.7975 - f1_perRow: 0.5579 - f1_perClass: 0.8275 - acc: 0.8604\n",
      "Epoch 167/200\n",
      "18925/18925 [==============================] - 7s 347us/step - loss: 9.7686 - f1_perRow: 0.5530 - f1_perClass: 0.8272 - acc: 0.8632\n",
      "Epoch 168/200\n",
      "18925/18925 [==============================] - 7s 350us/step - loss: 9.8447 - f1_perRow: 0.5587 - f1_perClass: 0.8284 - acc: 0.8621\n",
      "Epoch 169/200\n",
      "18925/18925 [==============================] - 7s 349us/step - loss: 10.2080 - f1_perRow: 0.5472 - f1_perClass: 0.8303 - acc: 0.8576\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 170/200\n",
      "18925/18925 [==============================] - 7s 347us/step - loss: 9.9250 - f1_perRow: 0.5639 - f1_perClass: 0.8289 - acc: 0.8618\n",
      "Epoch 171/200\n",
      "18925/18925 [==============================] - 7s 350us/step - loss: 9.8422 - f1_perRow: 0.5619 - f1_perClass: 0.8287 - acc: 0.8606\n",
      "Epoch 172/200\n",
      "18925/18925 [==============================] - 7s 349us/step - loss: 9.6538 - f1_perRow: 0.5707 - f1_perClass: 0.8335 - acc: 0.8648\n",
      "Epoch 173/200\n",
      "18925/18925 [==============================] - 7s 369us/step - loss: 9.8526 - f1_perRow: 0.5669 - f1_perClass: 0.8314 - acc: 0.8635\n",
      "Epoch 174/200\n",
      "18925/18925 [==============================] - 7s 347us/step - loss: 9.6926 - f1_perRow: 0.5802 - f1_perClass: 0.8329 - acc: 0.8670\n",
      "Epoch 175/200\n",
      "18925/18925 [==============================] - 7s 344us/step - loss: 9.7705 - f1_perRow: 0.5796 - f1_perClass: 0.8319 - acc: 0.8675\n",
      "Epoch 176/200\n",
      "18925/18925 [==============================] - 7s 348us/step - loss: 9.7281 - f1_perRow: 0.5734 - f1_perClass: 0.8336 - acc: 0.8680\n",
      "Epoch 177/200\n",
      "18925/18925 [==============================] - 6s 343us/step - loss: 9.5829 - f1_perRow: 0.5748 - f1_perClass: 0.8340 - acc: 0.8673\n",
      "Epoch 178/200\n",
      "18925/18925 [==============================] - 7s 348us/step - loss: 9.6519 - f1_perRow: 0.5818 - f1_perClass: 0.8325 - acc: 0.8656\n",
      "Epoch 179/200\n",
      "18925/18925 [==============================] - 7s 349us/step - loss: 9.5435 - f1_perRow: 0.5727 - f1_perClass: 0.8361 - acc: 0.8674\n",
      "Epoch 180/200\n",
      "18925/18925 [==============================] - 7s 344us/step - loss: 9.5346 - f1_perRow: 0.5838 - f1_perClass: 0.8363 - acc: 0.8666\n",
      "Epoch 181/200\n",
      "18925/18925 [==============================] - 7s 352us/step - loss: 9.6278 - f1_perRow: 0.5820 - f1_perClass: 0.8346 - acc: 0.8671\n",
      "Epoch 182/200\n",
      "18925/18925 [==============================] - 7s 354us/step - loss: 9.5933 - f1_perRow: 0.5843 - f1_perClass: 0.8367 - acc: 0.8658\n",
      "Epoch 183/200\n",
      "18925/18925 [==============================] - 7s 348us/step - loss: nan - f1_perRow: 0.5720 - f1_perClass: 0.8353 - acc: 0.8655\n",
      "Epoch 184/200\n",
      "18925/18925 [==============================] - 7s 349us/step - loss: nan - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 185/200\n",
      "18925/18925 [==============================] - 7s 349us/step - loss: nan - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 186/200\n",
      "18925/18925 [==============================] - 7s 346us/step - loss: nan - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 187/200\n",
      "18925/18925 [==============================] - 7s 346us/step - loss: nan - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 188/200\n",
      "18925/18925 [==============================] - 7s 349us/step - loss: nan - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 189/200\n",
      "18925/18925 [==============================] - 7s 347us/step - loss: nan - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 190/200\n",
      "18925/18925 [==============================] - 7s 348us/step - loss: nan - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 191/200\n",
      "18925/18925 [==============================] - 7s 348us/step - loss: nan - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 192/200\n",
      "18925/18925 [==============================] - 7s 372us/step - loss: nan - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 193/200\n",
      "18925/18925 [==============================] - 7s 347us/step - loss: nan - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 194/200\n",
      "18925/18925 [==============================] - 7s 349us/step - loss: nan - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 195/200\n",
      "18925/18925 [==============================] - 7s 348us/step - loss: nan - f1_perRow: 0.0000e+00 - f1_perClass: 0.0000e+00 - acc: 0.0017\n",
      "Epoch 196/200\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-68-58c69642724d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# print(model2.summary())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mhist2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_lstm_prossed_train2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_lstm_prossed_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m28500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/iot/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/.conda/envs/iot/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/iot/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/iot/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/iot/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# print(model2.summary())\n",
    "hist2 = model2.fit(x_lstm_prossed_train2, y_lstm_prossed_train, epochs=200, batch_size=28500, shuffle=True, callbacks=callbacks_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.load_weights('IoTDownNet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================HOME Case : home_os_final.json =============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/omid/.conda/envs/iot/lib/python3.6/site-packages/ipykernel_launcher.py:9: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  if __name__ == '__main__':\n",
      "/home/omid/.conda/envs/iot/lib/python3.6/site-packages/ipykernel_launcher.py:8: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  \n",
      "/home/omid/.conda/envs/iot/lib/python3.6/site-packages/ipykernel_launcher.py:12: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         Class  Accuracy     Recall  Precision   F Score    Count            TP/TN/FP/FN\n",
      "------------------------------------------------------------------------\n",
      "                  acceleration     0.996      0.351     0.351     0.351        57    20/18996/   37/   37\n",
      "                      activity     0.999      0.000       nan     0.000        16     0/19074/    0/   16\n",
      "                       battery     1.000      0.000       nan     0.000         7     0/19083/    0/    7\n",
      "                        button     0.570      0.083     0.000     0.000        12     1/10880/ 8198/   11\n",
      "              colorTemperature     1.000      0.800     0.800     0.800         5     4/19084/    1/    1\n",
      "                       contact     0.993      0.689     0.547     0.610       151   104/18853/   86/   47\n",
      "                         level     0.998      0.300     0.240     0.267        20     6/19051/   19/   14\n",
      "                          lock     0.995      0.706     0.216     0.331        34    24/18969/   87/   10\n",
      "                        motion     0.982      0.000       nan     0.000       343     0/18747/    0/  343\n",
      "                          ping     0.974      0.998     0.909     0.951      4814  4802/13793/  483/   12\n",
      "                        status     0.995      0.829     0.577     0.681       117    97/18902/   71/   20\n",
      "                        switch     0.998      0.571     0.308     0.400        21    12/19042/   27/    9\n",
      "                   temperature     0.941      0.000       nan     0.000      1120     0/17970/    0/ 1120\n",
      "                     threeAxis     0.997      0.833     0.349     0.492        36    30/18998/   56/    6\n",
      "                       unknown     0.693      1.000     0.693     0.818     13223 13223/    0/ 5867/    0\n",
      "                         water     1.000        nan       nan       nan         0     0/19090/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "                      AVERAGES     0.946      0.448     0.312     0.356     19090     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "             Weighted AVERAGES     0.786      0.917     0.688     0.783     19090     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "       known Weighted AVERAGES     0.970      0.755     0.678     0.713     19090     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      " known -ping Weighted AVERAGES     0.959      0.154     0.106     0.123     19090     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "       non zero count AVERAGES     0.942      0.477     0.333     0.380     19090     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "Macro F1 : 0.356295\n",
      "sample F1 : 0.709009\n",
      "weighted F1 : 0.782870\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/omid/.conda/envs/iot/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/omid/.conda/envs/iot/lib/python3.6/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exact Match ACC : 0.29188 \n",
      "Total Records : 19090 \n",
      "Total ZXeros in True : 0 (0.000)%\n",
      "Total ZXeros in Test : 0 (0.000)%\n",
      "=============================================================================\n",
      "==================HOME Case : test_data_light.json =============\n",
      "                         Class  Accuracy     Recall  Precision   F Score    Count            TP/TN/FP/FN\n",
      "------------------------------------------------------------------------\n",
      "                  acceleration     0.992        nan     0.000     0.000         0     0/  263/    2/    0\n",
      "                      activity     1.000        nan       nan       nan         0     0/  265/    0/    0\n",
      "                       battery     1.000        nan       nan       nan         0     0/  265/    0/    0\n",
      "                        button     0.777        nan     0.000     0.000         0     0/  206/   59/    0\n",
      "              colorTemperature     0.857      0.000     0.000     0.000        31     0/  227/    7/   31\n",
      "                       contact     0.992        nan     0.000     0.000         0     0/  263/    2/    0\n",
      "                         level     0.702      0.217     0.562     0.313        83    18/  168/   14/   65\n",
      "                          lock     1.000        nan       nan       nan         0     0/  265/    0/    0\n",
      "                        motion     1.000        nan       nan       nan         0     0/  265/    0/    0\n",
      "                          ping     0.981      0.808     1.000     0.894        26    21/  239/    0/    5\n",
      "                        status     0.992        nan     0.000     0.000         0     0/  263/    2/    0\n",
      "                        switch     0.834      0.333     0.222     0.267        24     8/  213/   28/   16\n",
      "                   temperature     0.992      0.000       nan     0.000         2     0/  263/    0/    2\n",
      "                     threeAxis     0.992        nan     0.000     0.000         0     0/  263/    2/    0\n",
      "                       unknown     0.521      1.000     0.521     0.685       138   138/    0/  127/    0\n",
      "                         water     1.000        nan       nan       nan         0     0/  265/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "                      AVERAGES     0.915      0.147     0.144     0.135       265     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "             Weighted AVERAGES     0.672      0.609     0.493     0.494       265     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "       known Weighted AVERAGES     0.797      0.283     0.470     0.335       265     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      " known -ping Weighted AVERAGES     0.763      0.186     0.372     0.231       265     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "       non zero count AVERAGES     0.814      0.393     0.384     0.360       265     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "Macro F1 : 0.134887\n",
      "sample F1 : 0.540629\n",
      "weighted F1 : 0.493842\n",
      "Exact Match ACC : 0.30566 \n",
      "Total Records : 265 \n",
      "Total ZXeros in True : 0 (0.000)%\n",
      "Total ZXeros in Test : 0 (0.000)%\n",
      "=============================================================================\n",
      "==================HOME Case : test_data_motion_2.json =============\n",
      "                         Class  Accuracy     Recall  Precision   F Score    Count            TP/TN/FP/FN\n",
      "------------------------------------------------------------------------\n",
      "                  acceleration     0.993      0.000     0.000     0.000        30     0/10365/   41/   30\n",
      "                      activity     1.000        nan       nan       nan         0     0/10436/    0/    0\n",
      "                       battery     1.000      0.000       nan     0.000         1     0/10435/    0/    1\n",
      "                        button     0.703        nan     0.000     0.000         0     0/ 7336/ 3100/    0\n",
      "              colorTemperature     1.000      0.000       nan     0.000         3     0/10433/    0/    3\n",
      "                       contact     0.979      0.008     0.012     0.009       131     1/10220/   85/  130\n",
      "                         level     0.999      0.200     0.167     0.182         5     1/10426/    5/    4\n",
      "                          lock     0.999        nan     0.000     0.000         0     0/10428/    8/    0\n",
      "                        motion     0.969      0.000       nan     0.000       325     0/10111/    0/  325\n",
      "                          ping     0.971      0.949     0.938     0.944      2662  2527/ 7608/  166/  135\n",
      "                        status     0.992        nan     0.000     0.000         0     0/10353/   83/    0\n",
      "                        switch     0.999      0.500     0.100     0.167         2     1/10425/    9/    1\n",
      "                   temperature     0.995      0.000       nan     0.000        50     0/10386/    0/   50\n",
      "                     threeAxis     0.994      0.000     0.000     0.000        18     0/10376/   42/   18\n",
      "                       unknown     0.742      1.000     0.742     0.852      7746  7746/    0/ 2690/    0\n",
      "                         water     1.000        nan       nan       nan         0     0/10436/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "                      AVERAGES     0.959      0.166     0.122     0.135     10436     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "             Weighted AVERAGES     0.810      0.936     0.752     0.831     10436     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "       known Weighted AVERAGES     0.972      0.784     0.775     0.779     10436     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      " known -ping Weighted AVERAGES     0.976      0.005     0.005     0.004     10436     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "       non zero count AVERAGES     0.967      0.242     0.178     0.196     10436     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "Macro F1 : 0.134596\n",
      "sample F1 : 0.777357\n",
      "weighted F1 : 0.830658\n",
      "Exact Match ACC : 0.43465 \n",
      "Total Records : 10436 \n",
      "Total ZXeros in True : 0 (0.000)%\n",
      "Total ZXeros in Test : 0 (0.000)%\n",
      "=============================================================================\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(lstm_tests_known)) :\n",
    "    print( \"==================HOME Case : %s =============\" % test_names[i])\n",
    "    lstm_pred= model2.predict( lstm_tests_known[i][0])\n",
    "    \n",
    "#     print_info( lstm_tests[i][1], lstm_pred, classes , confidance=0.7)\n",
    "    print_info( lstm_tests_known[i][1], lstm_pred, classes , confidance=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================HOME Case : home_os_final.json =============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/omid/.conda/envs/iot/lib/python3.6/site-packages/ipykernel_launcher.py:9: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  if __name__ == '__main__':\n",
      "/home/omid/.conda/envs/iot/lib/python3.6/site-packages/ipykernel_launcher.py:8: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  \n",
      "/home/omid/.conda/envs/iot/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/omid/.conda/envs/iot/lib/python3.6/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/home/omid/.conda/envs/iot/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         Class  Accuracy     Recall  Precision   F Score    Count            TP/TN/FP/FN\n",
      "------------------------------------------------------------------------\n",
      "                  acceleration     0.995      0.250     0.650     0.361        52    13/ 9449/    7/   39\n",
      "                      activity     0.998      0.000       nan     0.000        16     0/ 9492/    0/   16\n",
      "                       battery     0.998      0.000     0.000     0.000         3     0/ 9493/   12/    3\n",
      "                        button     0.989      0.000     0.000     0.000        12     0/ 9404/   92/   12\n",
      "              colorTemperature     0.999      0.000     0.000     0.000         5     0/ 9501/    2/    5\n",
      "                       contact     0.975      0.741     0.342     0.468       143   106/ 9161/  204/   37\n",
      "                         level     0.998      0.250     0.385     0.303        20     5/ 9480/    8/   15\n",
      "                          lock     0.996      0.000     0.000     0.000        33     0/ 9471/    4/   33\n",
      "                        motion     0.976      0.000       nan     0.000       228     0/ 9280/    0/  228\n",
      "                       no_logs     0.901        nan     0.000     0.000         0     0/ 8570/  938/    0\n",
      "                          ping     0.962      0.995     0.935     0.964      4813  4788/ 4361/  334/   25\n",
      "                        status     0.991      0.838     0.581     0.686       111    93/ 9330/   67/   18\n",
      "                        switch     0.998      0.286     0.545     0.375        21     6/ 9482/    5/   15\n",
      "                   temperature     0.928      0.000     0.000     0.000       678     0/ 8823/    7/  678\n",
      "                     threeAxis     0.997      0.688     0.579     0.629        32    22/ 9460/   16/   10\n",
      "                       unknown     0.723      0.407     0.928     0.566      4212  1713/ 5163/  133/ 2499\n",
      "                         water     0.999        nan     0.000     0.000         0     0/ 9496/   12/    0\n",
      "------------------------------------------------------------------------\n",
      "                      AVERAGES     0.966      0.262     0.291     0.256      9508     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "             Weighted AVERAGES     0.864      0.650     0.828     0.695      9508     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "       known Weighted AVERAGES     0.961      0.816     0.760     0.784      9508     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      " known -ping Weighted AVERAGES     0.956      0.181     0.137     0.145      9508     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "       non zero count AVERAGES     0.968      0.297     0.330     0.290      9508     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "Macro F1 : 0.255968\n",
      "sample F1 : 0.591023\n",
      "weighted F1 : 0.695351\n",
      "--------------------------removed ping and unknown----------------------------------------------\n",
      "Macro F1 : 0.173333\n",
      "sample F1 : 0.029343\n",
      "weighted F1 : 0.054119\n",
      "Exact Match ACC : 0.50452 \n",
      "Total Records : 9508 \n",
      "Total ZXeros in True : 0 (0.000)%\n",
      "Total ZXeros in Test : 3099 (0.326)%\n",
      "=============================================================================\n",
      "==================HOME Case : test_data_light.json =============\n",
      "                         Class  Accuracy     Recall  Precision   F Score    Count            TP/TN/FP/FN\n",
      "------------------------------------------------------------------------\n",
      "                  acceleration     1.000        nan       nan       nan         0     0/  220/    0/    0\n",
      "                      activity     1.000        nan       nan       nan         0     0/  220/    0/    0\n",
      "                       battery     1.000        nan       nan       nan         0     0/  220/    0/    0\n",
      "                        button     1.000        nan       nan       nan         0     0/  220/    0/    0\n",
      "              colorTemperature     0.814      0.032     0.083     0.047        31     1/  178/   11/   30\n",
      "                       contact     1.000        nan       nan       nan         0     0/  220/    0/    0\n",
      "                         level     0.577      0.145     0.353     0.205        83    12/  115/   22/   71\n",
      "                          lock     0.991        nan     0.000     0.000         0     0/  218/    2/    0\n",
      "                        motion     1.000        nan       nan       nan         0     0/  220/    0/    0\n",
      "                       no_logs     0.832        nan     0.000     0.000         0     0/  183/   37/    0\n",
      "                          ping     0.968      0.808     0.913     0.857        26    21/  192/    2/    5\n",
      "                        status     0.991        nan     0.000     0.000         0     0/  218/    2/    0\n",
      "                        switch     0.886      0.125     0.429     0.194        24     3/  192/    4/   21\n",
      "                   temperature     0.995      0.000       nan     0.000         1     0/  219/    0/    1\n",
      "                     threeAxis     1.000        nan       nan       nan         0     0/  220/    0/    0\n",
      "                       unknown     0.573      0.011     0.500     0.021        94     1/  125/    1/   93\n",
      "                         water     1.000        nan       nan       nan         0     0/  220/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "                      AVERAGES     0.919      0.066     0.134     0.078       220     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "             Weighted AVERAGES     0.673      0.147     0.436     0.183       220     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "       known Weighted AVERAGES     0.731      0.224     0.399     0.275       220     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      " known -ping Weighted AVERAGES     0.686      0.115     0.303     0.166       220     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "       non zero count AVERAGES     0.802      0.187     0.380     0.221       220     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "Macro F1 : 0.077833\n",
      "sample F1 : 0.137121\n",
      "weighted F1 : 0.182844\n",
      "--------------------------removed ping and unknown----------------------------------------------\n",
      "Macro F1 : 0.026671\n",
      "sample F1 : 0.048223\n",
      "weighted F1 : 0.098322\n",
      "Exact Match ACC : 0.10455 \n",
      "Total Records : 220 \n",
      "Total ZXeros in True : 0 (0.000)%\n",
      "Total ZXeros in Test : 116 (0.527)%\n",
      "=============================================================================\n",
      "==================HOME Case : test_data_motion_2.json =============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/omid/.conda/envs/iot/lib/python3.6/site-packages/ipykernel_launcher.py:12: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         Class  Accuracy     Recall  Precision   F Score    Count            TP/TN/FP/FN\n",
      "------------------------------------------------------------------------\n",
      "                  acceleration     0.997      0.000       nan     0.000        25     0/ 7436/    0/   25\n",
      "                      activity     0.999        nan     0.000     0.000         0     0/ 7455/    6/    0\n",
      "                       battery     1.000      0.000       nan     0.000         1     0/ 7460/    0/    1\n",
      "                        button     0.997        nan     0.000     0.000         0     0/ 7440/   21/    0\n",
      "              colorTemperature     1.000      0.000       nan     0.000         3     0/ 7458/    0/    3\n",
      "                       contact     0.981      0.000     0.000     0.000       110     0/ 7316/   35/  110\n",
      "                         level     0.987      0.200     0.011     0.021         5     1/ 7366/   90/    4\n",
      "                          lock     0.991        nan     0.000     0.000         0     0/ 7392/   69/    0\n",
      "                        motion     0.974      0.000       nan     0.000       197     0/ 7264/    0/  197\n",
      "                       no_logs     0.681      0.000     0.000     0.000         1     0/ 5079/ 2381/    1\n",
      "                          ping     0.956      0.937     0.940     0.938      2662  2495/ 4639/  160/  167\n",
      "                        status     0.992        nan     0.000     0.000         0     0/ 7400/   61/    0\n",
      "                        switch     0.994      0.500     0.022     0.042         2     1/ 7414/   45/    1\n",
      "                   temperature     0.995      0.000       nan     0.000        34     0/ 7427/    0/   34\n",
      "                     threeAxis     0.998      0.000       nan     0.000        18     0/ 7443/    0/   18\n",
      "                       unknown     0.371      0.063     0.826     0.116      4935   309/ 2461/   65/ 4626\n",
      "                         water     1.000        nan       nan       nan         0     0/ 7461/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "                      AVERAGES     0.936      0.100     0.106     0.066      7461     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "             Weighted AVERAGES     0.596      0.351     0.823     0.384      7461     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "       known Weighted AVERAGES     0.959      0.817     0.818     0.817      7461     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      " known -ping Weighted AVERAGES     0.980      0.005     0.000     0.000      7461     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "       non zero count AVERAGES     0.911      0.142     0.150     0.093      7461     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "Macro F1 : 0.065730\n",
      "sample F1 : 0.336059\n",
      "weighted F1 : 0.384453\n",
      "--------------------------removed ping and unknown----------------------------------------------\n",
      "Macro F1 : 0.003676\n",
      "sample F1 : 0.000209\n",
      "weighted F1 : 0.000037\n",
      "Exact Match ACC : 0.31497 \n",
      "Total Records : 7461 \n",
      "Total ZXeros in True : 0 (0.000)%\n",
      "Total ZXeros in Test : 2218 (0.297)%\n",
      "=============================================================================\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(lstm_tests_known)) :\n",
    "    print( \"==================HOME Case : %s =============\" % test_names[i])\n",
    "    lstm_pred= model2.predict( lstm_tests_known[i][0])\n",
    "    \n",
    "#     print_info( lstm_tests[i][1], lstm_pred, classes , confidance=0.7)\n",
    "    print_info( lstm_tests_known[i][1], lstm_pred, classes , confidance=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f2f1c4d7630>]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(hist2.history['f1_perClass'], c='red')\n",
    "plt.plot(hist2.history['loss'], c='blue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(lstm_tests)) :\n",
    "    print( \"==================HOME Case : %s =============\" % test_names[i])\n",
    "    lstm_pred= model2.predict( lstm_tests[i][0])\n",
    "    \n",
    "#     print_info( lstm_tests[i][1], lstm_pred, classes , confidance=0.7)\n",
    "    print_info( lstm_tests[i][1], lstm_pred, classes , confidance=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(hist2.history['f1_perClass'], c='red')\n",
    "plt.plot(hist2.history['loss'], c='blue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Bidirectional LSTM :D \n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers import Bidirectional\n",
    "from keras.layers import Flatten\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from keras.models import Model\n",
    "\n",
    "from keras.layers import Input, merge, concatenate, Conv2D, MaxPooling2D, Activation, UpSampling2D, Dropout, Conv2DTranspose, UpSampling2D, Lambda\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers.normalization import BatchNormalization as bn\n",
    "from keras.layers.merge import add\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from keras.optimizers import RMSprop\n",
    "from keras import regularizers\n",
    "from keras import backend as K\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers.merge import add\n",
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "from keras.regularizers import l2\n",
    "from keras.layers import Conv1D\n",
    "from keras.layers.merge import add\n",
    "from keras.layers import Dense,Conv1D,Dropout,Activation,BatchNormalization,MaxPooling1D,Flatten,Masking,TimeDistributed\n",
    "from keras.layers.recurrent import LSTM,GRU,SimpleRNN\n",
    "from keras.models import Input,Sequential,Model\n",
    "from keras.layers.merge import add\n",
    "from keras.optimizers import Adam\n",
    "from keras.losses import MSE,MSLE\n",
    "\n",
    "model2 = Sequential()\n",
    "\n",
    "\n",
    "def weighted_categorical_crossentropy(weights):\n",
    "    \"\"\"\n",
    "    A weighted version of keras.objectives.categorical_crossentropy\n",
    "    \n",
    "    Variables:\n",
    "        weights: numpy array of shape (C,) where C is the number of classes\n",
    "    \n",
    "    Usage:\n",
    "        weights = np.array([0.5,2,10]) # Class one at 0.5, class 2 twice the normal weights, class 3 10x.\n",
    "        loss = weighted_categorical_crossentropy(weights)\n",
    "        model.compile(loss=loss,optimizer='adam')\n",
    "    \"\"\"\n",
    "    \n",
    "    weights = K.variable(weights)\n",
    "        \n",
    "    def loss(y_true, y_pred):\n",
    "        # scale predictions so that the class probas of each sample sum to 1\n",
    "        y_pred /= K.sum(y_pred, axis=-1, keepdims=True)\n",
    "        # clip to prevent NaN's and Inf's\n",
    "        y_pred = K.clip(y_pred, K.epsilon(), 1 - K.epsilon())\n",
    "        # calc\n",
    "        loss = y_true * K.log(y_pred) * weights\n",
    "        loss = -K.sum(loss, -1)\n",
    "        return loss\n",
    "    \n",
    "    return loss\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "def f1_perRow(y_true, y_pred):\n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return K.mean(f1)\n",
    "\n",
    "\n",
    "def f1_perClass(y_true, y_pred):\n",
    "\n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=1)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=1)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=1)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=1)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return K.mean(f1)\n",
    "\n",
    "def f1_loss_perClass(y_true, y_pred):\n",
    "    \n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=1)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=1)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=1)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=1)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return (1 - K.mean(f1))**2\n",
    "\n",
    "def f1_loss_perRow(y_true, y_pred):\n",
    "    \n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return (1 - K.mean(f1))**2\n",
    "\n",
    "\n",
    "\n",
    "inputs  = Input( ( dim_size,1 ) )\n",
    "\n",
    "\n",
    "\n",
    "# bi_d_1 = Bidirectional( LSTM(200 ,  recurrent_dropout=0.12, return_sequences=True),input_shape=[dim_size,1],merge_mode='concat') (inputs)\n",
    "lstm_1 =  LSTM(100 ,  recurrent_dropout=0.04, return_sequences=True)(inputs)\n",
    "# lstm_2 = LSTM(30 ,  recurrent_dropout=0.14, return_sequences=True)(lstm_1)\n",
    "\n",
    "bi_d_1 =Dense(128, activation='relu')  (lstm_1)\n",
    "lstm_1 =  Dense(128, activation='relu')(bi_d_1)\n",
    "lstm_2 = Dense(128, activation='relu')(lstm_1)\n",
    "\n",
    "\n",
    "\n",
    "# td_1    = TimeDistributed(Dense(256, activation='relu'))(lstm_2)\n",
    "# dout_1  = Dropout(0.1)(td_1)\n",
    "dout_1  = Dropout(0.1)(lstm_2)\n",
    "flt_1   = Flatten()(dout_1)\n",
    "dense_1 = Dense(128, activation='relu')(flt_1)\n",
    "dout_2  = Dropout(0.2)(dense_1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "dens_out_3 = Dense( 128, activation='relu' )(dout_2)\n",
    "\n",
    "\n",
    "# fl2  = Flatten()(out_new)\n",
    "\n",
    "out_put_final = Dense(len(classes), activation='sigmoid', name='Event_output')(dens_out_3)\n",
    "\n",
    "toService_1 = Dense( 130, name=\"to_service1\" )(dens_out_3)\n",
    "toService_1 = Dense( 130, name=\"to_service2\" )(toService_1)\n",
    "\n",
    "service_output = Dense(len(classes  ), activation=\"sigmoid\", name = 'service_output')(toService_1)\n",
    "\n",
    "\n",
    "\n",
    "model2 = Model(inputs=[inputs], outputs=[service_output])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# model2.add(Bidirectional( LSTM(200 ,  recurrent_dropout=0.12, return_sequences=True),input_shape=[dim_size,1],merge_mode='concat'))\n",
    "# model2.add( LSTM(60 ,  recurrent_dropout=0.04, return_sequences=True))\n",
    "# model2.add( LSTM(30 ,  recurrent_dropout=0.14, return_sequences=True))\n",
    "# # model2.add(Bidirectional( LSTM(100 ,  recurrent_dropout=0.04, return_sequences=True),merge_mode='concat'))\n",
    "# model2.add(TimeDistributed(Dense(256, activation='relu')))\n",
    "# model2.add(Dropout(0.1))\n",
    "# model2.add(Flatten())\n",
    "# model2.add(Dense(128, activation='relu'))\n",
    "# model2.add(Dropout(0.2))\n",
    "# model2.add(Dense(len(classes), activation='sigmoid'))\n",
    "\n",
    "# model2.compile(loss=weighted_categorical_crossentropy(weights=weights), optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "losses = {\n",
    "#     \"service_output\": f1_loss_perClass ,\n",
    "    \"service_output\": f1_loss_perRow ,\n",
    "    \"service_output\": \"categorical_crossentropy\",\n",
    "}\n",
    "lossWeights = {#\"service_output\": 20,\n",
    "               \"service_output\": 30.0 ,\n",
    "    \"service_output\": 20}\n",
    " \n",
    "\n",
    "\n",
    "#model2.compile(loss=losses,loss_weights=lossWeights, optimizer='adam', metrics=[f1_perRow,f1_perClass,'acc'])\n",
    "model2.compile(loss=losses, loss_weights=lossWeights, optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "checkpoint = ModelCheckpoint('IoTDownNet', monitor='loss', verbose=0, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "print(model2.summary())\n",
    "hist2 = model2.fit(x_lstm_prossed_train2, y_lstm_prossed_train, epochs=1000, batch_size=12500, shuffle=True, callbacks=callbacks_list)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Bidirectional LSTM :D \n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers import Bidirectional\n",
    "from keras.layers import Flatten\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from keras.models import Model\n",
    "\n",
    "from keras.layers import Input, merge, concatenate, Conv2D, MaxPooling2D, Activation, UpSampling2D, Dropout, Conv2DTranspose, UpSampling2D, Lambda\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers.normalization import BatchNormalization as bn\n",
    "from keras.layers.merge import add\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from keras.optimizers import RMSprop\n",
    "from keras import regularizers\n",
    "from keras import backend as K\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers.merge import add\n",
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "from keras.regularizers import l2\n",
    "from keras.layers import Conv1D\n",
    "from keras.layers.merge import add\n",
    "from keras.layers import Dense,Conv1D,Dropout,Activation,BatchNormalization,MaxPooling1D,Flatten,Masking,TimeDistributed\n",
    "from keras.layers.recurrent import LSTM,GRU,SimpleRNN\n",
    "from keras.models import Input,Sequential,Model\n",
    "from keras.layers.merge import add\n",
    "from keras.optimizers import Adam\n",
    "from keras.losses import MSE,MSLE\n",
    "\n",
    "model2 = Sequential()\n",
    "\n",
    "\n",
    "def weighted_categorical_crossentropy(weights):\n",
    "    \"\"\"\n",
    "    A weighted version of keras.objectives.categorical_crossentropy\n",
    "    \n",
    "    Variables:\n",
    "        weights: numpy array of shape (C,) where C is the number of classes\n",
    "    \n",
    "    Usage:\n",
    "        weights = np.array([0.5,2,10]) # Class one at 0.5, class 2 twice the normal weights, class 3 10x.\n",
    "        loss = weighted_categorical_crossentropy(weights)\n",
    "        model.compile(loss=loss,optimizer='adam')\n",
    "    \"\"\"\n",
    "    \n",
    "    weights = K.variable(weights)\n",
    "        \n",
    "    def loss(y_true, y_pred):\n",
    "        # scale predictions so that the class probas of each sample sum to 1\n",
    "        y_pred /= K.sum(y_pred, axis=-1, keepdims=True)\n",
    "        # clip to prevent NaN's and Inf's\n",
    "        y_pred = K.clip(y_pred, K.epsilon(), 1 - K.epsilon())\n",
    "        # calc\n",
    "        loss = y_true * K.log(y_pred) * weights\n",
    "        loss = -K.sum(loss, -1)\n",
    "        return loss\n",
    "    \n",
    "    return loss\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "def f1_perRow(y_true, y_pred):\n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return K.mean(f1)\n",
    "\n",
    "\n",
    "def f1_perClass(y_true, y_pred):\n",
    "\n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=1)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=1)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=1)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=1)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return K.mean(f1)\n",
    "\n",
    "def f1_loss_perClass(y_true, y_pred):\n",
    "    \n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=1)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=1)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=1)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=1)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return (1 - K.mean(f1))**2\n",
    "\n",
    "def f1_loss_perRow(y_true, y_pred):\n",
    "    \n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return (1 - K.mean(f1))**2\n",
    "\n",
    "\n",
    "\n",
    "inputs  = Input( ( dim_size,1 ) )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "out = Conv1D(128,3,padding='same')(inputs)\n",
    "out = BatchNormalization()(out)\n",
    "out = Activation('relu')(out)\n",
    "out = Dropout(0.2)(out)\n",
    "out = Conv1D(128,3,padding='same')(out)\n",
    "# out = Flatten()(out)\n",
    "# out = MaxPooling1D(2,padding='same', name ='pooling')(out)\n",
    "\n",
    "\n",
    "out = Conv1D(128,3,padding='same')(out)\n",
    "out = BatchNormalization()(out)\n",
    "out = Activation('relu')(out)\n",
    "out = Dropout(0.2)(out)\n",
    "out = Conv1D(128,3,padding='same')(out)\n",
    "# out = Flatten()(out)\n",
    "# out = MaxPooling1D(2,padding='same', name ='pooling2')(out)\n",
    "\n",
    "\n",
    "out = Conv1D(128,3,padding='same')(out)\n",
    "out = BatchNormalization()(out)\n",
    "out = Activation('relu')(out)\n",
    "out = Dropout(0.2)(out)\n",
    "out = Conv1D(128,3,padding='same')(out)\n",
    "# out = Flatten()(out)\n",
    "# out = MaxPooling1D(2,padding='same', name ='pooling')(out)\n",
    "\n",
    "\n",
    "\n",
    "# fl_out_1 = Flatten()(dout_2)\n",
    "\n",
    "fl_out_cnn = Flatten()(out)\n",
    "\n",
    "\n",
    "dens_out_3 = Dense( 128, activation='relu' )(fl_out_cnn)\n",
    "\n",
    "# fl2  = Flatten()(out_new)\n",
    "\n",
    "out_put_final = Dense(len(classes), activation='sigmoid', name='Event_output')(dens_out_3)\n",
    "\n",
    "toService_1 = Dense( 130, name=\"to_service1\" )(dens_out_3)\n",
    "toService_1 = Dense( 130, name=\"to_service2\" )(toService_1)\n",
    "\n",
    "service_output = Dense(len(classes  ), activation=\"sigmoid\", name = 'service_output')(toService_1)\n",
    "\n",
    "\n",
    "\n",
    "model2 = Model(inputs=[inputs], outputs=[service_output])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# model2.add(Bidirectional( LSTM(200 ,  recurrent_dropout=0.12, return_sequences=True),input_shape=[dim_size,1],merge_mode='concat'))\n",
    "# model2.add( LSTM(60 ,  recurrent_dropout=0.04, return_sequences=True))\n",
    "# model2.add( LSTM(30 ,  recurrent_dropout=0.14, return_sequences=True))\n",
    "# # model2.add(Bidirectional( LSTM(100 ,  recurrent_dropout=0.04, return_sequences=True),merge_mode='concat'))\n",
    "# model2.add(TimeDistributed(Dense(256, activation='relu')))\n",
    "# model2.add(Dropout(0.1))\n",
    "# model2.add(Flatten())\n",
    "# model2.add(Dense(128, activation='relu'))\n",
    "# model2.add(Dropout(0.2))\n",
    "# model2.add(Dense(len(classes), activation='sigmoid'))\n",
    "\n",
    "# model2.compile(loss=weighted_categorical_crossentropy(weights=weights), optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "losses = {\n",
    "#     \"service_output\": f1_loss_perClass ,\n",
    "    \"service_output\": f1_loss_perRow ,\n",
    "    \"service_output\": \"categorical_crossentropy\",\n",
    "}\n",
    "lossWeights = {#\"service_output\": 20,\n",
    "               \"service_output\": 30.0 ,\n",
    "    \"service_output\": 20}\n",
    " \n",
    "\n",
    "\n",
    "model2.compile(loss=losses,loss_weights=lossWeights, optimizer='adam', metrics=[f1_perRow,f1_perClass,'acc'])\n",
    "# model2.compile(loss=losses, loss_weights=lossWeights, optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "checkpoint = ModelCheckpoint('IoTDownNet', monitor='loss', verbose=0, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "print(model2.summary())\n",
    "hist2 = model2.fit(x_lstm_prossed_train2, y_lstm_prossed_train, epochs=100, batch_size=12500, shuffle=True, callbacks=callbacks_list)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Bidirectional LSTM :D \n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers import Bidirectional\n",
    "from keras.layers import Flatten\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from keras.models import Model\n",
    "\n",
    "from keras.layers import Input, merge, concatenate, Conv2D, MaxPooling2D, Activation, UpSampling2D, Dropout, Conv2DTranspose, UpSampling2D, Lambda\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers.normalization import BatchNormalization as bn\n",
    "from keras.layers.merge import add\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from keras.optimizers import RMSprop\n",
    "from keras import regularizers\n",
    "from keras import backend as K\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers.merge import add\n",
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "from keras.regularizers import l2\n",
    "from keras.layers import Conv1D\n",
    "from keras.layers.merge import add\n",
    "from keras.layers import Dense,Conv1D,Dropout,Activation,BatchNormalization,MaxPooling1D,Flatten,Masking,TimeDistributed\n",
    "from keras.layers.recurrent import LSTM,GRU,SimpleRNN\n",
    "from keras.models import Input,Sequential,Model\n",
    "from keras.layers.merge import add\n",
    "from keras.optimizers import Adam\n",
    "from keras.losses import MSE,MSLE\n",
    "\n",
    "model2 = Sequential()\n",
    "\n",
    "\n",
    "def weighted_categorical_crossentropy(weights):\n",
    "    \"\"\"\n",
    "    A weighted version of keras.objectives.categorical_crossentropy\n",
    "    \n",
    "    Variables:\n",
    "        weights: numpy array of shape (C,) where C is the number of classes\n",
    "    \n",
    "    Usage:\n",
    "        weights = np.array([0.5,2,10]) # Class one at 0.5, class 2 twice the normal weights, class 3 10x.\n",
    "        loss = weighted_categorical_crossentropy(weights)\n",
    "        model.compile(loss=loss,optimizer='adam')\n",
    "    \"\"\"\n",
    "    \n",
    "    weights = K.variable(weights)\n",
    "        \n",
    "    def loss(y_true, y_pred):\n",
    "        # scale predictions so that the class probas of each sample sum to 1\n",
    "        y_pred /= K.sum(y_pred, axis=-1, keepdims=True)\n",
    "        # clip to prevent NaN's and Inf's\n",
    "        y_pred = K.clip(y_pred, K.epsilon(), 1 - K.epsilon())\n",
    "        # calc\n",
    "        loss = y_true * K.log(y_pred) * weights\n",
    "        loss = -K.sum(loss, -1)\n",
    "        return loss\n",
    "    \n",
    "    return loss\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "def f1_perRow(y_true, y_pred):\n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return K.mean(f1)\n",
    "\n",
    "\n",
    "def f1_perClass(y_true, y_pred):\n",
    "\n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=1)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=1)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=1)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=1)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return K.mean(f1)\n",
    "\n",
    "def f1_loss_perClass(y_true, y_pred):\n",
    "    \n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=1)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=1)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=1)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=1)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return (1 - K.mean(f1)) \n",
    "\n",
    "def f1_loss_perRow(y_true, y_pred):\n",
    "    \n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return (1 - K.mean(f1))\n",
    "\n",
    "\n",
    "\n",
    "inputs  = Input( ( dim_size,1 ) )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# bi_d_1 = Bidirectional( LSTM(200 ,  recurrent_dropout=0.12, return_sequences=True),input_shape=[dim_size,1],merge_mode='concat') (inputs)\n",
    "lstm_1 =  LSTM(100 ,  recurrent_dropout=0.04, return_sequences=True)(inputs)\n",
    "# lstm_1 = LSTM(40 ,  recurrent_dropout=0.14, return_sequences=True)(lstm_1)\n",
    "\n",
    "bi_d_raw_1 =Dense(128, activation='relu')  (lstm_1)\n",
    "lstm_raw_1 =  Dense(128, activation='relu')(bi_d_raw_1)\n",
    "lstm_raw_2 = Dense(128, activation='relu')(lstm_raw_1)\n",
    "\n",
    "dout_1  = Dropout(0.1)(lstm_raw_2)\n",
    "flt_1   = Flatten()(dout_1)\n",
    "dense_1 = Dense(128, activation='relu')(flt_1)\n",
    "dout_3  = Dropout(0.2)(dense_1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "out = Conv1D(128,3,padding='same')(inputs)\n",
    "out = BatchNormalization()(out)\n",
    "out = Activation('relu')(out)\n",
    "out = Dropout(0.2)(out)\n",
    "out = Conv1D(128,3,padding='same')(out)\n",
    "# out = Flatten()(out)\n",
    "# out = MaxPooling1D(2,padding='same', name ='pooling')(out)\n",
    "\n",
    "\n",
    "out = Conv1D(128,3,padding='same')(out)\n",
    "out = BatchNormalization()(out)\n",
    "out = Activation('relu')(out)\n",
    "out = Dropout(0.2)(out)\n",
    "out = Conv1D(128,3,padding='same')(out)\n",
    "# out = Flatten()(out)\n",
    "# out = MaxPooling1D(2,padding='same', name ='pooling2')(out)\n",
    "\n",
    "\n",
    "out = Conv1D(128,3,padding='same')(out)\n",
    "out = BatchNormalization()(out)\n",
    "out = Activation('relu')(out)\n",
    "out = Dropout(0.2)(out)\n",
    "out = Conv1D(128,3,padding='same')(out)\n",
    "# out = Flatten()(out)\n",
    "# out = MaxPooling1D(2,padding='same', name ='pooling')(out)\n",
    "\n",
    "\n",
    "\n",
    "# fl_out_1 = Flatten()(dout_2)\n",
    "\n",
    "fl_out_cnn = Flatten()(out)\n",
    "\n",
    "# out_new = concatenate( [fl_out_1, fl_out_cnn] , name='mergerguy')\n",
    "out_new = concatenate( [ fl_out_cnn,dout_3] , name='mergerguy')\n",
    "\n",
    "dens_out_1 = Dense( 128, activation='relu' )(out_new)\n",
    "dens_out_2 = Dense( 128, activation='relu' )(dens_out_1)\n",
    "dens_out_3 = Dense( 128, activation='relu' )(dens_out_2)\n",
    "\n",
    "\n",
    "\n",
    "service_output = Dense(len(classes  ), activation=\"sigmoid\", name = 'service_output')(dens_out_3)\n",
    "\n",
    "\n",
    "\n",
    "model2 = Model(inputs=[inputs], outputs=[service_output])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# model2.add(Bidirectional( LSTM(200 ,  recurrent_dropout=0.12, return_sequences=True),input_shape=[dim_size,1],merge_mode='concat'))\n",
    "# model2.add( LSTM(60 ,  recurrent_dropout=0.04, return_sequences=True))\n",
    "# model2.add( LSTM(30 ,  recurrent_dropout=0.14, return_sequences=True))\n",
    "# # model2.add(Bidirectional( LSTM(100 ,  recurrent_dropout=0.04, return_sequences=True),merge_mode='concat'))\n",
    "# model2.add(TimeDistributed(Dense(256, activation='relu')))\n",
    "# model2.add(Dropout(0.1))\n",
    "# model2.add(Flatten())\n",
    "# model2.add(Dense(128, activation='relu'))\n",
    "# model2.add(Dropout(0.2))\n",
    "# model2.add(Dense(len(classes), activation='sigmoid'))\n",
    "\n",
    "# model2.compile(loss=weighted_categorical_crossentropy(weights=weights), optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "losses = {\n",
    "#     \"service_output\": f1_loss_perClass ,\n",
    "    \"service_output\": f1_loss_perRow ,\n",
    "    \"service_output\": \"categorical_crossentropy\",\n",
    "}\n",
    "lossWeights = {#\"service_output\": 20,\n",
    "               \"service_output\": 30.0 ,\n",
    "    \"service_output\": 20}\n",
    " \n",
    "\n",
    "\n",
    "model2.compile(loss=losses,loss_weights=lossWeights, optimizer='adam', metrics=[f1_perRow,f1_perClass,'acc'])\n",
    "# model2.compile(loss=losses, loss_weights=lossWeights, optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "checkpoint = ModelCheckpoint('IoTDownNet', monitor='loss', verbose=0, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "print(model2.summary())\n",
    "hist2 = model2.fit(x_lstm_prossed_train2, y_lstm_prossed_train, epochs=100, batch_size=12500, shuffle=True, callbacks=callbacks_list)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = {\n",
    "#     \"service_output\": f1_loss_perClass ,\n",
    "    \"service_output\": f1_loss_perClass ,\n",
    "#     \"service_output\": \"categorical_crossentropy\",\n",
    "}\n",
    "lossWeights = {#\"service_output\": 20,\n",
    "               \"service_output\": 30.0 ,\n",
    "#     \"service_output\": 20\n",
    "}\n",
    " \n",
    "\n",
    "\n",
    "model2.compile(loss=losses, loss_weights=lossWeights, optimizer=keras.optimizers.Adam(lr=1e-6  ), metrics=[f1_perRow,f1_perClass,'acc'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Bidirectional LSTM :D \n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers import Bidirectional\n",
    "from keras.layers import Flatten\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from keras.models import Model\n",
    "\n",
    "from keras.layers import Input, merge, concatenate, Conv2D, MaxPooling2D, Activation, UpSampling2D, Dropout, Conv2DTranspose, UpSampling2D, Lambda\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers.normalization import BatchNormalization as bn\n",
    "from keras.layers.merge import add\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from keras.optimizers import RMSprop\n",
    "from keras import regularizers\n",
    "from keras import backend as K\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers.merge import add\n",
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "from keras.regularizers import l2\n",
    "from keras.layers import Conv1D\n",
    "from keras.layers.merge import add\n",
    "from keras.layers import Dense,Conv1D,Dropout,Activation,BatchNormalization,MaxPooling1D,Flatten,Masking,TimeDistributed\n",
    "from keras.layers.recurrent import LSTM,GRU,SimpleRNN\n",
    "from keras.models import Input,Sequential,Model\n",
    "from keras.layers.merge import add\n",
    "from keras.optimizers import Adam\n",
    "from keras.losses import MSE,MSLE\n",
    "\n",
    "model2 = Sequential()\n",
    "\n",
    "\n",
    "def weighted_categorical_crossentropy(weights):\n",
    "    \"\"\"\n",
    "    A weighted version of keras.objectives.categorical_crossentropy\n",
    "    \n",
    "    Variables:\n",
    "        weights: numpy array of shape (C,) where C is the number of classes\n",
    "    \n",
    "    Usage:\n",
    "        weights = np.array([0.5,2,10]) # Class one at 0.5, class 2 twice the normal weights, class 3 10x.\n",
    "        loss = weighted_categorical_crossentropy(weights)\n",
    "        model.compile(loss=loss,optimizer='adam')\n",
    "    \"\"\"\n",
    "    \n",
    "    weights = K.variable(weights)\n",
    "        \n",
    "    def loss(y_true, y_pred):\n",
    "        # scale predictions so that the class probas of each sample sum to 1\n",
    "        y_pred /= K.sum(y_pred, axis=-1, keepdims=True)\n",
    "        # clip to prevent NaN's and Inf's\n",
    "        y_pred = K.clip(y_pred, K.epsilon(), 1 - K.epsilon())\n",
    "        # calc\n",
    "        loss = y_true * K.log(y_pred) * weights\n",
    "        loss = -K.sum(loss, -1)\n",
    "        return loss\n",
    "    \n",
    "    return loss\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "def f1_perRow(y_true, y_pred):\n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return K.mean(f1)\n",
    "\n",
    "\n",
    "def f1_perClass(y_true, y_pred):\n",
    "\n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=1)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=1)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=1)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=1)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return K.mean(f1)\n",
    "\n",
    "def f1_loss_perClass(y_true, y_pred):\n",
    "    \n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=1)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=1)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=1)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=1)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return (1 - K.mean(f1))**2\n",
    "\n",
    "def f1_loss_perRow(y_true, y_pred):\n",
    "    \n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return (1 - K.mean(f1))**2\n",
    "\n",
    "\n",
    "\n",
    "inputs  = Input( ( dim_size,1 ) )\n",
    "\n",
    "\n",
    "\n",
    "# bi_d_1 = Bidirectional( LSTM(200 ,  recurrent_dropout=0.12, return_sequences=True),input_shape=[dim_size,1],merge_mode='concat') (inputs)\n",
    "lstm_1 =  LSTM(32 ,  recurrent_dropout=0.3, return_sequences=True)(inputs)\n",
    "lstm_2 = LSTM(32 ,  recurrent_dropout=0.3, return_sequences=True)(lstm_1)\n",
    "\n",
    "lstm_2=Flatten()(lstm_2)\n",
    "lstm_2 = Dense(256, activation='relu')(lstm_2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "service_output = Dense(len(classes  ), activation=\"sigmoid\", name = 'service_output')(lstm_2)\n",
    "\n",
    "\n",
    "\n",
    "model2 = Model(inputs=[inputs], outputs=[service_output])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# model2.add(Bidirectional( LSTM(200 ,  recurrent_dropout=0.12, return_sequences=True),input_shape=[dim_size,1],merge_mode='concat'))\n",
    "# model2.add( LSTM(60 ,  recurrent_dropout=0.04, return_sequences=True))\n",
    "# model2.add( LSTM(30 ,  recurrent_dropout=0.14, return_sequences=True))\n",
    "# # model2.add(Bidirectional( LSTM(100 ,  recurrent_dropout=0.04, return_sequences=True),merge_mode='concat'))\n",
    "# model2.add(TimeDistributed(Dense(256, activation='relu')))\n",
    "# model2.add(Dropout(0.1))\n",
    "# model2.add(Flatten())\n",
    "# model2.add(Dense(128, activation='relu'))\n",
    "# model2.add(Dropout(0.2))\n",
    "# model2.add(Dense(len(classes), activation='sigmoid'))\n",
    "\n",
    "# model2.compile(loss=weighted_categorical_crossentropy(weights=weights), optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "losses = {\n",
    "#     \"service_output\": f1_loss_perClass ,\n",
    "    \"service_output\": f1_loss_perRow ,\n",
    "    \"service_output\": \"categorical_crossentropy\",\n",
    "}\n",
    "lossWeights = {#\"service_output\": 20,\n",
    "               \"service_output\": 30.0 ,\n",
    "    \"service_output\": 20}\n",
    " \n",
    "\n",
    "\n",
    "model2.compile(loss=losses,loss_weights=lossWeights, optimizer='adam', metrics=[f1_perRow,f1_perClass,'acc'])\n",
    "# model2.compile(loss=losses, loss_weights=lossWeights, optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "checkpoint = ModelCheckpoint('IoTDownNet', monitor='loss', verbose=0, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "print(model2.summary())\n",
    "\n",
    "hist2 = model2.fit(x_lstm_prossed_train2, y_lstm_prossed_train, epochs=100, batch_size=12500, shuffle=True, callbacks=callbacks_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split model\n",
    "## Bidirectional LSTM :D \n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers import Bidirectional\n",
    "from keras.layers import Flatten\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from keras.models import Model\n",
    "\n",
    "from keras.layers import Input, merge, concatenate, Conv2D, MaxPooling2D, Activation, UpSampling2D, Dropout, Conv2DTranspose, UpSampling2D, Lambda\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers.normalization import BatchNormalization as bn\n",
    "from keras.layers.merge import add\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from keras.optimizers import RMSprop\n",
    "from keras import regularizers\n",
    "from keras import backend as K\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers.merge import add\n",
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "from keras.regularizers import l2\n",
    "from keras.layers import Conv1D\n",
    "from keras.layers.merge import add\n",
    "from keras.layers import Dense,Conv1D,Dropout,Activation,BatchNormalization,MaxPooling1D,Flatten,Masking,TimeDistributed\n",
    "from keras.layers.recurrent import LSTM,GRU,SimpleRNN\n",
    "from keras.models import Input,Sequential,Model\n",
    "from keras.layers.merge import add\n",
    "from keras.optimizers import Adam\n",
    "from keras.losses import MSE,MSLE\n",
    "\n",
    "model2 = Sequential()\n",
    "\n",
    "\n",
    "def weighted_categorical_crossentropy(weights):\n",
    "    \"\"\"\n",
    "    A weighted version of keras.objectives.categorical_crossentropy\n",
    "    \n",
    "    Variables:\n",
    "        weights: numpy array of shape (C,) where C is the number of classes\n",
    "    \n",
    "    Usage:\n",
    "        weights = np.array([0.5,2,10]) # Class one at 0.5, class 2 twice the normal weights, class 3 10x.\n",
    "        loss = weighted_categorical_crossentropy(weights)\n",
    "        model.compile(loss=loss,optimizer='adam')\n",
    "    \"\"\"\n",
    "    \n",
    "    weights = K.variable(weights)\n",
    "        \n",
    "    def loss(y_true, y_pred):\n",
    "        # scale predictions so that the class probas of each sample sum to 1\n",
    "        y_pred /= K.sum(y_pred, axis=-1, keepdims=True)\n",
    "        # clip to prevent NaN's and Inf's\n",
    "        y_pred = K.clip(y_pred, K.epsilon(), 1 - K.epsilon())\n",
    "        # calc\n",
    "        loss = y_true * K.log(y_pred) * weights\n",
    "        loss = -K.sum(loss, -1)\n",
    "        return loss\n",
    "    \n",
    "    return loss\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "def f1_perRow(y_true, y_pred):\n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return K.mean(f1)\n",
    "\n",
    "\n",
    "def f1_perClass(y_true, y_pred):\n",
    "\n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=1)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=1)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=1)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=1)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return K.mean(f1)\n",
    "\n",
    "def f1_loss_perClass(y_true, y_pred):\n",
    "    \n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=1)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=1)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=1)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=1)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return (1 - K.mean(f1))**2\n",
    "\n",
    "def f1_loss_perRow(y_true, y_pred):\n",
    "    \n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return (1 - K.mean(f1))**2\n",
    "\n",
    "#splitting data\n",
    "X=x_lstm_prossed_train2\n",
    "y=y_lstm_prossed_train\n",
    "a,b,c,d,e,f,g,h,ii,jj,k,l,m,n,o,p=[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]\n",
    "print(len(y_lstm_prossed_train[0]))\n",
    "for i in range(0,len(y_lstm_prossed_train)):\n",
    "    a.append(y_lstm_prossed_train[i][0])\n",
    "    b.append(y_lstm_prossed_train[i][1])\n",
    "    c.append(y_lstm_prossed_train[i][2])\n",
    "    d.append(y_lstm_prossed_train[i][3])\n",
    "    e.append(y_lstm_prossed_train[i][4])\n",
    "    f.append(y_lstm_prossed_train[i][5])\n",
    "    g.append(y_lstm_prossed_train[i][6])\n",
    "    h.append(y_lstm_prossed_train[i][7])\n",
    "    ii.append(y_lstm_prossed_train[i][8])\n",
    "    jj.append(y_lstm_prossed_train[i][9])\n",
    "    k.append(y_lstm_prossed_train[i][10])\n",
    "    l.append(y_lstm_prossed_train[i][11])\n",
    "    m.append(y_lstm_prossed_train[i][12])\n",
    "    n.append(y_lstm_prossed_train[i][13])\n",
    "    o.append(y_lstm_prossed_train[i][14])\n",
    "    p.append(y_lstm_prossed_train[i][15])\n",
    "    \n",
    "zzzz=[]    \n",
    "zzzz.append(np.array(a))\n",
    "zzzz.append(np.array(b))\n",
    "zzzz.append(np.array(c))\n",
    "zzzz.append(np.array(d))\n",
    "zzzz.append(np.array(e))\n",
    "zzzz.append(np.array(f))\n",
    "zzzz.append(np.array(g))\n",
    "zzzz.append(np.array(h))\n",
    "zzzz.append(np.array(ii))\n",
    "zzzz.append(np.array(jj))\n",
    "zzzz.append(np.array(k))\n",
    "zzzz.append(np.array(l))\n",
    "zzzz.append(np.array(m))\n",
    "zzzz.append(np.array(n))\n",
    "zzzz.append(np.array(o))\n",
    "zzzz.append(np.array(p))\n",
    "\n",
    "\n",
    "for i in range(0,16):\n",
    "    \n",
    "    \n",
    "        \n",
    "        \n",
    "    \n",
    "\n",
    "\n",
    "    inputs  = Input( ( dim_size,1 ) )\n",
    "\n",
    "\n",
    "    out = Conv1D(128,3,padding='same')(inputs)\n",
    "    out = BatchNormalization()(out)\n",
    "    out = Activation('relu')(out)\n",
    "    out = Dropout(0.2)(out)\n",
    "    out = Conv1D(128,3,padding='same')(out)\n",
    "    # bi_d_1 = Bidirectional( LSTM(200 ,  recurrent_dropout=0.12, return_sequences=True),input_shape=[dim_size,1],merge_mode='concat') (inputs)\n",
    "    lstm_1 =  LSTM(100 ,  recurrent_dropout=0.04, return_sequences=True)(out)\n",
    "    # lstm_2 = LSTM(30 ,  recurrent_dropout=0.14, return_sequences=True)(lstm_1)\n",
    "\n",
    "    bi_d_1 =Dense(128, activation='relu')  (lstm_1)\n",
    "    lstm_1 =  Dense(128, activation='relu')(bi_d_1)\n",
    "    lstm_2 = Dense(128, activation='relu')(lstm_1)\n",
    "\n",
    "\n",
    "\n",
    "    # td_1    = TimeDistributed(Dense(256, activation='relu'))(lstm_2)\n",
    "    # dout_1  = Dropout(0.1)(td_1)\n",
    "    dout_1  = Dropout(0.1)(lstm_2)\n",
    "    flt_1   = Flatten()(dout_1)\n",
    "    dense_1 = Dense(128, activation='relu')(flt_1)\n",
    "    dout_2  = Dropout(0.2)(dense_1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # bi_d_1 = Bidirectional( LSTM(200 ,  recurrent_dropout=0.12, return_sequences=True),input_shape=[dim_size,1],merge_mode='concat') (inputs)\n",
    "    lstm_1 =  LSTM(100 ,  recurrent_dropout=0.04, return_sequences=True)(inputs)\n",
    "    # lstm_1 = LSTM(40 ,  recurrent_dropout=0.14, return_sequences=True)(lstm_1)\n",
    "\n",
    "    bi_d_raw_1 =Dense(128, activation='relu')  (lstm_1)\n",
    "    lstm_raw_1 =  Dense(128, activation='relu')(bi_d_raw_1)\n",
    "    lstm_raw_2 = Dense(128, activation='relu')(lstm_raw_1)\n",
    "\n",
    "    dout_1  = Dropout(0.1)(lstm_raw_2)\n",
    "    flt_1   = Flatten()(dout_1)\n",
    "    dense_1 = Dense(128, activation='relu')(flt_1)\n",
    "    dout_3  = Dropout(0.2)(dense_1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    out = Conv1D(128,3,padding='same')(inputs)\n",
    "    out = BatchNormalization()(out)\n",
    "    out = Activation('relu')(out)\n",
    "    out = Dropout(0.2)(out)\n",
    "    out = Conv1D(128,3,padding='same')(out)\n",
    "    # out = Flatten()(out)\n",
    "    # out = MaxPooling1D(2,padding='same', name ='pooling')(out)\n",
    "\n",
    "\n",
    "    out = Conv1D(128,3,padding='same')(out)\n",
    "    out = BatchNormalization()(out)\n",
    "    out = Activation('relu')(out)\n",
    "    out = Dropout(0.2)(out)\n",
    "    out = Conv1D(128,3,padding='same')(out)\n",
    "    # out = Flatten()(out)\n",
    "    # out = MaxPooling1D(2,padding='same', name ='pooling2')(out)\n",
    "\n",
    "\n",
    "    out = Conv1D(128,3,padding='same')(out)\n",
    "    out = BatchNormalization()(out)\n",
    "    out = Activation('relu')(out)\n",
    "    out = Dropout(0.2)(out)\n",
    "    out = Conv1D(128,3,padding='same')(out)\n",
    "    # out = Flatten()(out)\n",
    "    # out = MaxPooling1D(2,padding='same', name ='pooling')(out)\n",
    "\n",
    "\n",
    "\n",
    "    # fl_out_1 = Flatten()(dout_2)\n",
    "\n",
    "    fl_out_cnn = Flatten()(out)\n",
    "\n",
    "    # out_new = concatenate( [fl_out_1, fl_out_cnn] , name='mergerguy')\n",
    "    out_new = concatenate( [dout_2, fl_out_cnn,dout_3] , name='mergerguy')\n",
    "\n",
    "    dens_out_1 = Dense( 128, activation='relu' )(out_new)\n",
    "    dens_out_2 = Dense( 128, activation='relu' )(dens_out_1)\n",
    "    dens_out_3 = Dense( 128, activation='relu' )(dens_out_2)\n",
    "\n",
    "    # fl2  = Flatten()(out_new)\n",
    "\n",
    "    out_put_final = Dense(len(classes), activation='sigmoid', name='Event_output')(dens_out_3)\n",
    "\n",
    "    toService_1 = Dense( 130, name=\"to_service1\" )(dens_out_3)\n",
    "    toService_1 = Dense( 130, name=\"to_service2\" )(toService_1)\n",
    "\n",
    "    service_output = Dense(1, activation=\"sigmoid\", name = 'service_output')(toService_1)\n",
    "\n",
    "\n",
    "    losses = {\n",
    "    #     \"service_output\": f1_loss_perClass ,\n",
    "        \"service_output\": f1_loss_perRow ,\n",
    "        \"service_output\": \"binary_crossentropy\",\n",
    "    }\n",
    "    lossWeights = {#\"service_output\": 20,\n",
    "                   \"service_output\": 30.0 ,\n",
    "        \"service_output\": 20}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    model2 = Model(inputs=[inputs], outputs=[service_output])\n",
    "    model2.compile(loss=losses,loss_weights=lossWeights, optimizer='adam', metrics=[f1_perRow,f1_perClass,'acc'])\n",
    "    # model2.compile(loss=losses, loss_weights=lossWeights, optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    checkpoint = ModelCheckpoint('IoTDownNet', monitor='loss', verbose=0, save_best_only=True, mode='min')\n",
    "    callbacks_list = [checkpoint]\n",
    "    hist2 = model2.fit(x_lstm_prossed_train2, zzzz[i], epochs=200, batch_size=12500, shuffle=True, callbacks=callbacks_list)\n",
    "    model2.save('number'+str(i)+'.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model2.compile(loss=losses,loss_weights=lossWeights, optimizer=keras.optimizers.Adam(lr=5e-5  ), metrics=[f1_perRow,f1_perClass,'acc'])\n",
    "hist2 = model2.fit(x_lstm_prossed_train2, y_lstm_prossed_train, epochs=300, batch_size=16500, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.compile(loss=f1_loss, optimizer=keras.optimizers.Adam(lr=8e-5  ), metrics=[f1,'acc'])\n",
    "hist2 = model2.fit(x_lstm_prossed_train2, y_lstm_prossed_train, epochs=300, batch_size=7500, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.compile(loss=weighted_categorical_crossentropy(weights=weights), optimizer=keras.optimizers.Adam(lr=8e-5  ), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.compile(loss='categorical_crossentropy', optimizer=keras.optimizers.Adam(lr=8e-5  ), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.compile(loss=weighted_categorical_crossentropy(weights=weights), optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist2 = model2.fit(x_lstm_prossed_train2, y_lstm_prossed_train, epochs=300, batch_size=3500, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.save( \"LSTM-sigmoid-withRemovedClasses\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(hist2.history['loss'], c='red')\n",
    "plt.plot(hist2.history['acc'], c='blue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(hist2.history['loss'], c='red')\n",
    "# plt.plot(hist2.history['acc'], c='blue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import plot_model\n",
    "plot_model(model2, to_file='model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.models import load_model\n",
    "# model2=load_model( \"LSTM_withSigmoid_LargeData_F1_E100_B500_MSE_False\"  \n",
    "#            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(lstm_tests)) :\n",
    "    print( \"==================HOME Case : %s =============\" % test_names[i])\n",
    "    makeReadable( classes=classes, confidance=0.5,data=lstm_tests[i][0],gt=lstm_tests[i][1],model=model2,path=test_names[i],x=lstm_tests[i][0])\n",
    "    \n",
    "#     lstm_pred= model2.predict( lstm_tests[i][0])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# ------------- do not go any further :) ------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_pred= model2.predict( lstm_tests[i][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_pred= model2.predict( lstm_tests[1][0])\n",
    "lstm_pred__ = np.array(list(lstm_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_pred__ = np.array(list(lstm_pred))\n",
    "print_info( lstm_tests[1][1], lstm_pred__, classes , confidance=0.43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in [1] :\n",
    "for i in range(len(lstm_tests)) :\n",
    "    print( \"==================HOME Case : %s =============\" % test_names[i])\n",
    "    lstm_pred= model2.predict( lstm_tests[i][0])\n",
    "    \n",
    "#     print_info( lstm_tests[i][1], lstm_pred, classes , confidance=0.7)\n",
    "    print_info( lstm_tests[i][1], lstm_pred, classes , confidance=0.5)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in [1] :\n",
    "# for i in range(len(lstm_tests)) :\n",
    "    print( \"==================HOME Case : %s =============\" % test_names[i])\n",
    "    lstm_pred= model2.predict( lstm_tests[i][0])\n",
    "    \n",
    "#     print_info( lstm_tests[i][1], lstm_pred, classes , confidance=0.7)\n",
    "    print_info( lstm_tests[i][1], lstm_pred, classes , confidance=0.992)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_pred =model2.predict( x_lstm_prossed_test2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_info(y_lstm_prossed_test, lstm_pred, classes, confidance=0.60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_pred =model2.predict( x_lstm_prossed_test)\n",
    "print_info(y_lstm_prossed_test, lstm_pred, classes, confidance=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_pred = model2.predict( x_lstm_prossed_test)\n",
    "print_info(y_lstm_prossed_test, lstm_pred, classes, confidance=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_info(y_lstm_prossed_train, y_lstm_prossed_train, classes, confidance=0.60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[x for x  in lstm_pred  if  np.sum(x) > 0 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.save( \"LSTM_withSigmoid_LargeData_F%s_E%d_B%d_M%s_%r\" %\n",
    "            (\n",
    "            FoldID,\n",
    "                Epoch_count,\n",
    "                Batch_size,\n",
    "                Mapper,\n",
    "                IgnoreEmpty\n",
    "            ) \n",
    "           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_pred = model2.predict( x_lstm_prossed_test )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_info(y_lstm_prossed_test, lstm_pred, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train_muhammed,y_train_muhammed, classes = pre_process_raw( x_train, y_train , dim_size, zero_pad=True, normalize=False)\n",
    "# x_test_muhammed,y_test_muhammed, classes = pre_process_raw( x_test, y_test , dim_size, zero_pad=True, normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_pred = model2.predict( x_lstm_prossed_test )\n",
    "print_info(y_lstm_prossed_test, lstm_pred, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_pred = model2.predict( x_lstm_prossed_test )\n",
    "print_info(y_lstm_prossed_test, lstm_pred, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print_info(y_lstm_prossed_test, pred, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len( y_lstm_prossed_train[0] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_size =160\n",
    "x_lstm_prossed_train,y_lstm_prossed_train, _ = pre_process_raw( x_train, y_train , dim_size, zero_pad=True, normalize=False,classes=classes)\n",
    "x_lstm_prossed_test,y_lstm_prossed_test, _ = pre_process_raw( x_test, y_test , dim_size, zero_pad=True, normalize=False,classes=classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len([x  for x  in y_lstm_prossed_test if x[21]==1 or x[20]==1]), len(y_lstm_prossed_test  ) , len([x  for x  in y_lstm_prossed_test if x[21]==1 or x[20]==1])/len(y_lstm_prossed_test  ) *1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[ x for x  in  pred if np.sum(x) > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y_lstm_prossed_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_for_raun( pred   ):\n",
    "    pp = pred\n",
    "    pp[pp>=0.5] = 1\n",
    "    pp[pp<0.5] = 0\n",
    "    return pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len([x for x in pred if np.sum( do_for_raun(x) )==0 ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len([x for x in pred if  do_for_raun(x)[20] ==1 or do_for_raun(x)[21] ==1 ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# np.save(\"../files/muhammed/x_train.json\" , x_train_muhammed)\n",
    "# np.save(\"../files/muhammed/y_train.json\", )\n",
    "\n",
    "\n",
    "# np.save( \"../files/muhammed/x_train.json\", x_train_muhammed )\n",
    "# np.save(\"../files/muhammed/y_train.json\",  y_train_muhammed )\n",
    "# np.save( \"../files/muhammed/x_test.json\",x_test_muhammed )\n",
    "# np.save( \"../files/muhammed/y_test.json\",y_test_muhammed )\n",
    "# np.save( \"../files/muhammed/classes.json\",  classes )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(x_lstm_prossed_test) + len(x_lstm_prossed_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3.6(iot)",
   "language": "python",
   "name": "iot"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
