{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import json \n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import keras \n",
    "\n",
    "# import numpy\n",
    "# import pandas\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "from keras.datasets import imdb\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "import glob\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "\n",
    "\n",
    "from keras import backend as K\n",
    "\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# import os\n",
    "# os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from xgboost import plot_tree\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "loadFromMerged=True\n",
    "loadFromIndexes= False\n",
    "Mapper='SE'\n",
    "IgnoreEmpty= True\n",
    "FoldID =\"1\"\n",
    "Epoch_count=100\n",
    "Batch_size=5000\n",
    "INCLUDE_DIRECTION = True\n",
    "\n",
    "LOAD_OLD_DATA_TRAIN = False\n",
    "LOAD_OLD_DATA_TEST = False\n",
    "MERGE_TESTS=True\n",
    "\n",
    "TEST_CLASS_CAP =150"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data the old way\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_data= [] \n",
    "# y_data= [] \n",
    "\n",
    "\n",
    "# with open( '../files/txt/seq_mapping_large.txt' ) as f:\n",
    "#     x_data =   f.readlines()\n",
    "\n",
    "# with open( '../files/txt/command_mapping_large.txt' ) as f:\n",
    "#     y_data = f.readlines()\n",
    "    \n",
    "    \n",
    "# x_data =[ np.array([ int(y) for y in x.strip().split( ' ') ])   for x in  x_data ] \n",
    "# y_data =[ x.strip().split(' ') for x in  y_data ] \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Load The Data The New Way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  mapps the input records to a integer array for the input\n",
    "def mapping_x( inp, include_direction = False , TrimAt= 15 ):\n",
    "    if include_direction:\n",
    "        return np.array([ int(x[\"packet_length\"]) * (1 if x['packet_source']=='hub' else -1)  for x in inp ][:15])\n",
    "    else:\n",
    "        return np.array([ int(x[\"packet_length\"])  for x in inp ][:15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapping_y_service(inp):\n",
    "    return np.array(  list(set([x[\"event\"] for x in inp])) if (len(inp )>0) else [\"none\"] )\n",
    "\n",
    "def mapping_y_service_event(inp):\n",
    "    return np.array(  list(set([ \"%s-%s\"%( x[\"event\"] ,x[\"val\"] ) for x in inp])) if (len(inp )>0) else [\"none\"] )\n",
    "\n",
    "def mapping_y_device_service(inp):\n",
    "    return np.array(  list(set([ \"%s & %s\"%( x[\"device\"] ,x[\"event\"] ) for x in inp])) if (len(inp )>0) else [\"none\"] )\n",
    "\n",
    "def mapping_y_full(inp):\n",
    "    return np.array(  list(set([ \"%s & %s & %s\"%( x[\"device\"] ,x[\"event\"], x['val'] ) for x in inp])) if (len(inp )>0) else [\"none\"] )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this cleans the data removing emply nodes and turning the nodes into sarrays by calling the mapping function \n",
    "\n",
    "def clean_data( x_data, y_data , removeempty=True, Mapping='S', include_direction=False):\n",
    "    cleans = [] \n",
    "    cleans = (sorted([ x for x in y_data if (removeempty and len(y_data[x]) > 0) or not removeempty  ] ))\n",
    "    \n",
    "    ret_x  = [x_data[x] for x in cleans]\n",
    "    ret_y  = [y_data[x] for x in cleans] \n",
    "    \n",
    "    print( len(y_data), len(cleans) )\n",
    "    \n",
    "    ret_x  = [ mapping_x(x, include_direction=include_direction) for x in ret_x ] \n",
    "    ret_y_s = [ mapping_y_service(y) for y in ret_y ]\n",
    "    if Mapping=='S':\n",
    "        ret_y  = [ mapping_y_service(y) for y in ret_y ]\n",
    "    elif Mapping=='SE':\n",
    "        ret_y  = [ mapping_y_service_event(y) for y in ret_y ]\n",
    "    elif Mapping=='DS':\n",
    "        ret_y  = [ mapping_y_device_service(y) for y in ret_y ]\n",
    "    elif Mapping=='F':\n",
    "        ret_y  = [ mapping_y_full(y) for y in ret_y ]\n",
    "    \n",
    "#     ret_y = ret_y.tolist()\n",
    "#     ret_y_s = ret_y_s.tolist()\n",
    "    \n",
    "#     for t in ret_y:\n",
    "#         if 'no_logs' in t:\n",
    "#             t.remove('no_logs')\n",
    "#             t.append('unknown')\n",
    "#     ret_y_s.remove('no_logs')\n",
    "    \n",
    "#     ret_y = np.array(ret_y)\n",
    "#     ret_y_s = np.array(ret_y_s)\n",
    "    \n",
    "    return ret_x, ret_y, ret_y_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in load from merged\n",
      "2522 2335\n",
      "0 0\n",
      "7 6\n",
      "0 0\n",
      "9 9\n",
      "3161 3047\n",
      "2703 2229\n",
      "17 17\n",
      "29 17\n",
      "2960 2778\n",
      "1775 1697\n",
      "15 12\n",
      "191 143\n",
      "0 0\n",
      "10 9\n",
      "7114 6606\n",
      "983 652\n",
      "918 890\n",
      "1703 1540\n",
      "7 7\n",
      "2199 2179\n",
      "loading from test files\n",
      "found files :  5\n",
      "home_os_final.json\n",
      "18308 18308\n",
      "home_sk_final.json\n",
      "5837 5837\n",
      "test_data_light.json\n",
      "233 233\n",
      "test_data_lock.json\n",
      "807 807\n",
      "test_data_motion_2.json\n",
      "8133 8133\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(24173, 1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x= []\n",
    "y= []\n",
    "\n",
    "x_test = []\n",
    "y_test = []\n",
    "y_test_service= []\n",
    "\n",
    "x_train = []\n",
    "y_train = []\n",
    "y_train_service = []\n",
    "\n",
    "test_names = []\n",
    "\n",
    "add_to_trainig = [0,2]\n",
    "\n",
    "if loadFromMerged:\n",
    "    print(\"in load from merged\")\n",
    "    if LOAD_OLD_DATA_TRAIN:\n",
    "        with open(  '../files/train/test/test_homes/final_upload/Merged_final_with_home/merged_hub_segments_final.json'  ) as f:\n",
    "            y_data = json.load(f)\n",
    "\n",
    "        with open(  '../files/train/test/test_homes/final_upload/Merged_final_with_home/merged_pcap_segments_final.json'  ) as f:\n",
    "            x_data = json.load(f)\n",
    "\n",
    "    #     with open(  '../files/train/merged/hub_segments_2.json'  ) as f:\n",
    "    #         y_data = json.load(f)\n",
    "\n",
    "    #     with open(  '../files/train/merged/pcap_segments_2.json'  ) as f:\n",
    "    #         x_data = json.load(f)\n",
    "\n",
    "        if len( y_data ) != len(x_data) :\n",
    "            print( pick )\n",
    "\n",
    "\n",
    "        x_train,y_train, y_train_service= clean_data( x_data, y_data, IgnoreEmpty , \n",
    "                                                     Mapping=Mapper, include_direction=INCLUDE_DIRECTION )\n",
    "    else:\n",
    "        \n",
    "        for pick in sorted(glob.glob( '../files/iot_data_2020/train/hub_segments/*.json' )):\n",
    "            fname  = os.path.basename(pick)\n",
    "#             test_names.append( fname )\n",
    "            with open( os.path.join( '../files/iot_data_2020/train/hub_segments/', fname) ) as f:\n",
    "                y_data = json.load(f)\n",
    "\n",
    "            with open( os.path.join('../files/iot_data_2020/train/pcap_segments/', fname) ) as f:\n",
    "                x_data = json.load(f)\n",
    "\n",
    "            if len( y_data ) != len(x_data) :\n",
    "                print( pick )\n",
    "                continue\n",
    "\n",
    "            x_t,y_t, y_t_s= clean_data( x_data, y_data, IgnoreEmpty , \n",
    "                                                     Mapping=Mapper, include_direction=INCLUDE_DIRECTION )\n",
    "    \n",
    "            x_train.extend(x_t)\n",
    "            y_train.extend(y_t)\n",
    "            y_train_service.extend(y_t_s)\n",
    "            \n",
    "\n",
    "    #     continue\n",
    "#     if loadFromIndexes:\n",
    "#         print(\"load from indexes\")\n",
    "#         with open(\"../files/train/merged/items_2_test-train_indexes.json\")  as f:\n",
    "#             index_info = json.load(f)\n",
    "\n",
    "\n",
    "#         for i in index_info[FoldID][\"test\"]:\n",
    "#             x_test[str(i)]=(x_data[str(i)] )\n",
    "#             y_test[str(i)]=(y_data[str(i)] )\n",
    "\n",
    "#         for i in index_info[FoldID][\"train\"]:\n",
    "#             x_train[str(i)]=(  x_data[str(i)] )\n",
    "#             y_train[str(i)]=(  y_data[str(i)] )\n",
    "        \n",
    "#         x_test_t,y_test_t= clean_data( x_test, y_test, IgnoreEmpty , Mapping=Mapper)\n",
    "#         x_test.append(x_test_t)\n",
    "#         y_test.append(y_test_t)\n",
    "    #     else :\n",
    "    print(\"loading from test files\")\n",
    "    files_path =  '../files/train/test/test_homes/final_upload/usecases/pcap_segments_final_final/home*.json' if LOAD_OLD_DATA_TEST else '../files/iot_data_2020/usecases/pcap_segments_final/*.json'\n",
    "    test_y_dir = '../files/train/test/test_homes/final_upload/usecases/hub_segments_final_final/' if LOAD_OLD_DATA_TEST else '../files/iot_data_2020/usecases/hub_segments_final/'\n",
    "    test_x_dir = '../files/train/test/test_homes/final_upload/usecases/pcap_segments_final_final/' if LOAD_OLD_DATA_TEST else '../files/iot_data_2020/usecases/pcap_segments_final/'\n",
    "    \n",
    "    test_files = sorted(glob.glob(files_path))\n",
    "    print( \"found files : \" , len(test_files) )\n",
    "    \n",
    "    \n",
    "    for pick  in test_files:\n",
    "        fname  = os.path.basename(pick)\n",
    "        test_names.append( fname )\n",
    "        print(fname)\n",
    "        with open( os.path.join(test_y_dir , fname) ) as f:\n",
    "            y_data_test = json.load(f)\n",
    "\n",
    "        with open( os.path.join(test_x_dir, fname) ) as f:\n",
    "            x_data_test = json.load(f)\n",
    "\n",
    "\n",
    "        t_x,t_y, t_z= clean_data( x_data_test, y_data_test, False , Mapping=Mapper, include_direction= INCLUDE_DIRECTION )\n",
    "\n",
    "#         if test_files.index(pick) in add_to_trainig:\n",
    "#             x_test_t,y_test_t, y_test_service_t= clean_data( x_data_test, y_data_test, IgnoreEmpty , Mapping=Mapper)\n",
    "#             x_train.extend(x_test_t)\n",
    "#             y_train.extend(y_test_t)\n",
    "#             y_train_service.extend(y_test_service_t)\n",
    "\n",
    "                \n",
    "        if MERGE_TESTS:\n",
    "            x_test.extend(t_x)\n",
    "            y_test.extend(t_y)\n",
    "            y_test_service.extend(t_z)\n",
    "        else:\n",
    "            x_test.append(t_x)\n",
    "            y_test.append(t_y)\n",
    "            y_test_service.append(t_z)\n",
    "if MERGE_TESTS:\n",
    "    x_test = [x_test]\n",
    "    y_test = [y_test]\n",
    "    y_test_service = [y_test_service]\n",
    "    test_names =['MERGED']\n",
    "#     x_test = x_data[ index_info[\"1\"][\"test\"]  ]\n",
    "#     y_test = y_data[ index_info[\"1\"][\"test\"]  ]\n",
    "    \n",
    "#     x_train = x_data[ index_info[\"1\"][\"train\"]  ]\n",
    "#     y_train = y_data[ index_info[\"1\"][\"train\"]  ]\n",
    "#     x.extend(t_x)\n",
    "#     y.extend(t_y)\n",
    "else:\n",
    "    for pick in sorted(glob.glob( '../files/train/hub_segments/*.json' )):\n",
    "        fname  = os.path.basename(pick)\n",
    "        test_names.append( fname )\n",
    "        with open( os.path.join( '../files/train/hub_segments/', fname) ) as f:\n",
    "            y_data = json.load(f)\n",
    "\n",
    "        with open( os.path.join('../files/train/pcap_segments/', fname) ) as f:\n",
    "            x_data = json.load(f)\n",
    "\n",
    "        if len( y_data ) != len(x_data) :\n",
    "            print( pick )\n",
    "            continue\n",
    "\n",
    "        t_x,t_y= clean_data( x_data, y_data, True, include_direction=INCLUDE_DIRECTION )\n",
    "\n",
    "        x.extend( t_x)\n",
    "        y.extend(t_y)\n",
    "\n",
    "x= np.array(x)\n",
    "y= np.array(y)\n",
    "\n",
    "# x_train = np.append( x_train, x_test[0] , axis=0)\n",
    "# x_train = np.append( x_train, x_test[2] , axis=0)\n",
    "\n",
    "# y_train = np.append( y_train, y_test[0] , axis=0)\n",
    "# y_train = np.append( y_train, y_test[2] , axis=0)\n",
    "\n",
    "\n",
    "len(x_train), len(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Mittigation Techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packet Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# days =[7,4,2,2]\n",
    "# t_sum =0\n",
    "# for ii in range(len(x_test)):\n",
    "#     p = x_test[ii]\n",
    "#     sizes = np.unique(np.concatenate(p), return_counts=True)\n",
    "#     sums= 0 \n",
    "#     for i in range(len(sizes[0])):\n",
    "# #         print( \"%d--> %d\" % ( sizes[0][i], sizes[1][i] ) )\n",
    "#         if  sizes[0][i] < 1000:\n",
    "#             sums+= (1000-sizes[0][i] )* sizes[1][i]\n",
    "#     t_sum +=(sums / days[ii] )/1000000 \n",
    "#     print ( (sums / days[ii] )/1000000)\n",
    "# print('--------')\n",
    "# print(t_sum/4)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# days =[7,4,2,2]\n",
    "# t_sum =0\n",
    "# d_sum = 0\n",
    "# import math\n",
    "# for ii in range(len(x_test)):\n",
    "\n",
    "#     p = x_test[ii]\n",
    "#     for i in p : \n",
    "#         t_sum += math.ceil(np.sum(i) / 2000)\n",
    "#         d_sum+= np.sum( i )\n",
    "# total_fixed  =  t_sum* 2000 / 15\n",
    "\n",
    "# print ( total_fixed , d_sum, d_sum-t_sum*2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packet Insertion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# days =[7,4,2,2]\n",
    "# t_sum =0\n",
    "# for ii in range(len(x_test)):\n",
    "#     p = x_test[ii]\n",
    "#     sizes = np.unique(np.concatenate(p), return_counts=True)\n",
    "#     sums= 0 \n",
    "#     for i in range(len(sizes[0])):\n",
    "# #         print( \"%d--> %d\" % ( sizes[0][i], sizes[1][i] ) )\n",
    "#         if  sizes[0][i] < 1000:\n",
    "#             sums+= (1000-sizes[0][i] )* sizes[1][i]\n",
    "#     t_sum +=(sums / days[ii] )/1000000 \n",
    "#     print ( (sums / days[ii] )/1000000)\n",
    "# print('--------')\n",
    "# print(t_sum/4)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sets the classes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 'acceleration'),\n",
       " (1, 'activity'),\n",
       " (2, 'battery'),\n",
       " (3, 'button'),\n",
       " (4, 'colorTemperature'),\n",
       " (5, 'contact'),\n",
       " (6, 'level'),\n",
       " (7, 'lock'),\n",
       " (8, 'motion'),\n",
       " (9, 'no_logs'),\n",
       " (10, 'ping'),\n",
       " (11, 'status'),\n",
       " (12, 'switch'),\n",
       " (13, 'temperature'),\n",
       " (14, 'threeAxis'),\n",
       " (15, 'unknown'),\n",
       " (16, 'water')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = sorted(list(np.unique(  np.concatenate( y_train  ))))\n",
    "# print([ (i , classes[i]) for i in range( len(classes) ) ])\n",
    "\n",
    "service_classes = sorted(list(np.unique(  np.concatenate( y_train_service  ))))\n",
    "[ (i , service_classes[i]) for i in range( len(service_classes) ) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['acceleration-active',\n",
       " 'acceleration-inactive',\n",
       " 'activity-hubDisconnected',\n",
       " 'activity-offline',\n",
       " 'activity-online',\n",
       " 'battery-XXX',\n",
       " 'button-held',\n",
       " 'button-pushed',\n",
       " 'colorTemperature-XXX',\n",
       " 'contact-closed',\n",
       " 'contact-open',\n",
       " 'level-XXX',\n",
       " 'lock-locked',\n",
       " 'lock-unlocked',\n",
       " 'motion-active',\n",
       " 'motion-inactive',\n",
       " 'no_logs-',\n",
       " 'ping-ping',\n",
       " 'status-closed',\n",
       " 'status-open',\n",
       " 'switch-off',\n",
       " 'switch-on',\n",
       " 'temperature-XXX',\n",
       " 'threeAxis-XXX',\n",
       " 'unknown-',\n",
       " 'water-dry',\n",
       " 'water-wet']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter the records by service/event types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_clean_event( inp, return_clean= True  ):\n",
    "    return is_clean(inp, return_clean=return_clean, to_keep=[ 'no_logs', 'lock-unlocked', 'on/off-XXX', 'raw-XXX', 'read_attr_-_raw-XXX' ] )\n",
    "#     if return_clean:\n",
    "#         return  'no_logs' not in inp and 'lock-unlocked' not in inp and 'on/off-XXX' not in inp and 'raw-XXX' not in inp and 'read_attr_-_raw-XXX' not in inp\n",
    "#     else:\n",
    "#         return  'lock-locked' in inp or 'lock-unlocked'  in inp or 'on/off-XXX' in inp or  'raw-XXX' in inp  or 'read_attr_-_raw-XXX' in inp \n",
    "     \n",
    "def is_clean_service( inp, return_clean= True  ):\n",
    "    return is_clean(inp, to_keep=['no_logs','unknown', 'read_attr_-_raw'], return_clean=return_clean )\n",
    "    \n",
    "#     if return_clean:\n",
    "#         return  'no_logs' not in inp and 'unknown' not in inp and 'read_attr_-_raw' not in inp #and 'ping' not in inp \n",
    "#     else:\n",
    "#         return  'no_logs' in inp or  'unknown' in inp  or 'read_attr_-_raw' in inp #or 'ping' in inp \n",
    "\n",
    "def is_clean(inp, to_keep=[], return_clean=True):\n",
    "    ret = False \n",
    "    \n",
    "    for x  in to_keep:\n",
    "        if x in inp:\n",
    "            ret = True\n",
    "            \n",
    "    if not return_clean:\n",
    "        ret = not ret\n",
    "        \n",
    "    return ret\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "choose services to keep : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "if Mapper=='SE':\n",
    "    services_to_keep = [\n",
    "        \"colorTemperature-XXX\",\n",
    "\"contact-closed\",\n",
    "\"contact-open\",\n",
    "\"level-XXX\",\n",
    "\"lock-locked\",\n",
    "\"lock-unlocked\",\n",
    "\"motion-active\",\n",
    "\"motion-inactive\",\n",
    "\"ping-ping\",\n",
    "\"status-closed\",\n",
    "\"status-open\",\n",
    "\"switch-off\",\n",
    "\"switch-on\",\n",
    "\"temperature-XXX\"\n",
    "    ]\n",
    "#     services_to_keep = [x for x in classes if x  not in ['unknown-','no_logs-',\"acceleration-active\", 'acceleration-inactive','activity-hubDisconnected',\n",
    "#  'activity-offline',\n",
    "#  'activity-online',\n",
    "#  'battery-XXX',] ]#[ 'contact', 'lock', 'motion',\"ping\", 'switch','unknown'] \n",
    "else:\n",
    "     services_to_keep =[\"button\",\n",
    "\"colorTemperature\",\n",
    "\"contact\",\n",
    "\"level\",\n",
    "\"lock\",\n",
    "\"motion\",\n",
    "\"ping\",\n",
    "\"status\",\n",
    "\"switch\",\n",
    "\"temperature\"]\n",
    "#     services_to_keep = [x for x in classes if x  not in ['no_logs',\"acceleration\",\"activity\",\"battery\"] ]#[ 'contact', 'lock', 'motion',\"ping\", 'switch','unknown'] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "find records which need change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_indexes_to_change =  [ i for i in range(len(y_train)) if\n",
    "              is_clean( y_train[i],to_keep=services_to_keep, return_clean=False) ] \n",
    "\n",
    "y_train = [ ['unknown'] if i in train_indexes_to_change else y_train[i] \n",
    "           for i in range(len(y_train)) ] \n",
    "\n",
    "for t_index in range(len(y_test)):\n",
    "    test_indexes_to_change =  [ i for i in range(len(y_test[t_index])) if\n",
    "                  is_clean( y_test[t_index][i],to_keep=services_to_keep, return_clean=False) ] \n",
    "\n",
    "    y_test[t_index] = [ ['unknown'] if i in test_indexes_to_change else y_test[t_index][i] \n",
    "               for i in range(len(y_test[t_index])) ] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_known_unknown(inp, unknown_ind):\n",
    "    return [ [1,0] if (x[unknown_ind] == 1 ) else [0,1]   for x in inp ]\n",
    "\n",
    "known_unknown_y_train = [ [1,0] if (len(x) == 1 and (\"unknown\" in x or 'unknown-' in x)) else [0,1]   for x in y_train ]\n",
    "\n",
    "known_unknown_y_test= [] \n",
    "\n",
    "for i in range(len(y_test)):\n",
    "    \n",
    "    known_unknown_y_test.append( [ [1,0] if (len(x) == 1 and \"unknown\" in x) else [0,1]   for x in y_test[i] ])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "remove classes that are ignored from the services list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24173, 24173, 24173, 33318, 33318)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train),len(y_train),len(known_unknown_y_train), len(y_test[0]), len(known_unknown_y_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['colorTemperature-XXX',\n",
       " 'contact-closed',\n",
       " 'contact-open',\n",
       " 'level-XXX',\n",
       " 'lock-locked',\n",
       " 'lock-unlocked',\n",
       " 'motion-active',\n",
       " 'motion-inactive',\n",
       " 'ping-ping',\n",
       " 'status-closed',\n",
       " 'status-open',\n",
       " 'switch-off',\n",
       " 'switch-on',\n",
       " 'temperature-XXX',\n",
       " 'unknown']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = services_to_keep\n",
    "classes.append('unknown')\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# toKeep = [ i for i in range(len(y_train)) if is_clean_event( y_train[i]) ] if Mapper=='SE' else [ i for i in range(len(y_train)) if is_clean_service( y_train[i]) ]\n",
    "# x_train= [ x_train[i] for i in toKeep ]\n",
    "# y_train= [ y_train[i] for i in toKeep ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for j in range(len(x_test)):\n",
    "#     toChange= [ i for i in range(len(y_test[j])) if is_clean_service( y_test[j][i], False) ]\n",
    "#     y_test[j] = [ (y_test[j][i] if i not in toChange else np.array( ['none'])) for i in range(len(y_test[j])) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classes.remove('read_attr_-_raw-XXX')\n",
    "# classes.remove('on/off-XXX')\n",
    "# classes.remove('raw-XXX')\n",
    "# classes.remove('lock-unlocked')\n",
    "# classes.remove('lock-locked')\n",
    "\n",
    "\n",
    "# classes.remove('read_attr_-_raw')\n",
    "# classes.remove('on/off')\n",
    "# classes.remove('raw')\n",
    "# classes.remove('unknown')\n",
    "\n",
    "# classes.remove('lock')\n",
    "# # classes.remove('lock')\n",
    "\n",
    "\n",
    "# classes.remove('switch-on')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ===== end of unknown packet control====="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process_raw( x_data,y_data, dim_size = 128, zero_pad = False, normalize = False ,\n",
    "                    classes=None, twoD= False, as_string=False, class_cap = 9999999, cheat=True ):\n",
    "#  y data \n",
    "# \"\"\"\n",
    "# this functino is in charge of preprocessing the records , the sourc e json contains a lot of extra stuff, this function tailors\n",
    "# the data and it fixes their lenghth\n",
    "# \"\"\"\n",
    "    if classes is None:\n",
    "        classes  = sorted(list(np.unique( np.concatenate( y_data  ))))\n",
    "    else :\n",
    "        classes = sorted(classes)\n",
    "    y_data_categorical = []  \n",
    "\n",
    "    to_keep_indexes = []\n",
    "    class_counts= {x:0 for x in classes}\n",
    "    for pick in ['ping','ping-ping','unknown']:\n",
    "        if pick in class_counts:\n",
    "            class_counts[pick] = -9999999\n",
    "\n",
    "    for i,x in enumerate(y_data):\n",
    "        temp = np.zeros(len(classes))\n",
    "        x= list(set(x))\n",
    "        for y in x: \n",
    "            \n",
    "            if cheat and (y=='unknown' or y=='unknown-') and len(x)>1:\n",
    "                    continue\n",
    "                    \n",
    "            if y in classes:\n",
    "                if class_counts[y] < class_cap:\n",
    "                    temp[classes.index(y)] = 1\n",
    "                    class_counts[y] += 1\n",
    "                    \n",
    "        if np.sum(temp) > 0 :    \n",
    "            y_data_categorical.append(temp)\n",
    "            to_keep_indexes.append(i)\n",
    "    y_data_categorical = np.vstack(y_data_categorical)\n",
    "    \n",
    "#     x_data = np.array( x_data) / 1500.0\n",
    "    \n",
    "    x_data_temp = [] \n",
    "    \n",
    "    if not zero_pad:\n",
    "        if twoD:\n",
    "            for i,x in enumerate( x_data):\n",
    "                if i not in to_keep_indexes:\n",
    "                    continue\n",
    "                    \n",
    "                temp = [] #list(x)\n",
    "                lst = list(x)\n",
    "                while dim_size**2 - len(temp )   > len(lst):\n",
    "                    temp.extend(lst)\n",
    "\n",
    "                while len(temp) < dim_size**2:\n",
    "                    temp.append( 0 )\n",
    "\n",
    "                x_data_temp.append(np.array(temp).reshape(dim_size,dim_size))\n",
    "\n",
    "\n",
    "            x_data_temp = np.array( x_data_temp )\n",
    "            x_data_temp=x_data_temp.reshape(x_data_temp.shape+(1,))\n",
    "        else: \n",
    "            temp = [] \n",
    "            lst = list(x)\n",
    "            for i,x in enumerate( x_data):\n",
    "                if i not in to_keep_indexes:\n",
    "                    continue\n",
    "                temp = [] #list(x)\n",
    "                lst = list(x)\n",
    "                while dim_size - len(temp )   > len(lst):\n",
    "                    temp.extend(lst)\n",
    "\n",
    "                while len(temp) < dim_size:\n",
    "                    temp.append( 0 )\n",
    "                \n",
    "                x_data_temp.append(np.array( temp))\n",
    "            \n",
    "    else :\n",
    "        x_data_temp = sequence.pad_sequences(x_data, maxlen=dim_size)\n",
    "    \n",
    "    \n",
    "    \n",
    "    if normalize:\n",
    "        x_data_temp = np.array( x_data_temp) / (np.amax( x_data_temp) + 0.000000000001)\n",
    "    else :\n",
    "        x_data_temp = np.array(x_data_temp)\n",
    "    \n",
    "    \n",
    "    if as_string:\n",
    "        x_data_temp = [ ' '.join(list(map(str,x))) for x in x_data_temp ]\n",
    "    \n",
    "    return x_data_temp ,y_data_categorical , classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y,_=pre_process_raw( x_train, y_train , 15, zero_pad=True, normalize=True, classes=classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in y_train:\n",
    "    if len(x) ==0 :\n",
    "        print(\"*\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_recall_shit( inp ):\n",
    "    tp = inp[1][1]\n",
    "    tn = inp[0][0]\n",
    "    fp = inp[0][1] \n",
    "    fn = inp[1][0]\n",
    "    \n",
    "    acc = (tp+tn)*1.0 / ( tp+tn+fp+fn)*1.0\n",
    "    recall = tp*1.0/ ( tp+fn ) *1.0\n",
    "    prec = tp*1.0 / ( tp+fp )*1.0\n",
    "    \n",
    "#     F= 2.0*( prec* recall )/ (prec+recall)\n",
    "    F= 2.0*( tp)/ (2*tp + fp + fn)\n",
    "    \n",
    "    return acc, recall, prec, F\n",
    "\n",
    "def acc_match( true, pred ):\n",
    "    \"\"\"\n",
    "    returns exact mathc accuracy\n",
    "    \"\"\"\n",
    " \n",
    "    return (len( [ x  for x  in  [np.sum(np.abs( true[i]- pred[i] )) for i in range(len(true))] if x  == 0]))*1.0 / len(true)\n",
    "\n",
    "\n",
    "# def acc_none_zero ( true, pred ):\n",
    "    \n",
    "\n",
    "def acc_match_wierd( true, pred ):\n",
    "    \"\"\"\n",
    "    returns exact mathc accuracy\n",
    "    \"\"\"\n",
    "    level = 6 \n",
    "    switch = 11\n",
    "    threeAxis=13\n",
    "    accel = 0 \n",
    "    status=10\n",
    "    contact=5\n",
    "    \n",
    "    counter  = 0 \n",
    "    for i in range( len (true) ):\n",
    "        if np.sum(np.abs( true[i]- pred[i] ))==0 :\n",
    "            counter+=1\n",
    "        else : \n",
    "            t_rec = np.array(list( pred[i]))\n",
    "            \n",
    "            if true[i][level]==1 and true[i][switch]==1 and t_rec[level]==1 :\n",
    "                t_rec[switch]=1\n",
    "            \n",
    "            if true[i][threeAxis]==1 and true[i][accel]==1 and t_rec[threeAxis]==1:\n",
    "                t_rec[accel] =1\n",
    "            \n",
    "            if true[i][status]==1 and true[i][contact]==1 and t_rec[status]==1:\n",
    "                t_rec[contact]=1\n",
    "#             print(t_rec , true[i])    \n",
    "            if np.sum(np.abs( true[i]- t_rec ))==0 :\n",
    "                counter+=1   \n",
    "            \n",
    "             \n",
    "            \n",
    "    \n",
    "    return counter*1.0 / len(true)\n",
    "\n",
    "\n",
    "def print_info(y_test, pred , classes , confidance=0.5, print_skf1=False):\n",
    "    \n",
    "    counts = np.sum( y_test.astype(int) , axis=0)\n",
    "    \n",
    "    pred[pred>=confidance] = 1\n",
    "    pred[pred<confidance] = 0\n",
    "    \n",
    "#     acc_wierd  =acc_match_wierd(y_test, pred)\n",
    "    \n",
    "    conf= multilabel_confusion_matrix( y_test , pred.astype(int), labels= range(len(classes)))\n",
    "    accs = [make_recall_shit(x) for x in conf]\n",
    "    print( \"%30s  %8s   %8s  %8s  %8s %8s %22s\"  %( \"Class\",\"Accuracy\", \"Recall\",\"Precision\",\"F Score\" , \"Count\", \"TP/TN/FP/FN\"))\n",
    "    print( \"------------------------------------------------------------------------\" )\n",
    "    ret  = [] \n",
    "    ret_description = [\"Class\",\"Accuracy\", \"Recall\",\"Precision\",\"F Score\" , \"Count\", \"TP\",\"TN\",\"FP\",\"FN\"]\n",
    "    for index in range(len(classes)):\n",
    "        tp = conf[index][1][1]\n",
    "        tn = conf[index][0][0]\n",
    "        fp = conf[index][0][1] \n",
    "        fn = conf[index][1][0]\n",
    "        item = (classes[index],\n",
    "              accs[index][0],\n",
    "              accs[index][1],\n",
    "              accs[index][2],\n",
    "              accs[index][3],\n",
    "              counts[index],\n",
    "                  tp ,\n",
    "                tn ,\n",
    "                fp ,\n",
    "                fn)\n",
    "        print( \"%30s  %8.3f   %8.3f  %8.3f  %8.3f  %8d %5d/%5d/%5d/%5d\"  %  item )\n",
    "        ret.append(item)\n",
    "        \n",
    "    n_zeros_true = len([ x  for x  in  [np.sum(np.abs( y_test[i] )) for i in range(len(y_test))] if x  == 0]  )\n",
    "    n_zeros_pred = len([ x  for x  in  [np.sum(np.abs( pred[i] )) for i in range(len(pred))] if x  == 0]  )\n",
    "    \n",
    "    accs = np.nan_to_num(accs)\n",
    "    \n",
    "    print (\"------------------------------------------------------------------------\")\n",
    "    print( \"%30s  %8.3f   %8.3f  %8.3f  %8.3f  %8d %5d/%5d/%5d/%5d\"  %\n",
    "             (\"AVERAGES\",\n",
    "              np.average( accs, axis=0)[0],\n",
    "              np.average( accs, axis=0)[1],\n",
    "              np.average( accs, axis=0)[2],\n",
    "              np.average( accs, axis=0)[3],\n",
    "              len(y_test),\n",
    "                  0 ,\n",
    "                0,\n",
    "                0 ,\n",
    "                0 ))\n",
    "    print (\"------------------------------------------------------------------------\")\n",
    "    print( \"%30s  %8.3f   %8.3f  %8.3f  %8.3f  %8d %5d/%5d/%5d/%5d\"  %\n",
    "             (\"Weighted AVERAGES\",\n",
    "              np.average( accs, weights=counts, axis=0)[0],\n",
    "              np.average( accs, weights=counts, axis=0)[1],\n",
    "              np.average( accs, weights=counts, axis=0)[2],\n",
    "              np.average( accs, weights=counts, axis=0)[3],\n",
    "              len(y_test),\n",
    "                  0 ,\n",
    "                0,\n",
    "                0 ,\n",
    "                0 ))\n",
    "    \n",
    "    print (\"------------------------------------------------------------------------\")\n",
    "    unknonw_index = [classes.index('unknown')]\n",
    "#     print(unknonw_index, len(accs))\n",
    "    accs_new = np.delete(accs,unknonw_index,0)\n",
    "    counts_new = [x for i,x in enumerate(counts) if i not in unknonw_index]\n",
    "#     print(unknonw_index, len(counts), len(counts_new),len(accs), len(accs_new))\n",
    "#     print(unknonw_index, len(accs))\n",
    "    print( \"%30s  %8.3f   %8.3f  %8.3f  %8.3f  %8d %5d/%5d/%5d/%5d\"  %\n",
    "             (\"known Weighted AVERAGES\",\n",
    "              np.average( accs_new, weights=counts_new, axis=0)[0],\n",
    "              np.average( accs_new, weights=counts_new, axis=0)[1],\n",
    "              np.average( accs_new, weights=counts_new, axis=0)[2],\n",
    "              np.average( accs_new, weights=counts_new, axis=0)[3],\n",
    "              len(y_test),\n",
    "                  0 ,\n",
    "                0,\n",
    "                0 ,\n",
    "                0 ))\n",
    "    \n",
    "    print (\"------------------------------------------------------------------------\")\n",
    "    if 'ping' in classes:\n",
    "        unknonw_index = [classes.index('unknown'), classes.index('ping')]\n",
    "    #     print(unknonw_index, len(accs))\n",
    "        accs_new = np.delete(accs,unknonw_index,0)\n",
    "        counts_new = [x for i,x in enumerate(counts) if i not in unknonw_index]\n",
    "    #     print(unknonw_index, len(counts), len(counts_new),len(accs), len(accs_new))\n",
    "    #     print(unknonw_index, len(accs))\n",
    "        print( \"%30s  %8.3f   %8.3f  %8.3f  %8.3f  %8d %5d/%5d/%5d/%5d\"  %\n",
    "                 (\"known -ping Weighted AVERAGES\",\n",
    "                  np.average( accs_new, weights=counts_new, axis=0)[0],\n",
    "                  np.average( accs_new, weights=counts_new, axis=0)[1],\n",
    "                  np.average( accs_new, weights=counts_new, axis=0)[2],\n",
    "                  np.average( accs_new, weights=counts_new, axis=0)[3],\n",
    "                  len(y_test),\n",
    "                      0 ,\n",
    "                    0,\n",
    "                    0 ,\n",
    "                    0 ))\n",
    "\n",
    "    print (\"------------------------------------------------------------------------\")\n",
    "    unknonw_index = classes.index('unknown')\n",
    "#     print(unknonw_index, len(accs))\n",
    "    to_delete = [i for i,x in enumerate(counts) if x == 0 ]\n",
    "    accs_new = np.delete(accs,to_delete,0)\n",
    "    counts_new = [x for i,x in enumerate(counts) if i not in  to_delete]\n",
    "#     print(unknonw_index, len(counts), len(counts_new),len(accs), len(accs_new))\n",
    "#     print(unknonw_index, len(accs))\n",
    "    print( \"%30s  %8.3f   %8.3f  %8.3f  %8.3f  %8d %5d/%5d/%5d/%5d\"  %\n",
    "             (\"non zero count AVERAGES\",\n",
    "              np.average( accs_new, axis=0)[0],\n",
    "              np.average( accs_new, axis=0)[1],\n",
    "              np.average( accs_new, axis=0)[2],\n",
    "              np.average( accs_new, axis=0)[3],\n",
    "              len(y_test),\n",
    "                  0 ,\n",
    "                0,\n",
    "                0 ,\n",
    "                0 ))\n",
    "    \n",
    "    print (\"------------------------------------------------------------------------\")\n",
    "    from sklearn.metrics import f1_score\n",
    "    f1 = f1_score(y_test, pred, average='macro')\n",
    "    print(\"Macro F1 : %f\" % f1)\n",
    "    f1 = f1_score(y_test, pred, average='samples')\n",
    "    print(\"sample F1 : %f\" % f1)\n",
    "    f1 = f1_score(y_test, pred, average='weighted')\n",
    "    print(\"weighted F1 : %f\" % f1)\n",
    "\n",
    "    \n",
    "    if 'ping' in classes and print_skf1:\n",
    "        unknonw_index = classes.index('unknown')\n",
    "        ping_index = classes.index('ping')\n",
    "        print (\"--------------------------removed ping and unknown----------------------------------------------\")\n",
    "        to_remove_indexes = [i for i,x in enumerate(pred) if x[ping_index]+x[unknonw_index] > 0.5]\n",
    "        new_pred   =np.array( [x for i,x  in enumerate(pred) if i not in to_remove_indexes ])\n",
    "        new_y_test = np.array([x for i,x  in enumerate(y_test) if i not in to_remove_indexes ])\n",
    "        f1 = f1_score(new_y_test, new_pred, average='macro')\n",
    "        print(\"Macro F1 : %f\" % f1)\n",
    "        f1 = f1_score(new_y_test, new_pred, average='samples')\n",
    "        print(\"sample F1 : %f\" % f1)\n",
    "        f1 = f1_score(new_y_test, new_pred, average='weighted')\n",
    "        print(\"weighted F1 : %f\" % f1)\n",
    "\n",
    "    \n",
    "    \n",
    "    print ( \"Exact Match ACC : %.5f \" % acc_match( y_test, pred )  )\n",
    "#     print ( \"Wierd Exact Match ACC : %.5f\" % acc_wierd)\n",
    "    print ( \"Total Records : %d \" % len(y_test)  )\n",
    "    print ( \"Total ZXeros in True : %d (%.3f)%%\" % (n_zeros_true ,  n_zeros_true * 1.0/ len(y_test)  ))\n",
    "    print ( \"Total ZXeros in Test : %d (%.3f)%%\" % (n_zeros_pred ,  n_zeros_pred * 1.0/ len(y_test)  ) )\n",
    "    print ('=============================================================================')\n",
    "    \n",
    "    return ret, ret_description\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_readable_results ( inp , classes , conffidance=True):\n",
    "    ret = [] \n",
    "    inp =inp.astype(int)\n",
    "    for xx in range(len(inp)) :\n",
    "        u = inp[xx]\n",
    "        temp = []\n",
    "        for j in range(len(u)) : \n",
    "            if u[j] >0:\n",
    "                temp.append(classes[j])\n",
    "        ret.append(temp)\n",
    "    return ret\n",
    "\n",
    "\n",
    "def makeReadable( model , data, gt, path , classes, x, confidance=0.5):\n",
    "    #collect across multi models\n",
    "    from keras.models import load_model\n",
    "    x=[]\n",
    "    for i in range(0,16):\n",
    "        model=load_model('number'+str(i)+'.h5',custom_objects={'f1_perRow':f1_perRow,'f1_perClass':f1_perClass,'f1_loss_perRow':f1_loss_perRow,'f1_loss_perClass':f1_loss_perClass})\n",
    "        x.append(model.predict(data))\n",
    "    x=np.array(x)\n",
    "    x=np.transpose(x)\n",
    "    x=np.squeeze(x)\n",
    "    print(x.shape)\n",
    "        \n",
    "        \n",
    "    pred_temp  = x\n",
    "    #pred_temp = model.predict(data)\n",
    "    print_info(gt, x, classes , confidance=confidance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_unknowns_back(y_pred, original_y, indexes, classes):\n",
    "    unknown = [1 if classes[i] == 'unknown' else\n",
    "                        0  \n",
    "                       for i in range(len(classes))]\n",
    "    the_y = [unknown for i in range(len(original_y))]\n",
    "    for i, v in enumerate(indexes):\n",
    "#         print(v)\n",
    "        the_y[v] = y_pred[i]\n",
    "    return np.array(the_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get the data and preprocess train and test portions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_size= 20\n",
    "x_random_forest_train,y_random_forest_train, _ = pre_process_raw( x_train, y_train , dim_size, zero_pad=False, normalize=False, classes=classes, as_string=True)\n",
    "rf_tests  = [ pre_process_raw( x_test[i], y_test[i] , dim_size, zero_pad=False, normalize=False, classes=classes, as_string=True, class_cap=TEST_CLASS_CAP) for i in range(len(x_test)) ] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24173, 24173, 24173)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train),len(x_random_forest_train), len(y_random_forest_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "vectorize the X vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(analyzer='word', ngram_range=(1, 5))\n",
    "x_random_forest_train = vectorizer.fit_transform(x_random_forest_train)\n",
    "for x in range(len(rf_tests)):\n",
    "    rf_tests[x] = ( vectorizer.transform(rf_tests[x][0]),\n",
    "                    rf_tests[x][1],\n",
    "                    rf_tests[x][2]\n",
    "                  )\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24173, 24173)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(known_unknown_y_train), len(x_random_forest_train.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "xgb_known_unknown_separator_classifier = OneVsRestClassifier(XGBClassifier())\n",
    "\n",
    "xgb_known_unknown_separator_classifier.fit(x_random_forest_train, np.array(known_unknown_y_train))\n",
    "\n",
    "train_known_unknown_pred=xgb_known_unknown_separator_classifier.predict_proba(x_random_forest_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31504, 31504, 33318)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rf_tests[0][1]),len(rf_tests[0][0].toarray()), len(known_unknown_y_test[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================HOME Case : MERGED =============\n",
      "                         Class  Accuracy     Recall  Precision   F Score    Count            TP/TN/FP/FN\n",
      "------------------------------------------------------------------------\n",
      "                       unknown     0.779      0.675     0.979     0.799     20483 13822/10722/  299/ 6661\n",
      "                         known     0.779      0.973     0.617     0.755     11021 10722/13822/ 6661/  299\n",
      "------------------------------------------------------------------------\n",
      "                      AVERAGES     0.779      0.824     0.798     0.777     31504     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "             Weighted AVERAGES     0.779      0.779     0.852     0.784     31504     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "       known Weighted AVERAGES     0.779      0.973     0.617     0.755     31504     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------\n",
      "       non zero count AVERAGES     0.779      0.824     0.798     0.777     31504     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "Macro F1 : 0.776916\n",
      "sample F1 : 0.779076\n",
      "weighted F1 : 0.783509\n",
      "Exact Match ACC : 0.77908 \n",
      "Total Records : 31504 \n",
      "Total ZXeros in True : 0 (0.000)%\n",
      "Total ZXeros in Test : 0 (0.000)%\n",
      "=============================================================================\n"
     ]
    }
   ],
   "source": [
    "test_known_unknown_predicted = []\n",
    "for i in range(len(rf_tests)) :\n",
    "    print( \"==================HOME Case : %s =============\" % test_names[ i] )\n",
    "    rf_pred=xgb_known_unknown_separator_classifier.predict( rf_tests[i][0])\n",
    "    test_known_unknown_predicted.append(rf_pred)\n",
    "    print_info( np.array( make_known_unknown(rf_tests[i][1], classes.index('unknown'))), rf_pred, [\"unknown\",\"known\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "known_indexes_train  = [ i for i in range(len(train_known_unknown_pred)) if train_known_unknown_pred[i][1] ==1 ]\n",
    "\n",
    "x_train_known = x_random_forest_train[known_indexes_train]\n",
    "y_train_known = y_random_forest_train[known_indexes_train]\n",
    "\n",
    "rf_test_known = [] \n",
    "\n",
    "for test_index in range(len(test_known_unknown_predicted)):\n",
    "    known_indexes= [ i for i in range(len(test_known_unknown_predicted[test_index])) if test_known_unknown_predicted[test_index][i][1] ==1 ]\n",
    "    \n",
    "    rf_test_known.append(  (rf_tests[test_index][0][known_indexes], \n",
    "                            rf_tests[test_index][1][known_indexes],\n",
    "                            rf_tests[test_index][2],\n",
    "                            known_indexes\n",
    "                           ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneVsRestClassifier(estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                            colsample_bylevel=None,\n",
       "                                            colsample_bynode=None,\n",
       "                                            colsample_bytree=None, gamma=None,\n",
       "                                            gpu_id=None, importance_type='gain',\n",
       "                                            interaction_constraints=None,\n",
       "                                            learning_rate=None,\n",
       "                                            max_delta_step=None, max_depth=None,\n",
       "                                            min_child_weight=None, missing=nan,\n",
       "                                            monotone_constraints=None,\n",
       "                                            n_estimators=100, n_jobs=None,\n",
       "                                            num_parallel_tree=None,\n",
       "                                            objective='binary:logistic',\n",
       "                                            random_state=None, reg_alpha=None,\n",
       "                                            reg_lambda=None,\n",
       "                                            scale_pos_weight=None,\n",
       "                                            subsample=None, tree_method=None,\n",
       "                                            validate_parameters=False,\n",
       "                                            verbosity=None),\n",
       "                    n_jobs=None)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_classifier = OneVsRestClassifier(XGBClassifier())\n",
    "\n",
    "xgb_classifier.fit(x_random_forest_train, np.array(y_random_forest_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================HOME Case : MERGED =============\n",
      "                         Class  Accuracy     Recall  Precision   F Score    Count            TP/TN/FP/FN\n",
      "------------------------------------------------------------------------\n",
      "          colorTemperature-XXX     1.000      0.800     0.889     0.842        40    32/31460/    4/    8\n",
      "                contact-closed     0.994      0.367     0.407     0.386       150    55/31274/   80/   95\n",
      "                  contact-open     0.995      0.600     0.474     0.529       150    90/31254/  100/   60\n",
      "                     level-XXX     0.989      0.727     0.261     0.384       150   109/31045/  309/   41\n",
      "                   lock-locked     0.997      0.148     0.387     0.214        81    12/31404/   19/   69\n",
      "                 lock-unlocked     0.997      0.024     0.333     0.045        82     2/31418/    4/   80\n",
      "                 motion-active     0.993      0.100     0.129     0.113       150    15/31253/  101/  135\n",
      "               motion-inactive     0.984      0.360     0.121     0.181       150    54/30961/  393/   96\n",
      "                     ping-ping     0.984      0.951     0.997     0.974      9948  9462/21529/   27/  486\n",
      "                 status-closed     0.997      0.487     0.709     0.577       115    56/31366/   23/   59\n",
      "                   status-open     0.998      0.731     0.674     0.702       119    87/31343/   42/   32\n",
      "                    switch-off     0.999      0.516     0.842     0.640        31    16/31470/    3/   15\n",
      "                     switch-on     0.999      0.290     0.750     0.419        31     9/31470/    3/   22\n",
      "               temperature-XXX     0.840      0.747     0.022     0.042       150   112/26337/ 5017/   38\n",
      "                       unknown     0.779      0.675     0.979     0.799     20483 13822/10722/  299/ 6661\n",
      "------------------------------------------------------------------------\n",
      "                      AVERAGES     0.970      0.502     0.532     0.456     31504     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "             Weighted AVERAGES     0.852      0.752     0.958     0.834     31504     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "       known Weighted AVERAGES     0.983      0.891     0.920     0.896     31504     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------\n",
      "       non zero count AVERAGES     0.970      0.502     0.532     0.456     31504     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "Macro F1 : 0.456477\n",
      "sample F1 : 0.753820\n",
      "weighted F1 : 0.833534\n",
      "Exact Match ACC : 0.75140 \n",
      "Total Records : 31504 \n",
      "Total ZXeros in True : 0 (0.000)%\n",
      "Total ZXeros in Test : 1443 (0.046)%\n",
      "=============================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/omid/.conda/envs/iot/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "xg_boost_results = []\n",
    "for i in range(len(rf_test_known)) :\n",
    "    print( \"==================HOME Case : %s =============\" % test_names[ i] )\n",
    "    rf_pred= xgb_classifier.predict( rf_test_known[i][0])\n",
    "    rf_pred = add_unknowns_back(rf_pred,rf_tests[i][1], rf_test_known[i][3] , classes)\n",
    "    xg_boost_results.append(print_info( rf_tests[i][1], rf_pred, classes, confidance=0.8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================HOME Case : MERGED =============\n",
      "                         Class  Accuracy     Recall  Precision   F Score    Count            TP/TN/FP/FN\n",
      "------------------------------------------------------------------------\n",
      "                       unknown     0.779      0.675     0.979     0.799     20483 13822/10722/  299/ 6661\n",
      "                         known     0.779      0.973     0.617     0.755     11021 10722/13822/ 6661/  299\n",
      "------------------------------------------------------------------------\n",
      "                      AVERAGES     0.779      0.824     0.798     0.777     31504     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "             Weighted AVERAGES     0.779      0.779     0.852     0.784     31504     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "       known Weighted AVERAGES     0.779      0.973     0.617     0.755     31504     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------\n",
      "       non zero count AVERAGES     0.779      0.824     0.798     0.777     31504     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "Macro F1 : 0.776916\n",
      "sample F1 : 0.779076\n",
      "weighted F1 : 0.783509\n",
      "Exact Match ACC : 0.77908 \n",
      "Total Records : 31504 \n",
      "Total ZXeros in True : 0 (0.000)%\n",
      "Total ZXeros in Test : 0 (0.000)%\n",
      "=============================================================================\n"
     ]
    }
   ],
   "source": [
    "test_known_unknown_predicted = []\n",
    "for i in range(len(rf_tests)) :\n",
    "    print( \"==================HOME Case : %s =============\" % test_names[ i] )\n",
    "    rf_pred=xgb_known_unknown_separator_classifier.predict( rf_tests[i][0])\n",
    "    test_known_unknown_predicted.append(rf_pred)\n",
    "    print_info( np.array( make_known_unknown(rf_tests[i][1], classes.index('unknown'))), rf_pred, [\"unknown\",\"known\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "separate known and unknowns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "known_indexes_train  = [ i for i in range(len(train_known_unknown_pred)) if train_known_unknown_pred[i][1] ==1 ]\n",
    "\n",
    "x_train_known = x_random_forest_train[known_indexes_train]\n",
    "y_train_known = y_random_forest_train[known_indexes_train]\n",
    "\n",
    "rf_test_known = [] \n",
    "\n",
    "for test_index in range(len(test_known_unknown_predicted)):\n",
    "    known_indexes= [ i for i in range(len(test_known_unknown_predicted[test_index])) if test_known_unknown_predicted[test_index][i][1] ==1 ]\n",
    "    \n",
    "    rf_test_known.append(  (rf_tests[test_index][0][known_indexes], \n",
    "                            rf_tests[test_index][1][known_indexes],\n",
    "                            rf_tests[test_index][2],\n",
    "                            known_indexes\n",
    "                           ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneVsRestClassifier(estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                            colsample_bylevel=None,\n",
       "                                            colsample_bynode=None,\n",
       "                                            colsample_bytree=None, gamma=None,\n",
       "                                            gpu_id=None, importance_type='gain',\n",
       "                                            interaction_constraints=None,\n",
       "                                            learning_rate=None,\n",
       "                                            max_delta_step=None, max_depth=None,\n",
       "                                            min_child_weight=None, missing=nan,\n",
       "                                            monotone_constraints=None,\n",
       "                                            n_estimators=100, n_jobs=None,\n",
       "                                            num_parallel_tree=None,\n",
       "                                            objective='binary:logistic',\n",
       "                                            random_state=None, reg_alpha=None,\n",
       "                                            reg_lambda=None,\n",
       "                                            scale_pos_weight=None,\n",
       "                                            subsample=None, tree_method=None,\n",
       "                                            validate_parameters=False,\n",
       "                                            verbosity=None),\n",
       "                    n_jobs=None)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_classifier = OneVsRestClassifier(XGBClassifier())\n",
    "\n",
    "xgb_classifier.fit(x_random_forest_train, np.array(y_random_forest_train))\n",
    "\n",
    "# train_known_unknown_pred=xgb_classifier.predict_proba(x_random_forest_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with putting back teh unknowns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================HOME Case : MERGED =============\n",
      "                         Class  Accuracy     Recall  Precision   F Score    Count            TP/TN/FP/FN\n",
      "------------------------------------------------------------------------\n",
      "          colorTemperature-XXX     1.000      0.800     0.889     0.842        40    32/31460/    4/    8\n",
      "                contact-closed     0.994      0.367     0.407     0.386       150    55/31274/   80/   95\n",
      "                  contact-open     0.995      0.600     0.474     0.529       150    90/31254/  100/   60\n",
      "                     level-XXX     0.989      0.727     0.261     0.384       150   109/31045/  309/   41\n",
      "                   lock-locked     0.997      0.148     0.387     0.214        81    12/31404/   19/   69\n",
      "                 lock-unlocked     0.997      0.024     0.333     0.045        82     2/31418/    4/   80\n",
      "                 motion-active     0.993      0.100     0.129     0.113       150    15/31253/  101/  135\n",
      "               motion-inactive     0.984      0.360     0.121     0.181       150    54/30961/  393/   96\n",
      "                     ping-ping     0.984      0.951     0.997     0.974      9948  9462/21529/   27/  486\n",
      "                 status-closed     0.997      0.487     0.709     0.577       115    56/31366/   23/   59\n",
      "                   status-open     0.998      0.731     0.674     0.702       119    87/31343/   42/   32\n",
      "                    switch-off     0.999      0.516     0.842     0.640        31    16/31470/    3/   15\n",
      "                     switch-on     0.999      0.290     0.750     0.419        31     9/31470/    3/   22\n",
      "               temperature-XXX     0.840      0.747     0.022     0.042       150   112/26337/ 5017/   38\n",
      "                       unknown     0.779      0.675     0.979     0.799     20483 13822/10722/  299/ 6661\n",
      "------------------------------------------------------------------------\n",
      "                      AVERAGES     0.970      0.502     0.532     0.456     31504     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "             Weighted AVERAGES     0.852      0.752     0.958     0.834     31504     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "       known Weighted AVERAGES     0.983      0.891     0.920     0.896     31504     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------\n",
      "       non zero count AVERAGES     0.970      0.502     0.532     0.456     31504     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "Macro F1 : 0.456477\n",
      "sample F1 : 0.753820\n",
      "weighted F1 : 0.833534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/omid/.conda/envs/iot/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exact Match ACC : 0.75140 \n",
      "Total Records : 31504 \n",
      "Total ZXeros in True : 0 (0.000)%\n",
      "Total ZXeros in Test : 1443 (0.046)%\n",
      "=============================================================================\n"
     ]
    }
   ],
   "source": [
    "xg_boost_results = []\n",
    "for i in range(len(rf_test_known)) :\n",
    "    print( \"==================HOME Case : %s =============\" % test_names[ i] )\n",
    "    rf_pred= xgb_classifier.predict( rf_test_known[i][0])\n",
    "    rf_pred = add_unknowns_back(rf_pred,rf_tests[i][1], rf_test_known[i][3] , classes)\n",
    "    xg_boost_results.append(print_info( rf_tests[i][1], rf_pred, classes, confidance=0.8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with out putting back the unknowns : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================HOME Case : MERGED =============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/omid/.conda/envs/iot/lib/python3.6/site-packages/ipykernel_launcher.py:9: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         Class  Accuracy     Recall  Precision   F Score    Count            TP/TN/FP/FN\n",
      "------------------------------------------------------------------------\n",
      "          colorTemperature-XXX     0.999      0.800     0.889     0.842        40    32/17339/    4/    8\n",
      "                contact-closed     0.991      0.423     0.407     0.415       130    55/17173/   80/   75\n",
      "                  contact-open     0.992      0.662     0.474     0.552       136    90/17147/  100/   46\n",
      "                     level-XXX     0.981      0.820     0.261     0.396       133   109/16941/  309/   24\n",
      "                   lock-locked     0.998      0.600     0.387     0.471        20    12/17344/   19/    8\n",
      "                 lock-unlocked     0.999      0.118     0.333     0.174        17     2/17362/    4/   15\n",
      "                 motion-active     0.991      0.208     0.129     0.160        72    15/17210/  101/   57\n",
      "               motion-inactive     0.973      0.425     0.121     0.188       127    54/16863/  393/   73\n",
      "                     ping-ping     0.971      0.951     0.997     0.974      9946  9462/ 7410/   27/  484\n",
      "                 status-closed     0.996      0.533     0.709     0.609       105    56/17255/   23/   49\n",
      "                   status-open     0.996      0.777     0.674     0.722       112    87/17229/   42/   25\n",
      "                    switch-off     0.999      0.552     0.842     0.667        29    16/17351/    3/   13\n",
      "                     switch-on     0.999      0.290     0.750     0.419        31     9/17349/    3/   22\n",
      "               temperature-XXX     0.710      0.875     0.022     0.043       128   112/12238/ 5017/   16\n",
      "                       unknown     0.617      0.000       nan     0.000      6661     0/10722/    0/ 6661\n",
      "------------------------------------------------------------------------\n",
      "                      AVERAGES     0.947      0.536     0.466     0.442     17383     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "             Weighted AVERAGES     0.837      0.572     0.585     0.573     17383     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "       known Weighted AVERAGES     0.969      0.917     0.938     0.919     17383     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------\n",
      "       non zero count AVERAGES     0.947      0.536     0.466     0.442     17383     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "Macro F1 : 0.441966\n",
      "sample F1 : 0.571038\n",
      "weighted F1 : 0.572745\n",
      "Exact Match ACC : 0.56665 \n",
      "Total Records : 17383 \n",
      "Total ZXeros in True : 0 (0.000)%\n",
      "Total ZXeros in Test : 1443 (0.083)%\n",
      "=============================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/omid/.conda/envs/iot/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(rf_test_known)) :\n",
    "    print( \"==================HOME Case : %s =============\" % test_names[ i] )\n",
    "    rf_pred= xgb_classifier.predict( rf_test_known[i][0])\n",
    "    print_info( rf_test_known[i][1], rf_pred, classes, confidance=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## string encoding test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "knownity_rf =  RandomForestClassifier(n_estimators=100, max_depth=400,\n",
    "                             random_state=0 )\n",
    "knownity_rf_results = knownity_rf.fit(x_random_forest_train, known_unknown_y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_known_unknown_pred=knownity_rf.predict(x_random_forest_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_known_unknown_predicted = []\n",
    "for i in range(len(rf_tests)) :\n",
    "    print( \"==================HOME Case : %s =============\" % test_names[ i] )\n",
    "    rf_pred=knownity_rf.predict( rf_tests[i][0])\n",
    "    test_known_unknown_predicted.append(rf_pred)\n",
    "    print_info( np.array( make_known_unknown(rf_tests[i][1], classes.index('unknown'))), rf_pred, [\"unknown\",\"known\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "known_indexes_train  = [ i for i in range(len(train_known_unknown_pred)) if train_known_unknown_pred[i][1] ==1 ]\n",
    "\n",
    "x_train_known = x_random_forest_train[known_indexes_train]\n",
    "y_train_known = y_random_forest_train[known_indexes_train]\n",
    "\n",
    "rf_test_known = [] \n",
    "\n",
    "for test_index in range(len(test_known_unknown_predicted)):\n",
    "    known_indexes= [ i for i in range(len(test_known_unknown_predicted[test_index])) if test_known_unknown_predicted[test_index][i][1] ==1 ]\n",
    "    \n",
    "    rf_test_known.append(  (rf_tests[test_index][0][known_indexes], \n",
    "                            rf_tests[test_index][1][known_indexes],\n",
    "                            rf_tests[test_index][2],\n",
    "                            known_indexes\n",
    "                           ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=200, max_depth=400,\n",
    "                             random_state=0 )\n",
    "t_hist = clf.fit(x_train_known, y_train_known)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================HOME Case : MERGED =============\n",
      "                         Class  Accuracy     Recall  Precision   F Score    Count            TP/TN/FP/FN\n",
      "------------------------------------------------------------------------\n",
      "          colorTemperature-XXX     0.999      0.225     1.000     0.367        40     9/33278/    0/   31\n",
      "                contact-closed     0.995      0.367     0.385     0.375       150    55/33080/   88/   95\n",
      "                  contact-open     0.995      0.507     0.458     0.481       150    76/33078/   90/   74\n",
      "                     level-XXX     0.988      0.860     0.253     0.391       150   129/32787/  381/   21\n",
      "                   lock-locked     0.997      0.148     0.387     0.214        81    12/33218/   19/   69\n",
      "                 lock-unlocked     0.997      0.024     0.286     0.045        82     2/33231/    5/   80\n",
      "                 motion-active     0.992      0.087     0.090     0.088       150    13/33036/  132/  137\n",
      "               motion-inactive     0.980      0.320     0.077     0.125       150    48/32595/  573/  102\n",
      "                     ping-ping     0.715      0.967     0.015     0.030       150   145/23691/ 9477/    5\n",
      "                 status-closed     0.998      0.513     0.720     0.599       115    59/33180/   23/   56\n",
      "                   status-open     0.997      0.571     0.660     0.613       119    68/33164/   35/   51\n",
      "                    switch-off     0.999      0.484     0.882     0.625        31    15/33285/    2/   16\n",
      "                     switch-on     0.999      0.161     0.333     0.217        31     5/33277/   10/   26\n",
      "               temperature-XXX     0.829      0.647     0.017     0.033       150    97/27536/ 5632/   53\n",
      "                       unknown     0.574      0.580     0.006     0.012       150    87/19031/14137/   63\n",
      "------------------------------------------------------------------------\n",
      "                      AVERAGES     0.937      0.431     0.371     0.281     33318     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "             Weighted AVERAGES     0.917      0.483     0.288     0.255     33318     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "       known Weighted AVERAGES     0.950      0.473     0.315     0.279     33318     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------\n",
      "       non zero count AVERAGES     0.937      0.431     0.371     0.281     33318     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "Macro F1 : 0.281023\n",
      "sample F1 : 0.019876\n",
      "weighted F1 : 0.255357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/omid/.conda/envs/iot/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/omid/.conda/envs/iot/lib/python3.6/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no true labels.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exact Match ACC : 0.07630 \n",
      "Total Records : 33318 \n",
      "Total ZXeros in True : 31945 (0.959)%\n",
      "Total ZXeros in Test : 2172 (0.065)%\n",
      "=============================================================================\n"
     ]
    }
   ],
   "source": [
    "rf_results = []\n",
    "for i in range(len(rf_test_known)) :\n",
    "    print( \"==================HOME Case : %s =============\" % test_names[ i] )\n",
    "    rf_pred= clf.predict( rf_test_known[i][0])\n",
    "    rf_pred = add_unknowns_back(rf_pred,rf_tests[i][1], rf_test_known[i][3] , classes)\n",
    "    rf_results.append(print_info( rf_tests[i][1], rf_pred, classes, confidance=0.09))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(len(rf_test_known)) :\n",
    "#     print( \"==================HOME Case : %s =============\" % test_names[ i] )\n",
    "#     rf_pred= clf.predict( rf_test_known[i][0])\n",
    "#     print_info( rf_test_known[i][1], rf_pred, classes, confidance=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [6016, 8133]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-fecf3188ab8f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprint_info\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mrf_test_known\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrf_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfidance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-23-4ad6eb0706ec>\u001b[0m in \u001b[0;36mprint_info\u001b[0;34m(y_test, pred, classes, confidance, print_skf1)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;31m#     acc_wierd  =acc_match_wierd(y_test, pred)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m     \u001b[0mconf\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mmultilabel_confusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0maccs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmake_recall_shit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconf\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m\"%30s  %8s   %8s  %8s  %8s %8s %22s\"\u001b[0m  \u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m\"Class\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"Accuracy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Recall\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"Precision\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"F Score\"\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;34m\"Count\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"TP/TN/FP/FN\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/iot/lib/python3.6/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36mmultilabel_confusion_matrix\u001b[0;34m(y_true, y_pred, sample_weight, labels, samplewise)\u001b[0m\n\u001b[1;32m    394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m     \"\"\"\n\u001b[0;32m--> 396\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    397\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m         \u001b[0msample_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/iot/lib/python3.6/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0marray\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindicator\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \"\"\"\n\u001b[0;32m---> 71\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m     \u001b[0mtype_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/iot/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    203\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0;32m--> 205\u001b[0;31m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [6016, 8133]"
     ]
    }
   ],
   "source": [
    "values, desc = print_info( rf_test_known[i][1], rf_pred, classes, confidance=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_nan(inp):\n",
    "    if np.isnan(inp):\n",
    "        return 0\n",
    "    else:\n",
    "        return inp\n",
    "desc = xg_boost_results[0][1]\n",
    "index = 0 \n",
    "for index in range(len(test_names)):\n",
    "    plt.figure(figsize=(14,4))\n",
    "    plt.plot( [x[0] for x in xg_boost_results[index][0]] , \n",
    "         [fix_nan(x[desc.index(\"F Score\")]) for x in xg_boost_results[index][0]],\n",
    "        label=\"XGBoost\",\n",
    "         color=\"red\" ,\n",
    "             alpha=0.5\n",
    "        )\n",
    "    plt.plot( [x[0] for x in rf_results[index][0]] , \n",
    "         [fix_nan(x[desc.index(\"F Score\")]) for x in rf_results[index][0]],\n",
    "        label=\"RF\",\n",
    "         color=\"blue\" ,\n",
    "             alpha=0.5\n",
    "        )\n",
    "    \n",
    "    plt.plot( [x[0] for x in xg_boost_results[index][0]] , \n",
    "         [fix_nan(x[desc.index(\"Precision\")]) for x in xg_boost_results[index][0]],\n",
    "        label=\"XGBoost - Precision\",\n",
    "         color=\"red\" ,\n",
    "             marker=\"s\",\n",
    "             alpha=0.5\n",
    "        )\n",
    "    plt.plot( [x[0] for x in rf_results[index][0]] , \n",
    "         [fix_nan(x[desc.index(\"Precision\")]) for x in rf_results[index][0]],\n",
    "        label=\"RF - Precision\",\n",
    "         color=\"blue\" ,\n",
    "             marker=\"s\",\n",
    "             alpha=0.5\n",
    "        )\n",
    "    plt.plot( [x[0] for x in xg_boost_results[index][0]] , \n",
    "         [fix_nan(x[desc.index(\"Recall\")]) for x in xg_boost_results[index][0]],\n",
    "        label=\"XGBoost - Recall\",\n",
    "         color=\"red\" ,\n",
    "             marker=\"+\",\n",
    "             alpha=0.5\n",
    "        )\n",
    "    plt.plot( [x[0] for x in rf_results[index][0]] , \n",
    "         [fix_nan(x[desc.index(\"Recall\")]) for x in rf_results[index][0]],\n",
    "        label=\"RF - Recall\",\n",
    "         color=\"blue\" ,\n",
    "             marker=\"+\",\n",
    "             alpha=0.5\n",
    "        )\n",
    "\n",
    "    # plt.plot( )\n",
    "    plt.legend()\n",
    "    plt.xticks(rotation=90, ha='right')\n",
    "    plt.title(test_names[ index] )\n",
    "    plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ok ... bye bye now ... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest baseline calc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "preproicess the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_size= 50\n",
    "x_random_forest_train,y_random_forest_train, _ = pre_process_raw( x_train, y_train , dim_size, zero_pad=True, normalize=False, classes=classes)\n",
    "rf_tests  = [ pre_process_raw( x_test[i], y_test[i] , dim_size, zero_pad=True, normalize=False, classes=classes, class_cap=TEST_CLASS_CAP) for i in range(len(x_test)) ] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "first stage RF will learn if it is a known or unknown instance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "knownity_rf =  RandomForestClassifier(n_estimators=960, max_depth=9050,\n",
    "                             random_state=0 )\n",
    "knownity_rf_results = knownity_rf.fit(x_random_forest_train, known_unknown_y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_known_unknown_pred=knownity_rf.predict(x_random_forest_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_known_unknown_predicted = []\n",
    "for i in range(len(rf_tests)) :\n",
    "    print( \"==================HOME Case : %s =============\" % test_names[ i] )\n",
    "    rf_pred=knownity_rf.predict( rf_tests[i][0])\n",
    "    test_known_unknown_predicted.append(rf_pred)\n",
    "    print_info( np.array( known_unknown_y_test[i]), rf_pred, [\"unknown\",\"known\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "known_indexes_train  = [ i for i in range(len(train_known_unknown_pred)) if train_known_unknown_pred[i][1] ==1 ]\n",
    "\n",
    "x_train_known = x_random_forest_train[known_indexes_train]\n",
    "y_train_known = y_random_forest_train[known_indexes_train]\n",
    "\n",
    "rf_test_known = [] \n",
    "\n",
    "for test_index in range(len(rf_tests)):\n",
    "    known_indexes= [ i for i in range(len(test_known_unknown_predicted[test_index])) if test_known_unknown_predicted[test_index][i][1] ==1 ]\n",
    "    \n",
    "    rf_test_known.append(  (rf_tests[test_index][0][known_indexes], \n",
    "                            rf_tests[test_index][1][known_indexes],\n",
    "                            rf_tests[test_index][2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=960, max_depth=9050,\n",
    "                             random_state=0 )\n",
    "t_hist = clf.fit(x_train_known, y_train_known)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(rf_test_known)) :\n",
    "    print( \"==================HOME Case : %s =============\" % test_names[ i] )\n",
    "    rf_pred= clf.predict( rf_test_known[i][0])\n",
    "    print_info( rf_test_known[i][1], rf_pred, classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the model\n",
    "dim_size =20\n",
    "x_lstm_prossed_train,y_lstm_prossed_train, _ = pre_process_raw( x_train, y_train , dim_size, zero_pad=False, normalize=False,classes=classes, as_string=True)\n",
    "_, y_s_lstm_processed_train ,_ =  pre_process_raw( x_train, y_train_service , dim_size, zero_pad=False, normalize=False,classes=service_classes, as_string=True)\n",
    "# x_lstm_prossed_test,y_lstm_prossed_test, _ = pre_process_raw( x_test, y_test_2 , dim_size, zero_pad=True, normalize=False,classes=classes)\n",
    "lstm_tests  = [ pre_process_raw( x_test[i], y_test[i] , dim_size, zero_pad=False, normalize=False, classes=classes, class_cap=TEST_CLASS_CAP) for i in range(len(x_test)) ] \n",
    "lstm_tests_services  = [ pre_process_raw( x_test[i], y_test_service[i] , dim_size, zero_pad=False, normalize=True, classes=service_classes, class_cap=TEST_CLASS_CAP) for i in range(len(x_test)) ] \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_random_forest_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-900afc774a84>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx_random_forest_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'x_random_forest_train' is not defined"
     ]
    }
   ],
   "source": [
    " x_random_forest_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(x_lstm_prossed_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "known_indexes_train  = [ i for i in range(len(train_known_unknown_pred)) if train_known_unknown_pred[i][1] ==1 ]\n",
    "\n",
    "# x_lstm_prossed_train = x_lstm_prossed_train[known_indexes_train]\n",
    "y_lstm_prossed_train = y_lstm_prossed_train[known_indexes_train]\n",
    "\n",
    "lstm_tests_known = [] \n",
    "\n",
    "for test_index in range(len(rf_tests)):\n",
    "    known_indexes= [ i for i in range(len(test_known_unknown_predicted[test_index])) if test_known_unknown_predicted[test_index][i][1] ==1 ]\n",
    "    \n",
    "    lstm_tests_known.append(  (lstm_tests[test_index][0][known_indexes], \n",
    "                            lstm_tests[test_index][1][known_indexes],\n",
    "                            lstm_tests[test_index][2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_lstm_prossed_test2 = np.expand_dims(x_lstm_prossed_test,axis=1)\n",
    "# x_lstm_prossed_train2 =np.expand_dims(x_random_forest_train,axis=1)\n",
    "# x_lstm_prossed_train2 =x_random_forest_train\n",
    "\n",
    "\n",
    "# x_lstm_prossed_test2 = x_lstm_prossed_test.reshape(len(x_lstm_prossed_test),dim_size,1)\n",
    "x_lstm_prossed_train2 =x_train_known.toarray().reshape((x_train_known.shape[0],x_train_known.shape[1],1))\n",
    "\n",
    "# y_lstm_prossed_test2 = y_lstm_prossed_test.reshape(len(y_lstm_prossed_test),len(classes),1)\n",
    "# y_lstm_prossed_train2 =y_lstm_prossed_train.reshape(len(y_lstm_prossed_train),len(classes),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tt  in range( len(rf_test_known) ):\n",
    "    rf_test_known[tt]= (rf_test_known[tt][0].toarray().reshape(rf_test_known[tt][0].shape[0],\n",
    "                                                     rf_test_known[tt][0].shape[1],\n",
    "                                                     1) ,\n",
    "                           rf_test_known[tt][1],\n",
    "                           rf_test_known[tt][1] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1.])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes.index('ping'), classes.index('unknown'), len(classes), len(y_lstm_prossed_train[0])\n",
    "ping=classes.index('ping')\n",
    "unknown =classes.index('unknown')\n",
    "key = np.ones_like(y_lstm_prossed_train[0])\n",
    "key[unknown]=0\n",
    "key[ping]=0\n",
    "key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Bidirectional LSTM :D \n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers import Bidirectional\n",
    "from keras.layers import Flatten\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from keras.models import Model\n",
    "\n",
    "from keras.layers import Input, merge, concatenate, Conv2D, MaxPooling2D, Activation, UpSampling2D, Dropout, Conv2DTranspose, UpSampling2D, Lambda\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers.normalization import BatchNormalization as bn\n",
    "from keras.layers.merge import add\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from keras.optimizers import RMSprop\n",
    "from keras import regularizers\n",
    "from keras import backend as K\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers.merge import add\n",
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "from keras.regularizers import l2\n",
    "from keras.layers import Conv1D\n",
    "from keras.layers.merge import add\n",
    "from keras.layers import Dense,Conv1D,Dropout,Activation,BatchNormalization,MaxPooling1D,Flatten,Masking,TimeDistributed\n",
    "from keras.layers.recurrent import LSTM,GRU,SimpleRNN\n",
    "from keras.models import Input,Sequential,Model\n",
    "from keras.layers.merge import add\n",
    "from keras.optimizers import Adam\n",
    "from keras.losses import MSE,MSLE\n",
    "model2 = Sequential()\n",
    "\n",
    "\n",
    "def weighted_categorical_crossentropy(weights):\n",
    "    \"\"\"\n",
    "    A weighted version of keras.objectives.categorical_crossentropy\n",
    "    \n",
    "    Variables:\n",
    "        weights: numpy array of shape (C,) where C is the number of classes\n",
    "    \n",
    "    Usage:\n",
    "        weights = np.array([0.5,2,10]) # Class one at 0.5, class 2 twice the normal weights, class 3 10x.\n",
    "        loss = weighted_categorical_crossentropy(weights)\n",
    "        model.compile(loss=loss,optimizer='adam')\n",
    "    \"\"\"\n",
    "    \n",
    "    weights = K.variable(weights)\n",
    "        \n",
    "    def loss(y_true, y_pred):\n",
    "        # scale predictions so that the class probas of each sample sum to 1\n",
    "        y_pred /= K.sum(y_pred, axis=-1, keepdims=True)\n",
    "        # clip to prevent NaN's and Inf's\n",
    "        y_pred = K.clip(y_pred, K.epsilon(), 1 - K.epsilon())\n",
    "        # calc\n",
    "        loss = y_true * K.log(y_pred) * weights\n",
    "        loss = -K.sum(loss, -1)\n",
    "        return loss\n",
    "    \n",
    "    return loss\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "def f1_perClass(y_true, y_pred):\n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return K.mean(f1)\n",
    "\n",
    "\n",
    "def f1_perRow(y_true, y_pred):\n",
    "\n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=1)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=1)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=1)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=1)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return K.mean(f1)\n",
    "\n",
    "def f1_loss_perRow(y_true, y_pred):\n",
    "    \n",
    "#     y_true = y_true * \n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=1) \n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=1) \n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=1) \n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=1) \n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "#     f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return (1 - K.mean(f1))**2\n",
    "\n",
    "def f1_loss_perClass(y_true, y_pred):\n",
    "    key = K.variable([1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1.])\n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = (2*p*r / (p+r+K.epsilon()))*key\n",
    "    \n",
    "#     f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return (1 - K.mean(f1))**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7468, 1)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_lstm_prossed_train2[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 15, 1)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 15, 128)           512       \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 15, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 15, 128)           0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 15, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_6 (Conv1D)            (None, 15, 64)            24640     \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 15, 64)            0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 15, 32)            2080      \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 480)               0         \n",
      "_________________________________________________________________\n",
      "Event_output (Dense)         (None, 14)                6734      \n",
      "=================================================================\n",
      "Total params: 34,478\n",
      "Trainable params: 34,222\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/70\n",
      "24173/24173 [==============================] - 1s 57us/step - loss: 10.5800 - f1_perRow: 0.2735 - f1_perClass: 0.1541 - acc: 0.5270\n",
      "Epoch 2/70\n",
      "24173/24173 [==============================] - 1s 27us/step - loss: 6.1565 - f1_perRow: 0.6034 - f1_perClass: 0.2983 - acc: 0.6327\n",
      "Epoch 3/70\n",
      "24173/24173 [==============================] - 1s 27us/step - loss: 5.3101 - f1_perRow: 0.6379 - f1_perClass: 0.3583 - acc: 0.6291\n",
      "Epoch 4/70\n",
      "24173/24173 [==============================] - 1s 27us/step - loss: 4.9679 - f1_perRow: 0.6573 - f1_perClass: 0.3815 - acc: 0.6469\n",
      "Epoch 5/70\n",
      "24173/24173 [==============================] - 1s 27us/step - loss: 4.7465 - f1_perRow: 0.6691 - f1_perClass: 0.4008 - acc: 0.6836\n",
      "Epoch 6/70\n",
      "24173/24173 [==============================] - 1s 27us/step - loss: 4.5481 - f1_perRow: 0.6754 - f1_perClass: 0.4147 - acc: 0.7130\n",
      "Epoch 7/70\n",
      "24173/24173 [==============================] - 1s 27us/step - loss: 4.3681 - f1_perRow: 0.6740 - f1_perClass: 0.4125 - acc: 0.7241\n",
      "Epoch 8/70\n",
      "24173/24173 [==============================] - 1s 27us/step - loss: 4.1836 - f1_perRow: 0.6057 - f1_perClass: 0.4196 - acc: 0.7418\n",
      "Epoch 9/70\n",
      "24173/24173 [==============================] - 1s 27us/step - loss: 4.0763 - f1_perRow: 0.5303 - f1_perClass: 0.4065 - acc: 0.7404\n",
      "Epoch 10/70\n",
      "24173/24173 [==============================] - 1s 27us/step - loss: 3.9554 - f1_perRow: 0.5384 - f1_perClass: 0.4167 - acc: 0.7502\n",
      "Epoch 11/70\n",
      "24173/24173 [==============================] - 1s 27us/step - loss: 3.8899 - f1_perRow: 0.5315 - f1_perClass: 0.4167 - acc: 0.7539\n",
      "Epoch 12/70\n",
      "24173/24173 [==============================] - 1s 26us/step - loss: 3.8191 - f1_perRow: 0.5290 - f1_perClass: 0.4200 - acc: 0.7539\n",
      "Epoch 13/70\n",
      "24173/24173 [==============================] - 1s 27us/step - loss: 3.7553 - f1_perRow: 0.5224 - f1_perClass: 0.4241 - acc: 0.7580\n",
      "Epoch 14/70\n",
      "24173/24173 [==============================] - 1s 26us/step - loss: 3.7350 - f1_perRow: 0.5666 - f1_perClass: 0.4374 - acc: 0.7607\n",
      "Epoch 15/70\n",
      "24173/24173 [==============================] - 1s 27us/step - loss: 3.6817 - f1_perRow: 0.5732 - f1_perClass: 0.4389 - acc: 0.7579\n",
      "Epoch 16/70\n",
      "24173/24173 [==============================] - 1s 27us/step - loss: 3.6564 - f1_perRow: 0.5691 - f1_perClass: 0.4386 - acc: 0.7658\n",
      "Epoch 17/70\n",
      "24173/24173 [==============================] - 1s 27us/step - loss: 3.6062 - f1_perRow: 0.5801 - f1_perClass: 0.4413 - acc: 0.7649\n",
      "Epoch 18/70\n",
      "24173/24173 [==============================] - 1s 27us/step - loss: 3.5924 - f1_perRow: 0.5879 - f1_perClass: 0.4412 - acc: 0.7638\n",
      "Epoch 19/70\n",
      "24173/24173 [==============================] - 1s 27us/step - loss: 3.5782 - f1_perRow: 0.6076 - f1_perClass: 0.4423 - acc: 0.7630\n",
      "Epoch 20/70\n",
      "24173/24173 [==============================] - 1s 27us/step - loss: 3.5415 - f1_perRow: 0.5986 - f1_perClass: 0.4524 - acc: 0.7680\n",
      "Epoch 21/70\n",
      "24173/24173 [==============================] - 1s 27us/step - loss: 3.5411 - f1_perRow: 0.6136 - f1_perClass: 0.4505 - acc: 0.7642\n",
      "Epoch 22/70\n",
      "24173/24173 [==============================] - 1s 27us/step - loss: 3.5135 - f1_perRow: 0.6183 - f1_perClass: 0.4548 - acc: 0.7690\n",
      "Epoch 23/70\n",
      "24173/24173 [==============================] - 1s 27us/step - loss: 3.4871 - f1_perRow: 0.6203 - f1_perClass: 0.4587 - acc: 0.7686\n",
      "Epoch 24/70\n",
      "24173/24173 [==============================] - 1s 27us/step - loss: 3.4794 - f1_perRow: 0.6259 - f1_perClass: 0.4610 - acc: 0.7707\n",
      "Epoch 25/70\n",
      "24173/24173 [==============================] - 1s 27us/step - loss: 3.4561 - f1_perRow: 0.6260 - f1_perClass: 0.4563 - acc: 0.7658\n",
      "Epoch 26/70\n",
      "24173/24173 [==============================] - 1s 27us/step - loss: 3.4686 - f1_perRow: 0.6220 - f1_perClass: 0.4574 - acc: 0.7707\n",
      "Epoch 27/70\n",
      "24173/24173 [==============================] - 1s 26us/step - loss: 3.4447 - f1_perRow: 0.6323 - f1_perClass: 0.4578 - acc: 0.7673\n",
      "Epoch 28/70\n",
      "24173/24173 [==============================] - 1s 26us/step - loss: 3.4232 - f1_perRow: 0.6478 - f1_perClass: 0.4683 - acc: 0.7721\n",
      "Epoch 29/70\n",
      "24173/24173 [==============================] - 1s 27us/step - loss: 3.4348 - f1_perRow: 0.6593 - f1_perClass: 0.4679 - acc: 0.7664\n",
      "Epoch 30/70\n",
      "24173/24173 [==============================] - 1s 27us/step - loss: 3.4130 - f1_perRow: 0.6536 - f1_perClass: 0.4657 - acc: 0.7728\n",
      "Epoch 31/70\n",
      "24173/24173 [==============================] - 1s 27us/step - loss: 3.4043 - f1_perRow: 0.6458 - f1_perClass: 0.4636 - acc: 0.7700\n",
      "Epoch 32/70\n",
      "24173/24173 [==============================] - 1s 27us/step - loss: 3.4148 - f1_perRow: 0.6546 - f1_perClass: 0.4694 - acc: 0.7705\n",
      "Epoch 33/70\n",
      "24173/24173 [==============================] - 1s 27us/step - loss: 3.3911 - f1_perRow: 0.6664 - f1_perClass: 0.4720 - acc: 0.7737\n",
      "Epoch 34/70\n",
      "24173/24173 [==============================] - 1s 27us/step - loss: 3.3741 - f1_perRow: 0.6665 - f1_perClass: 0.4770 - acc: 0.7681\n",
      "Epoch 35/70\n",
      "24173/24173 [==============================] - 1s 27us/step - loss: 3.3538 - f1_perRow: 0.6474 - f1_perClass: 0.4704 - acc: 0.7753\n",
      "Epoch 36/70\n",
      "24173/24173 [==============================] - 1s 27us/step - loss: 3.3487 - f1_perRow: 0.6653 - f1_perClass: 0.4673 - acc: 0.7740\n",
      "Epoch 37/70\n",
      "24173/24173 [==============================] - 1s 26us/step - loss: 3.3535 - f1_perRow: 0.6623 - f1_perClass: 0.4707 - acc: 0.7754\n",
      "Epoch 38/70\n",
      "24173/24173 [==============================] - 1s 27us/step - loss: 3.3376 - f1_perRow: 0.6723 - f1_perClass: 0.4677 - acc: 0.7749\n",
      "Epoch 39/70\n",
      "24173/24173 [==============================] - 1s 26us/step - loss: 3.3303 - f1_perRow: 0.6748 - f1_perClass: 0.4690 - acc: 0.7754\n",
      "Epoch 40/70\n",
      "24173/24173 [==============================] - 1s 27us/step - loss: 3.3125 - f1_perRow: 0.6662 - f1_perClass: 0.4690 - acc: 0.7753\n",
      "Epoch 41/70\n",
      "24173/24173 [==============================] - 1s 27us/step - loss: 3.3010 - f1_perRow: 0.6767 - f1_perClass: 0.4794 - acc: 0.7757\n",
      "Epoch 42/70\n",
      "24173/24173 [==============================] - 1s 27us/step - loss: 3.3219 - f1_perRow: 0.6873 - f1_perClass: 0.4745 - acc: 0.7740\n",
      "Epoch 43/70\n",
      "24173/24173 [==============================] - 1s 27us/step - loss: 3.3035 - f1_perRow: 0.6800 - f1_perClass: 0.4825 - acc: 0.7733\n",
      "Epoch 44/70\n",
      "24173/24173 [==============================] - 1s 27us/step - loss: 3.2882 - f1_perRow: 0.6787 - f1_perClass: 0.4801 - acc: 0.7735\n",
      "Epoch 45/70\n",
      "24173/24173 [==============================] - 1s 27us/step - loss: 3.2741 - f1_perRow: 0.6891 - f1_perClass: 0.4793 - acc: 0.7750\n",
      "Epoch 46/70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24173/24173 [==============================] - 1s 27us/step - loss: 3.2755 - f1_perRow: 0.6770 - f1_perClass: 0.4857 - acc: 0.7725\n",
      "Epoch 47/70\n",
      "24173/24173 [==============================] - 1s 27us/step - loss: 3.2742 - f1_perRow: 0.6951 - f1_perClass: 0.4805 - acc: 0.7779\n",
      "Epoch 48/70\n",
      "24173/24173 [==============================] - 1s 27us/step - loss: 3.2556 - f1_perRow: 0.6803 - f1_perClass: 0.4806 - acc: 0.7737\n",
      "Epoch 49/70\n",
      "24173/24173 [==============================] - 1s 27us/step - loss: 3.2839 - f1_perRow: 0.6868 - f1_perClass: 0.4798 - acc: 0.7716\n",
      "Epoch 50/70\n",
      "24173/24173 [==============================] - 1s 27us/step - loss: 3.2631 - f1_perRow: 0.6786 - f1_perClass: 0.4756 - acc: 0.7767\n",
      "Epoch 51/70\n",
      "24173/24173 [==============================] - 1s 27us/step - loss: 3.2274 - f1_perRow: 0.6829 - f1_perClass: 0.4817 - acc: 0.7747\n",
      "Epoch 52/70\n",
      "24173/24173 [==============================] - 1s 28us/step - loss: 3.2341 - f1_perRow: 0.6811 - f1_perClass: 0.4788 - acc: 0.7731\n",
      "Epoch 53/70\n",
      "24173/24173 [==============================] - 1s 27us/step - loss: 3.2254 - f1_perRow: 0.6868 - f1_perClass: 0.4769 - acc: 0.7771\n",
      "Epoch 54/70\n",
      "24173/24173 [==============================] - 1s 27us/step - loss: 3.2251 - f1_perRow: 0.6781 - f1_perClass: 0.4779 - acc: 0.7757\n",
      "Epoch 55/70\n",
      "24173/24173 [==============================] - 1s 27us/step - loss: 3.2335 - f1_perRow: 0.6888 - f1_perClass: 0.4755 - acc: 0.7759\n",
      "Epoch 56/70\n",
      "24173/24173 [==============================] - 1s 27us/step - loss: 3.2030 - f1_perRow: 0.6885 - f1_perClass: 0.4898 - acc: 0.7776\n",
      "Epoch 57/70\n",
      "24173/24173 [==============================] - 1s 27us/step - loss: 3.2025 - f1_perRow: 0.6933 - f1_perClass: 0.4842 - acc: 0.7735\n",
      "Epoch 58/70\n",
      "24173/24173 [==============================] - 1s 27us/step - loss: 3.1980 - f1_perRow: 0.6916 - f1_perClass: 0.4758 - acc: 0.7738\n",
      "Epoch 59/70\n",
      "24173/24173 [==============================] - 1s 27us/step - loss: 3.1891 - f1_perRow: 0.6902 - f1_perClass: 0.4856 - acc: 0.7717\n",
      "Epoch 60/70\n",
      "24173/24173 [==============================] - 1s 27us/step - loss: 3.1813 - f1_perRow: 0.6778 - f1_perClass: 0.4858 - acc: 0.7830\n",
      "Epoch 61/70\n",
      "24173/24173 [==============================] - 1s 27us/step - loss: 3.1954 - f1_perRow: 0.6901 - f1_perClass: 0.4825 - acc: 0.7750\n",
      "Epoch 62/70\n",
      "24173/24173 [==============================] - 1s 27us/step - loss: 3.1768 - f1_perRow: 0.6900 - f1_perClass: 0.4791 - acc: 0.7787\n",
      "Epoch 63/70\n",
      "24173/24173 [==============================] - 1s 27us/step - loss: 3.1893 - f1_perRow: 0.6909 - f1_perClass: 0.4840 - acc: 0.7749\n",
      "Epoch 64/70\n",
      "24173/24173 [==============================] - 1s 27us/step - loss: 3.1812 - f1_perRow: 0.6820 - f1_perClass: 0.4769 - acc: 0.7775\n",
      "Epoch 65/70\n",
      "24173/24173 [==============================] - 1s 27us/step - loss: 3.1694 - f1_perRow: 0.6905 - f1_perClass: 0.4803 - acc: 0.7730\n",
      "Epoch 66/70\n",
      "24173/24173 [==============================] - 1s 27us/step - loss: 3.1739 - f1_perRow: 0.6997 - f1_perClass: 0.4847 - acc: 0.7782\n",
      "Epoch 67/70\n",
      "24173/24173 [==============================] - 1s 27us/step - loss: 3.1567 - f1_perRow: 0.6897 - f1_perClass: 0.4828 - acc: 0.7779\n",
      "Epoch 68/70\n",
      "24173/24173 [==============================] - 1s 27us/step - loss: 3.1640 - f1_perRow: 0.7016 - f1_perClass: 0.4831 - acc: 0.7774\n",
      "Epoch 69/70\n",
      "24173/24173 [==============================] - 1s 26us/step - loss: 3.1321 - f1_perRow: 0.6867 - f1_perClass: 0.4798 - acc: 0.7731\n",
      "Epoch 70/70\n",
      "24173/24173 [==============================] - 1s 27us/step - loss: 3.1487 - f1_perRow: 0.6901 - f1_perClass: 0.4858 - acc: 0.7786\n"
     ]
    }
   ],
   "source": [
    "inputs  = Input(  (x_lstm_prossed_train2[0].shape[0]  ,1) )\n",
    "\n",
    "out = Conv1D(128,3,padding='same')(inputs)\n",
    "out = BatchNormalization()(out)\n",
    "out = Activation('relu')(out)\n",
    "out = Dropout(0.2)(out)\n",
    "out = Conv1D(64,3,padding='same')(out)\n",
    "\n",
    "dout_1  = Dropout(0.2)(out)\n",
    "# flt_1   = Flatten()(dout_1)\n",
    "dense_1 = Dense(32, activation='relu')(dout_1)\n",
    "# dout_3  = Dropout(0.2)(dense_1)\n",
    "flt_1   = Flatten()(dense_1)\n",
    "\n",
    "out_put_final = Dense(len(classes), activation='sigmoid', name='Event_output')(flt_1)\n",
    "\n",
    "\n",
    "model2 = Model(inputs=[inputs], outputs=[out_put_final])\n",
    "\n",
    "\n",
    "losses = {\n",
    "    \"Event_output\": f1_loss_perClass ,\n",
    "#     \"Event_output\": f1_loss_perRow \n",
    "    \"Event_output\": \"categorical_crossentropy\",\n",
    "}\n",
    "lossWeights = {\"Event_output\": 200,\n",
    "#                \"Event_output\": 30.0 \n",
    "    \"Event_output\": 5\n",
    "              }\n",
    " \n",
    "\n",
    "\n",
    "model2.compile(loss=losses,loss_weights=lossWeights, optimizer='adam', metrics=[f1_perRow,f1_perClass,'acc'])\n",
    "# model2.compile(loss=losses, loss_weights=lossWeights, optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "checkpoint = ModelCheckpoint('IoTDownNet_cnn_newloss', monitor='loss', verbose=0, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "print(model2.summary())\n",
    "hist2 = model2.fit(x_lstm_prossed_train2, y_lstm_prossed_train, epochs=70, batch_size=2000, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "losses = {\n",
    "    \"Event_output\": f1_loss_perClass ,\n",
    "    \"Event_output\": f1_loss_perRow ,\n",
    "    \"Event_output\": \"categorical_crossentropy\",\n",
    "}\n",
    "lossWeights = {\n",
    "    \"Event_output\": 300,\n",
    "               \"Event_output\": 300.0 ,\n",
    "    \"Event_output\": 20\n",
    "              }\n",
    " \n",
    "\n",
    "\n",
    "model2.compile(loss=losses,loss_weights=lossWeights, optimizer='adam', metrics=[f1_perRow,f1_perClass,'acc'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "24173/24173 [==============================] - 2s 70us/step - loss: 38.7257 - f1_perRow: 0.8345 - f1_perClass: 0.6618 - acc: 0.8022\n",
      "Epoch 2/100\n",
      "24173/24173 [==============================] - 1s 35us/step - loss: 34.6942 - f1_perRow: 0.8098 - f1_perClass: 0.6319 - acc: 0.7996\n",
      "Epoch 3/100\n",
      "24173/24173 [==============================] - 1s 36us/step - loss: 31.0465 - f1_perRow: 0.8043 - f1_perClass: 0.6300 - acc: 0.8052\n",
      "Epoch 4/100\n",
      "24173/24173 [==============================] - 1s 35us/step - loss: 29.9974 - f1_perRow: 0.7930 - f1_perClass: 0.6135 - acc: 0.8056\n",
      "Epoch 5/100\n",
      "24173/24173 [==============================] - 1s 35us/step - loss: 29.0578 - f1_perRow: 0.8011 - f1_perClass: 0.6189 - acc: 0.8074\n",
      "Epoch 6/100\n",
      "24173/24173 [==============================] - 1s 35us/step - loss: 28.6152 - f1_perRow: 0.8018 - f1_perClass: 0.6249 - acc: 0.8058\n",
      "Epoch 7/100\n",
      "24173/24173 [==============================] - 1s 36us/step - loss: 28.2980 - f1_perRow: 0.8005 - f1_perClass: 0.6165 - acc: 0.8047\n",
      "Epoch 8/100\n",
      "24173/24173 [==============================] - 1s 35us/step - loss: 23.4588 - f1_perRow: 0.7821 - f1_perClass: 0.6103 - acc: 0.7936\n",
      "Epoch 9/100\n",
      "24173/24173 [==============================] - 1s 35us/step - loss: 20.9386 - f1_perRow: 0.6577 - f1_perClass: 0.5989 - acc: 0.6212\n",
      "Epoch 10/100\n",
      "24173/24173 [==============================] - 1s 35us/step - loss: 20.8592 - f1_perRow: 0.6502 - f1_perClass: 0.5962 - acc: 0.4672\n",
      "Epoch 11/100\n",
      "24173/24173 [==============================] - 1s 36us/step - loss: 20.6127 - f1_perRow: 0.6541 - f1_perClass: 0.6068 - acc: 0.3915\n",
      "Epoch 12/100\n",
      "24173/24173 [==============================] - 1s 35us/step - loss: 20.5336 - f1_perRow: 0.6573 - f1_perClass: 0.6179 - acc: 0.3361\n",
      "Epoch 13/100\n",
      "24173/24173 [==============================] - 1s 35us/step - loss: 20.4525 - f1_perRow: 0.6556 - f1_perClass: 0.6141 - acc: 0.3132\n",
      "Epoch 14/100\n",
      "24173/24173 [==============================] - 1s 35us/step - loss: 20.6058 - f1_perRow: 0.6525 - f1_perClass: 0.6053 - acc: 0.3086\n",
      "Epoch 15/100\n",
      "24173/24173 [==============================] - 1s 35us/step - loss: 20.2384 - f1_perRow: 0.6577 - f1_perClass: 0.6181 - acc: 0.3129\n",
      "Epoch 16/100\n",
      "24173/24173 [==============================] - 1s 36us/step - loss: 20.3554 - f1_perRow: 0.6554 - f1_perClass: 0.6121 - acc: 0.3142\n",
      "Epoch 17/100\n",
      "24173/24173 [==============================] - 1s 35us/step - loss: 20.3380 - f1_perRow: 0.6548 - f1_perClass: 0.6108 - acc: 0.3180\n",
      "Epoch 18/100\n",
      "24173/24173 [==============================] - 1s 35us/step - loss: 20.1121 - f1_perRow: 0.6571 - f1_perClass: 0.6146 - acc: 0.3167\n",
      "Epoch 19/100\n",
      "24173/24173 [==============================] - 1s 35us/step - loss: 20.1933 - f1_perRow: 0.6568 - f1_perClass: 0.6175 - acc: 0.3202\n",
      "Epoch 20/100\n",
      "24173/24173 [==============================] - 1s 36us/step - loss: 20.1527 - f1_perRow: 0.6551 - f1_perClass: 0.6121 - acc: 0.3235\n",
      "Epoch 21/100\n",
      "24173/24173 [==============================] - 1s 35us/step - loss: 19.7585 - f1_perRow: 0.6574 - f1_perClass: 0.6210 - acc: 0.3260\n",
      "Epoch 22/100\n",
      "24173/24173 [==============================] - 1s 36us/step - loss: 19.5122 - f1_perRow: 0.6601 - f1_perClass: 0.6270 - acc: 0.3317\n",
      "Epoch 23/100\n",
      "24173/24173 [==============================] - 1s 35us/step - loss: 19.6292 - f1_perRow: 0.6576 - f1_perClass: 0.6168 - acc: 0.3396\n",
      "Epoch 24/100\n",
      "24173/24173 [==============================] - 1s 35us/step - loss: 19.5331 - f1_perRow: 0.6553 - f1_perClass: 0.6057 - acc: 0.3436\n",
      "Epoch 25/100\n",
      "24173/24173 [==============================] - 1s 35us/step - loss: 19.0425 - f1_perRow: 0.6569 - f1_perClass: 0.6079 - acc: 0.3369\n",
      "Epoch 26/100\n",
      "24173/24173 [==============================] - 1s 35us/step - loss: 19.1249 - f1_perRow: 0.6566 - f1_perClass: 0.6140 - acc: 0.3418\n",
      "Epoch 27/100\n",
      "24173/24173 [==============================] - 1s 36us/step - loss: 19.0791 - f1_perRow: 0.6565 - f1_perClass: 0.6087 - acc: 0.3553\n",
      "Epoch 28/100\n",
      "24173/24173 [==============================] - 1s 35us/step - loss: 18.8149 - f1_perRow: 0.6559 - f1_perClass: 0.6074 - acc: 0.3620\n",
      "Epoch 29/100\n",
      "24173/24173 [==============================] - 1s 35us/step - loss: 19.0058 - f1_perRow: 0.6581 - f1_perClass: 0.6153 - acc: 0.3712\n",
      "Epoch 30/100\n",
      "24173/24173 [==============================] - 1s 35us/step - loss: 18.8504 - f1_perRow: 0.6581 - f1_perClass: 0.6204 - acc: 0.3752\n",
      "Epoch 31/100\n",
      "24173/24173 [==============================] - 1s 35us/step - loss: 18.6964 - f1_perRow: 0.6585 - f1_perClass: 0.6188 - acc: 0.3805\n",
      "Epoch 32/100\n",
      "24173/24173 [==============================] - 1s 35us/step - loss: 18.5898 - f1_perRow: 0.6604 - f1_perClass: 0.6173 - acc: 0.3964\n",
      "Epoch 33/100\n",
      "24173/24173 [==============================] - 1s 36us/step - loss: 18.5524 - f1_perRow: 0.6589 - f1_perClass: 0.6142 - acc: 0.3987\n",
      "Epoch 34/100\n",
      "24173/24173 [==============================] - 1s 36us/step - loss: 18.4005 - f1_perRow: 0.6612 - f1_perClass: 0.6173 - acc: 0.4169\n",
      "Epoch 35/100\n",
      "24173/24173 [==============================] - 1s 36us/step - loss: 18.7724 - f1_perRow: 0.6587 - f1_perClass: 0.6155 - acc: 0.4498\n",
      "Epoch 36/100\n",
      "24173/24173 [==============================] - 1s 36us/step - loss: 18.3313 - f1_perRow: 0.6601 - f1_perClass: 0.6188 - acc: 0.4700\n",
      "Epoch 37/100\n",
      "24173/24173 [==============================] - 1s 35us/step - loss: 18.9048 - f1_perRow: 0.6524 - f1_perClass: 0.5944 - acc: 0.4646\n",
      "Epoch 38/100\n",
      "24173/24173 [==============================] - 1s 36us/step - loss: 18.2908 - f1_perRow: 0.6600 - f1_perClass: 0.6155 - acc: 0.4750\n",
      "Epoch 39/100\n",
      "24173/24173 [==============================] - 1s 35us/step - loss: 18.3624 - f1_perRow: 0.6602 - f1_perClass: 0.6170 - acc: 0.5016\n",
      "Epoch 40/100\n",
      "24173/24173 [==============================] - 1s 35us/step - loss: 18.1556 - f1_perRow: 0.6597 - f1_perClass: 0.6189 - acc: 0.5136\n",
      "Epoch 41/100\n",
      "24173/24173 [==============================] - 1s 36us/step - loss: 18.0811 - f1_perRow: 0.6613 - f1_perClass: 0.6140 - acc: 0.5512\n",
      "Epoch 42/100\n",
      "24173/24173 [==============================] - 1s 36us/step - loss: 18.3779 - f1_perRow: 0.6569 - f1_perClass: 0.6057 - acc: 0.5708\n",
      "Epoch 43/100\n",
      "24173/24173 [==============================] - 1s 35us/step - loss: 18.1038 - f1_perRow: 0.6602 - f1_perClass: 0.6055 - acc: 0.5654\n",
      "Epoch 44/100\n",
      "24173/24173 [==============================] - 1s 36us/step - loss: 18.0885 - f1_perRow: 0.6594 - f1_perClass: 0.6053 - acc: 0.5701\n",
      "Epoch 45/100\n",
      "24173/24173 [==============================] - 1s 36us/step - loss: 17.8532 - f1_perRow: 0.6617 - f1_perClass: 0.6171 - acc: 0.5965\n",
      "Epoch 46/100\n",
      "24173/24173 [==============================] - 1s 35us/step - loss: 17.9704 - f1_perRow: 0.6637 - f1_perClass: 0.6187 - acc: 0.6389\n",
      "Epoch 47/100\n",
      "24173/24173 [==============================] - 1s 36us/step - loss: 17.8896 - f1_perRow: 0.6646 - f1_perClass: 0.6194 - acc: 0.6765\n",
      "Epoch 48/100\n",
      "24173/24173 [==============================] - 1s 35us/step - loss: 17.9637 - f1_perRow: 0.6649 - f1_perClass: 0.6082 - acc: 0.7242\n",
      "Epoch 49/100\n",
      "24173/24173 [==============================] - 1s 35us/step - loss: 16.2635 - f1_perRow: 0.7450 - f1_perClass: 0.6086 - acc: 0.7866\n",
      "Epoch 50/100\n",
      "24173/24173 [==============================] - 1s 36us/step - loss: 15.1955 - f1_perRow: 0.7635 - f1_perClass: 0.6209 - acc: 0.7846\n",
      "Epoch 51/100\n",
      "24173/24173 [==============================] - 1s 36us/step - loss: 14.4112 - f1_perRow: 0.7704 - f1_perClass: 0.6231 - acc: 0.7882\n",
      "Epoch 52/100\n",
      "24173/24173 [==============================] - 1s 35us/step - loss: 14.1802 - f1_perRow: 0.7677 - f1_perClass: 0.6136 - acc: 0.7839\n",
      "Epoch 53/100\n",
      "24173/24173 [==============================] - 1s 35us/step - loss: 13.7421 - f1_perRow: 0.7693 - f1_perClass: 0.6222 - acc: 0.7817\n",
      "Epoch 54/100\n",
      "24173/24173 [==============================] - 1s 35us/step - loss: 13.5189 - f1_perRow: 0.7743 - f1_perClass: 0.6205 - acc: 0.7851\n",
      "Epoch 55/100\n",
      "24173/24173 [==============================] - 1s 35us/step - loss: 14.2570 - f1_perRow: 0.7657 - f1_perClass: 0.5964 - acc: 0.7820\n",
      "Epoch 56/100\n",
      "24173/24173 [==============================] - 1s 35us/step - loss: 13.2136 - f1_perRow: 0.7711 - f1_perClass: 0.6173 - acc: 0.7841\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24173/24173 [==============================] - 1s 35us/step - loss: 12.9776 - f1_perRow: 0.7756 - f1_perClass: 0.6247 - acc: 0.7861\n",
      "Epoch 58/100\n",
      "24173/24173 [==============================] - 1s 36us/step - loss: 12.8053 - f1_perRow: 0.7499 - f1_perClass: 0.6183 - acc: 0.7864\n",
      "Epoch 59/100\n",
      "24173/24173 [==============================] - 1s 36us/step - loss: 13.1175 - f1_perRow: 0.7601 - f1_perClass: 0.6093 - acc: 0.7910\n",
      "Epoch 60/100\n",
      "24173/24173 [==============================] - 1s 36us/step - loss: 12.7681 - f1_perRow: 0.7649 - f1_perClass: 0.6194 - acc: 0.7896\n",
      "Epoch 61/100\n",
      "24173/24173 [==============================] - 1s 35us/step - loss: 12.6907 - f1_perRow: 0.7589 - f1_perClass: 0.6160 - acc: 0.7865\n",
      "Epoch 62/100\n",
      "24173/24173 [==============================] - 1s 35us/step - loss: 12.6195 - f1_perRow: 0.7666 - f1_perClass: 0.6189 - acc: 0.7878\n",
      "Epoch 63/100\n",
      "24173/24173 [==============================] - 1s 35us/step - loss: 12.6410 - f1_perRow: 0.7616 - f1_perClass: 0.6118 - acc: 0.7864\n",
      "Epoch 64/100\n",
      "24173/24173 [==============================] - 1s 35us/step - loss: 12.5133 - f1_perRow: 0.7646 - f1_perClass: 0.6204 - acc: 0.7844\n",
      "Epoch 65/100\n",
      "24173/24173 [==============================] - 1s 35us/step - loss: 12.4178 - f1_perRow: 0.7550 - f1_perClass: 0.6229 - acc: 0.7871\n",
      "Epoch 66/100\n",
      "24173/24173 [==============================] - 1s 36us/step - loss: 12.6338 - f1_perRow: 0.7577 - f1_perClass: 0.6182 - acc: 0.7884\n",
      "Epoch 67/100\n",
      "24173/24173 [==============================] - 1s 36us/step - loss: 12.3808 - f1_perRow: 0.7515 - f1_perClass: 0.6194 - acc: 0.7914\n",
      "Epoch 68/100\n",
      "24173/24173 [==============================] - 1s 35us/step - loss: 12.4639 - f1_perRow: 0.7562 - f1_perClass: 0.6131 - acc: 0.7939\n",
      "Epoch 69/100\n",
      "24173/24173 [==============================] - 1s 36us/step - loss: 12.6287 - f1_perRow: 0.7580 - f1_perClass: 0.6101 - acc: 0.7919\n",
      "Epoch 70/100\n",
      "24173/24173 [==============================] - 1s 36us/step - loss: 12.3317 - f1_perRow: 0.7577 - f1_perClass: 0.6146 - acc: 0.7919\n",
      "Epoch 71/100\n",
      "24173/24173 [==============================] - 1s 35us/step - loss: 12.4335 - f1_perRow: 0.7615 - f1_perClass: 0.6125 - acc: 0.7884\n",
      "Epoch 72/100\n",
      "24173/24173 [==============================] - 1s 35us/step - loss: 12.5565 - f1_perRow: 0.7542 - f1_perClass: 0.6062 - acc: 0.7878\n",
      "Epoch 73/100\n",
      "24173/24173 [==============================] - 1s 36us/step - loss: 12.3814 - f1_perRow: 0.7498 - f1_perClass: 0.6082 - acc: 0.7912\n",
      "Epoch 74/100\n",
      "24173/24173 [==============================] - 1s 35us/step - loss: 12.7125 - f1_perRow: 0.7546 - f1_perClass: 0.6040 - acc: 0.7848\n",
      "Epoch 75/100\n",
      "24173/24173 [==============================] - 1s 36us/step - loss: 12.7580 - f1_perRow: 0.7482 - f1_perClass: 0.6048 - acc: 0.7896\n",
      "Epoch 76/100\n",
      "24173/24173 [==============================] - 1s 36us/step - loss: 12.5342 - f1_perRow: 0.7521 - f1_perClass: 0.6065 - acc: 0.7896\n",
      "Epoch 77/100\n",
      "24173/24173 [==============================] - 1s 35us/step - loss: 12.3851 - f1_perRow: 0.7561 - f1_perClass: 0.6126 - acc: 0.7925\n",
      "Epoch 78/100\n",
      "24173/24173 [==============================] - 1s 35us/step - loss: 12.1895 - f1_perRow: 0.7622 - f1_perClass: 0.6192 - acc: 0.7942\n",
      "Epoch 79/100\n",
      "24173/24173 [==============================] - 1s 35us/step - loss: 12.0602 - f1_perRow: 0.7648 - f1_perClass: 0.6246 - acc: 0.7925\n",
      "Epoch 80/100\n",
      "24173/24173 [==============================] - 1s 36us/step - loss: 12.1456 - f1_perRow: 0.7601 - f1_perClass: 0.6168 - acc: 0.7898\n",
      "Epoch 81/100\n",
      "24173/24173 [==============================] - 1s 35us/step - loss: 12.2165 - f1_perRow: 0.7526 - f1_perClass: 0.6126 - acc: 0.7908\n",
      "Epoch 82/100\n",
      "24173/24173 [==============================] - 1s 35us/step - loss: 12.1044 - f1_perRow: 0.7541 - f1_perClass: 0.6195 - acc: 0.7949\n",
      "Epoch 83/100\n",
      "24173/24173 [==============================] - 1s 36us/step - loss: 12.1462 - f1_perRow: 0.7517 - f1_perClass: 0.6186 - acc: 0.7950\n",
      "Epoch 84/100\n",
      "24173/24173 [==============================] - 1s 36us/step - loss: 12.3633 - f1_perRow: 0.7569 - f1_perClass: 0.6089 - acc: 0.7984\n",
      "Epoch 85/100\n",
      "24173/24173 [==============================] - 1s 36us/step - loss: 12.0150 - f1_perRow: 0.7531 - f1_perClass: 0.6203 - acc: 0.8018\n",
      "Epoch 86/100\n",
      "24173/24173 [==============================] - 1s 36us/step - loss: 12.4191 - f1_perRow: 0.7512 - f1_perClass: 0.6071 - acc: 0.7855\n",
      "Epoch 87/100\n",
      "24173/24173 [==============================] - 1s 36us/step - loss: 12.3556 - f1_perRow: 0.7591 - f1_perClass: 0.6120 - acc: 0.7941\n",
      "Epoch 88/100\n",
      "24173/24173 [==============================] - 1s 36us/step - loss: 12.1282 - f1_perRow: 0.7492 - f1_perClass: 0.6127 - acc: 0.7963\n",
      "Epoch 89/100\n",
      "24173/24173 [==============================] - 1s 36us/step - loss: 12.1831 - f1_perRow: 0.7578 - f1_perClass: 0.6148 - acc: 0.7921\n",
      "Epoch 90/100\n",
      "24173/24173 [==============================] - 1s 35us/step - loss: 12.0014 - f1_perRow: 0.7621 - f1_perClass: 0.6176 - acc: 0.7970\n",
      "Epoch 91/100\n",
      "24173/24173 [==============================] - 1s 36us/step - loss: 12.0692 - f1_perRow: 0.7543 - f1_perClass: 0.6166 - acc: 0.8017\n",
      "Epoch 92/100\n",
      "24173/24173 [==============================] - 1s 35us/step - loss: 12.5523 - f1_perRow: 0.7503 - f1_perClass: 0.6024 - acc: 0.7843\n",
      "Epoch 93/100\n",
      "24173/24173 [==============================] - 1s 36us/step - loss: 12.2445 - f1_perRow: 0.7563 - f1_perClass: 0.6060 - acc: 0.7942\n",
      "Epoch 94/100\n",
      "24173/24173 [==============================] - 1s 35us/step - loss: 12.2041 - f1_perRow: 0.7541 - f1_perClass: 0.6116 - acc: 0.7991\n",
      "Epoch 95/100\n",
      "24173/24173 [==============================] - 1s 36us/step - loss: 12.1162 - f1_perRow: 0.7583 - f1_perClass: 0.6102 - acc: 0.7934\n",
      "Epoch 96/100\n",
      "24173/24173 [==============================] - 1s 36us/step - loss: 11.9095 - f1_perRow: 0.7673 - f1_perClass: 0.6213 - acc: 0.7972\n",
      "Epoch 97/100\n",
      "24173/24173 [==============================] - 1s 36us/step - loss: 11.9268 - f1_perRow: 0.7631 - f1_perClass: 0.6169 - acc: 0.7921\n",
      "Epoch 98/100\n",
      "24173/24173 [==============================] - 1s 36us/step - loss: 11.9173 - f1_perRow: 0.7605 - f1_perClass: 0.6102 - acc: 0.7943\n",
      "Epoch 99/100\n",
      "24173/24173 [==============================] - 1s 35us/step - loss: 12.0598 - f1_perRow: 0.7545 - f1_perClass: 0.6065 - acc: 0.7946\n",
      "Epoch 100/100\n",
      "24173/24173 [==============================] - 1s 36us/step - loss: 11.9454 - f1_perRow: 0.7550 - f1_perClass: 0.6116 - acc: 0.8012\n"
     ]
    }
   ],
   "source": [
    "hist2 = model2.fit(x_lstm_prossed_train2, y_lstm_prossed_train, epochs=100, batch_size=7010, shuffle=True, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "24173/24173 [==============================] - 1s 36us/step - loss: 8.5218 - f1_perRow: 0.8315 - f1_perClass: 0.6587 - acc: 0.7888\n",
      "Epoch 2/200\n",
      "24173/24173 [==============================] - 1s 46us/step - loss: 9.0337 - f1_perRow: 0.8265 - f1_perClass: 0.6455 - acc: 0.7913\n",
      "Epoch 3/200\n",
      "24173/24173 [==============================] - 1s 36us/step - loss: 8.7161 - f1_perRow: 0.8296 - f1_perClass: 0.6555 - acc: 0.7902\n",
      "Epoch 4/200\n",
      "24173/24173 [==============================] - 1s 36us/step - loss: 8.8283 - f1_perRow: 0.8285 - f1_perClass: 0.6478 - acc: 0.7877\n",
      "Epoch 5/200\n",
      "24173/24173 [==============================] - 1s 36us/step - loss: 8.9091 - f1_perRow: 0.8278 - f1_perClass: 0.6483 - acc: 0.7896\n",
      "Epoch 6/200\n",
      "24173/24173 [==============================] - 1s 36us/step - loss: 8.9829 - f1_perRow: 0.8270 - f1_perClass: 0.6511 - acc: 0.7908\n",
      "Epoch 7/200\n",
      "24173/24173 [==============================] - 1s 36us/step - loss: 8.5972 - f1_perRow: 0.8307 - f1_perClass: 0.6517 - acc: 0.7931\n",
      "Epoch 8/200\n",
      "24173/24173 [==============================] - 1s 36us/step - loss: 8.6233 - f1_perRow: 0.8305 - f1_perClass: 0.6547 - acc: 0.7907\n",
      "Epoch 9/200\n",
      "24173/24173 [==============================] - 1s 37us/step - loss: 8.4513 - f1_perRow: 0.8323 - f1_perClass: 0.6614 - acc: 0.7922\n",
      "Epoch 10/200\n",
      "24173/24173 [==============================] - 1s 36us/step - loss: 8.5888 - f1_perRow: 0.8311 - f1_perClass: 0.6517 - acc: 0.7942\n",
      "Epoch 11/200\n",
      "24173/24173 [==============================] - 1s 36us/step - loss: 8.7897 - f1_perRow: 0.8289 - f1_perClass: 0.6527 - acc: 0.7932\n",
      "Epoch 12/200\n",
      "24173/24173 [==============================] - 1s 36us/step - loss: 8.5468 - f1_perRow: 0.8315 - f1_perClass: 0.6558 - acc: 0.7923\n",
      "Epoch 13/200\n",
      "24173/24173 [==============================] - 1s 36us/step - loss: 8.4143 - f1_perRow: 0.8326 - f1_perClass: 0.6627 - acc: 0.7885\n",
      "Epoch 14/200\n",
      "24173/24173 [==============================] - 1s 36us/step - loss: 8.3829 - f1_perRow: 0.8330 - f1_perClass: 0.6655 - acc: 0.7917\n",
      "Epoch 15/200\n",
      "24173/24173 [==============================] - 1s 36us/step - loss: 8.2476 - f1_perRow: 0.8342 - f1_perClass: 0.6626 - acc: 0.7891\n",
      "Epoch 16/200\n",
      "24173/24173 [==============================] - 1s 36us/step - loss: 8.7427 - f1_perRow: 0.8295 - f1_perClass: 0.6547 - acc: 0.7921\n",
      "Epoch 17/200\n",
      "24173/24173 [==============================] - 1s 36us/step - loss: 8.6914 - f1_perRow: 0.8298 - f1_perClass: 0.6562 - acc: 0.7941\n",
      "Epoch 18/200\n",
      "24173/24173 [==============================] - 1s 36us/step - loss: 8.1760 - f1_perRow: 0.8350 - f1_perClass: 0.6673 - acc: 0.7950\n",
      "Epoch 19/200\n",
      "24173/24173 [==============================] - 1s 35us/step - loss: 8.2139 - f1_perRow: 0.8346 - f1_perClass: 0.6667 - acc: 0.7951\n",
      "Epoch 20/200\n",
      "24173/24173 [==============================] - 1s 36us/step - loss: 8.3016 - f1_perRow: 0.8337 - f1_perClass: 0.6658 - acc: 0.7899\n",
      "Epoch 21/200\n",
      "24173/24173 [==============================] - 1s 36us/step - loss: 8.6235 - f1_perRow: 0.8306 - f1_perClass: 0.6523 - acc: 0.7924\n",
      "Epoch 22/200\n",
      "24173/24173 [==============================] - 1s 36us/step - loss: 8.3341 - f1_perRow: 0.8334 - f1_perClass: 0.6611 - acc: 0.7946\n",
      "Epoch 23/200\n",
      "24173/24173 [==============================] - 1s 36us/step - loss: 8.5644 - f1_perRow: 0.8311 - f1_perClass: 0.6607 - acc: 0.7937\n",
      "Epoch 24/200\n",
      "24173/24173 [==============================] - 1s 36us/step - loss: 8.5335 - f1_perRow: 0.8315 - f1_perClass: 0.6523 - acc: 0.7938\n",
      "Epoch 25/200\n",
      "24173/24173 [==============================] - 1s 36us/step - loss: 8.3309 - f1_perRow: 0.8334 - f1_perClass: 0.6603 - acc: 0.7943\n",
      "Epoch 26/200\n",
      "24173/24173 [==============================] - 1s 36us/step - loss: 8.6026 - f1_perRow: 0.8307 - f1_perClass: 0.6573 - acc: 0.7934\n",
      "Epoch 27/200\n",
      "24173/24173 [==============================] - 1s 35us/step - loss: 8.3769 - f1_perRow: 0.8330 - f1_perClass: 0.6629 - acc: 0.7920\n",
      "Epoch 28/200\n",
      "24173/24173 [==============================] - 1s 36us/step - loss: 8.7427 - f1_perRow: 0.8296 - f1_perClass: 0.6440 - acc: 0.7933\n",
      "Epoch 29/200\n",
      "24173/24173 [==============================] - 1s 36us/step - loss: 8.4540 - f1_perRow: 0.8322 - f1_perClass: 0.6649 - acc: 0.7930\n",
      "Epoch 30/200\n",
      "24173/24173 [==============================] - 1s 36us/step - loss: 8.2716 - f1_perRow: 0.8340 - f1_perClass: 0.6663 - acc: 0.7951\n",
      "Epoch 31/200\n",
      "24173/24173 [==============================] - 1s 35us/step - loss: 8.7943 - f1_perRow: 0.8289 - f1_perClass: 0.6465 - acc: 0.7925\n",
      "Epoch 32/200\n",
      "24173/24173 [==============================] - 1s 36us/step - loss: 8.3404 - f1_perRow: 0.8333 - f1_perClass: 0.6616 - acc: 0.7915\n",
      "Epoch 33/200\n",
      "24173/24173 [==============================] - 1s 36us/step - loss: 8.3775 - f1_perRow: 0.8329 - f1_perClass: 0.6647 - acc: 0.7906\n",
      "Epoch 34/200\n",
      "24173/24173 [==============================] - 1s 36us/step - loss: 8.5529 - f1_perRow: 0.8313 - f1_perClass: 0.6558 - acc: 0.7923\n",
      "Epoch 35/200\n",
      "24173/24173 [==============================] - 1s 37us/step - loss: 8.3232 - f1_perRow: 0.8334 - f1_perClass: 0.6620 - acc: 0.7936\n",
      "Epoch 36/200\n",
      "24173/24173 [==============================] - 1s 36us/step - loss: 8.2750 - f1_perRow: 0.8340 - f1_perClass: 0.6633 - acc: 0.7950\n",
      "Epoch 37/200\n",
      "24173/24173 [==============================] - 1s 37us/step - loss: 8.5599 - f1_perRow: 0.8311 - f1_perClass: 0.6545 - acc: 0.7928\n",
      "Epoch 38/200\n",
      "24173/24173 [==============================] - 1s 36us/step - loss: 8.1288 - f1_perRow: 0.8355 - f1_perClass: 0.6708 - acc: 0.7949\n",
      "Epoch 39/200\n",
      "24173/24173 [==============================] - 1s 36us/step - loss: 8.3383 - f1_perRow: 0.8333 - f1_perClass: 0.6654 - acc: 0.7955\n",
      "Epoch 40/200\n",
      "24173/24173 [==============================] - 1s 36us/step - loss: 8.7229 - f1_perRow: 0.8295 - f1_perClass: 0.6453 - acc: 0.7934\n",
      "Epoch 41/200\n",
      "24173/24173 [==============================] - 1s 36us/step - loss: 8.5840 - f1_perRow: 0.8309 - f1_perClass: 0.6579 - acc: 0.7919\n",
      "Epoch 42/200\n",
      "24173/24173 [==============================] - 1s 36us/step - loss: 8.4770 - f1_perRow: 0.8320 - f1_perClass: 0.6558 - acc: 0.7935\n",
      "Epoch 43/200\n",
      "24173/24173 [==============================] - 1s 36us/step - loss: 8.8416 - f1_perRow: 0.8285 - f1_perClass: 0.6401 - acc: 0.7934\n",
      "Epoch 44/200\n",
      "24173/24173 [==============================] - 1s 36us/step - loss: 8.7095 - f1_perRow: 0.8299 - f1_perClass: 0.6454 - acc: 0.7956\n",
      "Epoch 45/200\n",
      "24173/24173 [==============================] - 1s 36us/step - loss: 8.9527 - f1_perRow: 0.8275 - f1_perClass: 0.6520 - acc: 0.7958\n",
      "Epoch 46/200\n",
      "24173/24173 [==============================] - 1s 36us/step - loss: 9.0652 - f1_perRow: 0.8262 - f1_perClass: 0.6528 - acc: 0.7944\n",
      "Epoch 47/200\n",
      "24173/24173 [==============================] - 1s 36us/step - loss: 8.6068 - f1_perRow: 0.8308 - f1_perClass: 0.6550 - acc: 0.7935\n",
      "Epoch 48/200\n",
      "24173/24173 [==============================] - 1s 36us/step - loss: 8.2438 - f1_perRow: 0.8343 - f1_perClass: 0.6598 - acc: 0.7934\n",
      "Epoch 49/200\n",
      "24173/24173 [==============================] - 1s 36us/step - loss: 8.2078 - f1_perRow: 0.8347 - f1_perClass: 0.6685 - acc: 0.7927\n",
      "Epoch 50/200\n",
      "24173/24173 [==============================] - 1s 39us/step - loss: 8.5888 - f1_perRow: 0.8310 - f1_perClass: 0.6590 - acc: 0.7956\n",
      "Epoch 51/200\n",
      "24173/24173 [==============================] - 1s 36us/step - loss: 8.5094 - f1_perRow: 0.8317 - f1_perClass: 0.6585 - acc: 0.7944\n",
      "Epoch 52/200\n",
      "24173/24173 [==============================] - 1s 36us/step - loss: 8.1246 - f1_perRow: 0.8355 - f1_perClass: 0.6658 - acc: 0.7945\n",
      "Epoch 53/200\n",
      "24173/24173 [==============================] - 1s 35us/step - loss: 8.2079 - f1_perRow: 0.8346 - f1_perClass: 0.6650 - acc: 0.7951\n",
      "Epoch 54/200\n",
      "24173/24173 [==============================] - 1s 36us/step - loss: 8.2878 - f1_perRow: 0.8338 - f1_perClass: 0.6644 - acc: 0.7923\n",
      "Epoch 55/200\n",
      "24173/24173 [==============================] - 1s 36us/step - loss: 7.9613 - f1_perRow: 0.8371 - f1_perClass: 0.6719 - acc: 0.7915\n",
      "Epoch 56/200\n",
      "24173/24173 [==============================] - 1s 36us/step - loss: 8.4081 - f1_perRow: 0.8327 - f1_perClass: 0.6588 - acc: 0.7919\n",
      "Epoch 57/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24173/24173 [==============================] - 1s 36us/step - loss: 9.1051 - f1_perRow: 0.8259 - f1_perClass: 0.6434 - acc: 0.7958\n",
      "Epoch 58/200\n",
      "24173/24173 [==============================] - 1s 36us/step - loss: 8.5781 - f1_perRow: 0.8309 - f1_perClass: 0.6548 - acc: 0.7973\n",
      "Epoch 59/200\n",
      "24173/24173 [==============================] - 1s 35us/step - loss: 8.2788 - f1_perRow: 0.8339 - f1_perClass: 0.6537 - acc: 0.7982\n",
      "Epoch 60/200\n",
      "24173/24173 [==============================] - 1s 36us/step - loss: 8.1306 - f1_perRow: 0.8354 - f1_perClass: 0.6690 - acc: 0.7970\n",
      "Epoch 61/200\n",
      "24173/24173 [==============================] - 1s 36us/step - loss: 8.7864 - f1_perRow: 0.8289 - f1_perClass: 0.6522 - acc: 0.7922\n",
      "Epoch 62/200\n",
      "24173/24173 [==============================] - 1s 36us/step - loss: 8.3009 - f1_perRow: 0.8337 - f1_perClass: 0.6633 - acc: 0.7913\n",
      "Epoch 63/200\n",
      "24173/24173 [==============================] - 1s 35us/step - loss: 8.3104 - f1_perRow: 0.8336 - f1_perClass: 0.6637 - acc: 0.7923\n",
      "Epoch 64/200\n",
      "24173/24173 [==============================] - 1s 35us/step - loss: 8.8080 - f1_perRow: 0.8289 - f1_perClass: 0.6444 - acc: 0.7955\n",
      "Epoch 65/200\n",
      "24173/24173 [==============================] - 1s 36us/step - loss: 8.7905 - f1_perRow: 0.8288 - f1_perClass: 0.6384 - acc: 0.7947\n",
      "Epoch 66/200\n",
      "24173/24173 [==============================] - 1s 36us/step - loss: 8.4624 - f1_perRow: 0.8323 - f1_perClass: 0.6622 - acc: 0.7959\n",
      "Epoch 67/200\n",
      "24173/24173 [==============================] - 1s 36us/step - loss: 9.0030 - f1_perRow: 0.8270 - f1_perClass: 0.6492 - acc: 0.7934\n",
      "Epoch 68/200\n",
      "24173/24173 [==============================] - 1s 36us/step - loss: 8.4704 - f1_perRow: 0.8320 - f1_perClass: 0.6551 - acc: 0.7911\n",
      "Epoch 69/200\n",
      "24173/24173 [==============================] - 1s 36us/step - loss: 8.3598 - f1_perRow: 0.8331 - f1_perClass: 0.6515 - acc: 0.7937\n",
      "Epoch 70/200\n",
      "24173/24173 [==============================] - 1s 36us/step - loss: 8.4495 - f1_perRow: 0.8322 - f1_perClass: 0.6616 - acc: 0.7982\n",
      "Epoch 71/200\n",
      "24173/24173 [==============================] - 1s 36us/step - loss: 8.9749 - f1_perRow: 0.8271 - f1_perClass: 0.6407 - acc: 0.8001\n",
      "Epoch 72/200\n",
      "24173/24173 [==============================] - 1s 36us/step - loss: 8.7851 - f1_perRow: 0.8290 - f1_perClass: 0.6406 - acc: 0.8019\n",
      "Epoch 73/200\n",
      "24173/24173 [==============================] - 1s 36us/step - loss: 8.5305 - f1_perRow: 0.8315 - f1_perClass: 0.6618 - acc: 0.7983\n",
      "Epoch 74/200\n",
      "24173/24173 [==============================] - 1s 35us/step - loss: 8.9767 - f1_perRow: 0.8273 - f1_perClass: 0.6529 - acc: 0.7958\n",
      "Epoch 75/200\n",
      "24173/24173 [==============================] - 1s 36us/step - loss: 8.3842 - f1_perRow: 0.8328 - f1_perClass: 0.6519 - acc: 0.7962\n",
      "Epoch 76/200\n",
      "24173/24173 [==============================] - 1s 36us/step - loss: 8.6259 - f1_perRow: 0.8305 - f1_perClass: 0.6359 - acc: 0.7997\n",
      "Epoch 77/200\n",
      "24173/24173 [==============================] - 1s 36us/step - loss: 8.3781 - f1_perRow: 0.8329 - f1_perClass: 0.6631 - acc: 0.7973\n",
      "Epoch 78/200\n",
      "24173/24173 [==============================] - 1s 35us/step - loss: 8.6099 - f1_perRow: 0.8307 - f1_perClass: 0.6602 - acc: 0.7960\n",
      "Epoch 79/200\n",
      "24173/24173 [==============================] - 1s 36us/step - loss: 8.2617 - f1_perRow: 0.8341 - f1_perClass: 0.6591 - acc: 0.7967\n",
      "Epoch 80/200\n",
      "24173/24173 [==============================] - 1s 35us/step - loss: 8.7140 - f1_perRow: 0.8300 - f1_perClass: 0.6495 - acc: 0.7962\n",
      "Epoch 81/200\n",
      "24173/24173 [==============================] - 1s 35us/step - loss: 8.3704 - f1_perRow: 0.8331 - f1_perClass: 0.6579 - acc: 0.7951\n",
      "Epoch 82/200\n",
      "24173/24173 [==============================] - 1s 35us/step - loss: 8.4205 - f1_perRow: 0.8326 - f1_perClass: 0.6623 - acc: 0.7958\n",
      "Epoch 83/200\n",
      "24173/24173 [==============================] - 1s 36us/step - loss: 8.5338 - f1_perRow: 0.8314 - f1_perClass: 0.6559 - acc: 0.7970\n",
      "Epoch 84/200\n",
      "24173/24173 [==============================] - 1s 36us/step - loss: 8.3997 - f1_perRow: 0.8327 - f1_perClass: 0.6527 - acc: 0.7955\n",
      "Epoch 85/200\n",
      "24173/24173 [==============================] - 1s 36us/step - loss: 8.1023 - f1_perRow: 0.8358 - f1_perClass: 0.6689 - acc: 0.7952\n",
      "Epoch 86/200\n",
      "24173/24173 [==============================] - 1s 36us/step - loss: 7.9781 - f1_perRow: 0.8370 - f1_perClass: 0.6679 - acc: 0.7959\n",
      "Epoch 87/200\n",
      "24173/24173 [==============================] - 1s 36us/step - loss: 7.9342 - f1_perRow: 0.8375 - f1_perClass: 0.6723 - acc: 0.7962\n",
      "Epoch 88/200\n",
      "24173/24173 [==============================] - 1s 36us/step - loss: 8.3365 - f1_perRow: 0.8334 - f1_perClass: 0.6616 - acc: 0.7966\n",
      "Epoch 89/200\n",
      "24173/24173 [==============================] - 1s 36us/step - loss: 8.6554 - f1_perRow: 0.8305 - f1_perClass: 0.6456 - acc: 0.7981\n",
      "Epoch 90/200\n",
      "24173/24173 [==============================] - 1s 36us/step - loss: 8.9412 - f1_perRow: 0.8276 - f1_perClass: 0.6309 - acc: 0.7977\n",
      "Epoch 91/200\n",
      "24173/24173 [==============================] - 1s 36us/step - loss: 8.6725 - f1_perRow: 0.8301 - f1_perClass: 0.6467 - acc: 0.7949\n",
      "Epoch 92/200\n",
      "24173/24173 [==============================] - 1s 35us/step - loss: 8.0835 - f1_perRow: 0.8359 - f1_perClass: 0.6689 - acc: 0.7941\n",
      "Epoch 93/200\n",
      "24173/24173 [==============================] - 1s 36us/step - loss: 7.8750 - f1_perRow: 0.8380 - f1_perClass: 0.6736 - acc: 0.7975\n",
      "Epoch 94/200\n",
      "24173/24173 [==============================] - 1s 36us/step - loss: 8.3225 - f1_perRow: 0.8336 - f1_perClass: 0.6570 - acc: 0.7957\n",
      "Epoch 95/200\n",
      "24173/24173 [==============================] - 1s 35us/step - loss: 8.1605 - f1_perRow: 0.8352 - f1_perClass: 0.6652 - acc: 0.7977\n",
      "Epoch 96/200\n",
      "24173/24173 [==============================] - 1s 36us/step - loss: 8.3732 - f1_perRow: 0.8329 - f1_perClass: 0.6596 - acc: 0.7996\n",
      "Epoch 97/200\n",
      "24173/24173 [==============================] - 1s 36us/step - loss: 7.9677 - f1_perRow: 0.8371 - f1_perClass: 0.6723 - acc: 0.8014\n",
      "Epoch 98/200\n",
      "24173/24173 [==============================] - 1s 36us/step - loss: 8.3490 - f1_perRow: 0.8333 - f1_perClass: 0.6552 - acc: 0.8035\n",
      "Epoch 99/200\n",
      "24173/24173 [==============================] - 1s 36us/step - loss: 8.3128 - f1_perRow: 0.8336 - f1_perClass: 0.6561 - acc: 0.8027\n",
      "Epoch 100/200\n",
      "24173/24173 [==============================] - 1s 36us/step - loss: 8.2825 - f1_perRow: 0.8339 - f1_perClass: 0.6548 - acc: 0.7996\n",
      "Epoch 101/200\n",
      "24173/24173 [==============================] - 1s 36us/step - loss: 8.0492 - f1_perRow: 0.8362 - f1_perClass: 0.6503 - acc: 0.7965\n",
      "Epoch 102/200\n",
      "24173/24173 [==============================] - 1s 36us/step - loss: 7.9220 - f1_perRow: 0.8375 - f1_perClass: 0.6623 - acc: 0.7954\n",
      "Epoch 103/200\n",
      "24173/24173 [==============================] - 1s 36us/step - loss: 8.1088 - f1_perRow: 0.8357 - f1_perClass: 0.6586 - acc: 0.7961\n",
      "Epoch 104/200\n",
      "24173/24173 [==============================] - 1s 36us/step - loss: 8.1114 - f1_perRow: 0.8357 - f1_perClass: 0.6540 - acc: 0.8010\n",
      "Epoch 105/200\n",
      "24173/24173 [==============================] - 1s 36us/step - loss: 7.9478 - f1_perRow: 0.8373 - f1_perClass: 0.6645 - acc: 0.8013\n",
      "Epoch 106/200\n",
      "24173/24173 [==============================] - 1s 36us/step - loss: 8.0376 - f1_perRow: 0.8363 - f1_perClass: 0.6611 - acc: 0.8016\n",
      "Epoch 107/200\n",
      "24173/24173 [==============================] - 1s 36us/step - loss: 8.0558 - f1_perRow: 0.8362 - f1_perClass: 0.6557 - acc: 0.8001\n",
      "Epoch 108/200\n",
      "24173/24173 [==============================] - 1s 36us/step - loss: 8.0118 - f1_perRow: 0.8367 - f1_perClass: 0.6603 - acc: 0.8009\n",
      "Epoch 109/200\n",
      "24173/24173 [==============================] - 1s 35us/step - loss: 7.8485 - f1_perRow: 0.8383 - f1_perClass: 0.6674 - acc: 0.7999\n",
      "Epoch 110/200\n",
      "24173/24173 [==============================] - 1s 36us/step - loss: 8.1950 - f1_perRow: 0.8348 - f1_perClass: 0.6520 - acc: 0.7990\n",
      "Epoch 111/200\n",
      "24173/24173 [==============================] - 1s 36us/step - loss: 8.2573 - f1_perRow: 0.8342 - f1_perClass: 0.6560 - acc: 0.7990\n",
      "Epoch 112/200\n",
      "24173/24173 [==============================] - 1s 36us/step - loss: 7.7478 - f1_perRow: 0.8393 - f1_perClass: 0.6690 - acc: 0.7994\n",
      "Epoch 113/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24173/24173 [==============================] - 1s 36us/step - loss: 8.3135 - f1_perRow: 0.8337 - f1_perClass: 0.6509 - acc: 0.8008\n",
      "Epoch 114/200\n",
      "24173/24173 [==============================] - 1s 36us/step - loss: 7.9767 - f1_perRow: 0.8370 - f1_perClass: 0.6626 - acc: 0.7994\n",
      "Epoch 115/200\n",
      "24173/24173 [==============================] - 1s 36us/step - loss: 8.6456 - f1_perRow: 0.8303 - f1_perClass: 0.6441 - acc: 0.8009\n",
      "Epoch 116/200\n",
      "24173/24173 [==============================] - 1s 36us/step - loss: 7.7430 - f1_perRow: 0.8394 - f1_perClass: 0.6707 - acc: 0.7993\n",
      "Epoch 117/200\n",
      "24173/24173 [==============================] - 1s 35us/step - loss: 7.9841 - f1_perRow: 0.8369 - f1_perClass: 0.6616 - acc: 0.8018\n",
      "Epoch 118/200\n",
      "24173/24173 [==============================] - 1s 36us/step - loss: 7.8762 - f1_perRow: 0.8380 - f1_perClass: 0.6617 - acc: 0.8022\n",
      "Epoch 119/200\n",
      "24173/24173 [==============================] - 1s 36us/step - loss: 7.9279 - f1_perRow: 0.8375 - f1_perClass: 0.6658 - acc: 0.8016\n",
      "Epoch 120/200\n",
      "24173/24173 [==============================] - 1s 36us/step - loss: 8.3530 - f1_perRow: 0.8332 - f1_perClass: 0.6473 - acc: 0.8018\n",
      "Epoch 121/200\n",
      "24173/24173 [==============================] - 1s 36us/step - loss: 8.6492 - f1_perRow: 0.8302 - f1_perClass: 0.6364 - acc: 0.8004\n",
      "Epoch 122/200\n",
      "24173/24173 [==============================] - 1s 36us/step - loss: 8.2310 - f1_perRow: 0.8345 - f1_perClass: 0.6542 - acc: 0.8012\n",
      "Epoch 123/200\n",
      "24173/24173 [==============================] - 1s 36us/step - loss: 8.3040 - f1_perRow: 0.8336 - f1_perClass: 0.6503 - acc: 0.8001\n",
      "Epoch 124/200\n",
      "24173/24173 [==============================] - 1s 36us/step - loss: 8.0144 - f1_perRow: 0.8366 - f1_perClass: 0.6594 - acc: 0.7997\n",
      "Epoch 125/200\n",
      "24173/24173 [==============================] - 1s 35us/step - loss: 7.9918 - f1_perRow: 0.8368 - f1_perClass: 0.6617 - acc: 0.8001\n",
      "Epoch 126/200\n",
      "24173/24173 [==============================] - 1s 36us/step - loss: 8.0689 - f1_perRow: 0.8361 - f1_perClass: 0.6589 - acc: 0.7985\n",
      "Epoch 127/200\n",
      "24173/24173 [==============================] - 1s 36us/step - loss: 8.1984 - f1_perRow: 0.8347 - f1_perClass: 0.6588 - acc: 0.7982\n",
      "Epoch 128/200\n",
      "24173/24173 [==============================] - 1s 36us/step - loss: 7.8064 - f1_perRow: 0.8387 - f1_perClass: 0.6688 - acc: 0.8016\n",
      "Epoch 129/200\n",
      "24173/24173 [==============================] - 1s 35us/step - loss: 8.3200 - f1_perRow: 0.8335 - f1_perClass: 0.6510 - acc: 0.8039\n",
      "Epoch 130/200\n",
      "24173/24173 [==============================] - 1s 36us/step - loss: 7.8536 - f1_perRow: 0.8382 - f1_perClass: 0.6656 - acc: 0.8066\n",
      "Epoch 131/200\n",
      "24173/24173 [==============================] - 1s 35us/step - loss: 8.2530 - f1_perRow: 0.8342 - f1_perClass: 0.6570 - acc: 0.8050\n",
      "Epoch 132/200\n",
      "24173/24173 [==============================] - 1s 35us/step - loss: 8.2837 - f1_perRow: 0.8339 - f1_perClass: 0.6507 - acc: 0.8069\n",
      "Epoch 133/200\n",
      "24173/24173 [==============================] - 1s 36us/step - loss: 8.3157 - f1_perRow: 0.8336 - f1_perClass: 0.6500 - acc: 0.8050\n",
      "Epoch 134/200\n",
      "24173/24173 [==============================] - 1s 36us/step - loss: 8.3197 - f1_perRow: 0.8337 - f1_perClass: 0.6575 - acc: 0.8048\n",
      "Epoch 135/200\n",
      "24173/24173 [==============================] - 1s 36us/step - loss: 8.1759 - f1_perRow: 0.8351 - f1_perClass: 0.6591 - acc: 0.8056\n",
      "Epoch 136/200\n",
      "24173/24173 [==============================] - 1s 36us/step - loss: 8.3570 - f1_perRow: 0.8332 - f1_perClass: 0.6429 - acc: 0.8009\n",
      "Epoch 137/200\n",
      "24173/24173 [==============================] - 1s 36us/step - loss: 7.8292 - f1_perRow: 0.8385 - f1_perClass: 0.6674 - acc: 0.8017\n",
      "Epoch 138/200\n",
      "24173/24173 [==============================] - 1s 36us/step - loss: 7.8163 - f1_perRow: 0.8386 - f1_perClass: 0.6675 - acc: 0.8016\n",
      "Epoch 139/200\n",
      "24173/24173 [==============================] - 1s 35us/step - loss: 7.8052 - f1_perRow: 0.8387 - f1_perClass: 0.6647 - acc: 0.8027\n",
      "Epoch 140/200\n",
      "24173/24173 [==============================] - 1s 36us/step - loss: 8.6612 - f1_perRow: 0.8301 - f1_perClass: 0.6411 - acc: 0.8057\n",
      "Epoch 141/200\n",
      "24173/24173 [==============================] - 1s 36us/step - loss: 7.8241 - f1_perRow: 0.8386 - f1_perClass: 0.6650 - acc: 0.8039\n",
      "Epoch 142/200\n",
      "24173/24173 [==============================] - 1s 36us/step - loss: 7.9792 - f1_perRow: 0.8370 - f1_perClass: 0.6620 - acc: 0.8021\n",
      "Epoch 143/200\n",
      "24173/24173 [==============================] - 1s 35us/step - loss: 7.8290 - f1_perRow: 0.8385 - f1_perClass: 0.6633 - acc: 0.8030\n",
      "Epoch 144/200\n",
      "24173/24173 [==============================] - 1s 36us/step - loss: 7.9748 - f1_perRow: 0.8370 - f1_perClass: 0.6639 - acc: 0.8046\n",
      "Epoch 145/200\n",
      "24173/24173 [==============================] - 1s 36us/step - loss: 8.2460 - f1_perRow: 0.8344 - f1_perClass: 0.6504 - acc: 0.8067\n",
      "Epoch 146/200\n",
      "24173/24173 [==============================] - 1s 36us/step - loss: 8.2997 - f1_perRow: 0.8340 - f1_perClass: 0.6459 - acc: 0.8028\n",
      "Epoch 147/200\n",
      "24173/24173 [==============================] - 1s 36us/step - loss: 7.7599 - f1_perRow: 0.8392 - f1_perClass: 0.6696 - acc: 0.8028\n",
      "Epoch 148/200\n",
      "24173/24173 [==============================] - 1s 35us/step - loss: 8.0194 - f1_perRow: 0.8366 - f1_perClass: 0.6578 - acc: 0.8015\n",
      "Epoch 149/200\n",
      "24173/24173 [==============================] - 1s 36us/step - loss: 8.0672 - f1_perRow: 0.8362 - f1_perClass: 0.6552 - acc: 0.8028\n",
      "Epoch 150/200\n",
      "24173/24173 [==============================] - 1s 36us/step - loss: 8.1070 - f1_perRow: 0.8357 - f1_perClass: 0.6608 - acc: 0.8019\n",
      "Epoch 151/200\n",
      "24173/24173 [==============================] - 1s 36us/step - loss: 7.8823 - f1_perRow: 0.8379 - f1_perClass: 0.6569 - acc: 0.8029\n",
      "Epoch 152/200\n",
      "24173/24173 [==============================] - 1s 36us/step - loss: 7.9478 - f1_perRow: 0.8373 - f1_perClass: 0.6603 - acc: 0.8023\n",
      "Epoch 153/200\n",
      "24173/24173 [==============================] - 1s 36us/step - loss: 8.0562 - f1_perRow: 0.8362 - f1_perClass: 0.6584 - acc: 0.8033\n",
      "Epoch 154/200\n",
      "24173/24173 [==============================] - 1s 36us/step - loss: 8.2606 - f1_perRow: 0.8342 - f1_perClass: 0.6500 - acc: 0.8024\n",
      "Epoch 155/200\n",
      "24173/24173 [==============================] - 1s 36us/step - loss: 8.2917 - f1_perRow: 0.8340 - f1_perClass: 0.6509 - acc: 0.8052\n",
      "Epoch 156/200\n",
      "24173/24173 [==============================] - 1s 36us/step - loss: 9.2973 - f1_perRow: 0.8240 - f1_perClass: 0.6135 - acc: 0.8073\n",
      "Epoch 157/200\n",
      "24173/24173 [==============================] - 1s 36us/step - loss: 9.5429 - f1_perRow: 0.8217 - f1_perClass: 0.5982 - acc: 0.8089\n",
      "Epoch 158/200\n",
      "24173/24173 [==============================] - 1s 36us/step - loss: 9.5792 - f1_perRow: 0.8213 - f1_perClass: 0.5995 - acc: 0.8104\n",
      "Epoch 159/200\n",
      "24173/24173 [==============================] - 1s 36us/step - loss: 9.5786 - f1_perRow: 0.8213 - f1_perClass: 0.5991 - acc: 0.8115\n",
      "Epoch 160/200\n",
      "24173/24173 [==============================] - 1s 36us/step - loss: 9.4698 - f1_perRow: 0.8224 - f1_perClass: 0.6017 - acc: 0.8083\n",
      "Epoch 161/200\n",
      "24173/24173 [==============================] - 1s 36us/step - loss: 9.0678 - f1_perRow: 0.8263 - f1_perClass: 0.6097 - acc: 0.8034\n",
      "Epoch 162/200\n",
      "24173/24173 [==============================] - 1s 36us/step - loss: 8.4219 - f1_perRow: 0.8325 - f1_perClass: 0.6338 - acc: 0.8042\n",
      "Epoch 163/200\n",
      "24173/24173 [==============================] - 1s 36us/step - loss: 8.5708 - f1_perRow: 0.8310 - f1_perClass: 0.6498 - acc: 0.8050\n",
      "Epoch 164/200\n",
      "24173/24173 [==============================] - 1s 35us/step - loss: 8.6780 - f1_perRow: 0.8299 - f1_perClass: 0.6433 - acc: 0.8049\n",
      "Epoch 165/200\n",
      "24173/24173 [==============================] - 1s 36us/step - loss: 8.0079 - f1_perRow: 0.8367 - f1_perClass: 0.6638 - acc: 0.8016\n",
      "Epoch 166/200\n",
      "24173/24173 [==============================] - 1s 35us/step - loss: 7.8188 - f1_perRow: 0.8386 - f1_perClass: 0.6676 - acc: 0.8044\n",
      "Epoch 167/200\n",
      "24173/24173 [==============================] - 1s 36us/step - loss: 7.9726 - f1_perRow: 0.8370 - f1_perClass: 0.6620 - acc: 0.8057\n",
      "Epoch 168/200\n",
      "24173/24173 [==============================] - 1s 35us/step - loss: 8.1053 - f1_perRow: 0.8357 - f1_perClass: 0.6571 - acc: 0.8054\n",
      "Epoch 169/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24173/24173 [==============================] - 1s 36us/step - loss: 8.1147 - f1_perRow: 0.8356 - f1_perClass: 0.6565 - acc: 0.8045\n",
      "Epoch 170/200\n",
      "24173/24173 [==============================] - 1s 35us/step - loss: 7.7348 - f1_perRow: 0.8396 - f1_perClass: 0.6694 - acc: 0.8063\n",
      "Epoch 171/200\n",
      "24173/24173 [==============================] - 1s 36us/step - loss: 7.9454 - f1_perRow: 0.8373 - f1_perClass: 0.6621 - acc: 0.8030\n",
      "Epoch 172/200\n",
      "24173/24173 [==============================] - 1s 36us/step - loss: 7.9318 - f1_perRow: 0.8374 - f1_perClass: 0.6633 - acc: 0.8035\n",
      "Epoch 173/200\n",
      "24173/24173 [==============================] - 1s 36us/step - loss: 8.0424 - f1_perRow: 0.8364 - f1_perClass: 0.6604 - acc: 0.8055\n",
      "Epoch 174/200\n",
      "24173/24173 [==============================] - 1s 35us/step - loss: 8.2409 - f1_perRow: 0.8344 - f1_perClass: 0.6526 - acc: 0.8015\n",
      "Epoch 175/200\n",
      "24173/24173 [==============================] - 1s 35us/step - loss: 7.6910 - f1_perRow: 0.8400 - f1_perClass: 0.6703 - acc: 0.8019\n",
      "Epoch 176/200\n",
      "24173/24173 [==============================] - 1s 36us/step - loss: 7.6914 - f1_perRow: 0.8399 - f1_perClass: 0.6688 - acc: 0.8030\n",
      "Epoch 177/200\n",
      "24173/24173 [==============================] - 1s 35us/step - loss: 8.3134 - f1_perRow: 0.8338 - f1_perClass: 0.6445 - acc: 0.8060\n",
      "Epoch 178/200\n",
      "24173/24173 [==============================] - 1s 36us/step - loss: 7.9984 - f1_perRow: 0.8368 - f1_perClass: 0.6599 - acc: 0.8061\n",
      "Epoch 179/200\n",
      "24173/24173 [==============================] - 1s 36us/step - loss: 8.5047 - f1_perRow: 0.8319 - f1_perClass: 0.6515 - acc: 0.8056\n",
      "Epoch 180/200\n",
      "24173/24173 [==============================] - 1s 36us/step - loss: 7.7282 - f1_perRow: 0.8396 - f1_perClass: 0.6680 - acc: 0.8051\n",
      "Epoch 181/200\n",
      "24173/24173 [==============================] - 1s 36us/step - loss: 8.1688 - f1_perRow: 0.8351 - f1_perClass: 0.6539 - acc: 0.8040\n",
      "Epoch 182/200\n",
      "24173/24173 [==============================] - 1s 35us/step - loss: 8.5572 - f1_perRow: 0.8312 - f1_perClass: 0.6492 - acc: 0.8027\n",
      "Epoch 183/200\n",
      "24173/24173 [==============================] - 1s 36us/step - loss: 7.8435 - f1_perRow: 0.8383 - f1_perClass: 0.6692 - acc: 0.8045\n",
      "Epoch 184/200\n",
      "24173/24173 [==============================] - 1s 36us/step - loss: 8.2798 - f1_perRow: 0.8342 - f1_perClass: 0.6439 - acc: 0.8045\n",
      "Epoch 185/200\n",
      "24173/24173 [==============================] - 1s 36us/step - loss: 7.8631 - f1_perRow: 0.8382 - f1_perClass: 0.6629 - acc: 0.8066\n",
      "Epoch 186/200\n",
      "24173/24173 [==============================] - 1s 36us/step - loss: 8.7082 - f1_perRow: 0.8298 - f1_perClass: 0.6464 - acc: 0.8062\n",
      "Epoch 187/200\n",
      "24173/24173 [==============================] - 1s 36us/step - loss: 7.8638 - f1_perRow: 0.8382 - f1_perClass: 0.6637 - acc: 0.8049\n",
      "Epoch 188/200\n",
      "24173/24173 [==============================] - 1s 36us/step - loss: 8.0178 - f1_perRow: 0.8366 - f1_perClass: 0.6544 - acc: 0.8029\n",
      "Epoch 189/200\n",
      "24173/24173 [==============================] - 1s 36us/step - loss: 8.2613 - f1_perRow: 0.8342 - f1_perClass: 0.6566 - acc: 0.8028\n",
      "Epoch 190/200\n",
      "24173/24173 [==============================] - 1s 35us/step - loss: 8.1692 - f1_perRow: 0.8352 - f1_perClass: 0.6553 - acc: 0.8017\n",
      "Epoch 191/200\n",
      "24173/24173 [==============================] - 1s 36us/step - loss: 8.0346 - f1_perRow: 0.8365 - f1_perClass: 0.6552 - acc: 0.8030\n",
      "Epoch 192/200\n",
      "24173/24173 [==============================] - 1s 36us/step - loss: 7.7051 - f1_perRow: 0.8398 - f1_perClass: 0.6686 - acc: 0.8047\n",
      "Epoch 193/200\n",
      "24173/24173 [==============================] - 1s 36us/step - loss: 7.9732 - f1_perRow: 0.8371 - f1_perClass: 0.6620 - acc: 0.8059\n",
      "Epoch 194/200\n",
      "24173/24173 [==============================] - 1s 36us/step - loss: 8.4405 - f1_perRow: 0.8323 - f1_perClass: 0.6455 - acc: 0.8061\n",
      "Epoch 195/200\n",
      "24173/24173 [==============================] - 1s 36us/step - loss: 8.2936 - f1_perRow: 0.8338 - f1_perClass: 0.6533 - acc: 0.8064\n",
      "Epoch 196/200\n",
      "24173/24173 [==============================] - 1s 35us/step - loss: 7.8932 - f1_perRow: 0.8378 - f1_perClass: 0.6630 - acc: 0.8062\n",
      "Epoch 197/200\n",
      "24173/24173 [==============================] - 1s 36us/step - loss: 7.8381 - f1_perRow: 0.8384 - f1_perClass: 0.6666 - acc: 0.8045\n",
      "Epoch 198/200\n",
      "24173/24173 [==============================] - 1s 35us/step - loss: 8.0513 - f1_perRow: 0.8362 - f1_perClass: 0.6583 - acc: 0.8039\n",
      "Epoch 199/200\n",
      "24173/24173 [==============================] - 1s 36us/step - loss: 7.7672 - f1_perRow: 0.8393 - f1_perClass: 0.6657 - acc: 0.8026\n",
      "Epoch 200/200\n",
      "24173/24173 [==============================] - 1s 36us/step - loss: 7.6608 - f1_perRow: 0.8402 - f1_perClass: 0.6705 - acc: 0.8047\n"
     ]
    }
   ],
   "source": [
    "hist2 = model2.fit(x_lstm_prossed_train2, y_lstm_prossed_train, epochs=200, batch_size=7000, shuffle=True, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "24173/24173 [==============================] - 1s 35us/step - loss: 8.0696 - f1_perRow: 0.8362 - f1_perClass: 0.6062 - acc: 0.8013\n",
      "Epoch 2/300\n",
      "24173/24173 [==============================] - 1s 34us/step - loss: 7.8232 - f1_perRow: 0.8386 - f1_perClass: 0.6084 - acc: 0.8051\n",
      "Epoch 3/300\n",
      "24173/24173 [==============================] - 1s 33us/step - loss: 7.4057 - f1_perRow: 0.8430 - f1_perClass: 0.6115 - acc: 0.8043\n",
      "Epoch 4/300\n",
      "24173/24173 [==============================] - 1s 35us/step - loss: 7.4052 - f1_perRow: 0.8430 - f1_perClass: 0.6156 - acc: 0.7989\n",
      "Epoch 5/300\n",
      "24173/24173 [==============================] - 1s 33us/step - loss: 7.9314 - f1_perRow: 0.8378 - f1_perClass: 0.6030 - acc: 0.7977\n",
      "Epoch 6/300\n",
      "24173/24173 [==============================] - 1s 33us/step - loss: 7.8353 - f1_perRow: 0.8385 - f1_perClass: 0.6045 - acc: 0.7976\n",
      "Epoch 7/300\n",
      "24173/24173 [==============================] - 1s 34us/step - loss: 7.4379 - f1_perRow: 0.8426 - f1_perClass: 0.6100 - acc: 0.7980\n",
      "Epoch 8/300\n",
      "24173/24173 [==============================] - 1s 35us/step - loss: 7.5947 - f1_perRow: 0.8409 - f1_perClass: 0.6200 - acc: 0.7989\n",
      "Epoch 9/300\n",
      "24173/24173 [==============================] - 1s 34us/step - loss: 8.0719 - f1_perRow: 0.8365 - f1_perClass: 0.6059 - acc: 0.8018\n",
      "Epoch 10/300\n",
      "24173/24173 [==============================] - 1s 34us/step - loss: 7.4639 - f1_perRow: 0.8423 - f1_perClass: 0.6124 - acc: 0.8013\n",
      "Epoch 11/300\n",
      "24173/24173 [==============================] - 1s 33us/step - loss: 7.6910 - f1_perRow: 0.8400 - f1_perClass: 0.6042 - acc: 0.7985\n",
      "Epoch 12/300\n",
      "24173/24173 [==============================] - 1s 33us/step - loss: 7.7800 - f1_perRow: 0.8390 - f1_perClass: 0.6139 - acc: 0.7990\n",
      "Epoch 13/300\n",
      "24173/24173 [==============================] - 1s 34us/step - loss: 7.8444 - f1_perRow: 0.8383 - f1_perClass: 0.6006 - acc: 0.8024\n",
      "Epoch 14/300\n",
      "24173/24173 [==============================] - 1s 35us/step - loss: 7.4557 - f1_perRow: 0.8425 - f1_perClass: 0.6184 - acc: 0.8003\n",
      "Epoch 15/300\n",
      "24173/24173 [==============================] - 1s 34us/step - loss: 7.4613 - f1_perRow: 0.8423 - f1_perClass: 0.6147 - acc: 0.7993\n",
      "Epoch 16/300\n",
      "24173/24173 [==============================] - 1s 34us/step - loss: 7.3805 - f1_perRow: 0.8432 - f1_perClass: 0.6186 - acc: 0.8007\n",
      "Epoch 17/300\n",
      "24173/24173 [==============================] - 1s 34us/step - loss: 7.4353 - f1_perRow: 0.8426 - f1_perClass: 0.6125 - acc: 0.8018\n",
      "Epoch 18/300\n",
      "24173/24173 [==============================] - 1s 33us/step - loss: 7.3989 - f1_perRow: 0.8430 - f1_perClass: 0.6187 - acc: 0.8005\n",
      "Epoch 19/300\n",
      "24173/24173 [==============================] - 1s 34us/step - loss: 7.5289 - f1_perRow: 0.8417 - f1_perClass: 0.6069 - acc: 0.8036\n",
      "Epoch 20/300\n",
      "24173/24173 [==============================] - 1s 33us/step - loss: 7.9140 - f1_perRow: 0.8379 - f1_perClass: 0.6072 - acc: 0.8033\n",
      "Epoch 21/300\n",
      "24173/24173 [==============================] - 1s 34us/step - loss: 7.3728 - f1_perRow: 0.8433 - f1_perClass: 0.6220 - acc: 0.8045\n",
      "Epoch 22/300\n",
      "24173/24173 [==============================] - 1s 33us/step - loss: 8.0778 - f1_perRow: 0.8360 - f1_perClass: 0.6042 - acc: 0.8030\n",
      "Epoch 23/300\n",
      "24173/24173 [==============================] - 1s 34us/step - loss: 7.4853 - f1_perRow: 0.8421 - f1_perClass: 0.6110 - acc: 0.7984\n",
      "Epoch 24/300\n",
      "24173/24173 [==============================] - 1s 33us/step - loss: 7.2361 - f1_perRow: 0.8447 - f1_perClass: 0.6160 - acc: 0.7974\n",
      "Epoch 25/300\n",
      "24173/24173 [==============================] - 1s 33us/step - loss: 7.7201 - f1_perRow: 0.8396 - f1_perClass: 0.6097 - acc: 0.7993\n",
      "Epoch 26/300\n",
      "24173/24173 [==============================] - 1s 33us/step - loss: 7.4282 - f1_perRow: 0.8427 - f1_perClass: 0.6128 - acc: 0.8049\n",
      "Epoch 27/300\n",
      "24173/24173 [==============================] - 1s 33us/step - loss: 7.4897 - f1_perRow: 0.8421 - f1_perClass: 0.6188 - acc: 0.8035\n",
      "Epoch 28/300\n",
      "24173/24173 [==============================] - 1s 33us/step - loss: 7.4043 - f1_perRow: 0.8430 - f1_perClass: 0.6212 - acc: 0.8010\n",
      "Epoch 29/300\n",
      "24173/24173 [==============================] - 1s 34us/step - loss: 8.1525 - f1_perRow: 0.8353 - f1_perClass: 0.5962 - acc: 0.8020\n",
      "Epoch 30/300\n",
      "24173/24173 [==============================] - 1s 32us/step - loss: 7.4999 - f1_perRow: 0.8419 - f1_perClass: 0.6136 - acc: 0.8004\n",
      "Epoch 31/300\n",
      "24173/24173 [==============================] - 1s 33us/step - loss: 7.9226 - f1_perRow: 0.8376 - f1_perClass: 0.6032 - acc: 0.8008\n",
      "Epoch 32/300\n",
      "24173/24173 [==============================] - 1s 34us/step - loss: 7.4538 - f1_perRow: 0.8424 - f1_perClass: 0.6199 - acc: 0.8037\n",
      "Epoch 33/300\n",
      "24173/24173 [==============================] - 1s 34us/step - loss: 7.6172 - f1_perRow: 0.8407 - f1_perClass: 0.6160 - acc: 0.8032\n",
      "Epoch 34/300\n",
      "24173/24173 [==============================] - 1s 33us/step - loss: 7.4438 - f1_perRow: 0.8426 - f1_perClass: 0.6164 - acc: 0.8039\n",
      "Epoch 35/300\n",
      "24173/24173 [==============================] - 1s 34us/step - loss: 7.7942 - f1_perRow: 0.8389 - f1_perClass: 0.6156 - acc: 0.8022\n",
      "Epoch 36/300\n",
      "24173/24173 [==============================] - 1s 33us/step - loss: 8.3846 - f1_perRow: 0.8332 - f1_perClass: 0.5907 - acc: 0.8032\n",
      "Epoch 37/300\n",
      "24173/24173 [==============================] - 1s 34us/step - loss: 8.0064 - f1_perRow: 0.8367 - f1_perClass: 0.6039 - acc: 0.7992\n",
      "Epoch 38/300\n",
      "24173/24173 [==============================] - 1s 34us/step - loss: 7.9989 - f1_perRow: 0.8369 - f1_perClass: 0.6015 - acc: 0.7994\n",
      "Epoch 39/300\n",
      "24173/24173 [==============================] - 1s 34us/step - loss: 7.9052 - f1_perRow: 0.8377 - f1_perClass: 0.5985 - acc: 0.8021\n",
      "Epoch 40/300\n",
      "24173/24173 [==============================] - 1s 33us/step - loss: 8.7998 - f1_perRow: 0.8290 - f1_perClass: 0.5928 - acc: 0.8046\n",
      "Epoch 41/300\n",
      "24173/24173 [==============================] - 1s 34us/step - loss: 7.5196 - f1_perRow: 0.8417 - f1_perClass: 0.6117 - acc: 0.8019\n",
      "Epoch 42/300\n",
      "24173/24173 [==============================] - 1s 33us/step - loss: 8.0561 - f1_perRow: 0.8362 - f1_perClass: 0.6010 - acc: 0.7986\n",
      "Epoch 43/300\n",
      "24173/24173 [==============================] - 1s 34us/step - loss: 7.3351 - f1_perRow: 0.8436 - f1_perClass: 0.6194 - acc: 0.7992\n",
      "Epoch 44/300\n",
      "24173/24173 [==============================] - 1s 33us/step - loss: 8.4096 - f1_perRow: 0.8329 - f1_perClass: 0.5902 - acc: 0.8001\n",
      "Epoch 45/300\n",
      "24173/24173 [==============================] - 1s 34us/step - loss: 7.6419 - f1_perRow: 0.8404 - f1_perClass: 0.5988 - acc: 0.8007\n",
      "Epoch 46/300\n",
      "24173/24173 [==============================] - 1s 33us/step - loss: 7.5937 - f1_perRow: 0.8410 - f1_perClass: 0.6177 - acc: 0.7994\n",
      "Epoch 47/300\n",
      "24173/24173 [==============================] - 1s 34us/step - loss: 7.5123 - f1_perRow: 0.8418 - f1_perClass: 0.6230 - acc: 0.7997\n",
      "Epoch 48/300\n",
      "24173/24173 [==============================] - 1s 33us/step - loss: 7.5014 - f1_perRow: 0.8420 - f1_perClass: 0.6141 - acc: 0.7983\n",
      "Epoch 49/300\n",
      "24173/24173 [==============================] - 1s 34us/step - loss: 7.4567 - f1_perRow: 0.8426 - f1_perClass: 0.6194 - acc: 0.8016\n",
      "Epoch 50/300\n",
      "24173/24173 [==============================] - 1s 33us/step - loss: 7.8735 - f1_perRow: 0.8382 - f1_perClass: 0.6113 - acc: 0.8040\n",
      "Epoch 51/300\n",
      "24173/24173 [==============================] - 1s 33us/step - loss: 7.2765 - f1_perRow: 0.8443 - f1_perClass: 0.6115 - acc: 0.8052\n",
      "Epoch 52/300\n",
      "24173/24173 [==============================] - 1s 34us/step - loss: 7.4469 - f1_perRow: 0.8425 - f1_perClass: 0.6120 - acc: 0.8032\n",
      "Epoch 53/300\n",
      "24173/24173 [==============================] - 1s 33us/step - loss: 7.8413 - f1_perRow: 0.8384 - f1_perClass: 0.6084 - acc: 0.8014\n",
      "Epoch 54/300\n",
      "24173/24173 [==============================] - 1s 33us/step - loss: 7.5290 - f1_perRow: 0.8419 - f1_perClass: 0.6159 - acc: 0.7996\n",
      "Epoch 55/300\n",
      "24173/24173 [==============================] - 1s 33us/step - loss: 8.1186 - f1_perRow: 0.8359 - f1_perClass: 0.5886 - acc: 0.8035\n",
      "Epoch 56/300\n",
      "24173/24173 [==============================] - 1s 33us/step - loss: 7.6038 - f1_perRow: 0.8412 - f1_perClass: 0.6144 - acc: 0.8048\n",
      "Epoch 57/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24173/24173 [==============================] - 1s 33us/step - loss: 8.6820 - f1_perRow: 0.8301 - f1_perClass: 0.5982 - acc: 0.8045\n",
      "Epoch 58/300\n",
      "24173/24173 [==============================] - 1s 34us/step - loss: 7.4773 - f1_perRow: 0.8422 - f1_perClass: 0.6211 - acc: 0.8032\n",
      "Epoch 59/300\n",
      "24173/24173 [==============================] - 1s 33us/step - loss: 8.6368 - f1_perRow: 0.8305 - f1_perClass: 0.5842 - acc: 0.7997\n",
      "Epoch 60/300\n",
      "24173/24173 [==============================] - 1s 34us/step - loss: 8.2889 - f1_perRow: 0.8339 - f1_perClass: 0.5895 - acc: 0.8012\n",
      "Epoch 61/300\n",
      "24173/24173 [==============================] - 1s 34us/step - loss: 7.7256 - f1_perRow: 0.8397 - f1_perClass: 0.6140 - acc: 0.8039\n",
      "Epoch 62/300\n",
      "24173/24173 [==============================] - 1s 33us/step - loss: 7.4365 - f1_perRow: 0.8426 - f1_perClass: 0.6175 - acc: 0.8044\n",
      "Epoch 63/300\n",
      "24173/24173 [==============================] - 1s 34us/step - loss: 7.3623 - f1_perRow: 0.8433 - f1_perClass: 0.6203 - acc: 0.8062\n",
      "Epoch 64/300\n",
      "24173/24173 [==============================] - 1s 34us/step - loss: 7.3030 - f1_perRow: 0.8440 - f1_perClass: 0.6207 - acc: 0.8032\n",
      "Epoch 65/300\n",
      "24173/24173 [==============================] - 1s 34us/step - loss: 7.2330 - f1_perRow: 0.8447 - f1_perClass: 0.6139 - acc: 0.8006\n",
      "Epoch 66/300\n",
      "24173/24173 [==============================] - 1s 34us/step - loss: 7.5140 - f1_perRow: 0.8418 - f1_perClass: 0.6097 - acc: 0.8011\n",
      "Epoch 67/300\n",
      "24173/24173 [==============================] - 1s 34us/step - loss: 7.3698 - f1_perRow: 0.8433 - f1_perClass: 0.6155 - acc: 0.8028\n",
      "Epoch 68/300\n",
      "24173/24173 [==============================] - 1s 34us/step - loss: 7.2787 - f1_perRow: 0.8443 - f1_perClass: 0.6209 - acc: 0.8045\n",
      "Epoch 69/300\n",
      "24173/24173 [==============================] - 1s 34us/step - loss: 8.4029 - f1_perRow: 0.8328 - f1_perClass: 0.6026 - acc: 0.8031\n",
      "Epoch 70/300\n",
      "24173/24173 [==============================] - 1s 33us/step - loss: 7.7618 - f1_perRow: 0.8393 - f1_perClass: 0.6149 - acc: 0.8011\n",
      "Epoch 71/300\n",
      "24173/24173 [==============================] - 1s 33us/step - loss: 7.4700 - f1_perRow: 0.8423 - f1_perClass: 0.6130 - acc: 0.8010\n",
      "Epoch 72/300\n",
      "24173/24173 [==============================] - 1s 33us/step - loss: 7.5462 - f1_perRow: 0.8414 - f1_perClass: 0.6064 - acc: 0.8022\n",
      "Epoch 73/300\n",
      "24173/24173 [==============================] - 1s 33us/step - loss: 7.2476 - f1_perRow: 0.8448 - f1_perClass: 0.6190 - acc: 0.8028\n",
      "Epoch 74/300\n",
      "24173/24173 [==============================] - 1s 34us/step - loss: 7.2197 - f1_perRow: 0.8449 - f1_perClass: 0.6212 - acc: 0.8008\n",
      "Epoch 75/300\n",
      "24173/24173 [==============================] - 1s 33us/step - loss: 7.4190 - f1_perRow: 0.8428 - f1_perClass: 0.6236 - acc: 0.7988\n",
      "Epoch 76/300\n",
      "24173/24173 [==============================] - 1s 33us/step - loss: 7.5697 - f1_perRow: 0.8413 - f1_perClass: 0.6049 - acc: 0.8020\n",
      "Epoch 77/300\n",
      "24173/24173 [==============================] - 1s 33us/step - loss: 8.0409 - f1_perRow: 0.8367 - f1_perClass: 0.6026 - acc: 0.8011\n",
      "Epoch 78/300\n",
      "24173/24173 [==============================] - 1s 33us/step - loss: 7.3060 - f1_perRow: 0.8440 - f1_perClass: 0.6163 - acc: 0.7995\n",
      "Epoch 79/300\n",
      "24173/24173 [==============================] - 1s 32us/step - loss: 7.5882 - f1_perRow: 0.8410 - f1_perClass: 0.6131 - acc: 0.8015\n",
      "Epoch 80/300\n",
      "24173/24173 [==============================] - 1s 33us/step - loss: 7.3410 - f1_perRow: 0.8436 - f1_perClass: 0.6133 - acc: 0.8023\n",
      "Epoch 81/300\n",
      "24173/24173 [==============================] - 1s 34us/step - loss: 7.8707 - f1_perRow: 0.8382 - f1_perClass: 0.6001 - acc: 0.8030\n",
      "Epoch 82/300\n",
      "24173/24173 [==============================] - 1s 33us/step - loss: 7.2196 - f1_perRow: 0.8449 - f1_perClass: 0.6196 - acc: 0.8045\n",
      "Epoch 83/300\n",
      "24173/24173 [==============================] - 1s 35us/step - loss: 7.4425 - f1_perRow: 0.8425 - f1_perClass: 0.6188 - acc: 0.8058\n",
      "Epoch 84/300\n",
      "24173/24173 [==============================] - 1s 33us/step - loss: 7.3653 - f1_perRow: 0.8434 - f1_perClass: 0.6198 - acc: 0.8055\n",
      "Epoch 85/300\n",
      "24173/24173 [==============================] - 1s 34us/step - loss: 7.7845 - f1_perRow: 0.8391 - f1_perClass: 0.6111 - acc: 0.8030\n",
      "Epoch 86/300\n",
      "24173/24173 [==============================] - 1s 33us/step - loss: 7.2566 - f1_perRow: 0.8445 - f1_perClass: 0.6251 - acc: 0.7992\n",
      "Epoch 87/300\n",
      "24173/24173 [==============================] - 1s 33us/step - loss: 7.3000 - f1_perRow: 0.8441 - f1_perClass: 0.6246 - acc: 0.8004\n",
      "Epoch 88/300\n",
      "24173/24173 [==============================] - 1s 33us/step - loss: 8.1618 - f1_perRow: 0.8353 - f1_perClass: 0.5974 - acc: 0.8056\n",
      "Epoch 89/300\n",
      "24173/24173 [==============================] - 1s 33us/step - loss: 8.0439 - f1_perRow: 0.8364 - f1_perClass: 0.6006 - acc: 0.8035\n",
      "Epoch 90/300\n",
      "24173/24173 [==============================] - 1s 33us/step - loss: 7.2282 - f1_perRow: 0.8448 - f1_perClass: 0.6234 - acc: 0.7992\n",
      "Epoch 91/300\n",
      "24173/24173 [==============================] - 1s 34us/step - loss: 7.5709 - f1_perRow: 0.8412 - f1_perClass: 0.6070 - acc: 0.7984\n",
      "Epoch 92/300\n",
      "24173/24173 [==============================] - 1s 33us/step - loss: 7.5645 - f1_perRow: 0.8414 - f1_perClass: 0.6078 - acc: 0.8042\n",
      "Epoch 93/300\n",
      "24173/24173 [==============================] - 1s 33us/step - loss: 7.5032 - f1_perRow: 0.8419 - f1_perClass: 0.6144 - acc: 0.8071\n",
      "Epoch 94/300\n",
      "24173/24173 [==============================] - 1s 33us/step - loss: 7.5947 - f1_perRow: 0.8409 - f1_perClass: 0.6037 - acc: 0.8057\n",
      "Epoch 95/300\n",
      "24173/24173 [==============================] - 1s 33us/step - loss: 7.3185 - f1_perRow: 0.8438 - f1_perClass: 0.6217 - acc: 0.8055\n",
      "Epoch 96/300\n",
      "24173/24173 [==============================] - 1s 34us/step - loss: 7.7138 - f1_perRow: 0.8399 - f1_perClass: 0.6072 - acc: 0.8018\n",
      "Epoch 97/300\n",
      "24173/24173 [==============================] - 1s 34us/step - loss: 7.2616 - f1_perRow: 0.8445 - f1_perClass: 0.6186 - acc: 0.8032\n",
      "Epoch 98/300\n",
      "24173/24173 [==============================] - 1s 35us/step - loss: 8.0890 - f1_perRow: 0.8361 - f1_perClass: 0.6043 - acc: 0.8020\n",
      "Epoch 99/300\n",
      "24173/24173 [==============================] - 1s 33us/step - loss: 7.4011 - f1_perRow: 0.8430 - f1_perClass: 0.6220 - acc: 0.8018\n",
      "Epoch 100/300\n",
      "24173/24173 [==============================] - 1s 34us/step - loss: 7.3638 - f1_perRow: 0.8434 - f1_perClass: 0.6121 - acc: 0.8048\n",
      "Epoch 101/300\n",
      "24173/24173 [==============================] - 1s 34us/step - loss: 7.2396 - f1_perRow: 0.8447 - f1_perClass: 0.6197 - acc: 0.8035\n",
      "Epoch 102/300\n",
      "24173/24173 [==============================] - 1s 34us/step - loss: 7.3539 - f1_perRow: 0.8434 - f1_perClass: 0.6186 - acc: 0.8024\n",
      "Epoch 103/300\n",
      "24173/24173 [==============================] - 1s 34us/step - loss: 7.6605 - f1_perRow: 0.8403 - f1_perClass: 0.6178 - acc: 0.7968\n",
      "Epoch 104/300\n",
      "24173/24173 [==============================] - 1s 33us/step - loss: 8.3451 - f1_perRow: 0.8334 - f1_perClass: 0.5922 - acc: 0.8011\n",
      "Epoch 105/300\n",
      "24173/24173 [==============================] - 1s 33us/step - loss: 7.5115 - f1_perRow: 0.8418 - f1_perClass: 0.6158 - acc: 0.7996\n",
      "Epoch 106/300\n",
      "24173/24173 [==============================] - 1s 33us/step - loss: 7.3089 - f1_perRow: 0.8439 - f1_perClass: 0.6238 - acc: 0.7993\n",
      "Epoch 107/300\n",
      "24173/24173 [==============================] - 1s 34us/step - loss: 7.6590 - f1_perRow: 0.8405 - f1_perClass: 0.6095 - acc: 0.7994\n",
      "Epoch 108/300\n",
      "24173/24173 [==============================] - 1s 33us/step - loss: 7.2492 - f1_perRow: 0.8446 - f1_perClass: 0.6214 - acc: 0.7991\n",
      "Epoch 109/300\n",
      "24173/24173 [==============================] - 1s 34us/step - loss: 7.8041 - f1_perRow: 0.8390 - f1_perClass: 0.6038 - acc: 0.8004\n",
      "Epoch 110/300\n",
      "24173/24173 [==============================] - 1s 33us/step - loss: 7.4412 - f1_perRow: 0.8426 - f1_perClass: 0.6038 - acc: 0.8005\n",
      "Epoch 111/300\n",
      "24173/24173 [==============================] - 1s 32us/step - loss: 7.5948 - f1_perRow: 0.8410 - f1_perClass: 0.6177 - acc: 0.8026\n",
      "Epoch 112/300\n",
      "24173/24173 [==============================] - 1s 34us/step - loss: 7.2825 - f1_perRow: 0.8443 - f1_perClass: 0.6132 - acc: 0.8033\n",
      "Epoch 113/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24173/24173 [==============================] - 1s 34us/step - loss: 7.8636 - f1_perRow: 0.8383 - f1_perClass: 0.6053 - acc: 0.8052\n",
      "Epoch 114/300\n",
      "24173/24173 [==============================] - 1s 33us/step - loss: 7.7305 - f1_perRow: 0.8395 - f1_perClass: 0.6137 - acc: 0.8046\n",
      "Epoch 115/300\n",
      "24173/24173 [==============================] - 1s 34us/step - loss: 7.9217 - f1_perRow: 0.8382 - f1_perClass: 0.6036 - acc: 0.8050\n",
      "Epoch 116/300\n",
      "24173/24173 [==============================] - 1s 34us/step - loss: 7.5282 - f1_perRow: 0.8417 - f1_perClass: 0.6137 - acc: 0.8049\n",
      "Epoch 117/300\n",
      "24173/24173 [==============================] - 1s 34us/step - loss: 8.1374 - f1_perRow: 0.8356 - f1_perClass: 0.6041 - acc: 0.8042\n",
      "Epoch 118/300\n",
      "24173/24173 [==============================] - 1s 33us/step - loss: 7.3709 - f1_perRow: 0.8433 - f1_perClass: 0.6233 - acc: 0.8012\n",
      "Epoch 119/300\n",
      "24173/24173 [==============================] - 1s 33us/step - loss: 7.4865 - f1_perRow: 0.8421 - f1_perClass: 0.6190 - acc: 0.8010\n",
      "Epoch 120/300\n",
      "24173/24173 [==============================] - 1s 33us/step - loss: 7.9183 - f1_perRow: 0.8377 - f1_perClass: 0.6062 - acc: 0.8041\n",
      "Epoch 121/300\n",
      "24173/24173 [==============================] - 1s 35us/step - loss: 7.2237 - f1_perRow: 0.8448 - f1_perClass: 0.6123 - acc: 0.8037\n",
      "Epoch 122/300\n",
      "24173/24173 [==============================] - 1s 33us/step - loss: 7.3894 - f1_perRow: 0.8431 - f1_perClass: 0.6191 - acc: 0.8029\n",
      "Epoch 123/300\n",
      "24173/24173 [==============================] - 1s 34us/step - loss: 7.3978 - f1_perRow: 0.8430 - f1_perClass: 0.6172 - acc: 0.8030\n",
      "Epoch 124/300\n",
      "24173/24173 [==============================] - 1s 33us/step - loss: 7.6043 - f1_perRow: 0.8411 - f1_perClass: 0.6049 - acc: 0.8043\n",
      "Epoch 125/300\n",
      "24173/24173 [==============================] - 1s 33us/step - loss: 7.2986 - f1_perRow: 0.8441 - f1_perClass: 0.6201 - acc: 0.8048\n",
      "Epoch 126/300\n",
      "24173/24173 [==============================] - 1s 34us/step - loss: 7.7203 - f1_perRow: 0.8397 - f1_perClass: 0.6046 - acc: 0.8039\n",
      "Epoch 127/300\n",
      "24173/24173 [==============================] - 1s 33us/step - loss: 7.2297 - f1_perRow: 0.8449 - f1_perClass: 0.6162 - acc: 0.8049\n",
      "Epoch 128/300\n",
      "24173/24173 [==============================] - 1s 33us/step - loss: 7.2726 - f1_perRow: 0.8443 - f1_perClass: 0.6135 - acc: 0.8042\n",
      "Epoch 129/300\n",
      "24173/24173 [==============================] - 1s 33us/step - loss: 7.2844 - f1_perRow: 0.8443 - f1_perClass: 0.6241 - acc: 0.8035\n",
      "Epoch 130/300\n",
      "24173/24173 [==============================] - 1s 33us/step - loss: 7.4784 - f1_perRow: 0.8421 - f1_perClass: 0.6221 - acc: 0.8021\n",
      "Epoch 131/300\n",
      "24173/24173 [==============================] - 1s 33us/step - loss: 7.3510 - f1_perRow: 0.8435 - f1_perClass: 0.6161 - acc: 0.8034\n",
      "Epoch 132/300\n",
      "24173/24173 [==============================] - 1s 33us/step - loss: 7.2756 - f1_perRow: 0.8443 - f1_perClass: 0.6185 - acc: 0.8034\n",
      "Epoch 133/300\n",
      "24173/24173 [==============================] - 1s 33us/step - loss: 7.9788 - f1_perRow: 0.8375 - f1_perClass: 0.6074 - acc: 0.8028\n",
      "Epoch 134/300\n",
      "24173/24173 [==============================] - 1s 34us/step - loss: 7.2623 - f1_perRow: 0.8444 - f1_perClass: 0.6212 - acc: 0.8001\n",
      "Epoch 135/300\n",
      "24173/24173 [==============================] - 1s 33us/step - loss: 7.3980 - f1_perRow: 0.8430 - f1_perClass: 0.6219 - acc: 0.8012\n",
      "Epoch 136/300\n",
      "24173/24173 [==============================] - 1s 33us/step - loss: 7.4920 - f1_perRow: 0.8421 - f1_perClass: 0.6184 - acc: 0.8019\n",
      "Epoch 137/300\n",
      "24173/24173 [==============================] - 1s 33us/step - loss: 7.6386 - f1_perRow: 0.8405 - f1_perClass: 0.6134 - acc: 0.7993\n",
      "Epoch 138/300\n",
      "24173/24173 [==============================] - 1s 33us/step - loss: 7.3359 - f1_perRow: 0.8437 - f1_perClass: 0.6099 - acc: 0.8013\n",
      "Epoch 139/300\n",
      "24173/24173 [==============================] - 1s 33us/step - loss: 7.3065 - f1_perRow: 0.8441 - f1_perClass: 0.6231 - acc: 0.8080\n",
      "Epoch 140/300\n",
      "24173/24173 [==============================] - 1s 34us/step - loss: 7.6692 - f1_perRow: 0.8402 - f1_perClass: 0.6115 - acc: 0.8075\n",
      "Epoch 141/300\n",
      "24173/24173 [==============================] - 1s 33us/step - loss: 7.4806 - f1_perRow: 0.8422 - f1_perClass: 0.6185 - acc: 0.8036\n",
      "Epoch 142/300\n",
      "24173/24173 [==============================] - 1s 33us/step - loss: 7.3565 - f1_perRow: 0.8435 - f1_perClass: 0.6087 - acc: 0.8041\n",
      "Epoch 143/300\n",
      "24173/24173 [==============================] - 1s 35us/step - loss: 7.5469 - f1_perRow: 0.8414 - f1_perClass: 0.6172 - acc: 0.8008\n",
      "Epoch 144/300\n",
      "24173/24173 [==============================] - 1s 34us/step - loss: 7.6334 - f1_perRow: 0.8406 - f1_perClass: 0.6118 - acc: 0.8013\n",
      "Epoch 145/300\n",
      "24173/24173 [==============================] - 1s 33us/step - loss: 7.8132 - f1_perRow: 0.8391 - f1_perClass: 0.5974 - acc: 0.8017\n",
      "Epoch 146/300\n",
      "24173/24173 [==============================] - 1s 34us/step - loss: 7.8723 - f1_perRow: 0.8381 - f1_perClass: 0.6010 - acc: 0.8028\n",
      "Epoch 147/300\n",
      "24173/24173 [==============================] - 1s 33us/step - loss: 7.4618 - f1_perRow: 0.8423 - f1_perClass: 0.6050 - acc: 0.8067\n",
      "Epoch 148/300\n",
      "24173/24173 [==============================] - 1s 33us/step - loss: 8.1745 - f1_perRow: 0.8352 - f1_perClass: 0.6011 - acc: 0.8052\n",
      "Epoch 149/300\n",
      "24173/24173 [==============================] - 1s 35us/step - loss: 8.0963 - f1_perRow: 0.8358 - f1_perClass: 0.5980 - acc: 0.8045\n",
      "Epoch 150/300\n",
      "24173/24173 [==============================] - 1s 34us/step - loss: 7.3613 - f1_perRow: 0.8434 - f1_perClass: 0.6181 - acc: 0.8018\n",
      "Epoch 151/300\n",
      "24173/24173 [==============================] - 1s 34us/step - loss: 7.4838 - f1_perRow: 0.8421 - f1_perClass: 0.6215 - acc: 0.8006\n",
      "Epoch 152/300\n",
      "24173/24173 [==============================] - 1s 34us/step - loss: 7.5445 - f1_perRow: 0.8415 - f1_perClass: 0.6111 - acc: 0.8042\n",
      "Epoch 153/300\n",
      "24173/24173 [==============================] - 1s 33us/step - loss: 7.9978 - f1_perRow: 0.8370 - f1_perClass: 0.6065 - acc: 0.8083\n",
      "Epoch 154/300\n",
      "24173/24173 [==============================] - 1s 34us/step - loss: 7.7659 - f1_perRow: 0.8393 - f1_perClass: 0.6055 - acc: 0.8057\n",
      "Epoch 155/300\n",
      "24173/24173 [==============================] - 1s 34us/step - loss: 7.9235 - f1_perRow: 0.8376 - f1_perClass: 0.6037 - acc: 0.7994\n",
      "Epoch 156/300\n",
      "24173/24173 [==============================] - 1s 34us/step - loss: 7.2958 - f1_perRow: 0.8441 - f1_perClass: 0.6258 - acc: 0.8004\n",
      "Epoch 157/300\n",
      "24173/24173 [==============================] - 1s 34us/step - loss: 7.4553 - f1_perRow: 0.8424 - f1_perClass: 0.6178 - acc: 0.8058\n",
      "Epoch 158/300\n",
      "24173/24173 [==============================] - 1s 34us/step - loss: 7.4123 - f1_perRow: 0.8429 - f1_perClass: 0.6180 - acc: 0.8060\n",
      "Epoch 159/300\n",
      "24173/24173 [==============================] - 1s 35us/step - loss: 7.4546 - f1_perRow: 0.8424 - f1_perClass: 0.6154 - acc: 0.8036\n",
      "Epoch 160/300\n",
      "24173/24173 [==============================] - 1s 33us/step - loss: 7.2161 - f1_perRow: 0.8450 - f1_perClass: 0.6256 - acc: 0.8033\n",
      "Epoch 161/300\n",
      "24173/24173 [==============================] - 1s 34us/step - loss: 7.9995 - f1_perRow: 0.8368 - f1_perClass: 0.6081 - acc: 0.8011\n",
      "Epoch 162/300\n",
      "24173/24173 [==============================] - 1s 34us/step - loss: 8.1100 - f1_perRow: 0.8360 - f1_perClass: 0.6025 - acc: 0.8025\n",
      "Epoch 163/300\n",
      "24173/24173 [==============================] - 1s 33us/step - loss: 8.3578 - f1_perRow: 0.8331 - f1_perClass: 0.5837 - acc: 0.8036\n",
      "Epoch 164/300\n",
      "24173/24173 [==============================] - 1s 34us/step - loss: 7.6941 - f1_perRow: 0.8400 - f1_perClass: 0.6104 - acc: 0.8053\n",
      "Epoch 165/300\n",
      "24173/24173 [==============================] - 1s 34us/step - loss: 8.2223 - f1_perRow: 0.8345 - f1_perClass: 0.6023 - acc: 0.8049\n",
      "Epoch 166/300\n",
      "24173/24173 [==============================] - 1s 34us/step - loss: 7.9324 - f1_perRow: 0.8378 - f1_perClass: 0.6026 - acc: 0.8052\n",
      "Epoch 167/300\n",
      "24173/24173 [==============================] - 1s 35us/step - loss: 8.5623 - f1_perRow: 0.8313 - f1_perClass: 0.5717 - acc: 0.7985\n",
      "Epoch 168/300\n",
      "24173/24173 [==============================] - 1s 34us/step - loss: 8.0875 - f1_perRow: 0.8360 - f1_perClass: 0.6034 - acc: 0.7985\n",
      "Epoch 169/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24173/24173 [==============================] - 1s 34us/step - loss: 8.7394 - f1_perRow: 0.8294 - f1_perClass: 0.6039 - acc: 0.8035\n",
      "Epoch 170/300\n",
      "24173/24173 [==============================] - 1s 34us/step - loss: 7.7661 - f1_perRow: 0.8391 - f1_perClass: 0.6134 - acc: 0.8092\n",
      "Epoch 171/300\n",
      "24173/24173 [==============================] - 1s 35us/step - loss: 8.0178 - f1_perRow: 0.8365 - f1_perClass: 0.5887 - acc: 0.8077\n",
      "Epoch 172/300\n",
      "24173/24173 [==============================] - 1s 33us/step - loss: 7.3958 - f1_perRow: 0.8430 - f1_perClass: 0.6124 - acc: 0.8047\n",
      "Epoch 173/300\n",
      "24173/24173 [==============================] - 1s 34us/step - loss: 8.0235 - f1_perRow: 0.8367 - f1_perClass: 0.6088 - acc: 0.8033\n",
      "Epoch 174/300\n",
      "24173/24173 [==============================] - 1s 34us/step - loss: 7.5050 - f1_perRow: 0.8419 - f1_perClass: 0.6194 - acc: 0.8015\n",
      "Epoch 175/300\n",
      "24173/24173 [==============================] - 1s 34us/step - loss: 7.7330 - f1_perRow: 0.8395 - f1_perClass: 0.6041 - acc: 0.8001\n",
      "Epoch 176/300\n",
      "24173/24173 [==============================] - 1s 33us/step - loss: 7.4666 - f1_perRow: 0.8423 - f1_perClass: 0.6138 - acc: 0.8065\n",
      "Epoch 177/300\n",
      "24173/24173 [==============================] - 1s 33us/step - loss: 7.5707 - f1_perRow: 0.8412 - f1_perClass: 0.6216 - acc: 0.8078\n",
      "Epoch 178/300\n",
      "24173/24173 [==============================] - 1s 34us/step - loss: 7.5355 - f1_perRow: 0.8415 - f1_perClass: 0.6125 - acc: 0.8071\n",
      "Epoch 179/300\n",
      "24173/24173 [==============================] - 1s 34us/step - loss: 7.3801 - f1_perRow: 0.8432 - f1_perClass: 0.6199 - acc: 0.8050\n",
      "Epoch 180/300\n",
      "24173/24173 [==============================] - 1s 32us/step - loss: 7.9717 - f1_perRow: 0.8371 - f1_perClass: 0.5975 - acc: 0.8033\n",
      "Epoch 181/300\n",
      "24173/24173 [==============================] - 1s 33us/step - loss: 7.2455 - f1_perRow: 0.8446 - f1_perClass: 0.6209 - acc: 0.8050\n",
      "Epoch 182/300\n",
      "24173/24173 [==============================] - 1s 34us/step - loss: 7.2439 - f1_perRow: 0.8446 - f1_perClass: 0.6178 - acc: 0.8073\n",
      "Epoch 183/300\n",
      "24173/24173 [==============================] - 1s 34us/step - loss: 7.7082 - f1_perRow: 0.8397 - f1_perClass: 0.6027 - acc: 0.8076\n",
      "Epoch 184/300\n",
      "24173/24173 [==============================] - 1s 33us/step - loss: 7.2726 - f1_perRow: 0.8443 - f1_perClass: 0.6249 - acc: 0.8059\n",
      "Epoch 185/300\n",
      "24173/24173 [==============================] - 1s 34us/step - loss: 7.5991 - f1_perRow: 0.8413 - f1_perClass: 0.6110 - acc: 0.8030\n",
      "Epoch 186/300\n",
      "24173/24173 [==============================] - 1s 33us/step - loss: 7.5564 - f1_perRow: 0.8414 - f1_perClass: 0.6115 - acc: 0.8047\n",
      "Epoch 187/300\n",
      "24173/24173 [==============================] - 1s 34us/step - loss: 7.1940 - f1_perRow: 0.8452 - f1_perClass: 0.6243 - acc: 0.8043\n",
      "Epoch 188/300\n",
      "24173/24173 [==============================] - 1s 33us/step - loss: 8.2207 - f1_perRow: 0.8346 - f1_perClass: 0.5952 - acc: 0.8022\n",
      "Epoch 189/300\n",
      "24173/24173 [==============================] - 1s 33us/step - loss: 8.1003 - f1_perRow: 0.8359 - f1_perClass: 0.5892 - acc: 0.7988\n",
      "Epoch 190/300\n",
      "24173/24173 [==============================] - 1s 35us/step - loss: 8.0357 - f1_perRow: 0.8364 - f1_perClass: 0.6091 - acc: 0.7993\n",
      "Epoch 191/300\n",
      "24173/24173 [==============================] - 1s 34us/step - loss: 7.6936 - f1_perRow: 0.8400 - f1_perClass: 0.6033 - acc: 0.8039\n",
      "Epoch 192/300\n",
      "24173/24173 [==============================] - 1s 33us/step - loss: 7.3188 - f1_perRow: 0.8438 - f1_perClass: 0.6161 - acc: 0.8064\n",
      "Epoch 193/300\n",
      "24173/24173 [==============================] - 1s 34us/step - loss: 7.6585 - f1_perRow: 0.8403 - f1_perClass: 0.6061 - acc: 0.8060\n",
      "Epoch 194/300\n",
      "24173/24173 [==============================] - 1s 34us/step - loss: 7.5590 - f1_perRow: 0.8415 - f1_perClass: 0.6233 - acc: 0.8036\n",
      "Epoch 195/300\n",
      "24173/24173 [==============================] - 1s 34us/step - loss: 7.4339 - f1_perRow: 0.8427 - f1_perClass: 0.6143 - acc: 0.8029\n",
      "Epoch 196/300\n",
      "24173/24173 [==============================] - 1s 33us/step - loss: 7.2645 - f1_perRow: 0.8444 - f1_perClass: 0.6234 - acc: 0.8033\n",
      "Epoch 197/300\n",
      "24173/24173 [==============================] - 1s 34us/step - loss: 7.5263 - f1_perRow: 0.8417 - f1_perClass: 0.6229 - acc: 0.8044\n",
      "Epoch 198/300\n",
      "24173/24173 [==============================] - 1s 34us/step - loss: 7.2275 - f1_perRow: 0.8448 - f1_perClass: 0.6146 - acc: 0.8062\n",
      "Epoch 199/300\n",
      "24173/24173 [==============================] - 1s 34us/step - loss: 7.4264 - f1_perRow: 0.8427 - f1_perClass: 0.6249 - acc: 0.8030\n",
      "Epoch 200/300\n",
      "24173/24173 [==============================] - 1s 33us/step - loss: 7.3348 - f1_perRow: 0.8438 - f1_perClass: 0.6218 - acc: 0.8041\n",
      "Epoch 201/300\n",
      "24173/24173 [==============================] - 1s 34us/step - loss: 7.6828 - f1_perRow: 0.8401 - f1_perClass: 0.6133 - acc: 0.8028\n",
      "Epoch 202/300\n",
      "24173/24173 [==============================] - 1s 34us/step - loss: 8.0577 - f1_perRow: 0.8362 - f1_perClass: 0.5981 - acc: 0.8003\n",
      "Epoch 203/300\n",
      "24173/24173 [==============================] - 1s 33us/step - loss: 7.8661 - f1_perRow: 0.8385 - f1_perClass: 0.6144 - acc: 0.8040\n",
      "Epoch 204/300\n",
      "24173/24173 [==============================] - 1s 33us/step - loss: 7.2500 - f1_perRow: 0.8446 - f1_perClass: 0.6303 - acc: 0.8071\n",
      "Epoch 205/300\n",
      "24173/24173 [==============================] - 1s 33us/step - loss: 7.3138 - f1_perRow: 0.8439 - f1_perClass: 0.6235 - acc: 0.8061\n",
      "Epoch 206/300\n",
      "24173/24173 [==============================] - 1s 33us/step - loss: 7.3238 - f1_perRow: 0.8439 - f1_perClass: 0.6174 - acc: 0.8050\n",
      "Epoch 207/300\n",
      "24173/24173 [==============================] - 1s 33us/step - loss: 7.3473 - f1_perRow: 0.8436 - f1_perClass: 0.6214 - acc: 0.8045\n",
      "Epoch 208/300\n",
      "24173/24173 [==============================] - 1s 33us/step - loss: 7.2473 - f1_perRow: 0.8446 - f1_perClass: 0.6215 - acc: 0.8042\n",
      "Epoch 209/300\n",
      "24173/24173 [==============================] - 1s 33us/step - loss: 7.3018 - f1_perRow: 0.8440 - f1_perClass: 0.6168 - acc: 0.8041\n",
      "Epoch 210/300\n",
      "24173/24173 [==============================] - 1s 33us/step - loss: 7.3226 - f1_perRow: 0.8438 - f1_perClass: 0.6119 - acc: 0.8028\n",
      "Epoch 211/300\n",
      "24173/24173 [==============================] - 1s 34us/step - loss: 7.5949 - f1_perRow: 0.8410 - f1_perClass: 0.6120 - acc: 0.8000\n",
      "Epoch 212/300\n",
      "24173/24173 [==============================] - 1s 33us/step - loss: 7.6505 - f1_perRow: 0.8405 - f1_perClass: 0.6122 - acc: 0.7995\n",
      "Epoch 213/300\n",
      "24173/24173 [==============================] - 1s 34us/step - loss: 7.1550 - f1_perRow: 0.8456 - f1_perClass: 0.6212 - acc: 0.8041\n",
      "Epoch 214/300\n",
      "24173/24173 [==============================] - 1s 34us/step - loss: 7.3021 - f1_perRow: 0.8440 - f1_perClass: 0.6103 - acc: 0.8064\n",
      "Epoch 215/300\n",
      "24173/24173 [==============================] - 1s 33us/step - loss: 7.2350 - f1_perRow: 0.8447 - f1_perClass: 0.6102 - acc: 0.8076\n",
      "Epoch 216/300\n",
      "24173/24173 [==============================] - 1s 34us/step - loss: 7.3124 - f1_perRow: 0.8439 - f1_perClass: 0.6225 - acc: 0.8098\n",
      "Epoch 217/300\n",
      "24173/24173 [==============================] - 1s 34us/step - loss: 7.4703 - f1_perRow: 0.8425 - f1_perClass: 0.6209 - acc: 0.8052\n",
      "Epoch 218/300\n",
      "24173/24173 [==============================] - 1s 33us/step - loss: 7.4393 - f1_perRow: 0.8426 - f1_perClass: 0.6142 - acc: 0.8038\n",
      "Epoch 219/300\n",
      "24173/24173 [==============================] - 1s 33us/step - loss: 7.6650 - f1_perRow: 0.8402 - f1_perClass: 0.6137 - acc: 0.8047\n",
      "Epoch 220/300\n",
      "24173/24173 [==============================] - 1s 33us/step - loss: 7.3178 - f1_perRow: 0.8438 - f1_perClass: 0.6167 - acc: 0.8060\n",
      "Epoch 221/300\n",
      "24173/24173 [==============================] - 1s 33us/step - loss: 7.5541 - f1_perRow: 0.8414 - f1_perClass: 0.6178 - acc: 0.8054\n",
      "Epoch 222/300\n",
      "24173/24173 [==============================] - 1s 33us/step - loss: 7.2674 - f1_perRow: 0.8444 - f1_perClass: 0.6223 - acc: 0.8085\n",
      "Epoch 223/300\n",
      "24173/24173 [==============================] - 1s 33us/step - loss: 7.2414 - f1_perRow: 0.8447 - f1_perClass: 0.6109 - acc: 0.8066\n",
      "Epoch 224/300\n",
      "24173/24173 [==============================] - 1s 34us/step - loss: 7.3838 - f1_perRow: 0.8432 - f1_perClass: 0.6134 - acc: 0.8052\n",
      "Epoch 225/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24173/24173 [==============================] - 1s 34us/step - loss: 7.7615 - f1_perRow: 0.8396 - f1_perClass: 0.6167 - acc: 0.8037\n",
      "Epoch 226/300\n",
      "24173/24173 [==============================] - 1s 33us/step - loss: 7.6707 - f1_perRow: 0.8401 - f1_perClass: 0.6106 - acc: 0.8034\n",
      "Epoch 227/300\n",
      "24173/24173 [==============================] - 1s 33us/step - loss: 7.2580 - f1_perRow: 0.8445 - f1_perClass: 0.6169 - acc: 0.8035\n",
      "Epoch 228/300\n",
      "24173/24173 [==============================] - 1s 33us/step - loss: 7.3693 - f1_perRow: 0.8435 - f1_perClass: 0.6226 - acc: 0.8040\n",
      "Epoch 229/300\n",
      "24173/24173 [==============================] - 1s 33us/step - loss: 7.3111 - f1_perRow: 0.8439 - f1_perClass: 0.6203 - acc: 0.8035\n",
      "Epoch 230/300\n",
      "24173/24173 [==============================] - 1s 33us/step - loss: 8.1803 - f1_perRow: 0.8351 - f1_perClass: 0.5978 - acc: 0.8030\n",
      "Epoch 231/300\n",
      "24173/24173 [==============================] - 1s 35us/step - loss: 7.7917 - f1_perRow: 0.8389 - f1_perClass: 0.5994 - acc: 0.8063\n",
      "Epoch 232/300\n",
      "24173/24173 [==============================] - 1s 34us/step - loss: 7.4765 - f1_perRow: 0.8422 - f1_perClass: 0.6197 - acc: 0.8065\n",
      "Epoch 233/300\n",
      "24173/24173 [==============================] - 1s 35us/step - loss: 7.5379 - f1_perRow: 0.8418 - f1_perClass: 0.6110 - acc: 0.8065\n",
      "Epoch 234/300\n",
      "24173/24173 [==============================] - 1s 34us/step - loss: 7.7250 - f1_perRow: 0.8398 - f1_perClass: 0.6117 - acc: 0.8061\n",
      "Epoch 235/300\n",
      "24173/24173 [==============================] - 1s 34us/step - loss: 7.6046 - f1_perRow: 0.8408 - f1_perClass: 0.6165 - acc: 0.8076\n",
      "Epoch 236/300\n",
      "24173/24173 [==============================] - 1s 34us/step - loss: 7.4828 - f1_perRow: 0.8421 - f1_perClass: 0.6158 - acc: 0.8042\n",
      "Epoch 237/300\n",
      "24173/24173 [==============================] - 1s 34us/step - loss: 7.3861 - f1_perRow: 0.8432 - f1_perClass: 0.6202 - acc: 0.8030\n",
      "Epoch 238/300\n",
      "24173/24173 [==============================] - 1s 35us/step - loss: 7.4691 - f1_perRow: 0.8424 - f1_perClass: 0.6127 - acc: 0.8052\n",
      "Epoch 239/300\n",
      "24173/24173 [==============================] - 1s 33us/step - loss: 7.2598 - f1_perRow: 0.8444 - f1_perClass: 0.6241 - acc: 0.8023\n",
      "Epoch 240/300\n",
      "24173/24173 [==============================] - 1s 34us/step - loss: 7.6373 - f1_perRow: 0.8405 - f1_perClass: 0.6137 - acc: 0.8039\n",
      "Epoch 241/300\n",
      "24173/24173 [==============================] - 1s 33us/step - loss: 7.5547 - f1_perRow: 0.8414 - f1_perClass: 0.6105 - acc: 0.8031\n",
      "Epoch 242/300\n",
      "24173/24173 [==============================] - 1s 35us/step - loss: 7.7377 - f1_perRow: 0.8395 - f1_perClass: 0.6097 - acc: 0.8038\n",
      "Epoch 243/300\n",
      "24173/24173 [==============================] - 1s 35us/step - loss: 7.7399 - f1_perRow: 0.8395 - f1_perClass: 0.6127 - acc: 0.8044\n",
      "Epoch 244/300\n",
      "24173/24173 [==============================] - 1s 33us/step - loss: 7.6097 - f1_perRow: 0.8408 - f1_perClass: 0.6159 - acc: 0.8055\n",
      "Epoch 245/300\n",
      "24173/24173 [==============================] - 1s 33us/step - loss: 7.6116 - f1_perRow: 0.8408 - f1_perClass: 0.6064 - acc: 0.8038\n",
      "Epoch 246/300\n",
      "24173/24173 [==============================] - 1s 33us/step - loss: 7.6681 - f1_perRow: 0.8401 - f1_perClass: 0.6142 - acc: 0.8016\n",
      "Epoch 247/300\n",
      "24173/24173 [==============================] - 1s 34us/step - loss: 7.3850 - f1_perRow: 0.8432 - f1_perClass: 0.6161 - acc: 0.8032\n",
      "Epoch 248/300\n",
      "24173/24173 [==============================] - 1s 34us/step - loss: 7.6382 - f1_perRow: 0.8405 - f1_perClass: 0.6077 - acc: 0.8062\n",
      "Epoch 249/300\n",
      "24173/24173 [==============================] - 1s 33us/step - loss: 7.2823 - f1_perRow: 0.8443 - f1_perClass: 0.6215 - acc: 0.8059\n",
      "Epoch 250/300\n",
      "24173/24173 [==============================] - 1s 34us/step - loss: 7.6250 - f1_perRow: 0.8407 - f1_perClass: 0.6068 - acc: 0.8059\n",
      "Epoch 251/300\n",
      "24173/24173 [==============================] - 1s 35us/step - loss: 7.3744 - f1_perRow: 0.8433 - f1_perClass: 0.6133 - acc: 0.8002\n",
      "Epoch 252/300\n",
      "24173/24173 [==============================] - 1s 34us/step - loss: 7.7617 - f1_perRow: 0.8392 - f1_perClass: 0.6163 - acc: 0.8018\n",
      "Epoch 253/300\n",
      "24173/24173 [==============================] - 1s 34us/step - loss: 7.3031 - f1_perRow: 0.8440 - f1_perClass: 0.6136 - acc: 0.8055\n",
      "Epoch 254/300\n",
      "24173/24173 [==============================] - 1s 34us/step - loss: 7.2551 - f1_perRow: 0.8446 - f1_perClass: 0.6154 - acc: 0.8069\n",
      "Epoch 255/300\n",
      "24173/24173 [==============================] - 1s 35us/step - loss: 7.6518 - f1_perRow: 0.8404 - f1_perClass: 0.6117 - acc: 0.8065\n",
      "Epoch 256/300\n",
      "24173/24173 [==============================] - 1s 34us/step - loss: 7.3492 - f1_perRow: 0.8436 - f1_perClass: 0.6071 - acc: 0.8057\n",
      "Epoch 257/300\n",
      "24173/24173 [==============================] - 1s 34us/step - loss: 7.6050 - f1_perRow: 0.8409 - f1_perClass: 0.6117 - acc: 0.8048\n",
      "Epoch 258/300\n",
      "24173/24173 [==============================] - 1s 33us/step - loss: 7.2760 - f1_perRow: 0.8443 - f1_perClass: 0.6236 - acc: 0.8042\n",
      "Epoch 259/300\n",
      "24173/24173 [==============================] - 1s 34us/step - loss: 7.7607 - f1_perRow: 0.8392 - f1_perClass: 0.6099 - acc: 0.8018\n",
      "Epoch 260/300\n",
      "24173/24173 [==============================] - 1s 35us/step - loss: 7.3270 - f1_perRow: 0.8438 - f1_perClass: 0.6041 - acc: 0.8018\n",
      "Epoch 261/300\n",
      "24173/24173 [==============================] - 1s 34us/step - loss: 7.2126 - f1_perRow: 0.8449 - f1_perClass: 0.6261 - acc: 0.8051\n",
      "Epoch 262/300\n",
      "24173/24173 [==============================] - 1s 34us/step - loss: 7.2711 - f1_perRow: 0.8443 - f1_perClass: 0.6141 - acc: 0.8042\n",
      "Epoch 263/300\n",
      "24173/24173 [==============================] - 1s 35us/step - loss: 7.2962 - f1_perRow: 0.8441 - f1_perClass: 0.6178 - acc: 0.8060\n",
      "Epoch 264/300\n",
      "24173/24173 [==============================] - 1s 34us/step - loss: 7.1930 - f1_perRow: 0.8452 - f1_perClass: 0.6215 - acc: 0.8068\n",
      "Epoch 265/300\n",
      "24173/24173 [==============================] - 1s 34us/step - loss: 7.5893 - f1_perRow: 0.8410 - f1_perClass: 0.6170 - acc: 0.8049\n",
      "Epoch 266/300\n",
      "24173/24173 [==============================] - 1s 34us/step - loss: 7.4869 - f1_perRow: 0.8421 - f1_perClass: 0.6133 - acc: 0.8047\n",
      "Epoch 267/300\n",
      "24173/24173 [==============================] - 1s 33us/step - loss: 7.1748 - f1_perRow: 0.8454 - f1_perClass: 0.6227 - acc: 0.8027\n",
      "Epoch 268/300\n",
      "24173/24173 [==============================] - 1s 34us/step - loss: 7.5696 - f1_perRow: 0.8413 - f1_perClass: 0.6185 - acc: 0.8046\n",
      "Epoch 269/300\n",
      "24173/24173 [==============================] - 1s 34us/step - loss: 7.2543 - f1_perRow: 0.8445 - f1_perClass: 0.6167 - acc: 0.8068\n",
      "Epoch 270/300\n",
      "24173/24173 [==============================] - 1s 34us/step - loss: 7.4266 - f1_perRow: 0.8428 - f1_perClass: 0.6108 - acc: 0.8067\n",
      "Epoch 271/300\n",
      "24173/24173 [==============================] - 1s 34us/step - loss: 7.2667 - f1_perRow: 0.8444 - f1_perClass: 0.6156 - acc: 0.8061\n",
      "Epoch 272/300\n",
      "24173/24173 [==============================] - 1s 34us/step - loss: 7.5059 - f1_perRow: 0.8421 - f1_perClass: 0.6070 - acc: 0.8025\n",
      "Epoch 273/300\n",
      "24173/24173 [==============================] - 1s 33us/step - loss: 7.7403 - f1_perRow: 0.8394 - f1_perClass: 0.6119 - acc: 0.8036\n",
      "Epoch 274/300\n",
      "24173/24173 [==============================] - 1s 34us/step - loss: 7.6974 - f1_perRow: 0.8398 - f1_perClass: 0.6117 - acc: 0.8062\n",
      "Epoch 275/300\n",
      "24173/24173 [==============================] - 1s 35us/step - loss: 7.1827 - f1_perRow: 0.8453 - f1_perClass: 0.6193 - acc: 0.8054\n",
      "Epoch 276/300\n",
      "24173/24173 [==============================] - 1s 34us/step - loss: 7.6252 - f1_perRow: 0.8407 - f1_perClass: 0.6133 - acc: 0.8034\n",
      "Epoch 277/300\n",
      "24173/24173 [==============================] - 1s 32us/step - loss: 8.0265 - f1_perRow: 0.8368 - f1_perClass: 0.5968 - acc: 0.8024\n",
      "Epoch 278/300\n",
      "24173/24173 [==============================] - 1s 35us/step - loss: 8.3181 - f1_perRow: 0.8337 - f1_perClass: 0.5842 - acc: 0.8035\n",
      "Epoch 279/300\n",
      "24173/24173 [==============================] - 1s 35us/step - loss: 7.5017 - f1_perRow: 0.8419 - f1_perClass: 0.6070 - acc: 0.8076\n",
      "Epoch 280/300\n",
      "24173/24173 [==============================] - 1s 46us/step - loss: 7.8866 - f1_perRow: 0.8381 - f1_perClass: 0.5936 - acc: 0.8071\n",
      "Epoch 281/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24173/24173 [==============================] - 1s 34us/step - loss: 7.6541 - f1_perRow: 0.8403 - f1_perClass: 0.6010 - acc: 0.8074\n",
      "Epoch 282/300\n",
      "24173/24173 [==============================] - 1s 35us/step - loss: 7.6204 - f1_perRow: 0.8408 - f1_perClass: 0.6208 - acc: 0.8061\n",
      "Epoch 283/300\n",
      "24173/24173 [==============================] - 1s 33us/step - loss: 7.9808 - f1_perRow: 0.8372 - f1_perClass: 0.6095 - acc: 0.8043\n",
      "Epoch 284/300\n",
      "24173/24173 [==============================] - 1s 35us/step - loss: 7.5123 - f1_perRow: 0.8418 - f1_perClass: 0.6136 - acc: 0.8042\n",
      "Epoch 285/300\n",
      "24173/24173 [==============================] - 1s 33us/step - loss: 7.3738 - f1_perRow: 0.8435 - f1_perClass: 0.6186 - acc: 0.8054\n",
      "Epoch 286/300\n",
      "24173/24173 [==============================] - 1s 34us/step - loss: 7.3469 - f1_perRow: 0.8437 - f1_perClass: 0.6235 - acc: 0.8039\n",
      "Epoch 287/300\n",
      "24173/24173 [==============================] - 1s 34us/step - loss: 7.4362 - f1_perRow: 0.8427 - f1_perClass: 0.6265 - acc: 0.8036\n",
      "Epoch 288/300\n",
      "24173/24173 [==============================] - 1s 34us/step - loss: 7.5137 - f1_perRow: 0.8418 - f1_perClass: 0.6091 - acc: 0.8084\n",
      "Epoch 289/300\n",
      "24173/24173 [==============================] - 1s 34us/step - loss: 8.0855 - f1_perRow: 0.8360 - f1_perClass: 0.6068 - acc: 0.8065\n",
      "Epoch 290/300\n",
      "24173/24173 [==============================] - 1s 34us/step - loss: 7.6270 - f1_perRow: 0.8406 - f1_perClass: 0.6182 - acc: 0.8016\n",
      "Epoch 291/300\n",
      "24173/24173 [==============================] - 1s 33us/step - loss: 8.0340 - f1_perRow: 0.8367 - f1_perClass: 0.5904 - acc: 0.8044\n",
      "Epoch 292/300\n",
      "24173/24173 [==============================] - 1s 34us/step - loss: 7.7514 - f1_perRow: 0.8393 - f1_perClass: 0.6012 - acc: 0.8071\n",
      "Epoch 293/300\n",
      "24173/24173 [==============================] - 1s 34us/step - loss: 7.6933 - f1_perRow: 0.8399 - f1_perClass: 0.6153 - acc: 0.8072\n",
      "Epoch 294/300\n",
      "24173/24173 [==============================] - 1s 34us/step - loss: 7.8824 - f1_perRow: 0.8380 - f1_perClass: 0.6148 - acc: 0.8074\n",
      "Epoch 295/300\n",
      "24173/24173 [==============================] - 1s 34us/step - loss: 7.5782 - f1_perRow: 0.8411 - f1_perClass: 0.6169 - acc: 0.8052\n",
      "Epoch 296/300\n",
      "24173/24173 [==============================] - 1s 34us/step - loss: 7.6958 - f1_perRow: 0.8400 - f1_perClass: 0.6118 - acc: 0.8041\n",
      "Epoch 297/300\n",
      "24173/24173 [==============================] - 1s 33us/step - loss: 7.3323 - f1_perRow: 0.8437 - f1_perClass: 0.6236 - acc: 0.8069\n",
      "Epoch 298/300\n",
      "24173/24173 [==============================] - 1s 33us/step - loss: 7.3996 - f1_perRow: 0.8430 - f1_perClass: 0.6214 - acc: 0.8047\n",
      "Epoch 299/300\n",
      "24173/24173 [==============================] - 1s 34us/step - loss: 7.7863 - f1_perRow: 0.8391 - f1_perClass: 0.6186 - acc: 0.8024\n",
      "Epoch 300/300\n",
      "24173/24173 [==============================] - 1s 34us/step - loss: 7.3530 - f1_perRow: 0.8435 - f1_perClass: 0.6040 - acc: 0.8028\n"
     ]
    }
   ],
   "source": [
    "hist2 = model2.fit(x_lstm_prossed_train2, y_lstm_prossed_train, epochs=300, batch_size=7000, shuffle=True, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.load_weights('IoTDownNet_cnn_nocca')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================HOME Case : MERGED =============\n",
      "                         Class  Accuracy     Recall  Precision   F Score    Count            TP/TN/FP/FN\n",
      "------------------------------------------------------------------------\n",
      "                        button     0.930      0.700     0.648     0.673        50    35/  415/   19/   15\n",
      "              colorTemperature     0.926      0.100     1.000     0.182        40     4/  444/    0/   36\n",
      "                       contact     0.884      0.900     0.469     0.616        50    45/  383/   51/    5\n",
      "                         level     0.860      0.600     0.385     0.469        50    30/  386/   48/   20\n",
      "                          lock     0.981      0.820     1.000     0.901        50    41/  434/    0/    9\n",
      "                        motion     0.874      0.160     0.296     0.208        50     8/  415/   19/   42\n",
      "                       no_logs     0.917      0.600     0.073     0.130         5     3/  441/   38/    2\n",
      "                          ping     0.977      0.980     0.831     0.899        50    49/  424/   10/    1\n",
      "                        status     0.895      0.900     0.495     0.638        50    45/  388/   46/    5\n",
      "                        switch     0.909      0.800     0.541     0.645        50    40/  400/   34/   10\n",
      "                   temperature     0.835      0.120     0.143     0.130        50     6/  398/   36/   44\n",
      "                     threeAxis     0.915      0.800     0.563     0.661        50    40/  403/   31/   10\n",
      "                       unknown     0.626      1.000     0.216     0.356        50    50/  253/  181/    0\n",
      "                         water     0.905        nan     0.000     0.000         0     0/  438/   46/    0\n",
      "------------------------------------------------------------------------\n",
      "                      AVERAGES     0.888      0.606     0.476     0.465       484     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "             Weighted AVERAGES     0.884      0.666     0.537     0.534       484     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "       known Weighted AVERAGES     0.908      0.635     0.567     0.550       484     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      " known -ping Weighted AVERAGES     0.900      0.600     0.540     0.515       484     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "       non zero count AVERAGES     0.887      0.652     0.512     0.501       484     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "Macro F1 : 0.464958\n",
      "sample F1 : 0.504060\n",
      "weighted F1 : 0.534089\n",
      "Exact Match ACC : 0.29132 \n",
      "Total Records : 484 \n",
      "Total ZXeros in True : 0 (0.000)%\n",
      "Total ZXeros in Test : 16 (0.033)%\n",
      "=============================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/omid/.conda/envs/iot/lib/python3.6/site-packages/ipykernel_launcher.py:8: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  \n",
      "/home/omid/.conda/envs/iot/lib/python3.6/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/home/omid/.conda/envs/iot/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(lstm_tests_known)) :\n",
    "    print( \"==================HOME Case : %s =============\" % test_names[i])\n",
    "    lstm_pred= model2.predict( lstm_tests_known[i][0])\n",
    "    \n",
    "#     print_info( lstm_tests[i][1], lstm_pred, classes , confidance=0.7)\n",
    "    print_info( lstm_tests_known[i][1], lstm_pred, classes , confidance=0.3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_tests_known[0][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def describe_output(classes, instance):\n",
    "    ret = [] \n",
    "    for x in range(len(instance)):\n",
    "        if instance[x] > 0.6:\n",
    "            ret.append(classes[x])\n",
    "    return ret\n",
    "def save_resutls(inp, y, y_hat, classes,the_name):\n",
    "    items = [] \n",
    "    for i in range(len(inp)):\n",
    "#         print(describe_output(classes, y[i]))\n",
    "        items.append({'inp': str(list(inp[i])),\n",
    "                     'true': list(describe_output(classes, y[i])),\n",
    "                     'pred': list(describe_output(classes, y_hat[i]))\n",
    "                     })\n",
    "#         print(items[-1])\n",
    "#         return\n",
    "    with open('cnn_for_karthika_'+the_name +'.json', 'w') as outfile:\n",
    "        json.dump(items, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "describe_output(['a','b'],[1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================HOME Case : home_os_final.json =============\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'rf_test_known' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-f12f6b9df906>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlstm_tests_known\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m\"==================HOME Case : %s =============\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mtest_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mlstm_pred\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mmodel2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mrf_test_known\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;31m#     save_resutls( lstm_tests_known[i][0], rf_test_known[i][1], lstm_pred,  classes, test_names[i] )\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#     break\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'rf_test_known' is not defined"
     ]
    }
   ],
   "source": [
    "lstm_pred = []\n",
    "for i in range(len(lstm_tests_known)) :\n",
    "    print( \"==================HOME Case : %s =============\" % test_names[i])\n",
    "    lstm_pred= model2.predict( rf_test_known[i][0])\n",
    "#     save_resutls( lstm_tests_known[i][0], rf_test_known[i][1], lstm_pred,  classes, test_names[i] )\n",
    "#     break \n",
    "#     print_info( lstm_tests[i][1], lstm_pred, classes , confidance=0.7)\n",
    "    print_info( rf_test_known[i][1], lstm_pred, classes , confidance=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_resutls( lstm_tests_known[0][0], rf_test_known[0][1], lstm_pred, classes, test_names[0] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "describe_output(classes, rf_test_known[0][1][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 10552, 1)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 10552, 128)        512       \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 10552, 128)        512       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 10552, 128)        0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 10552, 128)        0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 10552, 64)         24640     \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 10552, 30)         11400     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10552, 64)         1984      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10552, 32)         2080      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10552, 16)         528       \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 10552, 16)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 168832)            0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 16)                2701328   \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "Event_output (Dense)         (None, 17)                289       \n",
      "=================================================================\n",
      "Total params: 2,743,273\n",
      "Trainable params: 2,743,017\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/80\n",
      "  490/18925 [..............................] - ETA: 1:11:20 - loss: 55.6061 - f1_perRow: 0.0907 - f1_perClass: 0.1798 - acc: 0.3286"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-d0edcebc01ce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m \u001b[0mhist2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_lstm_prossed_train2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_lstm_prossed_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m80\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m70\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.conda/envs/iot/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/.conda/envs/iot/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/iot/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/iot/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/iot/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "inputs  = Input(  (x_lstm_prossed_train2[0].shape[0]  ,1) )\n",
    "\n",
    "\n",
    "out = Conv1D(128,3,padding='same')(inputs)\n",
    "out = BatchNormalization()(out)\n",
    "out = Activation('relu')(out)\n",
    "out = Dropout(0.2)(out)\n",
    "out = Conv1D(64,3,padding='same')(out)\n",
    "# bi_d_1 = Bidirectional( LSTM(200 ,  recurrent_dropout=0.12, return_sequences=True),input_shape=[dim_size,1],merge_mode='concat') (inputs)\n",
    "lstm_1 =  LSTM(30 ,  recurrent_dropout=0.04, return_sequences=True)(out)\n",
    "# lstm_2 = LSTM(30 ,  recurrent_dropout=0.14, return_sequences=True)(lstm_1)\n",
    "\n",
    "bi_d_1 =Dense(64, activation='relu')  (lstm_1)\n",
    "lstm_1 =  Dense(32, activation='relu')(bi_d_1)\n",
    "lstm_2 = Dense(16, activation='relu')(lstm_1)\n",
    "\n",
    "\n",
    "\n",
    "# td_1    = TimeDistributed(Dense(256, activation='relu'))(lstm_2)\n",
    "# dout_1  = Dropout(0.1)(td_1)\n",
    "dout_1  = Dropout(0.1)(lstm_2)\n",
    "flt_1   = Flatten()(dout_1)\n",
    "dense_1 = Dense(16, activation='relu')(flt_1)\n",
    "dout_2  = Dropout(0.2)(dense_1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # bi_d_1 = Bidirectional( LSTM(200 ,  recurrent_dropout=0.12, return_sequences=True),input_shape=[dim_size,1],merge_mode='concat') (inputs)\n",
    "# lstm_1 =  LSTM(100 ,  recurrent_dropout=0.04, return_sequences=True)(inputs)\n",
    "# # lstm_1 = LSTM(40 ,  recurrent_dropout=0.14, return_sequences=True)(lstm_1)\n",
    "\n",
    "# bi_d_raw_1 =Dense(128, activation='relu')  (lstm_1)\n",
    "# lstm_raw_1 =  Dense(128, activation='relu')(bi_d_raw_1)\n",
    "# lstm_raw_2 = Dense(128, activation='relu')(lstm_raw_1)\n",
    "\n",
    "# dout_1  = Dropout(0.1)(lstm_raw_2)\n",
    "# flt_1   = Flatten()(dout_1)\n",
    "# dense_1 = Dense(128, activation='relu')(flt_1)\n",
    "# dout_3  = Dropout(0.2)(dense_1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# out = Conv1D(128,3,padding='same')(inputs)\n",
    "# out = BatchNormalization()(out)\n",
    "# out = Activation('relu')(out)\n",
    "# out = Dropout(0.2)(out)\n",
    "# out = Conv1D(128,3,padding='same')(out)\n",
    "# # out = Flatten()(out)\n",
    "# # out = MaxPooling1D(2,padding='same', name ='pooling')(out)\n",
    "\n",
    "\n",
    "# out = Conv1D(128,3,padding='same')(out)\n",
    "# out = BatchNormalization()(out)\n",
    "# out = Activation('relu')(out)\n",
    "# out = Dropout(0.2)(out)\n",
    "# out = Conv1D(128,3,padding='same')(out)\n",
    "# # out = Flatten()(out)\n",
    "# # out = MaxPooling1D(2,padding='same', name ='pooling2')(out)\n",
    "\n",
    "\n",
    "# out = Conv1D(128,3,padding='same')(out)\n",
    "# out = BatchNormalization()(out)\n",
    "# out = Activation('relu')(out)\n",
    "# out = Dropout(0.2)(out)\n",
    "# out = Conv1D(128,3,padding='same')(out)\n",
    "\n",
    "\n",
    "# out = Flatten()(out)\n",
    "# out = MaxPooling1D(2,padding='same', name ='pooling')(out)\n",
    "\n",
    "\n",
    "\n",
    "# fl_out_1 = Flatten()(dout_2)\n",
    "\n",
    "# fl_out_cnn = Flatten()(out)\n",
    "\n",
    "# out_new = concatenate( [fl_out_1, fl_out_cnn] , name='mergerguy')\n",
    "# out_new = concatenate( [dout_2, fl_out_cnn,dout_3] , name='mergerguy')\n",
    "# out_new = concatenate( [dout_2] , name='mergerguy')\n",
    "\n",
    "# dens_out_1 = Dense( 128, activation='relu' )(out_new)\n",
    "# dens_out_2 = Dense( 128, activation='relu' )(dens_out_1)\n",
    "# dens_out_3 = Dense( 128, activation='relu' )(dens_out_2)\n",
    "\n",
    "# fl2  = Flatten()(out_new)\n",
    "\n",
    "out_put_final = Dense(len(classes), activation='sigmoid', name='Event_output')(dout_2)\n",
    "\n",
    "# toService_1 = Dense( 130, name=\"to_service1\" )(dens_out_3)\n",
    "# toService_1 = Dense( 130, name=\"to_service2\" )(toService_1)\n",
    "\n",
    "# service_output = Dense(len(classes  ), activation=\"sigmoid\", name = 'service_output')(toService_1)\n",
    "\n",
    "\n",
    "\n",
    "model2 = Model(inputs=[inputs], outputs=[out_put_final])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# model2.add(Bidirectional( LSTM(200 ,  recurrent_dropout=0.12, return_sequences=True),input_shape=[dim_size,1],merge_mode='concat'))\n",
    "# model2.add( LSTM(60 ,  recurrent_dropout=0.04, return_sequences=True))\n",
    "# model2.add( LSTM(30 ,  recurrent_dropout=0.14, return_sequences=True))\n",
    "# # model2.add(Bidirectional( LSTM(100 ,  recurrent_dropout=0.04, return_sequences=True),merge_mode='concat'))\n",
    "# model2.add(TimeDistributed(Dense(256, activation='relu')))\n",
    "# model2.add(Dropout(0.1))\n",
    "# model2.add(Flatten())\n",
    "# model2.add(Dense(128, activation='relu'))\n",
    "# model2.add(Dropout(0.2))\n",
    "# model2.add(Dense(len(classes), activation='sigmoid'))\n",
    "\n",
    "# model2.compile(loss=weighted_categorical_crossentropy(weights=weights), optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "losses = {\n",
    "#     \"service_output\": f1_loss_perClass ,\n",
    "    \"Event_output\": f1_loss_perRow ,\n",
    "    \"Event_output\": \"categorical_crossentropy\",\n",
    "}\n",
    "lossWeights = {#\"service_output\": 20,\n",
    "               \"Event_output\": 30.0 ,\n",
    "    \"Event_output\": 20}\n",
    " \n",
    "\n",
    "\n",
    "model2.compile(loss=losses,loss_weights=lossWeights, optimizer='adam', metrics=[f1_perRow,f1_perClass,'acc'])\n",
    "# model2.compile(loss=losses, loss_weights=lossWeights, optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "checkpoint = ModelCheckpoint('IoTDownNet', monitor='loss', verbose=0, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "print(model2.summary())\n",
    "hist2 = model2.fit(x_lstm_prossed_train2, y_lstm_prossed_train, epochs=80, batch_size=70, shuffle=True, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(lstm_tests_known)) :\n",
    "    print( \"==================HOME Case : %s =============\" % test_names[i])\n",
    "    lstm_pred= model2.predict( rf_test_known[i][0])\n",
    "    \n",
    "#     print_info( lstm_tests[i][1], lstm_pred, classes , confidance=0.7)\n",
    "    print_info( rf_test_known[i][1], lstm_pred, classes , confidance=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the model\n",
    "dim_size =15\n",
    "x_lstm_prossed_train,y_lstm_prossed_train, _ = pre_process_raw( x_train, y_train , dim_size, zero_pad=False, normalize=False,classes=classes)\n",
    "_, y_s_lstm_processed_train ,_ =  pre_process_raw( x_train, y_train_service , dim_size, zero_pad=False, normalize=False,classes=service_classes)\n",
    "# x_lstm_prossed_test,y_lstm_prossed_test, _ = pre_process_raw( x_test, y_test_2 , dim_size, zero_pad=True, normalize=False,classes=classes)\n",
    "lstm_tests  = [ pre_process_raw( x_test[i], y_test[i] , dim_size, zero_pad=False, normalize=False, classes=classes, class_cap=TEST_CLASS_CAP) for i in range(len(x_test)) ] \n",
    "lstm_tests_services  = [ pre_process_raw( x_test[i], y_test_service[i] , dim_size, zero_pad=False, normalize=True, classes=service_classes, class_cap=TEST_CLASS_CAP) for i in range(len(x_test)) ] \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# known_indexes_train  = [ i for i in range(len(train_known_unknown_pred)) if train_known_unknown_pred[i][1] ==1 ]\n",
    "\n",
    "# x_lstm_prossed_train = x_lstm_prossed_train[known_indexes_train]\n",
    "# y_lstm_prossed_train = y_lstm_prossed_train[known_indexes_train]\n",
    "\n",
    "lstm_tests_known = [] \n",
    "\n",
    "for test_index in range(len(lstm_tests)):\n",
    "#     known_indexes= [ i for i in range(len(test_known_unknown_predicted[test_index])) if test_known_unknown_predicted[test_index][i][1] ==1 ]\n",
    "    \n",
    "    lstm_tests_known.append(  (lstm_tests[test_index][0], \n",
    "                            lstm_tests[test_index][1],\n",
    "                            lstm_tests[test_index][2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# known_indexes_train  = [ i for i in range(len(train_known_unknown_pred)) if train_known_unknown_pred[i][1] ==1 ]\n",
    "\n",
    "# x_lstm_prossed_train = x_lstm_prossed_train[known_indexes_train]\n",
    "# y_lstm_prossed_train = y_lstm_prossed_train[known_indexes_train]\n",
    "\n",
    "# lstm_tests_known = [] \n",
    "\n",
    "# for test_index in range(len(rf_tests)):\n",
    "#     known_indexes= [ i for i in range(len(test_known_unknown_predicted[test_index])) if test_known_unknown_predicted[test_index][i][1] ==1 ]\n",
    "    \n",
    "#     lstm_tests_known.append(  (lstm_tests[test_index][0][known_indexes], \n",
    "#                             lstm_tests[test_index][1][known_indexes],\n",
    "#                             lstm_tests[test_index][2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_lstm_prossed_test2 = np.expand_dims(x_lstm_prossed_test,axis=1)\n",
    "# x_lstm_prossed_train2 =np.expand_dims(x_lstm_prossed_train,axis=1)\n",
    "\n",
    "for tt  in range( len(lstm_tests_known) ):\n",
    "    lstm_tests_known[tt]= (lstm_tests_known[tt][0].reshape(len(lstm_tests_known[tt][0]),dim_size,1) ,\n",
    "                           lstm_tests_known[tt][1],\n",
    "                           lstm_tests_services[tt][1] )\n",
    "# x_lstm_prossed_test2 = x_lstm_prossed_test.reshape(len(x_lstm_prossed_test),dim_size,1)\n",
    "x_lstm_prossed_train2 =x_lstm_prossed_train.reshape(len(x_lstm_prossed_train),dim_size,1)\n",
    "\n",
    "# y_lstm_prossed_test2 = y_lstm_prossed_test.reshape(len(y_lstm_prossed_test),len(classes),1)\n",
    "# y_lstm_prossed_train2 =y_lstm_prossed_train.reshape(len(y_lstm_prossed_train),len(classes),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0407 13:39:22.673647 139833047426880 deprecation_wrapper.py:119] From /home/omid/.conda/envs/iot/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Bidirectional LSTM :D \n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers import Bidirectional\n",
    "from keras.layers import Flatten\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from keras.models import Model\n",
    "\n",
    "from keras.layers import Input, merge, concatenate, Conv2D, MaxPooling2D, Activation, UpSampling2D, Dropout, Conv2DTranspose, UpSampling2D, Lambda\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers.normalization import BatchNormalization as bn\n",
    "from keras.layers.merge import add\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from keras.optimizers import RMSprop\n",
    "from keras import regularizers\n",
    "from keras import backend as K\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers.merge import add\n",
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "from keras.regularizers import l2\n",
    "from keras.layers import Conv1D\n",
    "from keras.layers.merge import add\n",
    "from keras.layers import Dense,Conv1D,Dropout,Activation,BatchNormalization,MaxPooling1D,Flatten,Masking,TimeDistributed\n",
    "from keras.layers.recurrent import LSTM,GRU,SimpleRNN\n",
    "from keras.models import Input,Sequential,Model\n",
    "from keras.layers.merge import add\n",
    "from keras.optimizers import Adam\n",
    "from keras.losses import MSE,MSLE\n",
    "model2 = Sequential()\n",
    "\n",
    "\n",
    "def weighted_categorical_crossentropy(weights):\n",
    "    \"\"\"\n",
    "    A weighted version of keras.objectives.categorical_crossentropy\n",
    "    \n",
    "    Variables:\n",
    "        weights: numpy array of shape (C,) where C is the number of classes\n",
    "    \n",
    "    Usage:\n",
    "        weights = np.array([0.5,2,10]) # Class one at 0.5, class 2 twice the normal weights, class 3 10x.\n",
    "        loss = weighted_categorical_crossentropy(weights)\n",
    "        model.compile(loss=loss,optimizer='adam')\n",
    "    \"\"\"\n",
    "    \n",
    "    weights = K.variable(weights)\n",
    "        \n",
    "    def loss(y_true, y_pred):\n",
    "        # scale predictions so that the class probas of each sample sum to 1\n",
    "        y_pred /= K.sum(y_pred, axis=-1, keepdims=True)\n",
    "        # clip to prevent NaN's and Inf's\n",
    "        y_pred = K.clip(y_pred, K.epsilon(), 1 - K.epsilon())\n",
    "        # calc\n",
    "        loss = y_true * K.log(y_pred) * weights\n",
    "        loss = -K.sum(loss, -1)\n",
    "        return loss\n",
    "    \n",
    "    return loss\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "def f1_perClass(y_true, y_pred):\n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return K.mean(f1)\n",
    "\n",
    "\n",
    "def f1_perRow(y_true, y_pred):\n",
    "\n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=1)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=1)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=1)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=1)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return K.mean(f1)\n",
    "\n",
    "def f1_loss_perRow(y_true, y_pred):\n",
    "    \n",
    "#     y_true = y_true * \n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=1) \n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=1) \n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=1) \n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=1) \n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "#     f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return (1 - K.mean(f1))**2\n",
    "\n",
    "def f1_loss_perClass(y_true, y_pred):\n",
    "#     key = K.variable([1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1.])\n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = (2*p*r / (p+r+K.epsilon())) #*key\n",
    "    \n",
    "#     f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return (1 - K.mean(f1))**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24173"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 15, 1)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_11 (Conv1D)              (None, 15, 128)      512         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 15, 128)      512         conv1d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 15, 128)      0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_9 (Conv1D)               (None, 15, 128)      512         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)            (None, 15, 128)      0           activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 15, 128)      512         conv1d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_12 (Conv1D)              (None, 15, 128)      49280       dropout_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 15, 128)      0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_13 (Conv1D)              (None, 15, 128)      49280       conv1d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 15, 128)      0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 15, 128)      512         conv1d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_10 (Conv1D)              (None, 15, 128)      49280       dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 15, 128)      0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   (None, 15, 100)      91600       conv1d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)            (None, 15, 128)      0           activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lstm_4 (LSTM)                   (None, 15, 100)      40800       input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 15, 128)      12928       lstm_3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_14 (Conv1D)              (None, 15, 128)      49280       dropout_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_16 (Dense)                (None, 15, 128)      12928       lstm_4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 15, 128)      16512       dense_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_15 (Conv1D)              (None, 15, 128)      49280       conv1d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_17 (Dense)                (None, 15, 128)      16512       dense_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, 15, 128)      16512       dense_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 15, 128)      512         conv1d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_18 (Dense)                (None, 15, 128)      16512       dense_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 15, 128)      0           dense_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 15, 128)      0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 15, 128)      0           dense_18[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)             (None, 1920)         0           dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_16 (Dropout)            (None, 15, 128)      0           activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_5 (Flatten)             (None, 1920)         0           dropout_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_15 (Dense)                (None, 128)          245888      flatten_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_16 (Conv1D)              (None, 15, 128)      49280       dropout_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_19 (Dense)                (None, 128)          245888      flatten_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 128)          0           dense_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_6 (Flatten)             (None, 1920)         0           conv1d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)            (None, 128)          0           dense_19[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "mergerguy (Concatenate)         (None, 2176)         0           dropout_11[0][0]                 \n",
      "                                                                 flatten_6[0][0]                  \n",
      "                                                                 dropout_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_20 (Dense)                (None, 128)          278656      mergerguy[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_21 (Dense)                (None, 128)          16512       dense_20[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_22 (Dense)                (None, 128)          16512       dense_21[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "to_service1 (Dense)             (None, 130)          16770       dense_22[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "to_service2 (Dense)             (None, 130)          17030       to_service1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "service_output (Dense)          (None, 13)           1703        to_service2[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 1,362,015\n",
      "Trainable params: 1,360,991\n",
      "Non-trainable params: 1,024\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "24173/24173 [==============================] - 11s 461us/step - loss: 42.6948 - f1_perRow: 0.2694 - f1_perClass: 0.1459 - acc: 0.4506\n",
      "Epoch 2/100\n",
      "24173/24173 [==============================] - 8s 311us/step - loss: 26.8386 - f1_perRow: 0.5130 - f1_perClass: 0.2550 - acc: 0.5502\n",
      "Epoch 3/100\n",
      "24173/24173 [==============================] - 8s 311us/step - loss: 25.5550 - f1_perRow: 0.5435 - f1_perClass: 0.3259 - acc: 0.6042\n",
      "Epoch 4/100\n",
      "24173/24173 [==============================] - 7s 310us/step - loss: 23.8917 - f1_perRow: 0.5354 - f1_perClass: 0.3734 - acc: 0.6133\n",
      "Epoch 5/100\n",
      "24173/24173 [==============================] - 7s 309us/step - loss: 23.2153 - f1_perRow: 0.5559 - f1_perClass: 0.4056 - acc: 0.5878\n",
      "Epoch 6/100\n",
      "24173/24173 [==============================] - 7s 310us/step - loss: 20.5609 - f1_perRow: 0.6334 - f1_perClass: 0.4075 - acc: 0.6486\n",
      "Epoch 7/100\n",
      "24173/24173 [==============================] - 7s 309us/step - loss: 18.8503 - f1_perRow: 0.6444 - f1_perClass: 0.4244 - acc: 0.6640\n",
      "Epoch 8/100\n",
      "24173/24173 [==============================] - 7s 310us/step - loss: 17.2840 - f1_perRow: 0.6783 - f1_perClass: 0.4647 - acc: 0.6677\n",
      "Epoch 9/100\n",
      "24173/24173 [==============================] - 7s 310us/step - loss: 16.4273 - f1_perRow: 0.7047 - f1_perClass: 0.4750 - acc: 0.6762\n",
      "Epoch 10/100\n",
      "24173/24173 [==============================] - 7s 309us/step - loss: 15.6745 - f1_perRow: 0.7131 - f1_perClass: 0.4827 - acc: 0.7043\n",
      "Epoch 11/100\n",
      "24173/24173 [==============================] - 7s 309us/step - loss: 15.3166 - f1_perRow: 0.7175 - f1_perClass: 0.4886 - acc: 0.7086\n",
      "Epoch 12/100\n",
      "24173/24173 [==============================] - 8s 310us/step - loss: 14.9110 - f1_perRow: 0.7179 - f1_perClass: 0.4880 - acc: 0.7109\n",
      "Epoch 13/100\n",
      "24173/24173 [==============================] - 7s 309us/step - loss: 14.5172 - f1_perRow: 0.7310 - f1_perClass: 0.5075 - acc: 0.7245\n",
      "Epoch 14/100\n",
      "24173/24173 [==============================] - 7s 309us/step - loss: 14.3603 - f1_perRow: 0.7139 - f1_perClass: 0.4925 - acc: 0.7402\n",
      "Epoch 15/100\n",
      "24173/24173 [==============================] - 7s 309us/step - loss: 14.4720 - f1_perRow: 0.7144 - f1_perClass: 0.5004 - acc: 0.7484\n",
      "Epoch 16/100\n",
      "24173/24173 [==============================] - 7s 310us/step - loss: 13.9859 - f1_perRow: 0.7312 - f1_perClass: 0.5054 - acc: 0.7488\n",
      "Epoch 17/100\n",
      "24173/24173 [==============================] - 7s 309us/step - loss: 13.6094 - f1_perRow: 0.7004 - f1_perClass: 0.4964 - acc: 0.7565\n",
      "Epoch 18/100\n",
      "24173/24173 [==============================] - 7s 310us/step - loss: 13.2599 - f1_perRow: 0.6988 - f1_perClass: 0.5063 - acc: 0.7680\n",
      "Epoch 19/100\n",
      "24173/24173 [==============================] - 8s 311us/step - loss: 13.0906 - f1_perRow: 0.7167 - f1_perClass: 0.5120 - acc: 0.7649\n",
      "Epoch 20/100\n",
      "24173/24173 [==============================] - 7s 309us/step - loss: 13.0227 - f1_perRow: 0.7322 - f1_perClass: 0.5121 - acc: 0.7683\n",
      "Epoch 21/100\n",
      "24173/24173 [==============================] - 7s 310us/step - loss: 12.9675 - f1_perRow: 0.7318 - f1_perClass: 0.5228 - acc: 0.7604\n",
      "Epoch 22/100\n",
      "24173/24173 [==============================] - 7s 309us/step - loss: 13.2055 - f1_perRow: 0.7436 - f1_perClass: 0.5239 - acc: 0.7535\n",
      "Epoch 23/100\n",
      "24173/24173 [==============================] - 7s 308us/step - loss: 12.7282 - f1_perRow: 0.7469 - f1_perClass: 0.5193 - acc: 0.7680\n",
      "Epoch 24/100\n",
      "24173/24173 [==============================] - 7s 308us/step - loss: 12.6522 - f1_perRow: 0.7540 - f1_perClass: 0.5279 - acc: 0.7740\n",
      "Epoch 25/100\n",
      "24173/24173 [==============================] - 7s 309us/step - loss: 12.4375 - f1_perRow: 0.7528 - f1_perClass: 0.5280 - acc: 0.7905\n",
      "Epoch 26/100\n",
      "24173/24173 [==============================] - 7s 310us/step - loss: 12.3928 - f1_perRow: 0.7425 - f1_perClass: 0.5273 - acc: 0.7939\n",
      "Epoch 27/100\n",
      "24173/24173 [==============================] - 7s 308us/step - loss: 12.3182 - f1_perRow: 0.7445 - f1_perClass: 0.5296 - acc: 0.7876\n",
      "Epoch 28/100\n",
      "24173/24173 [==============================] - 8s 311us/step - loss: 12.4273 - f1_perRow: 0.7360 - f1_perClass: 0.5275 - acc: 0.7800\n",
      "Epoch 29/100\n",
      "24173/24173 [==============================] - 7s 309us/step - loss: 12.3573 - f1_perRow: 0.7405 - f1_perClass: 0.5164 - acc: 0.7804\n",
      "Epoch 30/100\n",
      "24173/24173 [==============================] - 7s 309us/step - loss: 11.9932 - f1_perRow: 0.7482 - f1_perClass: 0.5278 - acc: 0.7840\n",
      "Epoch 31/100\n",
      "24173/24173 [==============================] - 7s 310us/step - loss: 12.5077 - f1_perRow: 0.7307 - f1_perClass: 0.5148 - acc: 0.7843\n",
      "Epoch 32/100\n",
      "24173/24173 [==============================] - 8s 310us/step - loss: 12.4861 - f1_perRow: 0.7383 - f1_perClass: 0.5197 - acc: 0.7770\n",
      "Epoch 33/100\n",
      "24173/24173 [==============================] - 7s 309us/step - loss: 11.9931 - f1_perRow: 0.7493 - f1_perClass: 0.4999 - acc: 0.7974\n",
      "Epoch 34/100\n",
      "24173/24173 [==============================] - 7s 309us/step - loss: 11.8047 - f1_perRow: 0.7640 - f1_perClass: 0.5316 - acc: 0.7918\n",
      "Epoch 35/100\n",
      "24173/24173 [==============================] - 8s 310us/step - loss: 11.8156 - f1_perRow: 0.7490 - f1_perClass: 0.5347 - acc: 0.7908\n",
      "Epoch 36/100\n",
      "24173/24173 [==============================] - 7s 308us/step - loss: 11.9038 - f1_perRow: 0.7505 - f1_perClass: 0.5307 - acc: 0.7945\n",
      "Epoch 37/100\n",
      "24173/24173 [==============================] - 7s 309us/step - loss: 11.8210 - f1_perRow: 0.7513 - f1_perClass: 0.5282 - acc: 0.8035\n",
      "Epoch 38/100\n",
      "24173/24173 [==============================] - 7s 308us/step - loss: 11.5945 - f1_perRow: 0.7655 - f1_perClass: 0.5447 - acc: 0.7871\n",
      "Epoch 39/100\n",
      "24173/24173 [==============================] - 8s 316us/step - loss: 11.6378 - f1_perRow: 0.7548 - f1_perClass: 0.5398 - acc: 0.7977\n",
      "Epoch 40/100\n",
      "24173/24173 [==============================] - 8s 314us/step - loss: 11.5323 - f1_perRow: 0.7581 - f1_perClass: 0.5465 - acc: 0.7938\n",
      "Epoch 41/100\n",
      "24173/24173 [==============================] - 8s 315us/step - loss: 11.4800 - f1_perRow: 0.7628 - f1_perClass: 0.5451 - acc: 0.7923\n",
      "Epoch 42/100\n",
      "24173/24173 [==============================] - 8s 314us/step - loss: 11.3731 - f1_perRow: 0.7577 - f1_perClass: 0.5471 - acc: 0.8069\n",
      "Epoch 43/100\n",
      "24173/24173 [==============================] - 8s 316us/step - loss: 11.2829 - f1_perRow: 0.7612 - f1_perClass: 0.5499 - acc: 0.7992\n",
      "Epoch 44/100\n",
      "24173/24173 [==============================] - 8s 317us/step - loss: 11.4604 - f1_perRow: 0.7480 - f1_perClass: 0.5465 - acc: 0.7937\n",
      "Epoch 45/100\n",
      "24173/24173 [==============================] - 8s 316us/step - loss: 11.7181 - f1_perRow: 0.7514 - f1_perClass: 0.5304 - acc: 0.7961\n",
      "Epoch 46/100\n",
      "24173/24173 [==============================] - 8s 315us/step - loss: 11.8050 - f1_perRow: 0.7542 - f1_perClass: 0.5380 - acc: 0.8079\n",
      "Epoch 47/100\n",
      "24173/24173 [==============================] - 8s 316us/step - loss: 11.5632 - f1_perRow: 0.7586 - f1_perClass: 0.5412 - acc: 0.8001\n",
      "Epoch 48/100\n",
      "24173/24173 [==============================] - 8s 316us/step - loss: 11.5729 - f1_perRow: 0.7585 - f1_perClass: 0.5391 - acc: 0.7952\n",
      "Epoch 49/100\n",
      "24173/24173 [==============================] - 8s 315us/step - loss: 11.4214 - f1_perRow: 0.7635 - f1_perClass: 0.5432 - acc: 0.7885\n",
      "Epoch 50/100\n",
      "24173/24173 [==============================] - 8s 315us/step - loss: 11.5740 - f1_perRow: 0.7527 - f1_perClass: 0.5378 - acc: 0.7849\n",
      "Epoch 51/100\n",
      "24173/24173 [==============================] - 8s 315us/step - loss: 11.4091 - f1_perRow: 0.7590 - f1_perClass: 0.5490 - acc: 0.7906\n",
      "Epoch 52/100\n",
      "24173/24173 [==============================] - 8s 315us/step - loss: 11.4564 - f1_perRow: 0.7638 - f1_perClass: 0.5389 - acc: 0.7917\n",
      "Epoch 53/100\n",
      "24173/24173 [==============================] - 8s 314us/step - loss: 11.4528 - f1_perRow: 0.7577 - f1_perClass: 0.5539 - acc: 0.8004\n",
      "Epoch 54/100\n",
      "24173/24173 [==============================] - 8s 314us/step - loss: 11.7088 - f1_perRow: 0.7541 - f1_perClass: 0.5440 - acc: 0.8026\n",
      "Epoch 55/100\n",
      "24173/24173 [==============================] - 8s 316us/step - loss: 11.4522 - f1_perRow: 0.7643 - f1_perClass: 0.5431 - acc: 0.8094\n",
      "Epoch 56/100\n",
      "24173/24173 [==============================] - 8s 315us/step - loss: 11.4324 - f1_perRow: 0.7666 - f1_perClass: 0.5515 - acc: 0.8025\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24173/24173 [==============================] - 8s 314us/step - loss: 11.3029 - f1_perRow: 0.7688 - f1_perClass: 0.5546 - acc: 0.8054\n",
      "Epoch 58/100\n",
      "24173/24173 [==============================] - 8s 315us/step - loss: 11.3305 - f1_perRow: 0.7696 - f1_perClass: 0.5586 - acc: 0.8117\n",
      "Epoch 59/100\n",
      "24173/24173 [==============================] - 8s 335us/step - loss: 11.2627 - f1_perRow: 0.7651 - f1_perClass: 0.5559 - acc: 0.7998\n",
      "Epoch 60/100\n",
      "24173/24173 [==============================] - 8s 313us/step - loss: 11.1902 - f1_perRow: 0.7691 - f1_perClass: 0.5570 - acc: 0.7919\n",
      "Epoch 61/100\n",
      "24173/24173 [==============================] - 8s 331us/step - loss: 11.1795 - f1_perRow: 0.7673 - f1_perClass: 0.5603 - acc: 0.7963\n",
      "Epoch 62/100\n",
      "24173/24173 [==============================] - 8s 312us/step - loss: 11.2310 - f1_perRow: 0.7621 - f1_perClass: 0.5627 - acc: 0.8017\n",
      "Epoch 63/100\n",
      "24173/24173 [==============================] - 8s 315us/step - loss: 11.3310 - f1_perRow: 0.7610 - f1_perClass: 0.5439 - acc: 0.7943\n",
      "Epoch 64/100\n",
      "24173/24173 [==============================] - 8s 318us/step - loss: 11.2031 - f1_perRow: 0.7581 - f1_perClass: 0.5523 - acc: 0.8031\n",
      "Epoch 65/100\n",
      "24173/24173 [==============================] - 8s 315us/step - loss: 11.1431 - f1_perRow: 0.7525 - f1_perClass: 0.5554 - acc: 0.8149\n",
      "Epoch 66/100\n",
      "24173/24173 [==============================] - 8s 315us/step - loss: 11.1271 - f1_perRow: 0.7558 - f1_perClass: 0.5462 - acc: 0.8034\n",
      "Epoch 67/100\n",
      "24173/24173 [==============================] - 8s 314us/step - loss: 11.1582 - f1_perRow: 0.7487 - f1_perClass: 0.5557 - acc: 0.7967\n",
      "Epoch 68/100\n",
      "24173/24173 [==============================] - 8s 315us/step - loss: 11.0936 - f1_perRow: 0.7563 - f1_perClass: 0.5536 - acc: 0.7959\n",
      "Epoch 69/100\n",
      "24173/24173 [==============================] - 8s 316us/step - loss: 11.1244 - f1_perRow: 0.7495 - f1_perClass: 0.5515 - acc: 0.7991\n",
      "Epoch 70/100\n",
      "24173/24173 [==============================] - 8s 315us/step - loss: 11.0445 - f1_perRow: 0.7473 - f1_perClass: 0.5503 - acc: 0.8011\n",
      "Epoch 71/100\n",
      "24173/24173 [==============================] - 8s 316us/step - loss: 11.1630 - f1_perRow: 0.7515 - f1_perClass: 0.5459 - acc: 0.7939\n",
      "Epoch 72/100\n",
      "24173/24173 [==============================] - 8s 315us/step - loss: 11.3016 - f1_perRow: 0.7543 - f1_perClass: 0.5543 - acc: 0.8120\n",
      "Epoch 73/100\n",
      "24173/24173 [==============================] - 8s 313us/step - loss: 11.0341 - f1_perRow: 0.7634 - f1_perClass: 0.5646 - acc: 0.8122\n",
      "Epoch 74/100\n",
      "24173/24173 [==============================] - 8s 317us/step - loss: 10.9560 - f1_perRow: 0.7658 - f1_perClass: 0.5656 - acc: 0.8104\n",
      "Epoch 75/100\n",
      "24173/24173 [==============================] - 8s 315us/step - loss: 10.8869 - f1_perRow: 0.7615 - f1_perClass: 0.5596 - acc: 0.8095\n",
      "Epoch 76/100\n",
      "24173/24173 [==============================] - 8s 317us/step - loss: 10.8584 - f1_perRow: 0.7580 - f1_perClass: 0.5611 - acc: 0.8118\n",
      "Epoch 77/100\n",
      "24173/24173 [==============================] - 8s 316us/step - loss: 11.1765 - f1_perRow: 0.7522 - f1_perClass: 0.5503 - acc: 0.8028\n",
      "Epoch 78/100\n",
      "24173/24173 [==============================] - 8s 314us/step - loss: 11.3375 - f1_perRow: 0.7466 - f1_perClass: 0.5325 - acc: 0.8043\n",
      "Epoch 79/100\n",
      "24173/24173 [==============================] - 8s 313us/step - loss: 11.0592 - f1_perRow: 0.7577 - f1_perClass: 0.5460 - acc: 0.8036\n",
      "Epoch 80/100\n",
      "24173/24173 [==============================] - 8s 316us/step - loss: 11.0503 - f1_perRow: 0.7635 - f1_perClass: 0.5588 - acc: 0.8061\n",
      "Epoch 81/100\n",
      "24173/24173 [==============================] - 8s 315us/step - loss: 10.9897 - f1_perRow: 0.7546 - f1_perClass: 0.5563 - acc: 0.8032\n",
      "Epoch 82/100\n",
      "24173/24173 [==============================] - 8s 315us/step - loss: 10.9474 - f1_perRow: 0.7638 - f1_perClass: 0.5671 - acc: 0.7947\n",
      "Epoch 83/100\n",
      "24173/24173 [==============================] - 8s 317us/step - loss: 10.9906 - f1_perRow: 0.7637 - f1_perClass: 0.5661 - acc: 0.7965\n",
      "Epoch 84/100\n",
      "24173/24173 [==============================] - 8s 314us/step - loss: 10.9725 - f1_perRow: 0.7563 - f1_perClass: 0.5661 - acc: 0.8101\n",
      "Epoch 85/100\n",
      "24173/24173 [==============================] - 8s 317us/step - loss: 10.9487 - f1_perRow: 0.7583 - f1_perClass: 0.5564 - acc: 0.8097\n",
      "Epoch 86/100\n",
      "24173/24173 [==============================] - 8s 313us/step - loss: 11.4734 - f1_perRow: 0.7490 - f1_perClass: 0.5605 - acc: 0.8016\n",
      "Epoch 87/100\n",
      "24173/24173 [==============================] - 8s 315us/step - loss: 11.1716 - f1_perRow: 0.7604 - f1_perClass: 0.5487 - acc: 0.8097\n",
      "Epoch 88/100\n",
      "24173/24173 [==============================] - 8s 316us/step - loss: 11.1750 - f1_perRow: 0.7610 - f1_perClass: 0.5636 - acc: 0.8147\n",
      "Epoch 89/100\n",
      "24173/24173 [==============================] - 8s 315us/step - loss: 11.1303 - f1_perRow: 0.7690 - f1_perClass: 0.5577 - acc: 0.8030\n",
      "Epoch 90/100\n",
      "24173/24173 [==============================] - 8s 314us/step - loss: 11.0715 - f1_perRow: 0.7618 - f1_perClass: 0.5579 - acc: 0.7927\n",
      "Epoch 91/100\n",
      "24173/24173 [==============================] - 8s 315us/step - loss: 11.0626 - f1_perRow: 0.7687 - f1_perClass: 0.5575 - acc: 0.8054\n",
      "Epoch 92/100\n",
      "24173/24173 [==============================] - 8s 313us/step - loss: 10.9434 - f1_perRow: 0.7664 - f1_perClass: 0.5706 - acc: 0.8132\n",
      "Epoch 93/100\n",
      "24173/24173 [==============================] - 8s 315us/step - loss: 10.9095 - f1_perRow: 0.7695 - f1_perClass: 0.5698 - acc: 0.8018\n",
      "Epoch 94/100\n",
      "24173/24173 [==============================] - 8s 315us/step - loss: 10.9337 - f1_perRow: 0.7740 - f1_perClass: 0.5706 - acc: 0.8030\n",
      "Epoch 95/100\n",
      "24173/24173 [==============================] - 8s 316us/step - loss: 11.0375 - f1_perRow: 0.7624 - f1_perClass: 0.5618 - acc: 0.7958\n",
      "Epoch 96/100\n",
      "24173/24173 [==============================] - 8s 313us/step - loss: 11.0164 - f1_perRow: 0.7698 - f1_perClass: 0.5666 - acc: 0.8107\n",
      "Epoch 97/100\n",
      "24173/24173 [==============================] - 8s 315us/step - loss: 10.8431 - f1_perRow: 0.7724 - f1_perClass: 0.5717 - acc: 0.8097\n",
      "Epoch 98/100\n",
      "24173/24173 [==============================] - 8s 314us/step - loss: 10.8115 - f1_perRow: 0.7693 - f1_perClass: 0.5731 - acc: 0.8014\n",
      "Epoch 99/100\n",
      "24173/24173 [==============================] - 8s 316us/step - loss: 10.9743 - f1_perRow: 0.7676 - f1_perClass: 0.5650 - acc: 0.7932\n",
      "Epoch 100/100\n",
      "24173/24173 [==============================] - 8s 315us/step - loss: 10.8687 - f1_perRow: 0.7663 - f1_perClass: 0.5722 - acc: 0.7973\n"
     ]
    }
   ],
   "source": [
    "inputs  = Input( ( dim_size,1 ) )\n",
    "\n",
    "\n",
    "out = Conv1D(128,3,padding='same')(inputs)\n",
    "out = BatchNormalization()(out)\n",
    "out = Activation('relu')(out)\n",
    "out = Dropout(0.2)(out)\n",
    "out = Conv1D(128,3,padding='same')(out)\n",
    "# bi_d_1 = Bidirectional( LSTM(200 ,  recurrent_dropout=0.12, return_sequences=True),input_shape=[dim_size,1],merge_mode='concat') (inputs)\n",
    "lstm_1 =  LSTM(100 ,  recurrent_dropout=0.04, return_sequences=True)(out)\n",
    "# lstm_2 = LSTM(30 ,  recurrent_dropout=0.14, return_sequences=True)(lstm_1)\n",
    "\n",
    "bi_d_1 =Dense(128, activation='relu')  (lstm_1)\n",
    "lstm_1 =  Dense(128, activation='relu')(bi_d_1)\n",
    "lstm_2 = Dense(128, activation='relu')(lstm_1)\n",
    "\n",
    "\n",
    "\n",
    "# td_1    = TimeDistributed(Dense(256, activation='relu'))(lstm_2)\n",
    "# dout_1  = Dropout(0.1)(td_1)\n",
    "dout_1  = Dropout(0.1)(lstm_2)\n",
    "flt_1   = Flatten()(dout_1)\n",
    "dense_1 = Dense(128, activation='relu')(flt_1)\n",
    "dout_2  = Dropout(0.2)(dense_1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# bi_d_1 = Bidirectional( LSTM(200 ,  recurrent_dropout=0.12, return_sequences=True),input_shape=[dim_size,1],merge_mode='concat') (inputs)\n",
    "lstm_1 =  LSTM(100 ,  recurrent_dropout=0.04, return_sequences=True)(inputs)\n",
    "# lstm_1 = LSTM(40 ,  recurrent_dropout=0.14, return_sequences=True)(lstm_1)\n",
    "\n",
    "bi_d_raw_1 =Dense(128, activation='relu')  (lstm_1)\n",
    "lstm_raw_1 =  Dense(128, activation='relu')(bi_d_raw_1)\n",
    "lstm_raw_2 = Dense(128, activation='relu')(lstm_raw_1)\n",
    "\n",
    "dout_1  = Dropout(0.1)(lstm_raw_2)\n",
    "flt_1   = Flatten()(dout_1)\n",
    "dense_1 = Dense(128, activation='relu')(flt_1)\n",
    "dout_3  = Dropout(0.2)(dense_1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "out = Conv1D(128,3,padding='same')(inputs)\n",
    "out = BatchNormalization()(out)\n",
    "out = Activation('relu')(out)\n",
    "out = Dropout(0.2)(out)\n",
    "out = Conv1D(128,3,padding='same')(out)\n",
    "# out = Flatten()(out)\n",
    "# out = MaxPooling1D(2,padding='same', name ='pooling')(out)\n",
    "\n",
    "\n",
    "out = Conv1D(128,3,padding='same')(out)\n",
    "out = BatchNormalization()(out)\n",
    "out = Activation('relu')(out)\n",
    "out = Dropout(0.2)(out)\n",
    "out = Conv1D(128,3,padding='same')(out)\n",
    "# out = Flatten()(out)\n",
    "# out = MaxPooling1D(2,padding='same', name ='pooling2')(out)\n",
    "\n",
    "\n",
    "out = Conv1D(128,3,padding='same')(out)\n",
    "out = BatchNormalization()(out)\n",
    "out = Activation('relu')(out)\n",
    "out = Dropout(0.2)(out)\n",
    "out = Conv1D(128,3,padding='same')(out)\n",
    "# out = Flatten()(out)\n",
    "# out = MaxPooling1D(2,padding='same', name ='pooling')(out)\n",
    "\n",
    "\n",
    "\n",
    "# fl_out_1 = Flatten()(dout_2)\n",
    "\n",
    "fl_out_cnn = Flatten()(out)\n",
    "\n",
    "# out_new = concatenate( [fl_out_1, fl_out_cnn] , name='mergerguy')\n",
    "out_new = concatenate( [dout_2, fl_out_cnn,dout_3] , name='mergerguy')\n",
    "\n",
    "dens_out_1 = Dense( 128, activation='relu' )(out_new)\n",
    "dens_out_2 = Dense( 128, activation='relu' )(dens_out_1)\n",
    "dens_out_3 = Dense( 128, activation='relu' )(dens_out_2)\n",
    "\n",
    "# fl2  = Flatten()(out_new)\n",
    "\n",
    "out_put_final = Dense(len(classes), activation='sigmoid', name='Event_output')(dens_out_3)\n",
    "\n",
    "toService_1 = Dense( 130, name=\"to_service1\" )(dens_out_3)\n",
    "toService_1 = Dense( 130, name=\"to_service2\" )(toService_1)\n",
    "\n",
    "service_output = Dense(len(classes  ), activation=\"sigmoid\", name = 'service_output')(toService_1)\n",
    "\n",
    "\n",
    "\n",
    "model2 = Model(inputs=[inputs], outputs=[service_output])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# model2.add(Bidirectional( LSTM(200 ,  recurrent_dropout=0.12, return_sequences=True),input_shape=[dim_size,1],merge_mode='concat'))\n",
    "# model2.add( LSTM(60 ,  recurrent_dropout=0.04, return_sequences=True))\n",
    "# model2.add( LSTM(30 ,  recurrent_dropout=0.14, return_sequences=True))\n",
    "# # model2.add(Bidirectional( LSTM(100 ,  recurrent_dropout=0.04, return_sequences=True),merge_mode='concat'))\n",
    "# model2.add(TimeDistributed(Dense(256, activation='relu')))\n",
    "# model2.add(Dropout(0.1))\n",
    "# model2.add(Flatten())\n",
    "# model2.add(Dense(128, activation='relu'))\n",
    "# model2.add(Dropout(0.2))\n",
    "# model2.add(Dense(len(classes), activation='sigmoid'))\n",
    "\n",
    " \n",
    "weights = [\n",
    "1.0/(57.0 / len(y_train)),\n",
    "1.0/(19.0 / len(y_train)),\n",
    "1.0/(7.0 / len(y_train)),\n",
    "1.0/(14.0 / len(y_train)),\n",
    "1.0/(6.0 / len(y_train)),\n",
    "1.0/(176.0 / len(y_train)),\n",
    "1.0/(27.0 / len(y_train)),\n",
    "1.0/(35.0 / len(y_train)),\n",
    "1.0/(371.0 / len(y_train)),\n",
    "1.0/(11111.0 / len(y_train)),\n",
    "1.0/(4842.0 / len(y_train)),\n",
    "1.0/(119.0 / len(y_train)),\n",
    "1.0/(21.0 / len(y_train)),\n",
    "1.0/(1168.0 / len(y_train)),\n",
    "1.0/(63.0 / len(y_train)),\n",
    "1.0/(13305.0 / len(y_train)),\n",
    "1.0/(11111.0 / len(y_train)),\n",
    "]\n",
    "    \n",
    "\n",
    "\n",
    "# model2.compile(loss=weighted_categorical_crossentropy(weights=weights), optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "losses = {\n",
    "    \"service_output\": f1_loss_perClass ,\n",
    "    \"service_output\": f1_loss_perRow ,\n",
    "    \"service_output\": \"categorical_crossentropy\",\n",
    "}\n",
    "lossWeights = {\"service_output\": 200,\n",
    "               \"service_output\": 30.0 ,\n",
    "    \"service_output\": 20}\n",
    " \n",
    "\n",
    "\n",
    "model2.compile(loss=losses,loss_weights=lossWeights, optimizer='adam', metrics=[f1_perRow,f1_perClass,'acc'])\n",
    "# model2.compile(loss=losses, loss_weights=lossWeights, optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "checkpoint = ModelCheckpoint('lstm_IoTDownNet_old_data', monitor='loss', verbose=0, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "print(model2.summary())\n",
    "hist2 = model2.fit(x_lstm_prossed_train2, y_lstm_prossed_train, epochs=100, batch_size=7000, shuffle=True, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "24173/24173 [==============================] - 8s 311us/step - loss: 11.0858 - f1_perRow: 0.7730 - f1_perClass: 0.5586 - acc: 0.8101\n",
      "Epoch 2/20\n",
      "24173/24173 [==============================] - 8s 312us/step - loss: 10.8619 - f1_perRow: 0.7740 - f1_perClass: 0.5711 - acc: 0.7999\n",
      "Epoch 3/20\n",
      "24173/24173 [==============================] - 8s 311us/step - loss: 10.9457 - f1_perRow: 0.7723 - f1_perClass: 0.5701 - acc: 0.8009\n",
      "Epoch 4/20\n",
      "24173/24173 [==============================] - 8s 310us/step - loss: 10.9980 - f1_perRow: 0.7654 - f1_perClass: 0.5545 - acc: 0.7986\n",
      "Epoch 5/20\n",
      "24173/24173 [==============================] - 8s 312us/step - loss: 10.8949 - f1_perRow: 0.7685 - f1_perClass: 0.5628 - acc: 0.8035\n",
      "Epoch 6/20\n",
      "24173/24173 [==============================] - 8s 311us/step - loss: 11.0368 - f1_perRow: 0.7683 - f1_perClass: 0.5717 - acc: 0.7985\n",
      "Epoch 7/20\n",
      "24173/24173 [==============================] - 8s 313us/step - loss: 10.9577 - f1_perRow: 0.7643 - f1_perClass: 0.5547 - acc: 0.7987\n",
      "Epoch 8/20\n",
      "24173/24173 [==============================] - 8s 312us/step - loss: 10.9852 - f1_perRow: 0.7684 - f1_perClass: 0.5752 - acc: 0.8009\n",
      "Epoch 9/20\n",
      "24173/24173 [==============================] - 8s 311us/step - loss: 11.0861 - f1_perRow: 0.7722 - f1_perClass: 0.5553 - acc: 0.8017\n",
      "Epoch 10/20\n",
      "24173/24173 [==============================] - 8s 310us/step - loss: 11.1265 - f1_perRow: 0.7638 - f1_perClass: 0.5620 - acc: 0.8019\n",
      "Epoch 11/20\n",
      "24173/24173 [==============================] - 8s 311us/step - loss: 11.0182 - f1_perRow: 0.7764 - f1_perClass: 0.5606 - acc: 0.8074\n",
      "Epoch 12/20\n",
      "24173/24173 [==============================] - 8s 311us/step - loss: 10.9780 - f1_perRow: 0.7674 - f1_perClass: 0.5656 - acc: 0.8107\n",
      "Epoch 13/20\n",
      "24173/24173 [==============================] - 8s 311us/step - loss: 10.9656 - f1_perRow: 0.7672 - f1_perClass: 0.5452 - acc: 0.7989\n",
      "Epoch 14/20\n",
      "24173/24173 [==============================] - 8s 312us/step - loss: 10.9538 - f1_perRow: 0.7682 - f1_perClass: 0.5786 - acc: 0.8036\n",
      "Epoch 15/20\n",
      "24173/24173 [==============================] - 8s 312us/step - loss: 11.1142 - f1_perRow: 0.7690 - f1_perClass: 0.5662 - acc: 0.8000\n",
      "Epoch 16/20\n",
      "24173/24173 [==============================] - 8s 311us/step - loss: 10.9144 - f1_perRow: 0.7725 - f1_perClass: 0.5688 - acc: 0.7980\n",
      "Epoch 17/20\n",
      "24173/24173 [==============================] - 8s 312us/step - loss: 11.4767 - f1_perRow: 0.7770 - f1_perClass: 0.5667 - acc: 0.8069\n",
      "Epoch 18/20\n",
      "24173/24173 [==============================] - 8s 311us/step - loss: 11.0183 - f1_perRow: 0.7761 - f1_perClass: 0.5651 - acc: 0.8069\n",
      "Epoch 19/20\n",
      "24173/24173 [==============================] - 8s 312us/step - loss: 11.1027 - f1_perRow: 0.7820 - f1_perClass: 0.5694 - acc: 0.8043\n",
      "Epoch 20/20\n",
      "24173/24173 [==============================] - 8s 313us/step - loss: 10.9367 - f1_perRow: 0.7821 - f1_perClass: 0.5777 - acc: 0.8021\n"
     ]
    }
   ],
   "source": [
    "# print(model2.summary())\n",
    "hist2 = model2.fit(x_lstm_prossed_train2, y_lstm_prossed_train, epochs=20, batch_size=5000, shuffle=True, callbacks=callbacks_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.load_weights('lstm_IoTDownNet_old_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================HOME Case : MERGED =============\n",
      "                         Class  Accuracy     Recall  Precision   F Score    Count            TP/TN/FP/FN\n",
      "------------------------------------------------------------------------\n",
      "                        button     0.513      0.754     0.075     0.137        61    46/  564/  564/   15\n",
      "              colorTemperature     0.968      0.300     0.545     0.387        40    12/ 1139/   10/   28\n",
      "                       contact     0.437      0.933     0.175     0.295       150   140/  379/  660/   10\n",
      "                         level     0.607      0.940     0.235     0.377       150   141/  581/  458/    9\n",
      "                          lock     0.976      0.873     0.936     0.903       150   131/ 1030/    9/   19\n",
      "                        motion     0.799      0.200     0.201     0.201       150    30/  920/  119/  120\n",
      "                          ping     0.949      0.993     0.713     0.830       150   149/  979/   60/    1\n",
      "                        status     0.573      0.953     0.222     0.360       150   143/  538/  501/    7\n",
      "                        switch     0.926      0.934     0.404     0.564        61    57/ 1044/   84/    4\n",
      "                   temperature     0.642      0.900     0.247     0.388       150   135/  628/  411/   15\n",
      "                     threeAxis     0.805      0.945     0.275     0.426        91    86/  871/  227/    5\n",
      "                       unknown     0.333      0.973     0.156     0.269       150   146/  250/  789/    4\n",
      "                         water     0.839        nan     0.000     0.000         0     0/  998/  191/    0\n",
      "------------------------------------------------------------------------\n",
      "                      AVERAGES     0.721      0.746     0.322     0.395      1189     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "             Weighted AVERAGES     0.686      0.837     0.350     0.441      1189     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "       known Weighted AVERAGES     0.727      0.821     0.373     0.461      1189     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      " known -ping Weighted AVERAGES     0.698      0.799     0.328     0.412      1189     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "       non zero count AVERAGES     0.711      0.808     0.349     0.428      1189     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "Macro F1 : 0.395154\n",
      "sample F1 : 0.415898\n",
      "weighted F1 : 0.440757\n",
      "Exact Match ACC : 0.04037 \n",
      "Total Records : 1189 \n",
      "Total ZXeros in True : 0 (0.000)%\n",
      "Total ZXeros in Test : 0 (0.000)%\n",
      "=============================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/omid/.conda/envs/iot/lib/python3.6/site-packages/ipykernel_launcher.py:8: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "for i in range(len(lstm_tests_known)) :\n",
    "    print( \"==================HOME Case : %s =============\" % test_names[i])\n",
    "    lstm_pred= model2.predict( lstm_tests_known[i][0])\n",
    "    \n",
    "#     print_info( lstm_tests[i][1], lstm_pred, classes , confidance=0.7)\n",
    "    print_info( lstm_tests_known[i][1], lstm_pred, classes , confidance=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================HOME Case : home_os_final.json =============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/omid/.conda/envs/iot/lib/python3.6/site-packages/ipykernel_launcher.py:9: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  if __name__ == '__main__':\n",
      "/home/omid/.conda/envs/iot/lib/python3.6/site-packages/ipykernel_launcher.py:8: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  \n",
      "/home/omid/.conda/envs/iot/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/omid/.conda/envs/iot/lib/python3.6/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/home/omid/.conda/envs/iot/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         Class  Accuracy     Recall  Precision   F Score    Count            TP/TN/FP/FN\n",
      "------------------------------------------------------------------------\n",
      "                  acceleration     0.995      0.250     0.650     0.361        52    13/ 9449/    7/   39\n",
      "                      activity     0.998      0.000       nan     0.000        16     0/ 9492/    0/   16\n",
      "                       battery     0.998      0.000     0.000     0.000         3     0/ 9493/   12/    3\n",
      "                        button     0.989      0.000     0.000     0.000        12     0/ 9404/   92/   12\n",
      "              colorTemperature     0.999      0.000     0.000     0.000         5     0/ 9501/    2/    5\n",
      "                       contact     0.975      0.741     0.342     0.468       143   106/ 9161/  204/   37\n",
      "                         level     0.998      0.250     0.385     0.303        20     5/ 9480/    8/   15\n",
      "                          lock     0.996      0.000     0.000     0.000        33     0/ 9471/    4/   33\n",
      "                        motion     0.976      0.000       nan     0.000       228     0/ 9280/    0/  228\n",
      "                       no_logs     0.901        nan     0.000     0.000         0     0/ 8570/  938/    0\n",
      "                          ping     0.962      0.995     0.935     0.964      4813  4788/ 4361/  334/   25\n",
      "                        status     0.991      0.838     0.581     0.686       111    93/ 9330/   67/   18\n",
      "                        switch     0.998      0.286     0.545     0.375        21     6/ 9482/    5/   15\n",
      "                   temperature     0.928      0.000     0.000     0.000       678     0/ 8823/    7/  678\n",
      "                     threeAxis     0.997      0.688     0.579     0.629        32    22/ 9460/   16/   10\n",
      "                       unknown     0.723      0.407     0.928     0.566      4212  1713/ 5163/  133/ 2499\n",
      "                         water     0.999        nan     0.000     0.000         0     0/ 9496/   12/    0\n",
      "------------------------------------------------------------------------\n",
      "                      AVERAGES     0.966      0.262     0.291     0.256      9508     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "             Weighted AVERAGES     0.864      0.650     0.828     0.695      9508     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "       known Weighted AVERAGES     0.961      0.816     0.760     0.784      9508     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      " known -ping Weighted AVERAGES     0.956      0.181     0.137     0.145      9508     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "       non zero count AVERAGES     0.968      0.297     0.330     0.290      9508     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "Macro F1 : 0.255968\n",
      "sample F1 : 0.591023\n",
      "weighted F1 : 0.695351\n",
      "--------------------------removed ping and unknown----------------------------------------------\n",
      "Macro F1 : 0.173333\n",
      "sample F1 : 0.029343\n",
      "weighted F1 : 0.054119\n",
      "Exact Match ACC : 0.50452 \n",
      "Total Records : 9508 \n",
      "Total ZXeros in True : 0 (0.000)%\n",
      "Total ZXeros in Test : 3099 (0.326)%\n",
      "=============================================================================\n",
      "==================HOME Case : test_data_light.json =============\n",
      "                         Class  Accuracy     Recall  Precision   F Score    Count            TP/TN/FP/FN\n",
      "------------------------------------------------------------------------\n",
      "                  acceleration     1.000        nan       nan       nan         0     0/  220/    0/    0\n",
      "                      activity     1.000        nan       nan       nan         0     0/  220/    0/    0\n",
      "                       battery     1.000        nan       nan       nan         0     0/  220/    0/    0\n",
      "                        button     1.000        nan       nan       nan         0     0/  220/    0/    0\n",
      "              colorTemperature     0.814      0.032     0.083     0.047        31     1/  178/   11/   30\n",
      "                       contact     1.000        nan       nan       nan         0     0/  220/    0/    0\n",
      "                         level     0.577      0.145     0.353     0.205        83    12/  115/   22/   71\n",
      "                          lock     0.991        nan     0.000     0.000         0     0/  218/    2/    0\n",
      "                        motion     1.000        nan       nan       nan         0     0/  220/    0/    0\n",
      "                       no_logs     0.832        nan     0.000     0.000         0     0/  183/   37/    0\n",
      "                          ping     0.968      0.808     0.913     0.857        26    21/  192/    2/    5\n",
      "                        status     0.991        nan     0.000     0.000         0     0/  218/    2/    0\n",
      "                        switch     0.886      0.125     0.429     0.194        24     3/  192/    4/   21\n",
      "                   temperature     0.995      0.000       nan     0.000         1     0/  219/    0/    1\n",
      "                     threeAxis     1.000        nan       nan       nan         0     0/  220/    0/    0\n",
      "                       unknown     0.573      0.011     0.500     0.021        94     1/  125/    1/   93\n",
      "                         water     1.000        nan       nan       nan         0     0/  220/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "                      AVERAGES     0.919      0.066     0.134     0.078       220     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "             Weighted AVERAGES     0.673      0.147     0.436     0.183       220     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "       known Weighted AVERAGES     0.731      0.224     0.399     0.275       220     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      " known -ping Weighted AVERAGES     0.686      0.115     0.303     0.166       220     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "       non zero count AVERAGES     0.802      0.187     0.380     0.221       220     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "Macro F1 : 0.077833\n",
      "sample F1 : 0.137121\n",
      "weighted F1 : 0.182844\n",
      "--------------------------removed ping and unknown----------------------------------------------\n",
      "Macro F1 : 0.026671\n",
      "sample F1 : 0.048223\n",
      "weighted F1 : 0.098322\n",
      "Exact Match ACC : 0.10455 \n",
      "Total Records : 220 \n",
      "Total ZXeros in True : 0 (0.000)%\n",
      "Total ZXeros in Test : 116 (0.527)%\n",
      "=============================================================================\n",
      "==================HOME Case : test_data_motion_2.json =============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/omid/.conda/envs/iot/lib/python3.6/site-packages/ipykernel_launcher.py:12: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         Class  Accuracy     Recall  Precision   F Score    Count            TP/TN/FP/FN\n",
      "------------------------------------------------------------------------\n",
      "                  acceleration     0.997      0.000       nan     0.000        25     0/ 7436/    0/   25\n",
      "                      activity     0.999        nan     0.000     0.000         0     0/ 7455/    6/    0\n",
      "                       battery     1.000      0.000       nan     0.000         1     0/ 7460/    0/    1\n",
      "                        button     0.997        nan     0.000     0.000         0     0/ 7440/   21/    0\n",
      "              colorTemperature     1.000      0.000       nan     0.000         3     0/ 7458/    0/    3\n",
      "                       contact     0.981      0.000     0.000     0.000       110     0/ 7316/   35/  110\n",
      "                         level     0.987      0.200     0.011     0.021         5     1/ 7366/   90/    4\n",
      "                          lock     0.991        nan     0.000     0.000         0     0/ 7392/   69/    0\n",
      "                        motion     0.974      0.000       nan     0.000       197     0/ 7264/    0/  197\n",
      "                       no_logs     0.681      0.000     0.000     0.000         1     0/ 5079/ 2381/    1\n",
      "                          ping     0.956      0.937     0.940     0.938      2662  2495/ 4639/  160/  167\n",
      "                        status     0.992        nan     0.000     0.000         0     0/ 7400/   61/    0\n",
      "                        switch     0.994      0.500     0.022     0.042         2     1/ 7414/   45/    1\n",
      "                   temperature     0.995      0.000       nan     0.000        34     0/ 7427/    0/   34\n",
      "                     threeAxis     0.998      0.000       nan     0.000        18     0/ 7443/    0/   18\n",
      "                       unknown     0.371      0.063     0.826     0.116      4935   309/ 2461/   65/ 4626\n",
      "                         water     1.000        nan       nan       nan         0     0/ 7461/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "                      AVERAGES     0.936      0.100     0.106     0.066      7461     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "             Weighted AVERAGES     0.596      0.351     0.823     0.384      7461     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "       known Weighted AVERAGES     0.959      0.817     0.818     0.817      7461     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      " known -ping Weighted AVERAGES     0.980      0.005     0.000     0.000      7461     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "       non zero count AVERAGES     0.911      0.142     0.150     0.093      7461     0/    0/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "Macro F1 : 0.065730\n",
      "sample F1 : 0.336059\n",
      "weighted F1 : 0.384453\n",
      "--------------------------removed ping and unknown----------------------------------------------\n",
      "Macro F1 : 0.003676\n",
      "sample F1 : 0.000209\n",
      "weighted F1 : 0.000037\n",
      "Exact Match ACC : 0.31497 \n",
      "Total Records : 7461 \n",
      "Total ZXeros in True : 0 (0.000)%\n",
      "Total ZXeros in Test : 2218 (0.297)%\n",
      "=============================================================================\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(lstm_tests_known)) :\n",
    "    print( \"==================HOME Case : %s =============\" % test_names[i])\n",
    "    lstm_pred= model2.predict( lstm_tests_known[i][0])\n",
    "    \n",
    "#     print_info( lstm_tests[i][1], lstm_pred, classes , confidance=0.7)\n",
    "    print_info( lstm_tests_known[i][1], lstm_pred, classes , confidance=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f2f1c4d7630>]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(hist2.history['f1_perClass'], c='red')\n",
    "plt.plot(hist2.history['loss'], c='blue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(lstm_tests)) :\n",
    "    print( \"==================HOME Case : %s =============\" % test_names[i])\n",
    "    lstm_pred= model2.predict( lstm_tests[i][0])\n",
    "    \n",
    "#     print_info( lstm_tests[i][1], lstm_pred, classes , confidance=0.7)\n",
    "    print_info( lstm_tests[i][1], lstm_pred, classes , confidance=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(hist2.history['f1_perClass'], c='red')\n",
    "plt.plot(hist2.history['loss'], c='blue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Bidirectional LSTM :D \n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers import Bidirectional\n",
    "from keras.layers import Flatten\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from keras.models import Model\n",
    "\n",
    "from keras.layers import Input, merge, concatenate, Conv2D, MaxPooling2D, Activation, UpSampling2D, Dropout, Conv2DTranspose, UpSampling2D, Lambda\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers.normalization import BatchNormalization as bn\n",
    "from keras.layers.merge import add\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from keras.optimizers import RMSprop\n",
    "from keras import regularizers\n",
    "from keras import backend as K\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers.merge import add\n",
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "from keras.regularizers import l2\n",
    "from keras.layers import Conv1D\n",
    "from keras.layers.merge import add\n",
    "from keras.layers import Dense,Conv1D,Dropout,Activation,BatchNormalization,MaxPooling1D,Flatten,Masking,TimeDistributed\n",
    "from keras.layers.recurrent import LSTM,GRU,SimpleRNN\n",
    "from keras.models import Input,Sequential,Model\n",
    "from keras.layers.merge import add\n",
    "from keras.optimizers import Adam\n",
    "from keras.losses import MSE,MSLE\n",
    "\n",
    "model2 = Sequential()\n",
    "\n",
    "\n",
    "def weighted_categorical_crossentropy(weights):\n",
    "    \"\"\"\n",
    "    A weighted version of keras.objectives.categorical_crossentropy\n",
    "    \n",
    "    Variables:\n",
    "        weights: numpy array of shape (C,) where C is the number of classes\n",
    "    \n",
    "    Usage:\n",
    "        weights = np.array([0.5,2,10]) # Class one at 0.5, class 2 twice the normal weights, class 3 10x.\n",
    "        loss = weighted_categorical_crossentropy(weights)\n",
    "        model.compile(loss=loss,optimizer='adam')\n",
    "    \"\"\"\n",
    "    \n",
    "    weights = K.variable(weights)\n",
    "        \n",
    "    def loss(y_true, y_pred):\n",
    "        # scale predictions so that the class probas of each sample sum to 1\n",
    "        y_pred /= K.sum(y_pred, axis=-1, keepdims=True)\n",
    "        # clip to prevent NaN's and Inf's\n",
    "        y_pred = K.clip(y_pred, K.epsilon(), 1 - K.epsilon())\n",
    "        # calc\n",
    "        loss = y_true * K.log(y_pred) * weights\n",
    "        loss = -K.sum(loss, -1)\n",
    "        return loss\n",
    "    \n",
    "    return loss\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "def f1_perRow(y_true, y_pred):\n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return K.mean(f1)\n",
    "\n",
    "\n",
    "def f1_perClass(y_true, y_pred):\n",
    "\n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=1)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=1)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=1)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=1)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return K.mean(f1)\n",
    "\n",
    "def f1_loss_perClass(y_true, y_pred):\n",
    "    \n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=1)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=1)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=1)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=1)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return (1 - K.mean(f1))**2\n",
    "\n",
    "def f1_loss_perRow(y_true, y_pred):\n",
    "    \n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return (1 - K.mean(f1))**2\n",
    "\n",
    "\n",
    "\n",
    "inputs  = Input( ( dim_size,1 ) )\n",
    "\n",
    "\n",
    "\n",
    "# bi_d_1 = Bidirectional( LSTM(200 ,  recurrent_dropout=0.12, return_sequences=True),input_shape=[dim_size,1],merge_mode='concat') (inputs)\n",
    "lstm_1 =  LSTM(100 ,  recurrent_dropout=0.04, return_sequences=True)(inputs)\n",
    "# lstm_2 = LSTM(30 ,  recurrent_dropout=0.14, return_sequences=True)(lstm_1)\n",
    "\n",
    "bi_d_1 =Dense(128, activation='relu')  (lstm_1)\n",
    "lstm_1 =  Dense(128, activation='relu')(bi_d_1)\n",
    "lstm_2 = Dense(128, activation='relu')(lstm_1)\n",
    "\n",
    "\n",
    "\n",
    "# td_1    = TimeDistributed(Dense(256, activation='relu'))(lstm_2)\n",
    "# dout_1  = Dropout(0.1)(td_1)\n",
    "dout_1  = Dropout(0.1)(lstm_2)\n",
    "flt_1   = Flatten()(dout_1)\n",
    "dense_1 = Dense(128, activation='relu')(flt_1)\n",
    "dout_2  = Dropout(0.2)(dense_1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "dens_out_3 = Dense( 128, activation='relu' )(dout_2)\n",
    "\n",
    "\n",
    "# fl2  = Flatten()(out_new)\n",
    "\n",
    "out_put_final = Dense(len(classes), activation='sigmoid', name='Event_output')(dens_out_3)\n",
    "\n",
    "toService_1 = Dense( 130, name=\"to_service1\" )(dens_out_3)\n",
    "toService_1 = Dense( 130, name=\"to_service2\" )(toService_1)\n",
    "\n",
    "service_output = Dense(len(classes  ), activation=\"sigmoid\", name = 'service_output')(toService_1)\n",
    "\n",
    "\n",
    "\n",
    "model2 = Model(inputs=[inputs], outputs=[service_output])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# model2.add(Bidirectional( LSTM(200 ,  recurrent_dropout=0.12, return_sequences=True),input_shape=[dim_size,1],merge_mode='concat'))\n",
    "# model2.add( LSTM(60 ,  recurrent_dropout=0.04, return_sequences=True))\n",
    "# model2.add( LSTM(30 ,  recurrent_dropout=0.14, return_sequences=True))\n",
    "# # model2.add(Bidirectional( LSTM(100 ,  recurrent_dropout=0.04, return_sequences=True),merge_mode='concat'))\n",
    "# model2.add(TimeDistributed(Dense(256, activation='relu')))\n",
    "# model2.add(Dropout(0.1))\n",
    "# model2.add(Flatten())\n",
    "# model2.add(Dense(128, activation='relu'))\n",
    "# model2.add(Dropout(0.2))\n",
    "# model2.add(Dense(len(classes), activation='sigmoid'))\n",
    "\n",
    "# model2.compile(loss=weighted_categorical_crossentropy(weights=weights), optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "losses = {\n",
    "#     \"service_output\": f1_loss_perClass ,\n",
    "    \"service_output\": f1_loss_perRow ,\n",
    "    \"service_output\": \"categorical_crossentropy\",\n",
    "}\n",
    "lossWeights = {#\"service_output\": 20,\n",
    "               \"service_output\": 30.0 ,\n",
    "    \"service_output\": 20}\n",
    " \n",
    "\n",
    "\n",
    "#model2.compile(loss=losses,loss_weights=lossWeights, optimizer='adam', metrics=[f1_perRow,f1_perClass,'acc'])\n",
    "model2.compile(loss=losses, loss_weights=lossWeights, optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "checkpoint = ModelCheckpoint('IoTDownNet', monitor='loss', verbose=0, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "print(model2.summary())\n",
    "hist2 = model2.fit(x_lstm_prossed_train2, y_lstm_prossed_train, epochs=1000, batch_size=12500, shuffle=True, callbacks=callbacks_list)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Bidirectional LSTM :D \n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers import Bidirectional\n",
    "from keras.layers import Flatten\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from keras.models import Model\n",
    "\n",
    "from keras.layers import Input, merge, concatenate, Conv2D, MaxPooling2D, Activation, UpSampling2D, Dropout, Conv2DTranspose, UpSampling2D, Lambda\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers.normalization import BatchNormalization as bn\n",
    "from keras.layers.merge import add\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from keras.optimizers import RMSprop\n",
    "from keras import regularizers\n",
    "from keras import backend as K\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers.merge import add\n",
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "from keras.regularizers import l2\n",
    "from keras.layers import Conv1D\n",
    "from keras.layers.merge import add\n",
    "from keras.layers import Dense,Conv1D,Dropout,Activation,BatchNormalization,MaxPooling1D,Flatten,Masking,TimeDistributed\n",
    "from keras.layers.recurrent import LSTM,GRU,SimpleRNN\n",
    "from keras.models import Input,Sequential,Model\n",
    "from keras.layers.merge import add\n",
    "from keras.optimizers import Adam\n",
    "from keras.losses import MSE,MSLE\n",
    "\n",
    "model2 = Sequential()\n",
    "\n",
    "\n",
    "def weighted_categorical_crossentropy(weights):\n",
    "    \"\"\"\n",
    "    A weighted version of keras.objectives.categorical_crossentropy\n",
    "    \n",
    "    Variables:\n",
    "        weights: numpy array of shape (C,) where C is the number of classes\n",
    "    \n",
    "    Usage:\n",
    "        weights = np.array([0.5,2,10]) # Class one at 0.5, class 2 twice the normal weights, class 3 10x.\n",
    "        loss = weighted_categorical_crossentropy(weights)\n",
    "        model.compile(loss=loss,optimizer='adam')\n",
    "    \"\"\"\n",
    "    \n",
    "    weights = K.variable(weights)\n",
    "        \n",
    "    def loss(y_true, y_pred):\n",
    "        # scale predictions so that the class probas of each sample sum to 1\n",
    "        y_pred /= K.sum(y_pred, axis=-1, keepdims=True)\n",
    "        # clip to prevent NaN's and Inf's\n",
    "        y_pred = K.clip(y_pred, K.epsilon(), 1 - K.epsilon())\n",
    "        # calc\n",
    "        loss = y_true * K.log(y_pred) * weights\n",
    "        loss = -K.sum(loss, -1)\n",
    "        return loss\n",
    "    \n",
    "    return loss\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "def f1_perRow(y_true, y_pred):\n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return K.mean(f1)\n",
    "\n",
    "\n",
    "def f1_perClass(y_true, y_pred):\n",
    "\n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=1)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=1)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=1)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=1)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return K.mean(f1)\n",
    "\n",
    "def f1_loss_perClass(y_true, y_pred):\n",
    "    \n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=1)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=1)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=1)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=1)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return (1 - K.mean(f1))**2\n",
    "\n",
    "def f1_loss_perRow(y_true, y_pred):\n",
    "    \n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return (1 - K.mean(f1))**2\n",
    "\n",
    "\n",
    "\n",
    "inputs  = Input( ( dim_size,1 ) )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "out = Conv1D(128,3,padding='same')(inputs)\n",
    "out = BatchNormalization()(out)\n",
    "out = Activation('relu')(out)\n",
    "out = Dropout(0.2)(out)\n",
    "out = Conv1D(128,3,padding='same')(out)\n",
    "# out = Flatten()(out)\n",
    "# out = MaxPooling1D(2,padding='same', name ='pooling')(out)\n",
    "\n",
    "\n",
    "out = Conv1D(128,3,padding='same')(out)\n",
    "out = BatchNormalization()(out)\n",
    "out = Activation('relu')(out)\n",
    "out = Dropout(0.2)(out)\n",
    "out = Conv1D(128,3,padding='same')(out)\n",
    "# out = Flatten()(out)\n",
    "# out = MaxPooling1D(2,padding='same', name ='pooling2')(out)\n",
    "\n",
    "\n",
    "out = Conv1D(128,3,padding='same')(out)\n",
    "out = BatchNormalization()(out)\n",
    "out = Activation('relu')(out)\n",
    "out = Dropout(0.2)(out)\n",
    "out = Conv1D(128,3,padding='same')(out)\n",
    "# out = Flatten()(out)\n",
    "# out = MaxPooling1D(2,padding='same', name ='pooling')(out)\n",
    "\n",
    "\n",
    "\n",
    "# fl_out_1 = Flatten()(dout_2)\n",
    "\n",
    "fl_out_cnn = Flatten()(out)\n",
    "\n",
    "\n",
    "dens_out_3 = Dense( 128, activation='relu' )(fl_out_cnn)\n",
    "\n",
    "# fl2  = Flatten()(out_new)\n",
    "\n",
    "out_put_final = Dense(len(classes), activation='sigmoid', name='Event_output')(dens_out_3)\n",
    "\n",
    "toService_1 = Dense( 130, name=\"to_service1\" )(dens_out_3)\n",
    "toService_1 = Dense( 130, name=\"to_service2\" )(toService_1)\n",
    "\n",
    "service_output = Dense(len(classes  ), activation=\"sigmoid\", name = 'service_output')(toService_1)\n",
    "\n",
    "\n",
    "\n",
    "model2 = Model(inputs=[inputs], outputs=[service_output])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# model2.add(Bidirectional( LSTM(200 ,  recurrent_dropout=0.12, return_sequences=True),input_shape=[dim_size,1],merge_mode='concat'))\n",
    "# model2.add( LSTM(60 ,  recurrent_dropout=0.04, return_sequences=True))\n",
    "# model2.add( LSTM(30 ,  recurrent_dropout=0.14, return_sequences=True))\n",
    "# # model2.add(Bidirectional( LSTM(100 ,  recurrent_dropout=0.04, return_sequences=True),merge_mode='concat'))\n",
    "# model2.add(TimeDistributed(Dense(256, activation='relu')))\n",
    "# model2.add(Dropout(0.1))\n",
    "# model2.add(Flatten())\n",
    "# model2.add(Dense(128, activation='relu'))\n",
    "# model2.add(Dropout(0.2))\n",
    "# model2.add(Dense(len(classes), activation='sigmoid'))\n",
    "\n",
    "# model2.compile(loss=weighted_categorical_crossentropy(weights=weights), optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "losses = {\n",
    "#     \"service_output\": f1_loss_perClass ,\n",
    "    \"service_output\": f1_loss_perRow ,\n",
    "    \"service_output\": \"categorical_crossentropy\",\n",
    "}\n",
    "lossWeights = {#\"service_output\": 20,\n",
    "               \"service_output\": 30.0 ,\n",
    "    \"service_output\": 20}\n",
    " \n",
    "\n",
    "\n",
    "model2.compile(loss=losses,loss_weights=lossWeights, optimizer='adam', metrics=[f1_perRow,f1_perClass,'acc'])\n",
    "# model2.compile(loss=losses, loss_weights=lossWeights, optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "checkpoint = ModelCheckpoint('IoTDownNet', monitor='loss', verbose=0, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "print(model2.summary())\n",
    "hist2 = model2.fit(x_lstm_prossed_train2, y_lstm_prossed_train, epochs=100, batch_size=12500, shuffle=True, callbacks=callbacks_list)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Bidirectional LSTM :D \n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers import Bidirectional\n",
    "from keras.layers import Flatten\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from keras.models import Model\n",
    "\n",
    "from keras.layers import Input, merge, concatenate, Conv2D, MaxPooling2D, Activation, UpSampling2D, Dropout, Conv2DTranspose, UpSampling2D, Lambda\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers.normalization import BatchNormalization as bn\n",
    "from keras.layers.merge import add\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from keras.optimizers import RMSprop\n",
    "from keras import regularizers\n",
    "from keras import backend as K\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers.merge import add\n",
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "from keras.regularizers import l2\n",
    "from keras.layers import Conv1D\n",
    "from keras.layers.merge import add\n",
    "from keras.layers import Dense,Conv1D,Dropout,Activation,BatchNormalization,MaxPooling1D,Flatten,Masking,TimeDistributed\n",
    "from keras.layers.recurrent import LSTM,GRU,SimpleRNN\n",
    "from keras.models import Input,Sequential,Model\n",
    "from keras.layers.merge import add\n",
    "from keras.optimizers import Adam\n",
    "from keras.losses import MSE,MSLE\n",
    "\n",
    "model2 = Sequential()\n",
    "\n",
    "\n",
    "def weighted_categorical_crossentropy(weights):\n",
    "    \"\"\"\n",
    "    A weighted version of keras.objectives.categorical_crossentropy\n",
    "    \n",
    "    Variables:\n",
    "        weights: numpy array of shape (C,) where C is the number of classes\n",
    "    \n",
    "    Usage:\n",
    "        weights = np.array([0.5,2,10]) # Class one at 0.5, class 2 twice the normal weights, class 3 10x.\n",
    "        loss = weighted_categorical_crossentropy(weights)\n",
    "        model.compile(loss=loss,optimizer='adam')\n",
    "    \"\"\"\n",
    "    \n",
    "    weights = K.variable(weights)\n",
    "        \n",
    "    def loss(y_true, y_pred):\n",
    "        # scale predictions so that the class probas of each sample sum to 1\n",
    "        y_pred /= K.sum(y_pred, axis=-1, keepdims=True)\n",
    "        # clip to prevent NaN's and Inf's\n",
    "        y_pred = K.clip(y_pred, K.epsilon(), 1 - K.epsilon())\n",
    "        # calc\n",
    "        loss = y_true * K.log(y_pred) * weights\n",
    "        loss = -K.sum(loss, -1)\n",
    "        return loss\n",
    "    \n",
    "    return loss\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "def f1_perRow(y_true, y_pred):\n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return K.mean(f1)\n",
    "\n",
    "\n",
    "def f1_perClass(y_true, y_pred):\n",
    "\n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=1)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=1)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=1)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=1)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return K.mean(f1)\n",
    "\n",
    "def f1_loss_perClass(y_true, y_pred):\n",
    "    \n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=1)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=1)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=1)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=1)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return (1 - K.mean(f1)) \n",
    "\n",
    "def f1_loss_perRow(y_true, y_pred):\n",
    "    \n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return (1 - K.mean(f1))\n",
    "\n",
    "\n",
    "\n",
    "inputs  = Input( ( dim_size,1 ) )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# bi_d_1 = Bidirectional( LSTM(200 ,  recurrent_dropout=0.12, return_sequences=True),input_shape=[dim_size,1],merge_mode='concat') (inputs)\n",
    "lstm_1 =  LSTM(100 ,  recurrent_dropout=0.04, return_sequences=True)(inputs)\n",
    "# lstm_1 = LSTM(40 ,  recurrent_dropout=0.14, return_sequences=True)(lstm_1)\n",
    "\n",
    "bi_d_raw_1 =Dense(128, activation='relu')  (lstm_1)\n",
    "lstm_raw_1 =  Dense(128, activation='relu')(bi_d_raw_1)\n",
    "lstm_raw_2 = Dense(128, activation='relu')(lstm_raw_1)\n",
    "\n",
    "dout_1  = Dropout(0.1)(lstm_raw_2)\n",
    "flt_1   = Flatten()(dout_1)\n",
    "dense_1 = Dense(128, activation='relu')(flt_1)\n",
    "dout_3  = Dropout(0.2)(dense_1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "out = Conv1D(128,3,padding='same')(inputs)\n",
    "out = BatchNormalization()(out)\n",
    "out = Activation('relu')(out)\n",
    "out = Dropout(0.2)(out)\n",
    "out = Conv1D(128,3,padding='same')(out)\n",
    "# out = Flatten()(out)\n",
    "# out = MaxPooling1D(2,padding='same', name ='pooling')(out)\n",
    "\n",
    "\n",
    "out = Conv1D(128,3,padding='same')(out)\n",
    "out = BatchNormalization()(out)\n",
    "out = Activation('relu')(out)\n",
    "out = Dropout(0.2)(out)\n",
    "out = Conv1D(128,3,padding='same')(out)\n",
    "# out = Flatten()(out)\n",
    "# out = MaxPooling1D(2,padding='same', name ='pooling2')(out)\n",
    "\n",
    "\n",
    "out = Conv1D(128,3,padding='same')(out)\n",
    "out = BatchNormalization()(out)\n",
    "out = Activation('relu')(out)\n",
    "out = Dropout(0.2)(out)\n",
    "out = Conv1D(128,3,padding='same')(out)\n",
    "# out = Flatten()(out)\n",
    "# out = MaxPooling1D(2,padding='same', name ='pooling')(out)\n",
    "\n",
    "\n",
    "\n",
    "# fl_out_1 = Flatten()(dout_2)\n",
    "\n",
    "fl_out_cnn = Flatten()(out)\n",
    "\n",
    "# out_new = concatenate( [fl_out_1, fl_out_cnn] , name='mergerguy')\n",
    "out_new = concatenate( [ fl_out_cnn,dout_3] , name='mergerguy')\n",
    "\n",
    "dens_out_1 = Dense( 128, activation='relu' )(out_new)\n",
    "dens_out_2 = Dense( 128, activation='relu' )(dens_out_1)\n",
    "dens_out_3 = Dense( 128, activation='relu' )(dens_out_2)\n",
    "\n",
    "\n",
    "\n",
    "service_output = Dense(len(classes  ), activation=\"sigmoid\", name = 'service_output')(dens_out_3)\n",
    "\n",
    "\n",
    "\n",
    "model2 = Model(inputs=[inputs], outputs=[service_output])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# model2.add(Bidirectional( LSTM(200 ,  recurrent_dropout=0.12, return_sequences=True),input_shape=[dim_size,1],merge_mode='concat'))\n",
    "# model2.add( LSTM(60 ,  recurrent_dropout=0.04, return_sequences=True))\n",
    "# model2.add( LSTM(30 ,  recurrent_dropout=0.14, return_sequences=True))\n",
    "# # model2.add(Bidirectional( LSTM(100 ,  recurrent_dropout=0.04, return_sequences=True),merge_mode='concat'))\n",
    "# model2.add(TimeDistributed(Dense(256, activation='relu')))\n",
    "# model2.add(Dropout(0.1))\n",
    "# model2.add(Flatten())\n",
    "# model2.add(Dense(128, activation='relu'))\n",
    "# model2.add(Dropout(0.2))\n",
    "# model2.add(Dense(len(classes), activation='sigmoid'))\n",
    "\n",
    "# model2.compile(loss=weighted_categorical_crossentropy(weights=weights), optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "losses = {\n",
    "#     \"service_output\": f1_loss_perClass ,\n",
    "    \"service_output\": f1_loss_perRow ,\n",
    "    \"service_output\": \"categorical_crossentropy\",\n",
    "}\n",
    "lossWeights = {#\"service_output\": 20,\n",
    "               \"service_output\": 30.0 ,\n",
    "    \"service_output\": 20}\n",
    " \n",
    "\n",
    "\n",
    "model2.compile(loss=losses,loss_weights=lossWeights, optimizer='adam', metrics=[f1_perRow,f1_perClass,'acc'])\n",
    "# model2.compile(loss=losses, loss_weights=lossWeights, optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "checkpoint = ModelCheckpoint('IoTDownNet', monitor='loss', verbose=0, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "print(model2.summary())\n",
    "hist2 = model2.fit(x_lstm_prossed_train2, y_lstm_prossed_train, epochs=100, batch_size=12500, shuffle=True, callbacks=callbacks_list)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = {\n",
    "#     \"service_output\": f1_loss_perClass ,\n",
    "    \"service_output\": f1_loss_perClass ,\n",
    "#     \"service_output\": \"categorical_crossentropy\",\n",
    "}\n",
    "lossWeights = {#\"service_output\": 20,\n",
    "               \"service_output\": 30.0 ,\n",
    "#     \"service_output\": 20\n",
    "}\n",
    " \n",
    "\n",
    "\n",
    "model2.compile(loss=losses, loss_weights=lossWeights, optimizer=keras.optimizers.Adam(lr=1e-6  ), metrics=[f1_perRow,f1_perClass,'acc'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Bidirectional LSTM :D \n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers import Bidirectional\n",
    "from keras.layers import Flatten\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from keras.models import Model\n",
    "\n",
    "from keras.layers import Input, merge, concatenate, Conv2D, MaxPooling2D, Activation, UpSampling2D, Dropout, Conv2DTranspose, UpSampling2D, Lambda\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers.normalization import BatchNormalization as bn\n",
    "from keras.layers.merge import add\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from keras.optimizers import RMSprop\n",
    "from keras import regularizers\n",
    "from keras import backend as K\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers.merge import add\n",
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "from keras.regularizers import l2\n",
    "from keras.layers import Conv1D\n",
    "from keras.layers.merge import add\n",
    "from keras.layers import Dense,Conv1D,Dropout,Activation,BatchNormalization,MaxPooling1D,Flatten,Masking,TimeDistributed\n",
    "from keras.layers.recurrent import LSTM,GRU,SimpleRNN\n",
    "from keras.models import Input,Sequential,Model\n",
    "from keras.layers.merge import add\n",
    "from keras.optimizers import Adam\n",
    "from keras.losses import MSE,MSLE\n",
    "\n",
    "model2 = Sequential()\n",
    "\n",
    "\n",
    "def weighted_categorical_crossentropy(weights):\n",
    "    \"\"\"\n",
    "    A weighted version of keras.objectives.categorical_crossentropy\n",
    "    \n",
    "    Variables:\n",
    "        weights: numpy array of shape (C,) where C is the number of classes\n",
    "    \n",
    "    Usage:\n",
    "        weights = np.array([0.5,2,10]) # Class one at 0.5, class 2 twice the normal weights, class 3 10x.\n",
    "        loss = weighted_categorical_crossentropy(weights)\n",
    "        model.compile(loss=loss,optimizer='adam')\n",
    "    \"\"\"\n",
    "    \n",
    "    weights = K.variable(weights)\n",
    "        \n",
    "    def loss(y_true, y_pred):\n",
    "        # scale predictions so that the class probas of each sample sum to 1\n",
    "        y_pred /= K.sum(y_pred, axis=-1, keepdims=True)\n",
    "        # clip to prevent NaN's and Inf's\n",
    "        y_pred = K.clip(y_pred, K.epsilon(), 1 - K.epsilon())\n",
    "        # calc\n",
    "        loss = y_true * K.log(y_pred) * weights\n",
    "        loss = -K.sum(loss, -1)\n",
    "        return loss\n",
    "    \n",
    "    return loss\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "def f1_perRow(y_true, y_pred):\n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return K.mean(f1)\n",
    "\n",
    "\n",
    "def f1_perClass(y_true, y_pred):\n",
    "\n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=1)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=1)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=1)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=1)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return K.mean(f1)\n",
    "\n",
    "def f1_loss_perClass(y_true, y_pred):\n",
    "    \n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=1)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=1)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=1)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=1)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return (1 - K.mean(f1))**2\n",
    "\n",
    "def f1_loss_perRow(y_true, y_pred):\n",
    "    \n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return (1 - K.mean(f1))**2\n",
    "\n",
    "\n",
    "\n",
    "inputs  = Input( ( dim_size,1 ) )\n",
    "\n",
    "\n",
    "\n",
    "# bi_d_1 = Bidirectional( LSTM(200 ,  recurrent_dropout=0.12, return_sequences=True),input_shape=[dim_size,1],merge_mode='concat') (inputs)\n",
    "lstm_1 =  LSTM(32 ,  recurrent_dropout=0.3, return_sequences=True)(inputs)\n",
    "lstm_2 = LSTM(32 ,  recurrent_dropout=0.3, return_sequences=True)(lstm_1)\n",
    "\n",
    "lstm_2=Flatten()(lstm_2)\n",
    "lstm_2 = Dense(256, activation='relu')(lstm_2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "service_output = Dense(len(classes  ), activation=\"sigmoid\", name = 'service_output')(lstm_2)\n",
    "\n",
    "\n",
    "\n",
    "model2 = Model(inputs=[inputs], outputs=[service_output])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# model2.add(Bidirectional( LSTM(200 ,  recurrent_dropout=0.12, return_sequences=True),input_shape=[dim_size,1],merge_mode='concat'))\n",
    "# model2.add( LSTM(60 ,  recurrent_dropout=0.04, return_sequences=True))\n",
    "# model2.add( LSTM(30 ,  recurrent_dropout=0.14, return_sequences=True))\n",
    "# # model2.add(Bidirectional( LSTM(100 ,  recurrent_dropout=0.04, return_sequences=True),merge_mode='concat'))\n",
    "# model2.add(TimeDistributed(Dense(256, activation='relu')))\n",
    "# model2.add(Dropout(0.1))\n",
    "# model2.add(Flatten())\n",
    "# model2.add(Dense(128, activation='relu'))\n",
    "# model2.add(Dropout(0.2))\n",
    "# model2.add(Dense(len(classes), activation='sigmoid'))\n",
    "\n",
    "# model2.compile(loss=weighted_categorical_crossentropy(weights=weights), optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "losses = {\n",
    "#     \"service_output\": f1_loss_perClass ,\n",
    "    \"service_output\": f1_loss_perRow ,\n",
    "    \"service_output\": \"categorical_crossentropy\",\n",
    "}\n",
    "lossWeights = {#\"service_output\": 20,\n",
    "               \"service_output\": 30.0 ,\n",
    "    \"service_output\": 20}\n",
    " \n",
    "\n",
    "\n",
    "model2.compile(loss=losses,loss_weights=lossWeights, optimizer='adam', metrics=[f1_perRow,f1_perClass,'acc'])\n",
    "# model2.compile(loss=losses, loss_weights=lossWeights, optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "checkpoint = ModelCheckpoint('IoTDownNet', monitor='loss', verbose=0, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "print(model2.summary())\n",
    "\n",
    "hist2 = model2.fit(x_lstm_prossed_train2, y_lstm_prossed_train, epochs=100, batch_size=12500, shuffle=True, callbacks=callbacks_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split model\n",
    "## Bidirectional LSTM :D \n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers import Bidirectional\n",
    "from keras.layers import Flatten\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from keras.models import Model\n",
    "\n",
    "from keras.layers import Input, merge, concatenate, Conv2D, MaxPooling2D, Activation, UpSampling2D, Dropout, Conv2DTranspose, UpSampling2D, Lambda\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers.normalization import BatchNormalization as bn\n",
    "from keras.layers.merge import add\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from keras.optimizers import RMSprop\n",
    "from keras import regularizers\n",
    "from keras import backend as K\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers.merge import add\n",
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "from keras.regularizers import l2\n",
    "from keras.layers import Conv1D\n",
    "from keras.layers.merge import add\n",
    "from keras.layers import Dense,Conv1D,Dropout,Activation,BatchNormalization,MaxPooling1D,Flatten,Masking,TimeDistributed\n",
    "from keras.layers.recurrent import LSTM,GRU,SimpleRNN\n",
    "from keras.models import Input,Sequential,Model\n",
    "from keras.layers.merge import add\n",
    "from keras.optimizers import Adam\n",
    "from keras.losses import MSE,MSLE\n",
    "\n",
    "model2 = Sequential()\n",
    "\n",
    "\n",
    "def weighted_categorical_crossentropy(weights):\n",
    "    \"\"\"\n",
    "    A weighted version of keras.objectives.categorical_crossentropy\n",
    "    \n",
    "    Variables:\n",
    "        weights: numpy array of shape (C,) where C is the number of classes\n",
    "    \n",
    "    Usage:\n",
    "        weights = np.array([0.5,2,10]) # Class one at 0.5, class 2 twice the normal weights, class 3 10x.\n",
    "        loss = weighted_categorical_crossentropy(weights)\n",
    "        model.compile(loss=loss,optimizer='adam')\n",
    "    \"\"\"\n",
    "    \n",
    "    weights = K.variable(weights)\n",
    "        \n",
    "    def loss(y_true, y_pred):\n",
    "        # scale predictions so that the class probas of each sample sum to 1\n",
    "        y_pred /= K.sum(y_pred, axis=-1, keepdims=True)\n",
    "        # clip to prevent NaN's and Inf's\n",
    "        y_pred = K.clip(y_pred, K.epsilon(), 1 - K.epsilon())\n",
    "        # calc\n",
    "        loss = y_true * K.log(y_pred) * weights\n",
    "        loss = -K.sum(loss, -1)\n",
    "        return loss\n",
    "    \n",
    "    return loss\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "def f1_perRow(y_true, y_pred):\n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return K.mean(f1)\n",
    "\n",
    "\n",
    "def f1_perClass(y_true, y_pred):\n",
    "\n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=1)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=1)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=1)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=1)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return K.mean(f1)\n",
    "\n",
    "def f1_loss_perClass(y_true, y_pred):\n",
    "    \n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=1)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=1)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=1)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=1)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return (1 - K.mean(f1))**2\n",
    "\n",
    "def f1_loss_perRow(y_true, y_pred):\n",
    "    \n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return (1 - K.mean(f1))**2\n",
    "\n",
    "#splitting data\n",
    "X=x_lstm_prossed_train2\n",
    "y=y_lstm_prossed_train\n",
    "a,b,c,d,e,f,g,h,ii,jj,k,l,m,n,o,p=[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]\n",
    "print(len(y_lstm_prossed_train[0]))\n",
    "for i in range(0,len(y_lstm_prossed_train)):\n",
    "    a.append(y_lstm_prossed_train[i][0])\n",
    "    b.append(y_lstm_prossed_train[i][1])\n",
    "    c.append(y_lstm_prossed_train[i][2])\n",
    "    d.append(y_lstm_prossed_train[i][3])\n",
    "    e.append(y_lstm_prossed_train[i][4])\n",
    "    f.append(y_lstm_prossed_train[i][5])\n",
    "    g.append(y_lstm_prossed_train[i][6])\n",
    "    h.append(y_lstm_prossed_train[i][7])\n",
    "    ii.append(y_lstm_prossed_train[i][8])\n",
    "    jj.append(y_lstm_prossed_train[i][9])\n",
    "    k.append(y_lstm_prossed_train[i][10])\n",
    "    l.append(y_lstm_prossed_train[i][11])\n",
    "    m.append(y_lstm_prossed_train[i][12])\n",
    "    n.append(y_lstm_prossed_train[i][13])\n",
    "    o.append(y_lstm_prossed_train[i][14])\n",
    "    p.append(y_lstm_prossed_train[i][15])\n",
    "    \n",
    "zzzz=[]    \n",
    "zzzz.append(np.array(a))\n",
    "zzzz.append(np.array(b))\n",
    "zzzz.append(np.array(c))\n",
    "zzzz.append(np.array(d))\n",
    "zzzz.append(np.array(e))\n",
    "zzzz.append(np.array(f))\n",
    "zzzz.append(np.array(g))\n",
    "zzzz.append(np.array(h))\n",
    "zzzz.append(np.array(ii))\n",
    "zzzz.append(np.array(jj))\n",
    "zzzz.append(np.array(k))\n",
    "zzzz.append(np.array(l))\n",
    "zzzz.append(np.array(m))\n",
    "zzzz.append(np.array(n))\n",
    "zzzz.append(np.array(o))\n",
    "zzzz.append(np.array(p))\n",
    "\n",
    "\n",
    "for i in range(0,16):\n",
    "    \n",
    "    \n",
    "        \n",
    "        \n",
    "    \n",
    "\n",
    "\n",
    "    inputs  = Input( ( dim_size,1 ) )\n",
    "\n",
    "\n",
    "    out = Conv1D(128,3,padding='same')(inputs)\n",
    "    out = BatchNormalization()(out)\n",
    "    out = Activation('relu')(out)\n",
    "    out = Dropout(0.2)(out)\n",
    "    out = Conv1D(128,3,padding='same')(out)\n",
    "    # bi_d_1 = Bidirectional( LSTM(200 ,  recurrent_dropout=0.12, return_sequences=True),input_shape=[dim_size,1],merge_mode='concat') (inputs)\n",
    "    lstm_1 =  LSTM(100 ,  recurrent_dropout=0.04, return_sequences=True)(out)\n",
    "    # lstm_2 = LSTM(30 ,  recurrent_dropout=0.14, return_sequences=True)(lstm_1)\n",
    "\n",
    "    bi_d_1 =Dense(128, activation='relu')  (lstm_1)\n",
    "    lstm_1 =  Dense(128, activation='relu')(bi_d_1)\n",
    "    lstm_2 = Dense(128, activation='relu')(lstm_1)\n",
    "\n",
    "\n",
    "\n",
    "    # td_1    = TimeDistributed(Dense(256, activation='relu'))(lstm_2)\n",
    "    # dout_1  = Dropout(0.1)(td_1)\n",
    "    dout_1  = Dropout(0.1)(lstm_2)\n",
    "    flt_1   = Flatten()(dout_1)\n",
    "    dense_1 = Dense(128, activation='relu')(flt_1)\n",
    "    dout_2  = Dropout(0.2)(dense_1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # bi_d_1 = Bidirectional( LSTM(200 ,  recurrent_dropout=0.12, return_sequences=True),input_shape=[dim_size,1],merge_mode='concat') (inputs)\n",
    "    lstm_1 =  LSTM(100 ,  recurrent_dropout=0.04, return_sequences=True)(inputs)\n",
    "    # lstm_1 = LSTM(40 ,  recurrent_dropout=0.14, return_sequences=True)(lstm_1)\n",
    "\n",
    "    bi_d_raw_1 =Dense(128, activation='relu')  (lstm_1)\n",
    "    lstm_raw_1 =  Dense(128, activation='relu')(bi_d_raw_1)\n",
    "    lstm_raw_2 = Dense(128, activation='relu')(lstm_raw_1)\n",
    "\n",
    "    dout_1  = Dropout(0.1)(lstm_raw_2)\n",
    "    flt_1   = Flatten()(dout_1)\n",
    "    dense_1 = Dense(128, activation='relu')(flt_1)\n",
    "    dout_3  = Dropout(0.2)(dense_1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    out = Conv1D(128,3,padding='same')(inputs)\n",
    "    out = BatchNormalization()(out)\n",
    "    out = Activation('relu')(out)\n",
    "    out = Dropout(0.2)(out)\n",
    "    out = Conv1D(128,3,padding='same')(out)\n",
    "    # out = Flatten()(out)\n",
    "    # out = MaxPooling1D(2,padding='same', name ='pooling')(out)\n",
    "\n",
    "\n",
    "    out = Conv1D(128,3,padding='same')(out)\n",
    "    out = BatchNormalization()(out)\n",
    "    out = Activation('relu')(out)\n",
    "    out = Dropout(0.2)(out)\n",
    "    out = Conv1D(128,3,padding='same')(out)\n",
    "    # out = Flatten()(out)\n",
    "    # out = MaxPooling1D(2,padding='same', name ='pooling2')(out)\n",
    "\n",
    "\n",
    "    out = Conv1D(128,3,padding='same')(out)\n",
    "    out = BatchNormalization()(out)\n",
    "    out = Activation('relu')(out)\n",
    "    out = Dropout(0.2)(out)\n",
    "    out = Conv1D(128,3,padding='same')(out)\n",
    "    # out = Flatten()(out)\n",
    "    # out = MaxPooling1D(2,padding='same', name ='pooling')(out)\n",
    "\n",
    "\n",
    "\n",
    "    # fl_out_1 = Flatten()(dout_2)\n",
    "\n",
    "    fl_out_cnn = Flatten()(out)\n",
    "\n",
    "    # out_new = concatenate( [fl_out_1, fl_out_cnn] , name='mergerguy')\n",
    "    out_new = concatenate( [dout_2, fl_out_cnn,dout_3] , name='mergerguy')\n",
    "\n",
    "    dens_out_1 = Dense( 128, activation='relu' )(out_new)\n",
    "    dens_out_2 = Dense( 128, activation='relu' )(dens_out_1)\n",
    "    dens_out_3 = Dense( 128, activation='relu' )(dens_out_2)\n",
    "\n",
    "    # fl2  = Flatten()(out_new)\n",
    "\n",
    "    out_put_final = Dense(len(classes), activation='sigmoid', name='Event_output')(dens_out_3)\n",
    "\n",
    "    toService_1 = Dense( 130, name=\"to_service1\" )(dens_out_3)\n",
    "    toService_1 = Dense( 130, name=\"to_service2\" )(toService_1)\n",
    "\n",
    "    service_output = Dense(1, activation=\"sigmoid\", name = 'service_output')(toService_1)\n",
    "\n",
    "\n",
    "    losses = {\n",
    "    #     \"service_output\": f1_loss_perClass ,\n",
    "        \"service_output\": f1_loss_perRow ,\n",
    "        \"service_output\": \"binary_crossentropy\",\n",
    "    }\n",
    "    lossWeights = {#\"service_output\": 20,\n",
    "                   \"service_output\": 30.0 ,\n",
    "        \"service_output\": 20}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    model2 = Model(inputs=[inputs], outputs=[service_output])\n",
    "    model2.compile(loss=losses,loss_weights=lossWeights, optimizer='adam', metrics=[f1_perRow,f1_perClass,'acc'])\n",
    "    # model2.compile(loss=losses, loss_weights=lossWeights, optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    checkpoint = ModelCheckpoint('IoTDownNet', monitor='loss', verbose=0, save_best_only=True, mode='min')\n",
    "    callbacks_list = [checkpoint]\n",
    "    hist2 = model2.fit(x_lstm_prossed_train2, zzzz[i], epochs=200, batch_size=12500, shuffle=True, callbacks=callbacks_list)\n",
    "    model2.save('number'+str(i)+'.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model2.compile(loss=losses,loss_weights=lossWeights, optimizer=keras.optimizers.Adam(lr=5e-5  ), metrics=[f1_perRow,f1_perClass,'acc'])\n",
    "hist2 = model2.fit(x_lstm_prossed_train2, y_lstm_prossed_train, epochs=300, batch_size=16500, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.compile(loss=f1_loss, optimizer=keras.optimizers.Adam(lr=8e-5  ), metrics=[f1,'acc'])\n",
    "hist2 = model2.fit(x_lstm_prossed_train2, y_lstm_prossed_train, epochs=300, batch_size=7500, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.compile(loss=weighted_categorical_crossentropy(weights=weights), optimizer=keras.optimizers.Adam(lr=8e-5  ), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.compile(loss='categorical_crossentropy', optimizer=keras.optimizers.Adam(lr=8e-5  ), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.compile(loss=weighted_categorical_crossentropy(weights=weights), optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist2 = model2.fit(x_lstm_prossed_train2, y_lstm_prossed_train, epochs=300, batch_size=3500, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.save( \"LSTM-sigmoid-withRemovedClasses\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(hist2.history['loss'], c='red')\n",
    "plt.plot(hist2.history['acc'], c='blue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(hist2.history['loss'], c='red')\n",
    "# plt.plot(hist2.history['acc'], c='blue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import plot_model\n",
    "plot_model(model2, to_file='model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.models import load_model\n",
    "# model2=load_model( \"LSTM_withSigmoid_LargeData_F1_E100_B500_MSE_False\"  \n",
    "#            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(lstm_tests)) :\n",
    "    print( \"==================HOME Case : %s =============\" % test_names[i])\n",
    "    makeReadable( classes=classes, confidance=0.5,data=lstm_tests[i][0],gt=lstm_tests[i][1],model=model2,path=test_names[i],x=lstm_tests[i][0])\n",
    "    \n",
    "#     lstm_pred= model2.predict( lstm_tests[i][0])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# ------------- do not go any further :) ------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_pred= model2.predict( lstm_tests[i][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_pred= model2.predict( lstm_tests[1][0])\n",
    "lstm_pred__ = np.array(list(lstm_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_pred__ = np.array(list(lstm_pred))\n",
    "print_info( lstm_tests[1][1], lstm_pred__, classes , confidance=0.43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in [1] :\n",
    "for i in range(len(lstm_tests)) :\n",
    "    print( \"==================HOME Case : %s =============\" % test_names[i])\n",
    "    lstm_pred= model2.predict( lstm_tests[i][0])\n",
    "    \n",
    "#     print_info( lstm_tests[i][1], lstm_pred, classes , confidance=0.7)\n",
    "    print_info( lstm_tests[i][1], lstm_pred, classes , confidance=0.5)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in [1] :\n",
    "# for i in range(len(lstm_tests)) :\n",
    "    print( \"==================HOME Case : %s =============\" % test_names[i])\n",
    "    lstm_pred= model2.predict( lstm_tests[i][0])\n",
    "    \n",
    "#     print_info( lstm_tests[i][1], lstm_pred, classes , confidance=0.7)\n",
    "    print_info( lstm_tests[i][1], lstm_pred, classes , confidance=0.992)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_pred =model2.predict( x_lstm_prossed_test2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_info(y_lstm_prossed_test, lstm_pred, classes, confidance=0.60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_pred =model2.predict( x_lstm_prossed_test)\n",
    "print_info(y_lstm_prossed_test, lstm_pred, classes, confidance=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_pred = model2.predict( x_lstm_prossed_test)\n",
    "print_info(y_lstm_prossed_test, lstm_pred, classes, confidance=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_info(y_lstm_prossed_train, y_lstm_prossed_train, classes, confidance=0.60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[x for x  in lstm_pred  if  np.sum(x) > 0 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.save( \"LSTM_withSigmoid_LargeData_F%s_E%d_B%d_M%s_%r\" %\n",
    "            (\n",
    "            FoldID,\n",
    "                Epoch_count,\n",
    "                Batch_size,\n",
    "                Mapper,\n",
    "                IgnoreEmpty\n",
    "            ) \n",
    "           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_pred = model2.predict( x_lstm_prossed_test )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_info(y_lstm_prossed_test, lstm_pred, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train_muhammed,y_train_muhammed, classes = pre_process_raw( x_train, y_train , dim_size, zero_pad=True, normalize=False)\n",
    "# x_test_muhammed,y_test_muhammed, classes = pre_process_raw( x_test, y_test , dim_size, zero_pad=True, normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_pred = model2.predict( x_lstm_prossed_test )\n",
    "print_info(y_lstm_prossed_test, lstm_pred, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_pred = model2.predict( x_lstm_prossed_test )\n",
    "print_info(y_lstm_prossed_test, lstm_pred, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print_info(y_lstm_prossed_test, pred, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len( y_lstm_prossed_train[0] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_size =160\n",
    "x_lstm_prossed_train,y_lstm_prossed_train, _ = pre_process_raw( x_train, y_train , dim_size, zero_pad=True, normalize=False,classes=classes)\n",
    "x_lstm_prossed_test,y_lstm_prossed_test, _ = pre_process_raw( x_test, y_test , dim_size, zero_pad=True, , class_cap=TEST_CLASS_CAPnormalize=False,classes=classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len([x  for x  in y_lstm_prossed_test if x[21]==1 or x[20]==1]), len(y_lstm_prossed_test  ) , len([x  for x  in y_lstm_prossed_test if x[21]==1 or x[20]==1])/len(y_lstm_prossed_test  ) *1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[ x for x  in  pred if np.sum(x) > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y_lstm_prossed_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_for_raun( pred   ):\n",
    "    pp = pred\n",
    "    pp[pp>=0.5] = 1\n",
    "    pp[pp<0.5] = 0\n",
    "    return pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len([x for x in pred if np.sum( do_for_raun(x) )==0 ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len([x for x in pred if  do_for_raun(x)[20] ==1 or do_for_raun(x)[21] ==1 ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# np.save(\"../files/muhammed/x_train.json\" , x_train_muhammed)\n",
    "# np.save(\"../files/muhammed/y_train.json\", )\n",
    "\n",
    "\n",
    "# np.save( \"../files/muhammed/x_train.json\", x_train_muhammed )\n",
    "# np.save(\"../files/muhammed/y_train.json\",  y_train_muhammed )\n",
    "# np.save( \"../files/muhammed/x_test.json\",x_test_muhammed )\n",
    "# np.save( \"../files/muhammed/y_test.json\",y_test_muhammed )\n",
    "# np.save( \"../files/muhammed/classes.json\",  classes )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(x_lstm_prossed_test) + len(x_lstm_prossed_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3.6(iot)",
   "language": "python",
   "name": "iot"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
