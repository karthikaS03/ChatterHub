{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58958 57867\n",
      "loading from test files\n",
      "found files :  4\n",
      "32069 31258\n"
     ]
    }
   ],
   "source": [
    "import json \n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import hamming_loss\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from xgboost import plot_tree\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "\n",
    "loadFromMerged=True\n",
    "loadFromIndexes= False\n",
    "Mapper='S'\n",
    "IgnoreEmpty= True\n",
    "FoldID =\"1\"\n",
    "Epoch_count=100\n",
    "Batch_size=5000\n",
    "INCLUDE_DIRECTION = True\n",
    "\n",
    "\n",
    "def vectorize_docs (sequences):\n",
    "    vectorizer = CountVectorizer(analyzer='word', ngram_range=(2, 5))\n",
    "    X = vectorizer.fit_transform(sequences)\n",
    "    #print(vectorizer.get_feature_names())\n",
    "    return X\n",
    "\n",
    "\n",
    "def print_info(y_test, pred , classes , confidence=0.90 ):\n",
    "    # print(classification_report(y_test, pred, target_names=classes))\n",
    "    # print(hamming_loss(y_test,pred))\n",
    "   \n",
    "    def make_recall_shit( inp ):\n",
    "        tp = inp[1][1]\n",
    "        tn = inp[0][0]\n",
    "        fp = inp[0][1] \n",
    "        fn = inp[1][0]\n",
    "        \n",
    "        acc = (tp+tn)*1.0 / ( tp+tn+fp+fn)*1.0\n",
    "        recall = tp*1.0/ ( tp+fn ) *1.0\n",
    "        prec = tp*1.0 / ( tp+fp )*1.0\n",
    "        \n",
    "    #   F= 2.0*( prec* recall )/ (prec+recall)\n",
    "        F= 2.0*( tp)/ (2*tp + fp + fn)\n",
    "        \n",
    "        return acc, recall, prec, F\n",
    "\n",
    "    counts = np.sum( y_test.astype(int) , axis=0)\n",
    "    \n",
    "    pred[pred>=confidence] = 1\n",
    "    pred[pred<confidence] = 0\n",
    "    \n",
    "    #   acc_wierd  =acc_match_wierd(y_test, pred)\n",
    "    \n",
    "    conf= multilabel_confusion_matrix( y_test , pred.astype(int), labels= range(len(classes)))\n",
    "    accs = [make_recall_shit(x) for x in conf]\n",
    "    print( \"%30s  %8s   %8s  %8s  %8s %8s %22s\" %( \"Class\",\"Accuracy\", \"Recall\",\"Precision\",\"F Score\" , \"Count\", \"TP/TN/FP/FN\"))\n",
    "    print( \"------------------------------------------------------------------------\" )\n",
    "    \n",
    "    for index in range(len(classes)):\n",
    "        tp = conf[index][1][1]\n",
    "        tn = conf[index][0][0]\n",
    "        fp = conf[index][0][1] \n",
    "        fn = conf[index][1][0]\n",
    "        \n",
    "        print( \"%30s  %8.3f   %8.3f  %8.3f  %8.3f  %8d %5d/%5d/%5d/%5d\"  %\n",
    "             (classes[index],\n",
    "              accs[index][0],\n",
    "              accs[index][1],\n",
    "              accs[index][2],\n",
    "              accs[index][3],\n",
    "              counts[index],\n",
    "                  tp ,\n",
    "                tn ,\n",
    "                fp ,\n",
    "                fn ))\n",
    "    n_zeros_true = len([ x  for x  in  [np.sum(np.abs( y_test[i] )) for i in range(len(y_test))] if x  == 0]  )\n",
    "    n_zeros_pred = len([ x  for x  in  [np.sum(np.abs( pred[i] )) for i in range(len(pred))] if x  == 0]  )\n",
    "    \n",
    "    accs = np.nan_to_num(accs)\n",
    "    \n",
    "    def acc_match( true, pred ):\n",
    "        \"\"\"\n",
    "        returns exact mathc accuracy\n",
    "        \"\"\"\n",
    "        \n",
    "        return (len( [ x  for x  in  [np.sum(np.abs( true[i]- pred[i] )) for i in range(len(true))] if x  == 0]))*1.0 / len(true)\n",
    "    \n",
    "    def acc_match_wierd( true, pred ):\n",
    "        \"\"\"\n",
    "        returns exact mathc accuracy\n",
    "        \"\"\"\n",
    "        level = 6 \n",
    "        switch = 11\n",
    "        threeAxis=13\n",
    "        accel = 0 \n",
    "        status=10\n",
    "        contact=5\n",
    "\n",
    "        counter  = 0 \n",
    "        for i in range( len (true) ):\n",
    "            if np.sum(np.abs( true[i]- pred[i] ))==0 :\n",
    "                counter+=1\n",
    "            else : \n",
    "                t_rec = np.array(list( pred[i]))\n",
    "                \n",
    "                if true[i][level]==1 or true[i][switch]==1 or t_rec[level]==1 :\n",
    "                    t_rec[switch]=1\n",
    "                \n",
    "                if true[i][threeAxis]==1 or true[i][accel]==1 or t_rec[threeAxis]==1:\n",
    "                    t_rec[accel] =1\n",
    "                \n",
    "                if true[i][status]==1 or true[i][contact]==1 or t_rec[status]==1:\n",
    "                    t_rec[contact]=1\n",
    "            #             print(t_rec , true[i])    \n",
    "                if np.sum(np.abs( true[i]- t_rec ))==0 :\n",
    "                    counter+=1   \n",
    "        return counter*1.0 / len(true)\n",
    "\n",
    "    print (\"------------------------------------------------------------------------\")\n",
    "    print( \"%30s  %8.3f   %8.3f  %8.3f  %8.3f  %8d %5d/%5d/%5d/%5d\"  %\n",
    "             (\"AVERAGES\",\n",
    "              np.average( accs, axis=0)[0],\n",
    "              np.average( accs, axis=0)[1],\n",
    "              np.average( accs, axis=0)[2],\n",
    "              np.average( accs, axis=0)[3],\n",
    "              len(y_test),\n",
    "                  0 ,\n",
    "                0,\n",
    "                0 ,\n",
    "                0 ))\n",
    "    print ( \"Exact Match ACC : %.5f \" % acc_match( y_test, pred )  )\n",
    "\n",
    "    # print ( \"Wierd Exact Match ACC : %.5f\" % acc_wierd)\n",
    "    print ( \"Total Records : %d \" % len(y_test)  )\n",
    "    print ( \"Total ZXeros in True : %d (%.3f)%%\" % (n_zeros_true ,  n_zeros_true * 1.0/ len(y_test)  ))\n",
    "    print ( \"Total ZXeros in Test : %d (%.3f)%%\" % (n_zeros_pred ,  n_zeros_pred * 1.0/ len(y_test)  ) )\n",
    "    print ('=============================================================================')\n",
    "\n",
    "\n",
    "# this cleans the data removing emply nodes and turning the nodes into sarrays by calling the mapping function \n",
    "def clean_data( x_data, y_data , removeempty=True, Mapping='S', includeDirection= False):\n",
    "\n",
    "    #  mapps the input records to a integer array for the input\n",
    "    def mapping_x( inp, includeDirection = False , TrimAt= 15 ):\n",
    "        includeDirection=True\n",
    "        if includeDirection:\n",
    "            return np.array([ x[\"frame_length\"] + (' hub' if x['packet_source']=='hub' else ' server')  for x in inp ][:15])\n",
    "        else:\n",
    "            return np.array([ int(int(x[\"frame_length\"])/10)*10  for x in inp ][:15])\n",
    "\n",
    "    def mapping_y_service(inp):\n",
    "        return np.array(  list(set([x[\"event\"] for x in inp])) if (len(inp )>0) else [\"none\"] )\n",
    "\n",
    "    def mapping_y_service_event(inp):\n",
    "        \n",
    "        return np.array(  list(set([ (\"%s-%s\"%( x[\"event\"] ,x[\"val\"] )) if \n",
    "                                    x['event']!= \"unknown\" else x['event'] for x in inp])) if (len(inp )>0) else [\"none\"] )\n",
    "\n",
    "    def mapping_y_device_service(inp):\n",
    "        return np.array(  list(set([ \"%s & %s\"%( x[\"device\"] ,x[\"event\"] ) for x in inp])) if (len(inp )>0) else [\"none\"] )\n",
    "\n",
    "    def mapping_y_full(inp):\n",
    "        return np.array(  list(set([ \"%s & %s & %s\"%( x[\"device\"] ,x[\"event\"], x['val'] ) for x in inp])) if (len(inp )>0) else [\"none\"] )\n",
    "\n",
    "    # print(y_data)\n",
    "    cleans = [] \n",
    "    cleans = (sorted([ x for x in y_data if  len(y_data[x]) > 0 ] ))\n",
    "    \n",
    "    ret_x  = [x_data[x] for x in cleans]\n",
    "    ret_y  = [y_data[x] for x in cleans] \n",
    "    \n",
    "    print( len(y_data), len(cleans) )\n",
    "    \n",
    "    ret_x  = [ mapping_x(x) for x in ret_x ] \n",
    "    ret_y_s = [ mapping_y_service(y) for y in ret_y ]\n",
    "    if Mapping=='S':\n",
    "        ret_y  = [ mapping_y_service(y) for y in ret_y ]\n",
    "    elif Mapping=='SE':\n",
    "        ret_y  = [ mapping_y_service_event(y) for y in ret_y ]\n",
    "    elif Mapping=='DS':\n",
    "        ret_y  = [ mapping_y_device_service(y) for y in ret_y ]\n",
    "    elif Mapping=='F':\n",
    "        ret_y  = [ mapping_y_full(y) for y in ret_y ]\n",
    "    return ret_x, ret_y, ret_y_s\n",
    "\n",
    "def pre_process_raw( x_data,y_data, dim_size = 128, test = False, normalize = False ,classes=None, twoD= False, string =False, include_direction=False ):\n",
    "    #  y data \n",
    "    # \"\"\"\n",
    "    # this functino is in charge of preprocessing the records , the sourc e json contains a lot of extra stuff, this function tailors\n",
    "    # the data and it fixes their lenghth\n",
    "    # \"\"\"\n",
    "    services=classes\n",
    "    if 'unknown' not in classes:\n",
    "        classes.append('unknown')\n",
    "    if classes is None:\n",
    "        classes  = sorted(list(np.unique(  np.concatenate( y_data  ))))\n",
    "    else :\n",
    "        classes = sorted(classes)\n",
    "    \n",
    "    y_data_categorical = []  \n",
    "    x_data_temp = [] \n",
    "    y_class_data = []\n",
    "    for i,x in enumerate(y_data):\n",
    "        classFound=False\n",
    "        temp = np.zeros( len(classes) )\n",
    "        # print(x)\n",
    "        y_class=[]\n",
    "        for y in x : \n",
    "            if y=='unknown' and len(x)>1:\n",
    "                continue\n",
    "            if y in services :\n",
    "                y_class.append(y)\n",
    "                temp[ classes.index( y ) ] = 1\n",
    "                classFound=True if not classFound else classFound\n",
    "        if 'known' in classes and not classFound:\n",
    "            temp[ classes.index( 'known') ] = 1\n",
    "            y_data_categorical.append( temp )\n",
    "            x_data_temp.append(x_data[i])            \n",
    "            y_class_data.append(x)\n",
    "        elif classFound or test:\n",
    "            # if 'lock' in y_class:\n",
    "            #     print(x_data[i])\n",
    "            y_class_data.append(' '.join(y_class))\n",
    "            if not classFound:\n",
    "                temp[ classes.index( 'unknown') ] = 1\n",
    "            y_data_categorical.append(temp )\n",
    "            x_data_temp.append(x_data[i])\n",
    "            \n",
    "    y_data_categorical = np.vstack(y_data_categorical)\n",
    "    # /////////print(y_data_categorical)\n",
    "    x_data=x_data_temp\n",
    "\n",
    "    x_data_temp=[]\n",
    "    temp = [] \n",
    "    lst = list(x)\n",
    "    for x in x_data:\n",
    "        temp = [] #list(x)\n",
    "        lst = list(x)\n",
    "        temp = lst\n",
    "        while dim_size - len(temp )   > len(lst):\n",
    "            temp.extend(lst)\n",
    "\n",
    "        while len(temp) < dim_size:\n",
    "            temp.append( 0 )\n",
    "        if not string:\n",
    "            x_data_temp.append(np.array(temp))\n",
    "        else:\n",
    "            x_data_temp.append(' '.join(list(map(str,temp))))\n",
    "        # print(temp)\n",
    "   \n",
    "    \n",
    "    if normalize:\n",
    "        x_data_temp = np.array( x_data_temp) / (np.amax( x_data_temp) + 0.000000000001)\n",
    "    else :\n",
    "        x_data_temp = np.array(x_data_temp)\n",
    "    \n",
    "   \n",
    "    return  x_data_temp ,y_data_categorical , y_class_data\n",
    "\n",
    "x_data= []\n",
    "y_data= []\n",
    "x_test = []\n",
    "y_test = []\n",
    "y_test_service= []\n",
    "x_train = {}\n",
    "y_train = {}\n",
    "test_names = []\n",
    "\n",
    "def load_data():\n",
    "    global x_train, y_train, y_train_service\n",
    "\n",
    "    with open('../files/train/test/test_homes/final_upload/Merged_final_with_home/merged_hub_segments_final.json'  ) as f:\n",
    "        y_data = json.load(f)\n",
    "\n",
    "    with open('../files/train/test/test_homes/final_upload/Merged_final_with_home/merged_pcap_segments_final.json'  ) as f:\n",
    "        x_data = json.load(f)\n",
    "        \n",
    "        \n",
    "    x_train,y_train, y_train_service= clean_data( x_data, y_data, IgnoreEmpty , \n",
    "                                                 Mapping=Mapper ,includeDirection= INCLUDE_DIRECTION)\n",
    "\n",
    "\n",
    "    print(\"loading from test files\")\n",
    "\n",
    "    test_files = sorted(os.listdir('../files/train/test/test_homes/final_upload/usecases/pcap_segments_final_final/'))\n",
    "    print( \"found files : \" , len(test_files) )\n",
    "\n",
    "    for pick  in test_files:        \n",
    "        if \"home_muhammed_final\"  in pick: #'home_os_final'\n",
    "            \n",
    "            fname  = os.path.basename(pick)\n",
    "            test_names.append( fname )\n",
    "\n",
    "            with open( os.path.join( '../files/train/test/test_homes/final_upload/usecases/hub_segments_final_final/', fname) ) as f:\n",
    "                y_data_test = json.load(f)\n",
    "\n",
    "            with open( os.path.join('../files/train/test/test_homes/final_upload/usecases/pcap_segments_final_final/', fname) ) as f:\n",
    "                x_data_test = json.load(f)\n",
    "\n",
    "            t_x,t_y, t_z= clean_data( x_data_test, y_data_test, False , Mapping=Mapper,\n",
    "                                     includeDirection=INCLUDE_DIRECTION )\n",
    "            x_test.append(t_x)\n",
    "            y_test.append(t_y)\n",
    "            y_test_service.append(t_z)\n",
    "\n",
    "def predict_labels(classes,x_test_new,y_test_new,confidence, original_y=None, the_indexes=None):\n",
    "    is_string=True\n",
    " \n",
    "    x_test_processed,y_test_processed_encoded, y_test_processed =\\\n",
    "            pre_process_raw( x_test_new, y_test_new , dim_size, \n",
    "    test=True, normalize=False, classes=classes, string=is_string)\n",
    "    # rf_tests  = [ pre_process_raw( x_test[i], y_test[i] , dim_size, zero_pad=True, normalize=False, \\\n",
    "    #   classes=classes, string=is_string) for i in range(len(x_test)) ] \n",
    "\n",
    "    # def classify_RandomForest():\n",
    "\n",
    "    #     clf = RandomForestClassifier(n_estimators=960, max_depth=9050,random_state=0 )\n",
    "    #     print('filtered data')\n",
    "    #     t_hist = clf.fit(x_train_processed, y_train_processed_encoded)\n",
    "\n",
    "    #     for i in range(len(rf_tests)) :\n",
    "    #         print( \"==================HOME Case : %s =============\" % test_names[ i] )\n",
    "    #         rf_pred= clf.predict( rf_tests[i][0])\n",
    "            \n",
    "    #         print(sum([x[0] for x in rf_tests[i][1]]))\n",
    "    #         print(sum(x[1] for x in rf_tests[i][1]))\n",
    "    #         print(classes)\n",
    "    #         print_info( rf_tests[i][1], rf_pred, classes)\n",
    "        \n",
    "    def draw_xgb_tree():\n",
    "        xgb = XGBClassifier()\n",
    "        y = [x.split(' ')[0] for x in y_train_processed]\n",
    "        xgb.fit(x_train_processed, y)\n",
    "        # plot single tree\n",
    "        plot_tree(xgb)\n",
    "        plt.show()\n",
    "\n",
    "    def classify_xgb(x_test_processed):\n",
    "        xgb_classifier = OneVsRestClassifier(XGBClassifier())\n",
    "        if is_string:\n",
    "            vectorizer = CountVectorizer(analyzer='word', ngram_range=(1, 5))\n",
    "            x_train_str = vectorizer.fit_transform(x_train_processed)\n",
    "            \n",
    "            x_test_str = vectorizer.transform(x_test_processed)\n",
    "            print(y_train_processed_encoded)\n",
    "            print(type(x_train_str), x_train_str[0], type(y_train_processed_encoded),y_train_processed_encoded[0])\n",
    "            xgb_classifier.fit(x_train_str, y_train_processed_encoded)\n",
    "\n",
    "        else:\n",
    "            xgb_classifier.fit(x_train_processed, y_train_processed_encoded)\n",
    "\n",
    "        known_x_data=[]\n",
    "        known_y_data=[]\n",
    "        indexes = []\n",
    "        print(\"==================HOME Case : Omid =============\")\n",
    "        rf_pred= xgb_classifier.predict_proba(x_test_str)\n",
    "        \n",
    "        # if there is a big set supplied use it for accuracy caluclation \n",
    "        if original_y is not None:\n",
    "            unknown = [1 if classes[i] == 'unknown' else\n",
    "                        0 \n",
    "                       \n",
    "                       for i in range(len(classes))]\n",
    "            the_y = [unknown for i in range(len(original_y))]\n",
    "            \n",
    "            for ind, val in enumerate(the_indexes):\n",
    "                the_y[val] = rf_pred[ind]\n",
    "            the_y = np.array(the_y)\n",
    "            print((original_y[0]), (the_y[0]))\n",
    "            print_info(original_y, the_y, classes, confidence)\n",
    "            \n",
    "        else :\n",
    "            print_info(y_test_processed_encoded, rf_pred, classes, confidence)\n",
    "            \n",
    "        for ind,y_true in enumerate(y_test_processed):   \n",
    "               \n",
    "            y_pred_class = [classes[i] for i,x in enumerate(rf_pred[ind]) if x>confidence]\n",
    "            # if 'known' not in classes: \n",
    "            #     # print(y_true, y_pred_class)\n",
    "            #     if not y_true and y_pred_class and 'unknown' not in y_pred_class:\n",
    "            #         print(\"True: \", y_true,\"\\n Pred: \",y_pred_class )\n",
    "            #         print(\"Last 5 true: \",y_test_processed[ind-10:ind])\n",
    "            #         print(x_test_processed[ind])\n",
    "            y_pred_class = y_pred_class if y_pred_class else ['no_prediction']\n",
    "            if 'known'  in y_pred_class:\n",
    "                # print(x_test_processed[ind],\"\\nTrue: \",y_true, \"\\nPrediction: \", ' '.join(y_pred_class))\n",
    "                known_x_data.append(x_test_processed[ind].split(' '))\n",
    "                known_y_data.append(y_test_processed[ind])\n",
    "                indexes.append(ind)\n",
    "        return known_x_data, known_y_data, indexes\n",
    "    # classify_RandomForest()\n",
    "    return classify_xgb(x_test_processed)\n",
    "\n",
    "# all_classes = sorted(list(np.unique(  np.concatenate( y_train  ))))\n",
    "\n",
    "load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_classes = sorted(list(np.unique(  np.concatenate( y_train  ))))\n",
    "reduced_cases = [x for x in all_classes if x not in ['temperature','battery','level','threeAxis','water']]\n",
    "to_keep = [\n",
    "#     'lock-locked',\n",
    "#  'lock-unlocked',\n",
    " 'motion-active',\n",
    "#  'motion-inactive',\n",
    "#            'contact-closed',\n",
    " 'contact-open',\n",
    " 'ping-ping']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " ...\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]]\n",
      "<class 'scipy.sparse.csr.csr_matrix'>   (0, 5005)\t4\n",
      "  (0, 11256)\t8\n",
      "  (0, 630)\t8\n",
      "  (0, 8630)\t8\n",
      "  (0, 6165)\t4\n",
      "  (0, 5006)\t4\n",
      "  (0, 11547)\t4\n",
      "  (0, 631)\t4\n",
      "  (0, 10388)\t4\n",
      "  (0, 6166)\t4\n",
      "  (0, 8802)\t4\n",
      "  (0, 1012)\t4\n",
      "  (0, 13188)\t3\n",
      "  (0, 5007)\t4\n",
      "  (0, 11548)\t4\n",
      "  (0, 887)\t4\n",
      "  (0, 10389)\t4\n",
      "  (0, 6170)\t4\n",
      "  (0, 8836)\t4\n",
      "  (0, 1413)\t3\n",
      "  (0, 13189)\t3\n",
      "  (0, 5008)\t4\n",
      "  (0, 11674)\t4\n",
      "  (0, 888)\t4\n",
      "  (0, 10392)\t4\n",
      "  (0, 6171)\t4\n",
      "  (0, 8944)\t3\n",
      "  (0, 1414)\t3\n",
      "  (0, 13190)\t3\n",
      "  (0, 5016)\t4\n",
      "  (0, 11675)\t4\n",
      "  (0, 889)\t4\n",
      "  (0, 10393)\t4\n",
      "  (0, 6191)\t3\n",
      "  (0, 8945)\t3\n",
      "  (0, 1415)\t3\n",
      "  (0, 13191)\t3 <class 'numpy.ndarray'> [1. 0.]\n",
      "==================HOME Case : Omid =============\n",
      "                         Class  Accuracy     Recall  Precision   F Score    Count            TP/TN/FP/FN\n",
      "------------------------------------------------------------------------\n",
      "                         known     0.906      0.803     0.883     0.841      9721  7810/20502/ 1035/ 1911\n",
      "                       unknown     0.916      0.990     0.898     0.942     21537 21318/ 7308/ 2413/  219\n",
      "------------------------------------------------------------------------\n",
      "                      AVERAGES     0.911      0.897     0.891     0.892     31258     0/    0/    0/    0\n",
      "Exact Match ACC : 0.88969 \n",
      "Total Records : 31258 \n",
      "Total ZXeros in True : 0 (0.000)%\n",
      "Total ZXeros in Test : 0 (0.000)%\n",
      "=============================================================================\n",
      "8845\n",
      "[[0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]\n",
      " ...\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]]\n",
      "<class 'scipy.sparse.csr.csr_matrix'>   (0, 3957)\t8\n",
      "  (0, 5806)\t8\n",
      "  (0, 491)\t8\n",
      "  (0, 7557)\t8\n",
      "  (0, 3958)\t8\n",
      "  (0, 5950)\t8\n",
      "  (0, 708)\t8\n",
      "  (0, 9178)\t7\n",
      "  (0, 3959)\t8\n",
      "  (0, 5984)\t8\n",
      "  (0, 1043)\t7\n",
      "  (0, 9179)\t7\n",
      "  (0, 3960)\t8\n",
      "  (0, 6083)\t7\n",
      "  (0, 1044)\t7\n",
      "  (0, 9180)\t7\n",
      "  (0, 3976)\t7\n",
      "  (0, 6084)\t7\n",
      "  (0, 1045)\t7\n",
      "  (0, 9181)\t7 <class 'numpy.ndarray'> [0. 0. 0. 1.]\n",
      "==================HOME Case : Omid =============\n",
      "[1. 0.] [0 0 0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/omid/.conda/envs/iot/lib/python3.6/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 0 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "/home/omid/.conda/envs/iot/lib/python3.6/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 1 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "/home/omid/.conda/envs/iot/lib/python3.6/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 2 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "/home/omid/.conda/envs/iot/lib/python3.6/site-packages/sklearn/multiclass.py:76: UserWarning: Label 3 is present in all training examples.\n",
      "  str(classes[c]))\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Multi-label binary indicator input with different numbers of labels",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-2a561cd521b7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m x_train_processed,y_train_processed_encoded, y_train_processed =pre_process_raw( x_train, y_train , dim_size, test=False, normalize=False, classes=classes,\n\u001b[1;32m     15\u001b[0m                                                                                 string=is_string)\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mpredict_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx_test_new\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test_new\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mconfidence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_y\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moriginal_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthe_indexes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindexes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-1-c5a83c87ebf7>\u001b[0m in \u001b[0;36mpredict_labels\u001b[0;34m(classes, x_test_new, y_test_new, confidence, original_y, the_indexes)\u001b[0m\n\u001b[1;32m    404\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mknown_x_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mknown_y_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m     \u001b[0;31m# classify_RandomForest()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 406\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mclassify_xgb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test_processed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    407\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m \u001b[0;31m# all_classes = sorted(list(np.unique(  np.concatenate( y_train  ))))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-c5a83c87ebf7>\u001b[0m in \u001b[0;36mclassify_xgb\u001b[0;34m(x_test_processed)\u001b[0m\n\u001b[1;32m    382\u001b[0m             \u001b[0mthe_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthe_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moriginal_y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mthe_y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m             \u001b[0mprint_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moriginal_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthe_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfidence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    385\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m         \u001b[0;32melse\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-c5a83c87ebf7>\u001b[0m in \u001b[0;36mprint_info\u001b[0;34m(y_test, pred, classes, confidence)\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;31m#   acc_wierd  =acc_match_wierd(y_test, pred)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m     \u001b[0mconf\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mmultilabel_confusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m     \u001b[0maccs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmake_recall_shit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconf\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m\"%30s  %8s   %8s  %8s  %8s %8s %22s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m\"Class\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"Accuracy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Recall\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"Precision\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"F Score\"\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;34m\"Count\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"TP/TN/FP/FN\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/iot/lib/python3.6/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36mmultilabel_confusion_matrix\u001b[0;34m(y_true, y_pred, sample_weight, labels, samplewise)\u001b[0m\n\u001b[1;32m    402\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s is not supported\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 404\u001b[0;31m     \u001b[0mpresent_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munique_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    405\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpresent_labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/iot/lib/python3.6/site-packages/sklearn/utils/multiclass.py\u001b[0m in \u001b[0;36munique_labels\u001b[0;34m(*ys)\u001b[0m\n\u001b[1;32m     86\u001b[0m             len(set(check_array(y, ['csr', 'csc', 'coo']).shape[1]\n\u001b[1;32m     87\u001b[0m                     for y in ys)) > 1):\n\u001b[0;32m---> 88\u001b[0;31m         raise ValueError(\"Multi-label binary indicator input with \"\n\u001b[0m\u001b[1;32m     89\u001b[0m                          \"different numbers of labels\")\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Multi-label binary indicator input with different numbers of labels"
     ]
    }
   ],
   "source": [
    "dim_size= 20\n",
    "is_string =True\n",
    "services_to_keep = ['unknown','known']\n",
    "classes = sorted(services_to_keep)\n",
    "x_train_processed,y_train_processed_encoded, y_train_processed =  pre_process_raw( x_train, y_train , dim_size, test=False, normalize=False, classes=classes, string=is_string)\n",
    "confidence=0.4\n",
    "x_test_new,y_test_new, indexes = predict_labels(classes,x_test[0],y_test[0],confidence)\n",
    "original_y = y_train_processed_encoded\n",
    "print(len(x_test_new))\n",
    "# print(y_test_new)\n",
    "confidence=0.75\n",
    "services_to_keep =  to_keep # ['contact','lock','motion', 'switch','colorTemperature','button','ping']\n",
    "classes = sorted(services_to_keep)\n",
    "x_train_processed,y_train_processed_encoded, y_train_processed =pre_process_raw( x_train, y_train , dim_size, test=False, normalize=False, classes=classes,\n",
    "                                                                                string=is_string)\n",
    "predict_labels(classes,x_test_new,y_test_new,confidence, original_y=original_y, the_indexes=indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " ...\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]]\n",
      "<class 'scipy.sparse.csr.csr_matrix'>   (0, 5005)\t4\n",
      "  (0, 11256)\t8\n",
      "  (0, 630)\t8\n",
      "  (0, 8630)\t8\n",
      "  (0, 6165)\t4\n",
      "  (0, 5006)\t4\n",
      "  (0, 11547)\t4\n",
      "  (0, 631)\t4\n",
      "  (0, 10388)\t4\n",
      "  (0, 6166)\t4\n",
      "  (0, 8802)\t4\n",
      "  (0, 1012)\t4\n",
      "  (0, 13188)\t3\n",
      "  (0, 5007)\t4\n",
      "  (0, 11548)\t4\n",
      "  (0, 887)\t4\n",
      "  (0, 10389)\t4\n",
      "  (0, 6170)\t4\n",
      "  (0, 8836)\t4\n",
      "  (0, 1413)\t3\n",
      "  (0, 13189)\t3\n",
      "  (0, 5008)\t4\n",
      "  (0, 11674)\t4\n",
      "  (0, 888)\t4\n",
      "  (0, 10392)\t4\n",
      "  (0, 6171)\t4\n",
      "  (0, 8944)\t3\n",
      "  (0, 1414)\t3\n",
      "  (0, 13190)\t3\n",
      "  (0, 5016)\t4\n",
      "  (0, 11675)\t4\n",
      "  (0, 889)\t4\n",
      "  (0, 10393)\t4\n",
      "  (0, 6191)\t3\n",
      "  (0, 8945)\t3\n",
      "  (0, 1415)\t3\n",
      "  (0, 13191)\t3 <class 'numpy.ndarray'> [1. 0.]\n",
      "==================HOME Case : Omid =============\n",
      "                         Class  Accuracy     Recall  Precision   F Score    Count            TP/TN/FP/FN\n",
      "------------------------------------------------------------------------\n",
      "                         known     0.906      0.803     0.883     0.841      9721  7810/20502/ 1035/ 1911\n",
      "                       unknown     0.916      0.990     0.898     0.942     21537 21318/ 7308/ 2413/  219\n",
      "------------------------------------------------------------------------\n",
      "                      AVERAGES     0.911      0.897     0.891     0.892     31258     0/    0/    0/    0\n",
      "Exact Match ACC : 0.88969 \n",
      "Total Records : 31258 \n",
      "Total ZXeros in True : 0 (0.000)%\n",
      "Total ZXeros in Test : 0 (0.000)%\n",
      "=============================================================================\n",
      "8845\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "predict_labels() got an unexpected keyword argument 'indexes'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-923cbbac2efc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m x_train_processed,y_train_processed_encoded, y_train_processed =pre_process_raw( x_train, y_train , dim_size, test=False, normalize=False, classes=classes,\n\u001b[1;32m     15\u001b[0m                                                                                 string=is_string)\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mpredict_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx_test_new\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test_new\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mconfidence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_y\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moriginal_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindexes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: predict_labels() got an unexpected keyword argument 'indexes'"
     ]
    }
   ],
   "source": [
    "dim_size= 20\n",
    "is_string =True\n",
    "services_to_keep = ['unknown','known']\n",
    "classes = sorted(services_to_keep)\n",
    "x_train_processed,y_train_processed_encoded, y_train_processed =  pre_process_raw( x_train, y_train , dim_size, test=False, normalize=False, classes=classes, string=is_string)\n",
    "confidence=0.4\n",
    "x_test_new,y_test_new, indexes = predict_labels(classes,x_test[0],y_test[0],confidence)\n",
    "original_y = y_train_processed_encoded\n",
    "print(len(x_test_new))\n",
    "# print(y_test_new)\n",
    "confidence=0.75\n",
    "services_to_keep =  to_keep # ['contact','lock','motion', 'switch','colorTemperature','button','ping']\n",
    "classes = sorted(services_to_keep)\n",
    "x_train_processed,y_train_processed_encoded, y_train_processed =pre_process_raw( x_train, y_train , dim_size, test=False, normalize=False, classes=classes,\n",
    "                                                                                string=is_string)\n",
    "predict_labels(classes,x_test_new,y_test_new,confidence, original_y=original_y, indexes=indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================HOME Case : Omid =============\n",
      "                         Class  Accuracy     Recall  Precision   F Score    Count            TP/TN/FP/FN\n",
      "------------------------------------------------------------------------\n",
      "                         known     0.906      0.803     0.883     0.841      9721  7810/20502/ 1035/ 1911\n",
      "                       unknown     0.916      0.990     0.898     0.942     21537 21318/ 7308/ 2413/  219\n",
      "------------------------------------------------------------------------\n",
      "                      AVERAGES     0.911      0.897     0.891     0.892     31258     0/    0/    0/    0\n",
      "Exact Match ACC : 0.88969 \n",
      "Total Records : 31258 \n",
      "Total ZXeros in True : 0 (0.000)%\n",
      "Total ZXeros in Test : 0 (0.000)%\n",
      "=============================================================================\n",
      "8845\n",
      "==================HOME Case : Omid =============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/omid/.conda/envs/iot/lib/python3.6/site-packages/ipykernel_launcher.py:52: RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/omid/.conda/envs/iot/lib/python3.6/site-packages/ipykernel_launcher.py:53: RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/omid/.conda/envs/iot/lib/python3.6/site-packages/ipykernel_launcher.py:56: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         Class  Accuracy     Recall  Precision   F Score    Count            TP/TN/FP/FN\n",
      "------------------------------------------------------------------------\n",
      "                  acceleration     1.000      0.250     1.000     0.400         4     1/ 8841/    0/    3\n",
      "                      activity     0.999      0.846     0.917     0.880        26    22/ 8817/    2/    4\n",
      "                        button     1.000      0.857     1.000     0.923         7     6/ 8838/    0/    1\n",
      "              colorTemperature     1.000        nan       nan       nan         0     0/ 8845/    0/    0\n",
      "                       contact     0.999      0.860     0.977     0.915        50    43/ 8794/    1/    7\n",
      "                          lock     0.999      0.538     0.636     0.583        13     7/ 8828/    4/    6\n",
      "                        motion     0.989      0.623     0.820     0.708       183   114/ 8637/   25/   69\n",
      "                          ping     0.989      0.997     0.990     0.993      6975  6953/ 1797/   73/   22\n",
      "                        status     0.998      0.636     0.966     0.767        44    28/ 8800/    1/   16\n",
      "                        switch     0.999      0.739     0.895     0.810        23    17/ 8820/    2/    6\n",
      "                       unknown     0.951      0.738     0.988     0.845      1583  1168/ 7248/   14/  415\n",
      "------------------------------------------------------------------------\n",
      "                      AVERAGES     0.993      0.644     0.835     0.711      8845     0/    0/    0/    0\n",
      "Exact Match ACC : 0.93906 \n",
      "Total Records : 8845 \n",
      "Total ZXeros in True : 0 (0.000)%\n",
      "Total ZXeros in Test : 399 (0.045)%\n",
      "=============================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([], [])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim_size= 20\n",
    "is_string =True\n",
    "services_to_keep = ['unknown','known']\n",
    "classes = sorted(services_to_keep)\n",
    "x_train_processed,y_train_processed_encoded, y_train_processed =  pre_process_raw( x_train, y_train , dim_size, test=False, normalize=False, classes=classes, string=is_string)\n",
    "confidence=0.4\n",
    "x_test_new,y_test_new = predict_labels(classes,x_test[0],y_test[0],confidence)\n",
    "\n",
    "print(len(x_test_new))\n",
    "# print(y_test_new)\n",
    "confidence=0.75\n",
    "services_to_keep =  reduced_cases # ['contact','lock','motion', 'switch','colorTemperature','button','ping']\n",
    "classes = sorted(services_to_keep)\n",
    "x_train_processed,y_train_processed_encoded, y_train_processed =pre_process_raw( x_train, y_train , dim_size, test=False, normalize=False, classes=classes, string=is_string)\n",
    "predict_labels(classes,x_test_new,y_test_new,confidence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "['temperature','battery','level']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['acceleration-active',\n",
       " 'acceleration-inactive',\n",
       " 'activity-hubDisconnected',\n",
       " 'activity-offline',\n",
       " 'activity-online',\n",
       " 'battery-XXX',\n",
       " 'button-held',\n",
       " 'button-pushed',\n",
       " 'colorTemperature-XXX',\n",
       " 'contact-closed',\n",
       " 'contact-open',\n",
       " 'level-XXX',\n",
       " 'lock-locked',\n",
       " 'lock-unlocked',\n",
       " 'motion-active',\n",
       " 'motion-inactive',\n",
       " 'ping-ping',\n",
       " 'status-closed',\n",
       " 'status-open',\n",
       " 'switch-off',\n",
       " 'switch-on',\n",
       " 'temperature-XXX',\n",
       " 'threeAxis-XXX',\n",
       " 'unknown-',\n",
       " 'water-dry',\n",
       " 'water-wet']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "The first input argument needs to be a sequence",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-078d3b0b5cf6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m  \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0my_train\u001b[0m  \u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: The first input argument needs to be a sequence"
     ]
    }
   ],
   "source": [
    " sorted(list(np.unique(  np.concatenate( y_train  ))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "The first input argument needs to be a sequence",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-078d3b0b5cf6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m  \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0my_train\u001b[0m  \u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: The first input argument needs to be a sequence"
     ]
    }
   ],
   "source": [
    "sorted(list(np.unique(  np.concatenate( y_train  ))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3.6(iot)",
   "language": "python",
   "name": "iot"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
