{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58958 57867\n",
      "loading from test files\n",
      "found files :  4\n",
      "19968 19516\n",
      "9109 8941\n"
     ]
    }
   ],
   "source": [
    "import json \n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import hamming_loss\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from xgboost import plot_tree\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "\n",
    "loadFromMerged=True\n",
    "loadFromIndexes= False\n",
    "Mapper='S'\n",
    "IgnoreEmpty= True\n",
    "FoldID =\"1\"\n",
    "Epoch_count=100\n",
    "Batch_size=5000\n",
    "\n",
    "\n",
    "def vectorize_docs (sequences):\n",
    "    vectorizer = CountVectorizer(analyzer='word', ngram_range=(2, 5))\n",
    "    X = vectorizer.fit_transform(sequences)\n",
    "    #print(vectorizer.get_feature_names())\n",
    "    return X\n",
    "\n",
    "\n",
    "def print_info(y_test, pred , classes , confidence=0.90 ):\n",
    "    # print(classification_report(y_test, pred, target_names=classes))\n",
    "    # print(hamming_loss(y_test,pred))\n",
    "   \n",
    "    def make_recall_shit( inp ):\n",
    "        tp = inp[1][1]\n",
    "        tn = inp[0][0]\n",
    "        fp = inp[0][1] \n",
    "        fn = inp[1][0]\n",
    "        \n",
    "        acc = (tp+tn)*1.0 / ( tp+tn+fp+fn)*1.0\n",
    "        recall = tp*1.0/ ( tp+fn ) *1.0\n",
    "        prec = tp*1.0 / ( tp+fp )*1.0\n",
    "        \n",
    "    #   F= 2.0*( prec* recall )/ (prec+recall)\n",
    "        F= 2.0*( tp)/ (2*tp + fp + fn)\n",
    "        \n",
    "        return acc, recall, prec, F\n",
    "\n",
    "    counts = np.sum( y_test.astype(int) , axis=0)\n",
    "    \n",
    "    pred[pred>=confidence] = 1\n",
    "    pred[pred<confidence] = 0\n",
    "    \n",
    "    #   acc_wierd  =acc_match_wierd(y_test, pred)\n",
    "    \n",
    "    conf= multilabel_confusion_matrix( y_test , pred.astype(int), labels= range(len(classes)))\n",
    "    accs = [make_recall_shit(x) for x in conf]\n",
    "    print( \"%30s  %8s   %8s  %8s  %8s %8s %22s\" %( \"Class\",\"Accuracy\", \"Recall\",\"Precision\",\"F Score\" , \"Count\", \"TP/TN/FP/FN\"))\n",
    "    print( \"------------------------------------------------------------------------\" )\n",
    "    \n",
    "    for index in range(len(classes)):\n",
    "        tp = conf[index][1][1]\n",
    "        tn = conf[index][0][0]\n",
    "        fp = conf[index][0][1] \n",
    "        fn = conf[index][1][0]\n",
    "        \n",
    "        print( \"%30s  %8.3f   %8.3f  %8.3f  %8.3f  %8d %5d/%5d/%5d/%5d\"  %\n",
    "             (classes[index],\n",
    "              accs[index][0],\n",
    "              accs[index][1],\n",
    "              accs[index][2],\n",
    "              accs[index][3],\n",
    "              counts[index],\n",
    "                  tp ,\n",
    "                tn ,\n",
    "                fp ,\n",
    "                fn ))\n",
    "    n_zeros_true = len([ x  for x  in  [np.sum(np.abs( y_test[i] )) for i in range(len(y_test))] if x  == 0]  )\n",
    "    n_zeros_pred = len([ x  for x  in  [np.sum(np.abs( pred[i] )) for i in range(len(pred))] if x  == 0]  )\n",
    "    \n",
    "    accs = np.nan_to_num(accs)\n",
    "    \n",
    "    def acc_match( true, pred ):\n",
    "        \"\"\"\n",
    "        returns exact mathc accuracy\n",
    "        \"\"\"\n",
    "        \n",
    "        return (len( [ x  for x  in  [np.sum(np.abs( true[i]- pred[i] )) for i in range(len(true))] if x  == 0]))*1.0 / len(true)\n",
    "    \n",
    "    def acc_match_wierd( true, pred ):\n",
    "        \"\"\"\n",
    "        returns exact mathc accuracy\n",
    "        \"\"\"\n",
    "        level = 6 \n",
    "        switch = 11\n",
    "        threeAxis=13\n",
    "        accel = 0 \n",
    "        status=10\n",
    "        contact=5\n",
    "\n",
    "        counter  = 0 \n",
    "        for i in range( len (true) ):\n",
    "            if np.sum(np.abs( true[i]- pred[i] ))==0 :\n",
    "                counter+=1\n",
    "            else : \n",
    "                t_rec = np.array(list( pred[i]))\n",
    "                \n",
    "                if true[i][level]==1 or true[i][switch]==1 or t_rec[level]==1 :\n",
    "                    t_rec[switch]=1\n",
    "                \n",
    "                if true[i][threeAxis]==1 or true[i][accel]==1 or t_rec[threeAxis]==1:\n",
    "                    t_rec[accel] =1\n",
    "                \n",
    "                if true[i][status]==1 or true[i][contact]==1 or t_rec[status]==1:\n",
    "                    t_rec[contact]=1\n",
    "            #             print(t_rec , true[i])    \n",
    "                if np.sum(np.abs( true[i]- t_rec ))==0 :\n",
    "                    counter+=1   \n",
    "        return counter*1.0 / len(true)\n",
    "\n",
    "    print (\"------------------------------------------------------------------------\")\n",
    "    print( \"%30s  %8.3f   %8.3f  %8.3f  %8.3f  %8d %5d/%5d/%5d/%5d\"  %\n",
    "             (\"AVERAGES\",\n",
    "              np.average( accs, axis=0)[0],\n",
    "              np.average( accs, axis=0)[1],\n",
    "              np.average( accs, axis=0)[2],\n",
    "              np.average( accs, axis=0)[3],\n",
    "              len(y_test),\n",
    "                  0 ,\n",
    "                0,\n",
    "                0 ,\n",
    "                0 ))\n",
    "    print ( \"Exact Match ACC : %.5f \" % acc_match( y_test, pred )  )\n",
    "\n",
    "    # print ( \"Wierd Exact Match ACC : %.5f\" % acc_wierd)\n",
    "    print ( \"Total Records : %d \" % len(y_test)  )\n",
    "    print ( \"Total ZXeros in True : %d (%.3f)%%\" % (n_zeros_true ,  n_zeros_true * 1.0/ len(y_test)  ))\n",
    "    print ( \"Total ZXeros in Test : %d (%.3f)%%\" % (n_zeros_pred ,  n_zeros_pred * 1.0/ len(y_test)  ) )\n",
    "    print ('=============================================================================')\n",
    "\n",
    "\n",
    "# this cleans the data removing emply nodes and turning the nodes into sarrays by calling the mapping function \n",
    "def clean_data( x_data, y_data , removeempty=True, Mapping='S'):\n",
    "\n",
    "    #  mapps the input records to a integer array for the input\n",
    "    def mapping_x( inp, includeDirection = False , TrimAt= 15 ):\n",
    "        includeDirection=True\n",
    "        if includeDirection:\n",
    "            return np.array([ x[\"frame_length\"] + (' hub' if x['packet_source']=='hub' else ' server')  for x in inp ][:15])\n",
    "        else:\n",
    "            return np.array([ int(int(x[\"frame_length\"])/10)*10  for x in inp ][:15])\n",
    "\n",
    "    def mapping_y_service(inp):\n",
    "        try:\n",
    "            return np.array(  list(set([x[\"event\"] for x in inp])) if (len(inp )>0) else [\"none\"] )\n",
    "        except:\n",
    "            print(inp)\n",
    "\n",
    "    def mapping_y_service_event(inp):\n",
    "        return np.array(  list(set([ \"%s-%s\"%( x[\"event\"] ,x[\"val\"] ) for x in inp])) if (len(inp )>0) else [\"none\"] )\n",
    "\n",
    "    def mapping_y_device_service(inp):\n",
    "        return np.array(  list(set([ \"%s & %s\"%( x[\"device\"] ,x[\"event\"] ) for x in inp])) if (len(inp )>0) else [\"none\"] )\n",
    "\n",
    "    def mapping_y_full(inp):\n",
    "        return np.array(  list(set([ \"%s & %s & %s\"%( x[\"device\"] ,x[\"event\"], x['val'] ) for x in inp])) if (len(inp )>0) else [\"none\"] )\n",
    "\n",
    "    # print(y_data)\n",
    "    cleans = [] \n",
    "    cleans = (sorted([ x for x in y_data if  len(y_data[x]) > 0 ] ))\n",
    "    \n",
    "    ret_x  = [x_data[x] for x in cleans]\n",
    "    ret_y  = [y_data[x] for x in cleans] \n",
    "    \n",
    "    print( len(y_data), len(cleans) )\n",
    "    \n",
    "    ret_x  = [ mapping_x(x) for x in ret_x ] \n",
    "    ret_y_s = [ mapping_y_service(y) for y in ret_y ]\n",
    "    if Mapping=='S':\n",
    "        ret_y  = [ mapping_y_service(y) for y in ret_y ]\n",
    "    elif Mapping=='SE':\n",
    "        ret_y  = [ mapping_y_service_event(y) for y in ret_y ]\n",
    "    elif Mapping=='DS':\n",
    "        ret_y  = [ mapping_y_device_service(y) for y in ret_y ]\n",
    "    elif Mapping=='F':\n",
    "        ret_y  = [ mapping_y_full(y) for y in ret_y ]\n",
    "    return ret_x, ret_y, ret_y_s\n",
    "\n",
    "def pre_process_raw( x_data,y_data, dim_size = 128, test = False, normalize = False ,classes=None, twoD= False, string =False ):\n",
    "    #  y data \n",
    "    # \"\"\"\n",
    "    # this functino is in charge of preprocessing the records , the sourc e json contains a lot of extra stuff, this function tailors\n",
    "    # the data and it fixes their lenghth\n",
    "    # \"\"\"\n",
    "    services=classes\n",
    "    if 'unknown' not in classes:\n",
    "        classes.append('unknown')\n",
    "    if classes is None:\n",
    "        classes  = sorted(list(np.unique(  np.concatenate( y_data  ))))\n",
    "    else :\n",
    "        classes = sorted(classes)\n",
    "    \n",
    "    y_data_categorical = []  \n",
    "    x_data_temp = [] \n",
    "    y_class_data = []\n",
    "    for i,x in enumerate(y_data):\n",
    "        classFound=False\n",
    "        temp = np.zeros( len(classes) )\n",
    "        # print(x)\n",
    "        y_class=[]\n",
    "        for y in x : \n",
    "            if y=='unknown' and len(x)>1:\n",
    "                continue\n",
    "            if y in services :\n",
    "                y_class.append(y)\n",
    "                temp[ classes.index( y ) ] = 1\n",
    "                classFound=True if not classFound else classFound\n",
    "        if 'known' in classes and not classFound:\n",
    "            temp[ classes.index( 'known') ] = 1\n",
    "            y_data_categorical.append( temp )\n",
    "            x_data_temp.append(x_data[i])            \n",
    "            y_class_data.append(x)\n",
    "        elif classFound or test:\n",
    "            # if 'lock' in y_class:\n",
    "            #     print(x_data[i])\n",
    "            y_class_data.append(' '.join(y_class))\n",
    "            if not classFound:\n",
    "                temp[ classes.index( 'unknown') ] = 1\n",
    "            y_data_categorical.append(temp )\n",
    "            x_data_temp.append(x_data[i])\n",
    "            \n",
    "    y_data_categorical = np.vstack(y_data_categorical)\n",
    "    # /////////print(y_data_categorical)\n",
    "    x_data=x_data_temp\n",
    "\n",
    "    x_data_temp=[]\n",
    "    temp = [] \n",
    "    lst = list(x)\n",
    "    for x in x_data:\n",
    "        temp = [] #list(x)\n",
    "        lst = list(x)\n",
    "        temp = lst\n",
    "        while dim_size - len(temp )   > len(lst):\n",
    "            temp.extend(lst)\n",
    "\n",
    "        while len(temp) < dim_size:\n",
    "            temp.append( 0 )\n",
    "        if not string:\n",
    "            x_data_temp.append(np.array(temp))\n",
    "        else:\n",
    "            x_data_temp.append(' '.join(list(map(str,temp))))\n",
    "        # print(temp)\n",
    "   \n",
    "    \n",
    "    if normalize:\n",
    "        x_data_temp = np.array( x_data_temp) / (np.amax( x_data_temp) + 0.000000000001)\n",
    "    else :\n",
    "        x_data_temp = np.array(x_data_temp)\n",
    "    \n",
    "   \n",
    "    return  x_data_temp ,y_data_categorical , y_class_data\n",
    "\n",
    "x_data= []\n",
    "y_data= []\n",
    "x_test = []\n",
    "y_test = []\n",
    "y_test_service= []\n",
    "x_train = {}\n",
    "y_train = {}\n",
    "test_names = []\n",
    "\n",
    "def load_data():\n",
    "    global x_train, y_train, y_train_service\n",
    "\n",
    "    with open('../files/train/test/test_homes/final_upload/Merged_final_with_home/merged_hub_segments_final.json'  ) as f:\n",
    "        y_data = json.load(f)\n",
    "\n",
    "    with open('../files/train/test/test_homes/final_upload/Merged_final_with_home/merged_pcap_segments_final.json'  ) as f:\n",
    "        x_data = json.load(f)\n",
    "        \n",
    "        \n",
    "    x_train,y_train, y_train_service= clean_data( x_data, y_data, IgnoreEmpty , Mapping=Mapper )\n",
    "\n",
    "\n",
    "    print(\"loading from test files\")\n",
    "\n",
    "    test_files = sorted(os.listdir('../files/train/test/test_homes/final_upload/usecases/pcap_segments_final_final/'))\n",
    "    print( \"found files : \" , len(test_files) )\n",
    "\n",
    "    for pick  in test_files:        \n",
    "        if 'home_os_final'  in pick:\n",
    "            fname  = os.path.basename(pick)\n",
    "            test_names.append( fname )\n",
    "\n",
    "            with open( os.path.join( '../files/train/test/test_homes/final_upload/usecases/hub_segments_final_final/', fname) ) as f:\n",
    "                y_data_test = json.load(f)\n",
    "\n",
    "            with open( os.path.join('../files/train/test/test_homes/final_upload/usecases/pcap_segments_final_final/', fname) ) as f:\n",
    "                x_data_test = json.load(f)\n",
    "\n",
    "            t_x,t_y, t_z= clean_data( x_data_test, y_data_test, False , Mapping=Mapper )\n",
    "            x_test.append(t_x)\n",
    "            y_test.append(t_y)\n",
    "            y_test_service.append(t_z)\n",
    "\n",
    "def predict_labels(classes,x_test_new,y_test_new,confidence):\n",
    "    is_string=True\n",
    " \n",
    "    x_test_processed,y_test_processed_encoded, y_test_processed =\\\n",
    "            pre_process_raw( x_test_new, y_test_new , dim_size, \n",
    "    test=True, normalize=False, classes=classes, string=is_string)\n",
    "    # rf_tests  = [ pre_process_raw( x_test[i], y_test[i] , dim_size, zero_pad=True, normalize=False, \\\n",
    "    #   classes=classes, string=is_string) for i in range(len(x_test)) ] \n",
    "\n",
    "    # def classify_RandomForest():\n",
    "\n",
    "    #     clf = RandomForestClassifier(n_estimators=960, max_depth=9050,random_state=0 )\n",
    "    #     print('filtered data')\n",
    "    #     t_hist = clf.fit(x_train_processed, y_train_processed_encoded)\n",
    "\n",
    "    #     for i in range(len(rf_tests)) :\n",
    "    #         print( \"==================HOME Case : %s =============\" % test_names[ i] )\n",
    "    #         rf_pred= clf.predict( rf_tests[i][0])\n",
    "            \n",
    "    #         print(sum([x[0] for x in rf_tests[i][1]]))\n",
    "    #         print(sum(x[1] for x in rf_tests[i][1]))\n",
    "    #         print(classes)\n",
    "    #         print_info( rf_tests[i][1], rf_pred, classes)\n",
    "        \n",
    "    def draw_xgb_tree():\n",
    "        xgb = XGBClassifier()\n",
    "        y = [x.split(' ')[0] for x in y_train_processed]\n",
    "        xgb.fit(x_train_processed, y)\n",
    "        # plot single tree\n",
    "        plot_tree(xgb)\n",
    "        plt.show()\n",
    "\n",
    "    def classify_xgb(x_test_processed):\n",
    "        xgb_classifier = OneVsRestClassifier(XGBClassifier())\n",
    "        if is_string:\n",
    "            vectorizer = CountVectorizer(analyzer='word', ngram_range=(1, 5))\n",
    "            x_train_str = vectorizer.fit_transform(x_train_processed)\n",
    "            \n",
    "            x_test_str = vectorizer.transform(x_test_processed)\n",
    "            \n",
    "            xgb_classifier.fit(x_train_str, y_train_processed_encoded)\n",
    "\n",
    "        else:\n",
    "            xgb_classifier.fit(x_train_processed, y_train_processed_encoded)\n",
    "\n",
    "        known_x_data=[]\n",
    "        known_y_data=[]\n",
    "        print( \"==================HOME Case : Omid =============\"  )\n",
    "        rf_pred= xgb_classifier.predict_proba(x_test_str)\n",
    "        print_info(y_test_processed_encoded, rf_pred, classes, confidence)\n",
    "        for ind,y_true in enumerate(y_test_processed):   \n",
    "               \n",
    "            y_pred_class = [classes[i] for i,x in enumerate(rf_pred[ind]) if x>confidence]\n",
    "            # if 'known' not in classes: \n",
    "            #     # print(y_true, y_pred_class)\n",
    "            #     if not y_true and y_pred_class and 'unknown' not in y_pred_class:\n",
    "            #         print(\"True: \", y_true,\"\\n Pred: \",y_pred_class )\n",
    "            #         print(\"Last 5 true: \",y_test_processed[ind-10:ind])\n",
    "            #         print(x_test_processed[ind])\n",
    "            y_pred_class = y_pred_class if y_pred_class else ['no_prediction']\n",
    "            if 'known'  in y_pred_class:\n",
    "                # print(x_test_processed[ind],\"\\nTrue: \",y_true, \"\\nPrediction: \", ' '.join(y_pred_class))\n",
    "                known_x_data.append(x_test_processed[ind].split(' '))\n",
    "                known_y_data.append(y_test_processed[ind])\n",
    "                    \n",
    "        return known_x_data,known_y_data\n",
    "    # classify_RandomForest()\n",
    "    return classify_xgb(x_test_processed)\n",
    "\n",
    "# all_classes = sorted(list(np.unique(  np.concatenate( y_train  ))))\n",
    "\n",
    "load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_classes = sorted(list(np.unique(  np.concatenate( y_train  ))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================HOME Case : Omid =============\n",
      "                         Class  Accuracy     Recall  Precision   F Score    Count            TP/TN/FP/FN\n",
      "------------------------------------------------------------------------\n",
      "                         known     0.887      0.846     0.827     0.837      6685  5654/11652/ 1179/ 1031\n",
      "                       unknown     0.917      0.989     0.895     0.940     12831 12688/ 5203/ 1482/  143\n",
      "------------------------------------------------------------------------\n",
      "                      AVERAGES     0.902      0.917     0.861     0.888     19516     0/    0/    0/    0\n",
      "Exact Match ACC : 0.86365 \n",
      "Total Records : 19516 \n",
      "Total ZXeros in True : 0 (0.000)%\n",
      "Total ZXeros in Test : 0 (0.000)%\n",
      "=============================================================================\n",
      "6833\n",
      "==================HOME Case : Omid =============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/omid/.conda/envs/iot/lib/python3.6/site-packages/ipykernel_launcher.py:53: RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/omid/.conda/envs/iot/lib/python3.6/site-packages/ipykernel_launcher.py:52: RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/omid/.conda/envs/iot/lib/python3.6/site-packages/ipykernel_launcher.py:56: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         Class  Accuracy     Recall  Precision   F Score    Count            TP/TN/FP/FN\n",
      "------------------------------------------------------------------------\n",
      "                  acceleration     0.994      0.051     0.667     0.095        39     2/ 6793/    1/   37\n",
      "                      activity     0.999      0.857     0.857     0.857        14    12/ 6817/    2/    2\n",
      "                       battery     1.000      0.000       nan     0.000         2     0/ 6831/    0/    2\n",
      "                        button     1.000      0.923     1.000     0.960        13    12/ 6820/    0/    1\n",
      "              colorTemperature     1.000      0.833     1.000     0.909         6     5/ 6827/    0/    1\n",
      "                       contact     0.992      0.585     0.962     0.727       130    76/ 6700/    3/   54\n",
      "                         level     0.990      0.720     0.234     0.353        25    18/ 6749/   59/    7\n",
      "                          lock     0.999      0.886     0.886     0.886        35    31/ 6794/    4/    4\n",
      "                        motion     0.984      0.500     0.477     0.488       102    51/ 6675/   56/   51\n",
      "                          ping     0.990      0.992     0.994     0.993      4842  4804/ 1961/   30/   38\n",
      "                        status     0.990      0.418     0.885     0.568       110    46/ 6717/    6/   64\n",
      "                        switch     0.999      0.714     0.833     0.769        21    15/ 6809/    3/    6\n",
      "                   temperature     0.928      0.004     0.182     0.008       484     2/ 6340/    9/  482\n",
      "                     threeAxis     0.994      0.128     1.000     0.226        47     6/ 6786/    0/   41\n",
      "                       unknown     0.827      0.000       nan     0.000      1179     0/ 5654/    0/ 1179\n",
      "                         water     1.000        nan       nan       nan         0     0/ 6833/    0/    0\n",
      "------------------------------------------------------------------------\n",
      "                      AVERAGES     0.980      0.476     0.623     0.490      6833     0/    0/    0/    0\n",
      "Exact Match ACC : 0.72545 \n",
      "Total Records : 6833 \n",
      "Total ZXeros in True : 0 (0.000)%\n",
      "Total ZXeros in Test : 1648 (0.241)%\n",
      "=============================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([], [])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim_size= 20\n",
    "is_string =True\n",
    "services_to_keep = ['unknown','known']\n",
    "classes = sorted(services_to_keep)\n",
    "x_train_processed,y_train_processed_encoded, y_train_processed =  pre_process_raw( x_train, y_train , dim_size, test=False, normalize=False, classes=classes, string=is_string)\n",
    "confidence=0.4\n",
    "x_test_new,y_test_new = predict_labels(classes,x_test[0],y_test[0],confidence)\n",
    "\n",
    "print(len(x_test_new))\n",
    "# print(y_test_new)\n",
    "confidence=0.75\n",
    "services_to_keep =  all_classes # ['contact','lock','motion', 'switch','colorTemperature','button','ping']\n",
    "classes = sorted(services_to_keep)\n",
    "x_train_processed,y_train_processed_encoded, y_train_processed =pre_process_raw( x_train, y_train , dim_size, test=False, normalize=False, classes=classes, string=is_string)\n",
    "predict_labels(classes,x_test_new,y_test_new,confidence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "remove() takes exactly one argument (2 given)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-9cae99031c9d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mall_classes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'threeAxis'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'battery'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: remove() takes exactly one argument (2 given)"
     ]
    }
   ],
   "source": [
    "all_classes.remove('threeAxis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "The first input argument needs to be a sequence",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-078d3b0b5cf6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m  \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0my_train\u001b[0m  \u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: The first input argument needs to be a sequence"
     ]
    }
   ],
   "source": [
    " sorted(list(np.unique(  np.concatenate( y_train  ))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "The first input argument needs to be a sequence",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-078d3b0b5cf6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m  \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0my_train\u001b[0m  \u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: The first input argument needs to be a sequence"
     ]
    }
   ],
   "source": [
    "sorted(list(np.unique(  np.concatenate( y_train  ))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3.6(iot)",
   "language": "python",
   "name": "iot"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
